{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHwyhFnnBgjg",
        "outputId": "6db86049-3000-4694-ff28-39428fde6757"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section"
      ],
      "metadata": {
        "id": "nSnw4ucY_nyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i-pKtoIEJpU",
        "outputId": "5c4a2e98-cafd-4a13-8bea-0f57b4e235a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0 # need to run and restart runtime for TabularDataset, Field and LabelField imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Zojl-TKxK5c"
      },
      "outputs": [],
      "source": [
        "### LIBRARY IMPORTS ###\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchtext\n",
        "#import torchtext.data as data\n",
        "from torchtext.data import get_tokenizer, TabularDataset, Field, LabelField\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import spacy   # may be unused not sure currently\n",
        "import nltk\n",
        "import random\n",
        "\n",
        "#import torchtext.data as data\n",
        "#from spacy.en import English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1aim4B4J8c-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcd80ed-df0a-47d0-9bfb-5e3a6e2835e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.twitter.27B.zip: 1.52GB [04:44, 5.34MB/s]                            \n",
            "100%|█████████▉| 1193513/1193514 [01:20<00:00, 14763.41it/s]\n"
          ]
        }
      ],
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"twitter.27B\", # trained on Wikipedia 2014 corpus\n",
        "                              dim=200)   # embedding size = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#glove2 =torchtext.vocab.GloVe(name=\"840B\", # trained on Wikipedia 2014 corpus\n",
        "#                              dim=200)   # embedding size = 50"
      ],
      "metadata": {
        "id": "qzaTr6R9lPq8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WeiQXAOm-jHL"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNaiN771x4gy",
        "outputId": "0e061dab-80d1-4336-a32d-825760234dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZssxsDUFthmI",
        "outputId": "be6f4ebb-8f15-4416-9c11-f20ea86d211c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacey\n",
            "  Downloading spacey-0.1.1-py3-none-any.whl (2.1 kB)\n",
            "Installing collected packages: spacey\n",
            "Successfully installed spacey-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install spacey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB7_Eq5Lwrif",
        "outputId": "7abcced7-7c9b-45db-9497-080ea2893796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DIzBodZXowKt"
      },
      "outputs": [],
      "source": [
        "data_fr   = pd.read_csv(\"//content//fr_train_df.csv\")\n",
        "data_es   = pd.read_csv(\"//content//es_train_df.csv\")\n",
        "data_it   = pd.read_csv(\"//content//it_train_df.csv\")\n",
        "data_nl   = pd.read_csv(\"//content//nl_train_df.csv\")\n",
        "data_de   = pd.read_csv(\"//content//de_train_df.csv\")\n",
        "data_ch   = pd.read_csv(\"//content//ch_train_df.csv\")\n",
        "data_ar   = pd.read_csv(\"//content//ar_train_df.csv\")\n",
        "data_orig = pd.read_csv(   \"//content//train_df.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUVBcxzWqfdj",
        "outputId": "4dbb124f-cf4a-4b3a-dd3d-52b0aa33c51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our actions are the reason for this #Earthquak...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents who have been asked to \"take ref...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  I just got this photo from Ruby #Alaska as smo...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ],
      "source": [
        "data = pd.concat([data_it, data_de, data_ch, data_ar, data_orig])\n",
        "print(data.head())\n",
        "print(data_orig.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7yS9M3w6fH_",
        "outputId": "53eae32c-5e7b-4f1e-d3f0-32f0d3fdabe9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3271"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data2 = pd.read_csv(\"//content//train.csv\")\n",
        "#data = pd.read_csv(\"//content//inf_past_decade.csv\")\n",
        "#data = pd.read_csv(\"//content//Data50k.csv\")\n",
        "len(data2[data2[\"target\"]==1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i, dis in enumerate(np.array(data2[data2[\"target\"]==1][:]),0):\n",
        "  if i % 3 == 0:\n",
        "    #print(dis.tolist())\n",
        "    dis_dict = {}\n",
        "    for j, elem in enumerate(dis, 0):\n",
        "      dis_dict[data2.columns[j]] = elem\n",
        "    #pd.DataFrame(dis)\n",
        "    #print(dis_dict)\n",
        "    data2 = data2.append(dis_dict, ignore_index=True)\n",
        "    #break\n",
        "  \n",
        "#len(data2[data2[\"target\"]==1])\n",
        "#data2[data2[\"target\"]==1]\n",
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "gBXDZWlgJ-3Y",
        "outputId": "0cfb2212-b7d5-46e3-e80b-2e9c4a83aa81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "8699  10855     NaN      NaN   \n",
              "8700  10862     NaN      NaN   \n",
              "8701  10866     NaN      NaN   \n",
              "8702  10870     NaN      NaN   \n",
              "8703  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "8699  Evacuation order lifted for town of Roosevelt:...       1  \n",
              "8700  Officials say a quarantine is in place at an A...       1  \n",
              "8701  Suicide bomber kills 15 in Saudi security site...       1  \n",
              "8702  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "8703  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[8704 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3b36a46-ce7f-422a-92f7-c3997d7e1403\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>10855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Evacuation order lifted for town of Roosevelt:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8700</th>\n",
              "      <td>10862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Officials say a quarantine is in place at an A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8701</th>\n",
              "      <td>10866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8702</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8703</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8704 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3b36a46-ce7f-422a-92f7-c3997d7e1403')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3b36a46-ce7f-422a-92f7-c3997d7e1403 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3b36a46-ce7f-422a-92f7-c3997d7e1403');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data2[data2[\"target\"]==1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0TIfbZ7JPlY",
        "outputId": "fb0796e0-7e3c-4c17-950a-339d2e4c4b9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4362"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "K5qm-lZf6bIz",
        "outputId": "c9be50e4-87cf-4fad-e6d4-f487dc148bf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id    keyword                  location  \\\n",
              "0      8433  sandstorm                       USA   \n",
              "1      9466  terrorism                       NaN   \n",
              "2      5943     hazard                   Arizona   \n",
              "3      4901    explode                       NaN   \n",
              "4      9765    trapped  10 Steps Ahead.  Cloud 9   \n",
              "...     ...        ...                       ...   \n",
              "8699   7742  panicking                       NaN   \n",
              "8700   8742      siren                        nc   \n",
              "8701   8024   refugees                       NaN   \n",
              "8702   8841     sirens                       NaN   \n",
              "8703  10869        NaN                       NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Watch This Airport Get Swallowed Up By A Sands...       1  \n",
              "1     DHS Refuses to Call Chattanooga Û÷Islamic Ter...       1  \n",
              "2                                   Get that hazard pay       0  \n",
              "3                         All these people explode ????       0  \n",
              "4     Bomb head? Explosive decisions dat produced mo...       1  \n",
              "...                                                 ...     ...  \n",
              "8699  you can stop panicking ?????? @ogtomd  https:/...       0  \n",
              "8700  I just made a weird high pitched noise and the...       0  \n",
              "8701  reaad/ plsss 12000 Nigerian refugees repatriat...       1  \n",
              "8702  It's 'Run From Sirens' by 'Half Hour Hotel' @h...       0  \n",
              "8703  Two giant cranes holding a bridge collapse int...       1  \n",
              "\n",
              "[8704 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-232185e8-d8f2-43f6-9458-ab63093eae36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8433</td>\n",
              "      <td>sandstorm</td>\n",
              "      <td>USA</td>\n",
              "      <td>Watch This Airport Get Swallowed Up By A Sands...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9466</td>\n",
              "      <td>terrorism</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DHS Refuses to Call Chattanooga Û÷Islamic Ter...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5943</td>\n",
              "      <td>hazard</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>Get that hazard pay</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4901</td>\n",
              "      <td>explode</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All these people explode ????</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9765</td>\n",
              "      <td>trapped</td>\n",
              "      <td>10 Steps Ahead.  Cloud 9</td>\n",
              "      <td>Bomb head? Explosive decisions dat produced mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>7742</td>\n",
              "      <td>panicking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>you can stop panicking ?????? @ogtomd  https:/...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8700</th>\n",
              "      <td>8742</td>\n",
              "      <td>siren</td>\n",
              "      <td>nc</td>\n",
              "      <td>I just made a weird high pitched noise and the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8701</th>\n",
              "      <td>8024</td>\n",
              "      <td>refugees</td>\n",
              "      <td>NaN</td>\n",
              "      <td>reaad/ plsss 12000 Nigerian refugees repatriat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8702</th>\n",
              "      <td>8841</td>\n",
              "      <td>sirens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It's 'Run From Sirens' by 'Half Hour Hotel' @h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8703</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8704 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-232185e8-d8f2-43f6-9458-ab63093eae36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-232185e8-d8f2-43f6-9458-ab63093eae36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-232185e8-d8f2-43f6-9458-ab63093eae36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data2 = data2.sample(frac=1).reset_index(drop=True)\n",
        "data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RcpOk5oQta0Z"
      },
      "outputs": [],
      "source": [
        "data_reduced = data2[[\"text\", \"target\"]]\n",
        "data_reduced_val = pd.read_csv(\"valid_df.csv\")[[\"text\", \"target\"]]\n",
        "data_reduced_test = pd.read_csv(\"test_df.csv\")[[\"text\", \"target\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jKtGY7hsPmH",
        "outputId": "7719f454-7be0-43da-d448-abdc12e39fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8704"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(data_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6eZQD4Sq661I",
        "outputId": "32cf792e-18ea-4a7f-cc6c-43c27099bbe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target\n",
              "8699  you can stop panicking ?????? @ogtomd  https:/...       0\n",
              "8700  I just made a weird high pitched noise and the...       0\n",
              "8701  reaad/ plsss 12000 Nigerian refugees repatriat...       1\n",
              "8702  It's 'Run From Sirens' by 'Half Hour Hotel' @h...       0\n",
              "8703  Two giant cranes holding a bridge collapse int...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74a63c25-3685-4c48-a2b6-135c8216e084\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>you can stop panicking ?????? @ogtomd  https:/...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8700</th>\n",
              "      <td>I just made a weird high pitched noise and the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8701</th>\n",
              "      <td>reaad/ plsss 12000 Nigerian refugees repatriat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8702</th>\n",
              "      <td>It's 'Run From Sirens' by 'Half Hour Hotel' @h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8703</th>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74a63c25-3685-4c48-a2b6-135c8216e084')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74a63c25-3685-4c48-a2b6-135c8216e084 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74a63c25-3685-4c48-a2b6-135c8216e084');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data_reduced.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVNupGl0z3sc",
        "outputId": "cf9e0fed-2ce4-4a49-9c53-6cab7ccf1865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0.0,\n",
              " 'tweet': ['Next',\n",
              "  'Man',\n",
              "  'Up',\n",
              "  '---',\n",
              "  'AH',\n",
              "  'SCREW',\n",
              "  'THIS',\n",
              "  '!',\n",
              "  'I',\n",
              "  \"'m\",\n",
              "  'so',\n",
              "  'tired',\n",
              "  'of',\n",
              "  'injuries',\n",
              "  '.',\n",
              "  ' \\n\\n',\n",
              "  'What',\n",
              "  'happened',\n",
              "  'to',\n",
              "  'Camp',\n",
              "  'Cupcake',\n",
              "  '?',\n",
              "  'More',\n",
              "  'like',\n",
              "  'Camp',\n",
              "  'Cramp',\n",
              "  'and',\n",
              "  'Break',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# convert to tabular dataset\n",
        "data_reduced.to_csv(\"tokenized_data.csv\", index=None)\n",
        "data_reduced_val.to_csv(\"tokenized_val_data.csv\", index=None)\n",
        "data_reduced_test.to_csv(\"tokenized_test_data.csv\", index=None)\n",
        "tokenised_data = Field(tokenize=\"spacy\", use_vocab=True, tokenizer_language=\"en_core_web_sm\")\n",
        "# https://github.com/pytorch/text/issues/78\n",
        "labels = LabelField(dtype = torch.float, use_vocab=False, preprocessing=float)#, postprocessing=torchtext.data.Pipeline(lambda x: float(x))) # converting string ratios to doubles and not using a vocab for target labels\n",
        "dataset = TabularDataset(path=\"tokenized_data.csv\", format=\"CSV\", fields=[(\"tweet\", tokenised_data),(\"label\", labels)],skip_header=True)\n",
        "dataset_valid = TabularDataset(path=\"tokenized_val_data.csv\", format=\"CSV\", fields=[(\"tweet\", tokenised_data),(\"label\", labels)],skip_header=True)\n",
        "dataset_test = TabularDataset(path=\"tokenized_test_data.csv\", format=\"CSV\", fields=[(\"tweet\", tokenised_data),(\"label\", labels)],skip_header=True)\n",
        "vars(dataset_valid[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tL82Qk8ix7lQ"
      },
      "outputs": [],
      "source": [
        "train_set, val_set, test_set = dataset.split(split_ratio=[0.74, 0.13, 0.13],random_state=random.seed(0))  \n",
        "#train_set = dataset\n",
        "#val_set = dataset_valid\n",
        "#test_set = dataset_test\n",
        "sanity_set, _ = val_set.split(split_ratio=[0.004,0.996],random_state=random.seed(0))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3HhY58sp38QL",
        "outputId": "867faa5c-885a-4866-ea0e-3d6af80a39ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tokenised_data.build_vocab(train_set, max_size=30000) # dictionary stores a maximum of 50000 words as to get the jist of the tweets while saving space.\n",
        "labels.build_vocab(train_set) \n",
        "print(len(tokenised_data.vocab))\n",
        "tokenised_data.vocab.freqs.most_common(20)\n",
        "tokenised_data.vocab.itos[21]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M2CWIPRtCdxk"
      },
      "outputs": [],
      "source": [
        "# def dim(a):\n",
        "#     if not type(a) == list and not type(a) == torch.float32:\n",
        "#         return []\n",
        "#     return [len(a)] + dim(a[0])\n",
        "\n",
        "# nn_embedding_vocab = [glove[word] for word in tokenised_data.vocab.itos]\n",
        "# print(dim(nn_embedding_vocab))\n",
        "# words = [word for word in tokenised_data.vocab.itos]\n",
        "#nn_embedding_vocab = torch.Tensor(np.array(nn_embedding_vocab, dtype=np.float64))\n",
        "#indices = nn_embedding_vocab.where(nn_embedding_vocab[0])\n",
        "#indices = [i for i, x in enumerate(nn_embedding_vocab) if x == nn_embedding_vocab[0]]\n",
        "#print(nn_embedding_vocab.index(nn_embedding_vocab[0]))\n",
        "    #[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0.]))\n",
        "#print(words[0])\n",
        "#print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPRQ8VVs3HWB",
        "outputId": "0084f71d-dbf1-4380-ab2e-d5a60fdb047c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6441 1131 1132 5\n"
          ]
        }
      ],
      "source": [
        "print(len(train_set), len(val_set), len(test_set), len(sanity_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esAe1-emp-sL",
        "outputId": "4be5dc00-94bb-4fcf-880c-48ba5e010555"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.dataset.Dataset at 0x7fc2d09f3650>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_loader  = torchtext.data.BucketIterator( train_set, batch_size=5, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "val_loader    = torchtext.data.BucketIterator(   val_set, batch_size=5, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "test_loader   = torchtext.data.BucketIterator(  test_set, batch_size=5, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "sanity_loader = torchtext.data.BucketIterator(sanity_set, batch_size=5, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False) # lambda x: len(x.tokenized_tweets)\n",
        "sanity_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB6sBOOBBIqm",
        "outputId": "f2e0c7ac-c170-4ff9-be4c-dc01af7c5a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 0., 0.], device='cuda:0')\n",
            "tensor([[    2,   294,     2,     0,   116],\n",
            "        [ 1235,   352,   758,    18,   643],\n",
            "        [   15,  6619,   383,   263,     6],\n",
            "        [   12,    20,  1263,    54,     0],\n",
            "        [   48,  1286, 20765,   302,     0],\n",
            "        [   33,    10,  1189,    29,     0],\n",
            "        [  929,  1501,   666,  2353,    18],\n",
            "        [   39,   134,   806,    18,  3762],\n",
            "        [    4,  1339,   674,     0,  2116],\n",
            "        [    2,   208,   681,     4,   349],\n",
            "        [ 3109,   932, 17230,     0,     0],\n",
            "        [ 4339,    13,     1,     4,     0],\n",
            "        [   22, 20058,     1,   198,     1],\n",
            "        [    2,     8,     1,    33,     1],\n",
            "        [    0,    16,     1,  1624,     1],\n",
            "        [    2,    11,     1,     0,     1],\n",
            "        [  592, 16951,     1,    19,     1],\n",
            "        [    2, 18402,     1,     0,     1],\n",
            "        [    0,    84,     1,    15,     1],\n",
            "        [    2,     2,     1,     0,     1],\n",
            "        [    0, 11469,     1,     1,     1],\n",
            "        [    2,    32,     1,     1,     1],\n",
            "        [    0,     1,     1,     1,     1],\n",
            "        [    2,     1,     1,     1,     1],\n",
            "        [    0,     1,     1,     1,     1],\n",
            "        [    0,     1,     1,     1,     1]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#for data in sanity_loader:\n",
        "#  break\n",
        "for i, data in enumerate(sanity_loader, 0):\n",
        "  text, label = data\n",
        "  print(label) \n",
        "  print(text)      # each column represents 1 tweet, each word coded to one integer. 1s represent sentence padding, each batch has different sentence lengths\n",
        "  \n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJniJ07JgPKz"
      },
      "source": [
        "# The different models we have done testing with"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kSZIeNGq_z0v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "P_EACVjJvzAe"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class RatioNet(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(RatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"RatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(embedding_size, 200, 3)\n",
        "    o = (64 - 3)//1 + 1         # conv1 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(200, 250, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv2 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv3 = nn.Conv1d(250, self.lstmis, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv3 output size\n",
        "    #print(o)\n",
        "    self.maxpool = nn.MaxPool1d(2, 2)\n",
        "    lstm_input_size = (o - 2)//2 + 1        # maxpool output size\n",
        "    #print(lstm_input_size, \"word reduction\")\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = self.lstmis, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=bi_direc) # batch_first==True >>> (batch, seq, features) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * (self.bd + 1), 2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 2, 0)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    \n",
        "    #print(x.size(), \"permute\")\n",
        "    x = (F.relu(self.conv1(x)))\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.maxpool(F.relu(self.conv3(x)))\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.permute(0, 2, 1) # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True) \n",
        "\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    \n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    out = self.output_layer(x[:,-1,:])\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IGRatioNet(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(IGRatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"IGRatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(glove.vectors)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(embedding_size, 200, 3, padding=1)\n",
        "    o = (64 - 3)//1 + 1         # conv1 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(200, 250, 3, padding=1)\n",
        "    o = (o - 3)//1 + 1                      # conv2 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv3 = nn.Conv1d(250, self.lstmis, 3, padding=1)\n",
        "    o = (o - 3)//1 + 1                      # conv3 output size\n",
        "    #print(o)\n",
        "    self.maxpool = nn.MaxPool1d(2, 2)\n",
        "    lstm_input_size = (o - 2)//2 + 1        # maxpool output size\n",
        "    #print(lstm_input_size, \"word reduction\")\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = self.lstmis, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=bi_direc) # batch_first==True >>> (batch, seq, features) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * 2 * (self.bd + 1), 2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(0, 2, 1)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    \n",
        "    #print(x.size(), \"permute\")\n",
        "    \n",
        "    x = (F.relu(self.conv1(x)))\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = (F.relu(self.conv3(x)))#self.maxpool(F.relu(self.conv3(x)))\n",
        "\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.permute(0, 2, 1) # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True) \n",
        "\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    \n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    #out = self.output_layer(x[:,-1,:])\n",
        "    out = torch.cat([torch.max(x, dim=1)[0], \n",
        "                      torch.mean(x, dim=1)], dim=1) \n",
        "    out = self.output_layer(out)   \n",
        "    return out"
      ],
      "metadata": {
        "id": "sN-OXN6IRZ19"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FypE4pBCBt8T"
      },
      "outputs": [],
      "source": [
        "class ANNRatioNet(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(RatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"ANNRatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "    \n",
        "\n",
        "    self.fc1 = nn.Linear()\n",
        "    self.fc2 = nn.Linear()\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = self.lstmis, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=bi_direc) # batch_first==True >>> (batch, seq, features) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * (self.bd + 1), 2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 2, 0)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    x= torch.flatten(x, start_dim=1)\n",
        "    #print(x.size())\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    \n",
        "    x = x.reshape([x.shape[0], self.lstmis, -1])\n",
        "\n",
        "    x = x.permute(0, 2, 1) # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True) \n",
        "\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    \n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    out = self.output_layer(x[:,-1,:])\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HPFXtym16AhR"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class RatioNet3(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(RatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"RatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(embedding_size, 150, 3)\n",
        "    o = (64 - 3)//1 + 1         # conv1 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(150, 125, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv2 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv3 = nn.Conv1d(110, self.lstmis, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv3 output size\n",
        "    #print(o)\n",
        "    self.maxpool = nn.MaxPool1d(2, 2)\n",
        "    lstm_input_size = (o - 2)//2 + 1        # maxpool output size\n",
        "    #print(lstm_input_size, \"word reduction\")\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = self.lstmis, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=bi_direc) # batch_first==True >>> (batch, seq, features) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * (self.bd + 1), 2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 2, 0)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    \n",
        "    #print(x.size(), \"permute\")\n",
        "    x = (F.relu(self.conv1(x)))\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.maxpool(F.relu(self.conv3(x)))\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.permute(0, 2, 1) # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True) \n",
        "\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    \n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    out = self.output_layer(x[:,-1,:])\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TPDQJVIN_Sxq"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class RatioNet2(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(RatioNet2, self).__init__()\n",
        "\n",
        "    self.name = \"RatioNet2\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(embedding_size,150, 3)\n",
        "    o = (64 - 3)//1 + 1         # conv1 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(100, self.lstmis, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv2 output size\n",
        "    self.maxpool = nn.MaxPool1d(2, 2)\n",
        "    lstm_input_size = (o - 2)//2 + 1        # maxpool output size\n",
        "    #print(lstm_input_size, \"word reduction\")\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = self.lstmis, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=bi_direc) # batch_first==True >>> (batch, seq, features) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * (self.bd + 1), 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 2, 0)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    \n",
        "    #print(x.size(), \"permute\")\n",
        "    x = (F.relu(self.conv1(x)))\n",
        "    x = self.maxpool(F.relu(self.conv2(x)))\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.permute(0, 2, 1) # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True) \n",
        "\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    #print(self.stacked_LSTM.all_weights)\n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    out = F.relu(self.output_layer(x[:,-1,:]))    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8qoR1YHVuNaz"
      },
      "outputs": [],
      "source": [
        "class no_conv_RatioNet(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(no_conv_RatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"no_conv_RatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.stacked_LSTM = nn.LSTM(input_size = embedding_size, hidden_size = self.hs, num_layers = self.nl, batch_first=True, dropout=dropout, bidirectional=True) # batch_first==True >>> (batch, seq len, emb dim) , batch_first==False (seq, batch, feature)\n",
        "    \n",
        "    self.output_layer = nn.Linear(self.hs * (self.bd + 1), 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 0, 2)   # convert to (batch_size, number of words, embedding dimension) order to feed into stacked lstm layer (batch_first set to True)    \n",
        "    #print(x.shape)\n",
        "    h_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    c_0 = torch.ones(self.nl * (int(self.bd)+1), x.shape[0], self.hs).to(self.device)\n",
        "    x, (h_n, c_n) = self.stacked_LSTM(x, (h_0, c_0))  # output, hidden state, cell state\n",
        "    # if you visualize the lstm you can see that x[:,-1,:] (output from the final word) is the same as the output of the second hidden layer output (only for non-bidirectional LSTMs)\n",
        "    # print(h_n[-1]==x[:,-1,:])\n",
        "    #print(x.size())\n",
        "    #print(h_n.size())\n",
        "    \n",
        "    # passing lstm final output into output layer for ratio prediction\n",
        "    #out = F.relu(self.output_layer(h_n[-1])) # output should be above 0 but unbounded above pass in final hidden layer\n",
        "    out = F.relu(self.output_layer(x[:,-1,:]))\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JqU0HIxXvYub"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import dropout\n",
        "class no_lstm_RatioNet(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers = 2, dropout=0.5, bi_direc=True):\n",
        "    super(no_lstm_RatioNet, self).__init__()\n",
        "\n",
        "    self.name = \"no_lstm_RatioNet\"\n",
        "    self.device =device\n",
        "    self.bs = batch_size\n",
        "    self.lstmis = lstm_input_size\n",
        "    self.hs = hidden_size\n",
        "    self.nl = num_layers\n",
        "    self.bd = bi_direc\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)  # sequence size (padded tweet length), batch_size, embedding size (ie vector representation of integer words)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(embedding_size, 200, 3)\n",
        "    o = (64 - 3)//1 + 1         # conv1 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(200, 250, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv2 output size\n",
        "    #o = (o - 2)//2 + 1                      # maxpool output size\n",
        "    #print(o)\n",
        "\n",
        "    self.conv3 = nn.Conv1d(250, 300, 3)\n",
        "    o = (o - 3)//1 + 1                      # conv3 output size\n",
        "    #print(o)\n",
        "    self.maxpool = nn.MaxPool1d(2, 2)\n",
        "    fc_input_size = (o - 2)//2 + 1        # maxpool output size\n",
        "    #print(lstm_input_size, \"word reduction\")\n",
        "    \n",
        "    self.output_layer = nn.Linear(300, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # convert integer coded tweets to embeddings\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute(1, 2, 0)   # convert to (batch_size, embedding dimension, number of words) order to feed into conv layers (embedding dimension == # channels)\n",
        "    \n",
        "    #print(x.size(), \"permute\")\n",
        "    x = (F.relu(self.conv1(x)))\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.maxpool(F.relu(self.conv3(x)))\n",
        "    x, _ = x.max(dim=-1)\n",
        "    out = F.relu(self.output_layer(x))    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TSeVwbooMlIM"
      },
      "outputs": [],
      "source": [
        "#onehot_sms = torch.eye(len(text_field.vocab.itos))\n",
        "#onehot_labels = torch.eye(2)\n",
        "\n",
        "onehot_tweets = torch.eye(len(tokenised_data.vocab)).to(device)\n",
        "onehot_labels = torch.eye(2).to(device)\n",
        "\n",
        "class Simple_RNN(nn.Module):\n",
        "  def __init__(self, input_size, batch_size, device, hidden_size=50, embedding_size=20, lstm_input_size=100, num_layers=1, dropout=0.5, bi_direc=True):\n",
        "    super(Simple_RNN, self).__init__()\n",
        "    self.name = \"Simple_RNN\"\n",
        "    self.device = device\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, num_layers=self.num_layers, bidirectional=bi_direc)\n",
        "    self.bs = batch_size\n",
        "    self.bd = bi_direc\n",
        "    self.fc = nn.Linear(hidden_size * 2 * (self.bd + 1), 2)\n",
        "  def forward(self, x):\n",
        "    # Set an initial hidden state\n",
        "    x = onehot_tweets[x]\n",
        "    x = x.permute(1,0,2)\n",
        "    h0 = torch.ones(self.num_layers * (int(self.bd)+1), x.shape[0], self.hidden_size).to(self.device)\n",
        "    # Forward propagate the RNN\n",
        "    out, _ = self.rnn(x, h0)\n",
        "    # Pass the output of the last time step to the classifier\n",
        "    out = torch.cat([torch.max(out, dim=1)[0], \n",
        "                      torch.mean(out, dim=1)], dim=1)\n",
        "    \n",
        "    #print(out.shape)\n",
        "    out = self.fc(out)\n",
        "    #print(out.shape)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranining code"
      ],
      "metadata": {
        "id": "ak0dVZmV_7S1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Fl4zjj37BWW0"
      },
      "outputs": [],
      "source": [
        "# Testing the model\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "P9XIl1oBLbsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53722f6d-31a0-4628-fa94-de43d0ed4cbd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hhg9hPOXfusY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ZZhNqX6uFosy"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "def get_accuracy(net, loader, criterion, suppress_print=False):\n",
        "  sum = 0\n",
        "  total = 0\n",
        "  loss_sum = 0\n",
        "  net.eval()\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "  confmat = ConfusionMatrix(num_classes=2)\n",
        "  for i, data in enumerate(loader, 0):\n",
        "    tweet, label = data\n",
        "    tweet, label = tweet.type(torch.long).to(device), onehot_labels[label.type(torch.long)].to(device) #onehot_tweets[tweet.type(torch.long)].to(device\n",
        "    preds = net(tweet)\n",
        "    loss = criterion(preds, label)\n",
        "    loss_sum += loss.item()\n",
        "    #print(preds)\n",
        "    preds = preds.tolist()\n",
        "    labels = label.tolist()\n",
        "    if not suppress_print:\n",
        "      print(\"\\r {}/{}\\t\".format(i, \"??\") + \"|\" * (i//100), end=\"\")\n",
        "    for j, pred in enumerate(preds,0):\n",
        "      sum += ( pred.index( max( pred ) ) == labels[j].index( max( labels[j] ) ) )\n",
        "      total += 1\n",
        "      preds_list.append(pred)\n",
        "      labels_list.append(labels[j])\n",
        "  loss_val = loss_sum / i\n",
        "  if not suppress_print:\n",
        "    print(\"\\r                                                     \\r\", end=\"\")# {}\\r\".format(sum/total))\n",
        "  preds_tensor = torch.Tensor(preds_list)\n",
        "  labels_tensor = torch.LongTensor(labels_list)\n",
        "  print(confmat(preds_tensor, labels_tensor))\n",
        "  net.train()\n",
        "  return(sum/total), loss_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "def get_accuracy(net, loader, criterion, suppress_print=False):\n",
        "  sum = 0\n",
        "  total = 0\n",
        "  loss_sum = 0\n",
        "  net.eval()\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "  confmat = ConfusionMatrix(num_classes=2)\n",
        "  correct = []\n",
        "  incorrect = []\n",
        "  for i, data in enumerate(loader, 0):\n",
        "    tweet, label = data\n",
        "    tweet, label = tweet.type(torch.long).to(device), onehot_labels[label.type(torch.long)].to(device) #onehot_tweets[tweet.type(torch.long)].to(device\n",
        "    preds_T = net(tweet)\n",
        "    loss = criterion(preds_T, label)\n",
        "    loss_sum += loss.item()\n",
        "    #print(preds)\n",
        "    preds = preds_T.tolist()\n",
        "    labels = label.tolist()\n",
        "    if not suppress_print:\n",
        "      print(\"\\r {}/{}\\t\".format(i, \"??\") + \"|\" * (i//100), end=\"\")\n",
        "    for j, pred in enumerate(preds,0):\n",
        "      sum += ( pred.index( max( pred ) ) == labels[j].index( max( labels[j] ) ) )\n",
        "      if ( pred.index( max( pred ) ) == labels[j].index( max( labels[j] ) ) ):\n",
        "        correct.append([tweet[j],F.softmax(preds_T[j]),labels[j]])\n",
        "      else:\n",
        "        incorrect.append([tweet[j],F.softmax(preds_T[j]),labels[j]])\n",
        "      total += 1\n",
        "      preds_list.append(pred)\n",
        "      labels_list.append(labels[j])\n",
        "  loss_val = loss_sum / i\n",
        "  if not suppress_print:\n",
        "    print(\"\\r                                                     \\r\", end=\"\")# {}\\r\".format(sum/total))\n",
        "  preds_tensor = torch.Tensor(preds_list)\n",
        "  labels_tensor = torch.LongTensor(labels_list)\n",
        "  print(confmat(preds_tensor, labels_tensor))\n",
        "  net.train()\n",
        "  return(sum/total), loss_val, correct, incorrect"
      ],
      "metadata": {
        "id": "P1V7uzk1Z08g"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KrgeBdN5JbF",
        "outputId": "af6f699e-60d8-49d2-ef8d-6dd1c7751f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "tensor([[-0.0738,  0.2224],\n",
            "        [-0.1204,  0.2154],\n",
            "        [-0.1010,  0.2302],\n",
            "        [-0.0844,  0.2138],\n",
            "        [-0.0919,  0.1779]], device='cuda:0', grad_fn=<AddmmBackward0>) out\n"
          ]
        }
      ],
      "source": [
        "print(text[0].size())\n",
        "net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=5, device=device, embedding_size=200, hidden_size=200, lstm_input_size=300).to(device)\n",
        "out = net(text)\n",
        "#len(tokenised_data.vocab)\n",
        "print(out, \"out\") # testing forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_9zSODTO1-FH"
      },
      "outputs": [],
      "source": [
        "def train_net(net,\n",
        "              data_loaders,\n",
        "              epochs=5,\n",
        "              learning_rate=1e-5,\n",
        "              batch_size=10,\n",
        "              dropout=0.5,\n",
        "              momentum=0.9,\n",
        "              sanity_check=False,\n",
        "              device=device,\n",
        "              weight_decay = 1e-5,\n",
        "              learning_rate_decay = 0.4,\n",
        "              adam=True,\n",
        "              L1_factor = 0.001\n",
        "              ):\n",
        "  net.train()\n",
        "  torch.manual_seed(0)\n",
        "  net = net.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  if adam:\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "  # initialize error and loss statistic numpy arrays\n",
        "  train_acc  = []\n",
        "  train_loss = []\n",
        "  valid_acc  = []\n",
        "  valid_loss = []\n",
        "  epochs_lst = []\n",
        "  start_time = time.time()\n",
        "\n",
        "  if sanity_check:\n",
        "    train_loader = data_loaders\n",
        "    valid_loader = train_loader\n",
        "    test_loader  = train_loader\n",
        "  else:\n",
        "    train_loader, valid_loader, test_loader = data_loaders\n",
        "  \n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=learning_rate_decay)\n",
        "  \n",
        "  scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8,20,25], gamma=learning_rate_decay)\n",
        "  #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,10,15,20,40], gamma=learning_rate_decay)\n",
        "\n",
        "  lrs=[]\n",
        "  valid_max_acc = 0\n",
        "  best_state_dict = copy.deepcopy(net.state_dict())\n",
        "  for epoch in range(epochs):\n",
        "    net.train()\n",
        "    for i, data in enumerate(train_loader,0):\n",
        "      tweet,label = data\n",
        "      tweet = tweet.type(torch.LongTensor).to(device)\n",
        "      label = onehot_labels[label.type(torch.LongTensor)].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out = net(tweet)\n",
        "      #print(net.parameters().shape)\n",
        "      #L1_reg = sum(torch.linalg.norm(p, 1) for p in net.parameters())\n",
        "      loss = criterion(out, label)# + L1_factor * L1_reg\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    train_epoch_acc, train_epoch_loss, correct, incorrect = get_accuracy(net, train_loader, criterion)\n",
        "    valid_epoch_acc, valid_epoch_loss, correct, incorrect = get_accuracy(net, valid_loader, criterion)\n",
        "    \n",
        "    train_acc.append(train_epoch_acc)\n",
        "    valid_acc.append(valid_epoch_acc)\n",
        "    train_loss.append(train_epoch_loss)   \n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    \n",
        "    epochs_lst.append(epoch)\n",
        "      \n",
        "    print(f\"Epoch: {epoch}, Train Accuracy: {train_acc[epoch]:.5f}, Train Loss: {train_loss[epoch]:.5f}, Validation Accuracy: {valid_acc[epoch]:.5f}, Validation Loss: {valid_loss[epoch]:.5f}, prediction: {[round(i,3) for i in F.softmax(out[-1], dim=-1).tolist()]}, true label: {label[-1].tolist()}\")\n",
        "\n",
        "    model_path = \"//content//model_{0}_bs{1}_lr{2}_epoch{3}\".format(net.name,\n",
        "                                                                    batch_size,\n",
        "                                                                    learning_rate,\n",
        "                                                                    epoch)\n",
        "    # save the parameters of the net every n epochs.\n",
        "    n=5\n",
        "    if epoch % n == 0:\n",
        "      torch.save(net.state_dict(), model_path)\n",
        "    print(valid_epoch_acc, valid_max_acc)\n",
        "    if valid_epoch_acc > valid_max_acc:\n",
        "      best_state_dict = copy.deepcopy(net.state_dict())\n",
        "      valid_max_acc = valid_epoch_acc\n",
        "      print(\"best_state_dict updated\")\n",
        "  plot_training_curves(train_acc, train_loss, valid_acc, valid_loss, epochs_lst, lrs)\n",
        "  return train_acc, train_loss, valid_acc, valid_loss, epochs_lst, lrs, best_state_dict\n",
        "\n",
        "\n",
        "def plot_training_curves(train_acc, train_loss, valid_acc, valid_loss, epochs, lrs=[-1]):\n",
        "  plt.title(\"Training Curve\")\n",
        "  plt.plot(epochs, train_loss, label=\"Train\")\n",
        "  plt.plot(epochs, valid_loss, label=\"Valid\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Training Curve\")\n",
        "  plt.plot(epochs, train_acc, label=\"Train\")\n",
        "  plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "  if lrs[0] != -1:\n",
        "    plt.title(\"Learning Rate Curve\")\n",
        "    plt.plot(lrs, label=\"Train\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"LR\")\n",
        "    #plt.legend(loc='best')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  return np.array(data_reduced)"
      ],
      "metadata": {
        "id": "W4NkKQPbaXHi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(get_data())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcWIfibhdNJ5",
        "outputId": "1d1d5cab-84e2-4e49-de83-082b80ac09bd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8704"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_tweet(tweet):\n",
        "    # separate punctuations\n",
        "    tweet = tweet.replace(\".\", \" . \") \\\n",
        "                 .replace(\",\", \" , \") \\\n",
        "                 .replace(\";\", \" ; \") \\\n",
        "                 .replace(\"?\", \" ? \")\n",
        "    return tweet.lower().split()\n",
        "\n",
        "split_tweet(\"hello; don't you know?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff15em4kara6",
        "outputId": "f1bd1b59-f144-4a87-d084-28dfbe7695d2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', ';', \"don't\", 'you', 'know', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tweet_words(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        #if i % 29 == 0:\n",
        "        tweet = line[0]\n",
        "        idxs = [glove_vector.stoi[w]        # lookup the index of word\n",
        "                for w in split_tweet(tweet)\n",
        "                if w in glove_vector.stoi] # keep words that has an embedding\n",
        "        if not idxs: # ignore tweets without any word with an embedding\n",
        "            continue\n",
        "        idxs = torch.tensor(idxs) # convert list to pytorch tensor\n",
        "        label = torch.tensor(line[1]).long()\n",
        "        #print(label)\n",
        "        if i % 8 < 6:\n",
        "            train.append((idxs, label))\n",
        "        elif i % 8 == 7:\n",
        "            valid.append((idxs, label))\n",
        "        else:\n",
        "            test.append((idxs, label))\n",
        "            #print(test)\n",
        "    return train, valid, test\n",
        "\n",
        "train, valid, test = get_tweet_words(glove)"
      ],
      "metadata": {
        "id": "6HTuEzMuaT5c"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train), len(valid), len(test), len(train)+len(valid)+len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaazJmuMavwa",
        "outputId": "18791e38-5ba0-4e14-e1dd-ce90f5a8b755"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6520 1087 1087 8694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "# train = pad_sequence([tweet for tweet, label in train],\n",
        "#                             batch_first=True)\n",
        "# valid = pad_sequence([tweet for tweet, label in valid],\n",
        "#                             batch_first=True)\n",
        "# test = pad_sequence([tweet for tweet, label in test],\n",
        "#                             batch_first=True)\n"
      ],
      "metadata": {
        "id": "ExJEaZc-gu59"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class TweetBatcher:\n",
        "    def __init__(self, tweets, batch_size=32, drop_last=False):\n",
        "        # store tweets by length\n",
        "        self.dataset = tweets\n",
        "        self.tweets_by_length = {}\n",
        "        for words, label in tweets:\n",
        "            # compute the length of the tweet\n",
        "            wlen = words.shape[0]\n",
        "            # put the tweet in the correct key inside self.tweet_by_length\n",
        "            if wlen not in self.tweets_by_length:\n",
        "                self.tweets_by_length[wlen] = []\n",
        "            self.tweets_by_length[wlen].append((words, label),)\n",
        "         \n",
        "        #  create a DataLoader for each set of tweets of the same length\n",
        "        self.loaders = {wlen : torch.utils.data.DataLoader(\n",
        "                                    tweets,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    drop_last=drop_last) # omit last batch if smaller than batch_size\n",
        "            for wlen, tweets in self.tweets_by_length.items()}\n",
        "        \n",
        "    def __iter__(self): # called by Python to create an iterator\n",
        "        # make an iterator for every tweet length\n",
        "        iters = [iter(loader) for loader in self.loaders.values()]\n",
        "        while iters:\n",
        "            # pick an iterator (a length)\n",
        "            im = random.choice(iters)\n",
        "            try:\n",
        "                yield next(im)\n",
        "            except StopIteration:\n",
        "                # no more elements in the iterator, remove it\n",
        "                iters.remove(im)"
      ],
      "metadata": {
        "id": "MdEYrq9pie63"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_accuracy(model, data_loader):\n",
        "#     correct, total = 0, 0\n",
        "#     for tweets, labels in data_loader:\n",
        "#         output = model(tweets)\n",
        "#         #print(tweets.shape)\n",
        "#         #print(output.shape)\n",
        "#         #print(onehot_labels[labels].shape)\n",
        "#         #break\n",
        "#         pred = output.max(1, keepdim=True)[1]\n",
        "#         correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "#         total += labels.shape[0]\n",
        "#     return correct / total\n",
        "\n",
        "# test_loader = TweetBatcher(test, batch_size=64, drop_last=False)\n",
        "# get_accuracy(IGRatioNet(1,64, device=\"cpu\", embedding_size=200), test_loader)"
      ],
      "metadata": {
        "id": "J2pvhlv4iyCK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faxw85rWiASi",
        "outputId": "fb77ed36-ff0f-4d7d-f089-152e7c84b2cd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([   433,     53,   3100,     87,  38364,     85,    152,     11, 209832,\n",
            "            35,   1477,     11,   1975,      1]), tensor(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xvWvDK-7V35G"
      },
      "outputs": [],
      "source": [
        "glove_emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "def tune_network(net=RatioNet,\n",
        "                 device=device,\n",
        "                 input_size=len(tokenised_data.vocab),\n",
        "                 batch_size=5,\n",
        "                 embedding_size=200,\n",
        "                 hidden_size=200,\n",
        "                 lstm_input_size=300,\n",
        "                 lstm_layers=2,\n",
        "                 bidirectional=True,\n",
        "                 epochs=5,\n",
        "                 learning_rate=1e-5,\n",
        "                 learning_rate_decay=0.03,\n",
        "                 dropout=0.5,\n",
        "                 momentum=0.9,\n",
        "                 weight_decay=1e-5,\n",
        "                 adam=True,\n",
        "                 sanity_check=False,\n",
        "                 run_test=False):\n",
        "  \"\"\"\n",
        "  Tune the network: Includes all trainable hyperparameters and should be compatible with all other networks in this notebook\n",
        "  \"\"\"\n",
        "  tokenised_data = Field(tokenize=\"spacy\", use_vocab=False, tokenizer_language=\"en_core_web_sm\")\n",
        "  # https://github.com/pytorch/text/issues/78\n",
        "  labels = LabelField(dtype = torch.float, use_vocab=False, preprocessing=float)#, postprocessing=torchtext.data.Pipeline(lambda x: float(x))) # converting string ratios to doubles and not using a vocab for target labels\n",
        "  dataset = TabularDataset(path=\"tokenized_data.csv\", format=\"CSV\", fields=[(\"tweet\", tokenised_data),(\"label\", labels)],skip_header=True)\n",
        "  train_set, val_set, test_set = dataset.split(split_ratio=[0.60, 0.20, 0.20],random_state=random.seed(0))  \n",
        "\n",
        "  # Construct data loaders of proper batch size\n",
        "  #train_loader  = torchtext.data.BucketIterator( train_set, batch_size=batch_size, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "  #val_loader    = torchtext.data.BucketIterator(   val_set, batch_size=batch_size, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "  #test_loader   = torchtext.data.BucketIterator(  test_set, batch_size=batch_size, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "  #sanity_loader = torchtext.data.BucketIterator(sanity_set, batch_size=batch_size, device = device, shuffle=True, sort_key = lambda x: len(x.tokenized_tweets), sort_within_batch=False)\n",
        "  print(len(train))\n",
        "  print(len(valid))\n",
        "  print(len(test))\n",
        "  train_loader = TweetBatcher(train, batch_size=batch_size, drop_last=False)  \n",
        "  val_loader = TweetBatcher(valid, batch_size=batch_size, drop_last=False)  \n",
        "  test_loader = TweetBatcher(test, batch_size=batch_size, drop_last=False)  \n",
        "  # initialize network NOTE: WHIEL ALL NETWORK INPUTS ARE THE SAME FOR ALL NETWORKS CERTAIN NETWORK INPUTS WILL HAVE NO EFFECT FOR CERTAIN NETWORKS, IE THE SIMPLE RNN MODEL WILL NOT USE THE LSTM_INPUT_SIZE INPUT AS NO LSTM IS PRESENT\n",
        "  network = net(input_size=input_size, batch_size=batch_size, device=device, hidden_size=hidden_size, embedding_size=embedding_size, lstm_input_size=lstm_input_size, num_layers=lstm_layers, dropout=dropout, bi_direc=bidirectional)\n",
        "  if run_test:\n",
        "    print(get_accuracy(network, test_loader, criterion = nn.CrossEntropyLoss()))\n",
        "  # train the network \n",
        "  a,b,c,d,e,f,best=train_net(network, [train_loader,val_loader,test_loader], epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, dropout=dropout, momentum=momentum, sanity_check=sanity_check, device=device, weight_decay=weight_decay, adam=adam, learning_rate_decay=learning_rate_decay)\n",
        "  return a,b,c,d,e,f,best,network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Mc5bVfW69MkA"
      },
      "outputs": [],
      "source": [
        "glove_data = []\n",
        "for i, text in enumerate(dataset,0):\n",
        "  tweet = [(glove[word]) for word in (vars(text)[\"tweet\"])]\n",
        "  glove_data.append(tweet)\n",
        "\n",
        "#glove_date = torch.cat(glove_data, dim=0)\n",
        "glove_data_tensor = [torch.cat(sub_list, dim=0) for sub_list in glove_data]\n",
        "\n",
        "#vars(dataset[0])\n",
        "#glove(word) for word in (text for text in data2[[\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgPM3TWhALjI",
        "outputId": "f544afc6-f476-401c-e914-61b274b3fa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8704\n",
            "torch.Size([2800])\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "print(len(glove_data_tensor))\n",
        "print(glove_data_tensor[0].shape)\n",
        "print(len(glove_data[1][0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "test=None"
      ],
      "metadata": {
        "id": "mntHYJqUm_Tr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Best Model on New Data"
      ],
      "metadata": {
        "id": "YbyvwexJBu4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_orig = [[\"Look at THOSE!!! #Hot #Fire #airforce1 #basketball https://www.nike.com/ca/t/air-force-1-07-shoes-cbBh9R/DR0155-001?nikemt=true&cp=608502688\",0],\n",
        "#              [\"Run! Run! Run! Tango Marathon this Sunday 8am, hope to see everyone there running 🏃 #marathon #running #event\",0],\n",
        "#              [\"Man who goes to the gym regardless of how he feels will always beat someone who goes to the gym when they feel like it. #Tater #TopG #alphaMale\",0],\n",
        "#              [\"I’d rather be fat and happy then this 6 pack and sad all day #paddypimblett #UFC\",0],\n",
        "#              [\"UKRAINE LASTEST: There are concerns of a new disaster following reports of shelling near Europe’s largest nuclear power plant that was seized by Russia in March.\",1],\n",
        "#              [\"Oil spill in south atlantic ocean following an unexpected explosion at an oil plant.\",1],\n",
        "#              [\"Breaking News: Donald Trump was just elected as the next president of America 2024-2028, what an disaster\",0],\n",
        "#              [\"Huge smoke spotted in the forest, seems to be a wild fire going on. 1Active-fire2-900x600.jpg\",1],\n",
        "#              [\"Moderate magnitude 4.3 earthquake 56 km southwest of Beykonak, Turkey.\",1],\n",
        "#              [\"The series of underwater earthquakes off the Andaman and Nicobar Islands last week has shaken local disaster officials in conducting a full review of the island’s tsunami-warning system and the readiness of local officials to quickly evacuate risk areas in case the need arises\",1],\n",
        "#              [\"God dam my house blown away by a tornado\", 1],\n",
        "#              [\"Lover is war is fire :fire:\", 0],\n",
        "#              #[\"U.S. officials plan to declare monkeypox a public health emergency, as cases top 6,600 nationwide, two sources familiar with the matter tell NBC News.\", 0],\n",
        "#              #[\"WNBA star Brittney Griner sentenced to 9 years in jail on drug charges in Russian court.\", 0],\n",
        "#              #[\"Rep. Jackie Walorski was killed, House Minority Leader McCarthy says.\", 1], \n",
        "#              #[\"World headed for 560 disasters a year by 2030, UN report warns\", 1],\n",
        "#              #[\"At least 15 people are dead and “that number is going to grow to probably more than double” as devastating rainfall continues in eastern Kentucky, Gov. Beshear says.\", 1],\n",
        "#              #[\"BREAKING: In an unexpected breakthrough, Sen. Joe Manchin announced he will support a bill that includes major investments to drive down drug prices as well as provisions to address climate change and taxes on the wealthy.\", 0],\n",
        "#              #[\"Just witnessed a gas station explosion near me, hope everyone is ok 🙏\", 1],\n",
        "#              #[\"OMG the volcano just erupted, sky’s all dark, ashes everywhere\", 1]]\n",
        "\n",
        "data_orig = [[\"Look at THOSE!!! #Hot #Fire #airforce1 #basketball  https://www.nike.com/ca/t/air-force-1-07-shoes-cbBh9R/DR0155-001?nikemt=true&cp=608502688\", 0],\n",
        "            [\"Run! Run! Run! Tango Marathon this Sunday 8am, hope to see everyone there running  #marathon #running #event\", 0],\n",
        "            [\"Man who goes to the gym regardless of how he feels will always beat someone who goes to the gym when they feel like it. #Tater #TopG #alphaMale\", 0],\n",
        "            [\"I’d rather be fat and happy then this 6 pack and sad all day #paddypimblett #UFC\", 0],\n",
        "            [\"UKRAINE LASTEST: There are concerns of a new disaster following reports of shelling near Europe’s largest nuclear power plant that was seized by Russia in March.\", 1],\n",
        "            [\"Oil spill in south atlantic ocean following an unexpected explosion at an oil plant.\", 1],\n",
        "            [\"Breaking News: Donald Trump was just elected as the next president of America 2024-2028, what a disaster #News\", 0],\n",
        "            [\"Huge smoke spotted in the forest, seems to be a wild fire going on. 1Active-fire2-900x600.jpg\", 1],\n",
        "            [\"Moderate magnitude 4.3 earthquake 56 km southwest of Beykonak, Turkey.\", 1],\n",
        "            [\"The series of underwater earthquakes off the Andaman and Nicobar Islands last week has shaken local disaster officials in conducting a full review of the island’s tsunami-warning system and the readiness of local officials to quickly evacuate risk areas in case the need arises\", 1],\n",
        "            [\"God dam my house was blown away WEB18-WeatherClimate-HurricaneIrma-FtLauderdaleFlorida-4696x2642.jpg\", 1],\n",
        "            [\"Lover is war is fire  #waifu #anime\", 0],\n",
        "            [\"U.S. officials plan to declare monkeypox a public health emergency, as cases top 6,600 nationwide, two sources familiar with the matter tell NBC News.\", 1],\n",
        "            [\"WNBA star Brittney Griner sentenced to 9 years in jail on drug charges in Russian court.\", 0],\n",
        "            [\"Rep. Jackie Walorski was killed in a car accident, House Minority Leader McCarthy says.\", 1],\n",
        "            [\"President Biden has tested negative for Covid and will leave isolation, the White House says. Biden will wear a mask for 10 days when around others, according to White House doctor Kevin O’Connor\", 0],\n",
        "            [\"At least 15 people are dead and “that number is going to grow to probably more than double” as devastating rainfall continues in eastern Kentucky, Gov. Beshear says.\", 1],\n",
        "            [\"BREAKING: In an unexpected breakthrough, Sen. Joe Manchin announced he will support a bill that includes major investments to drive down drug prices as well as provisions to address climate change and taxes on the wealthy.\", 0],\n",
        "            [\"Ivana Trump, Donald Trump’s first wife and the mother of his three oldest children, has died, the former president says.\", 0],\n",
        "            [\"OMG the volcano just erupted, sky’s all dark, ashes everywhere\", 1]]"
      ],
      "metadata": {
        "id": "1iJSEiCWwe0m"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Best Network\n",
        "network3 = torch.load(\"/content/drive/MyDrive/APS360/network3\")\n",
        "network3.eval()\n",
        "\n",
        "# Tokenizing data and passing getting glove embeddings\n",
        "valid = []\n",
        "for line in  data_orig:\n",
        "  tweet = line[0]\n",
        "  idxs = [glove.stoi[w]        # glove index\n",
        "          for w in split_tweet(tweet)\n",
        "          if w in glove.stoi]  # only keep words with embeddings\n",
        "  idxs = torch.tensor(idxs)    # convert list to pytorch tensor\n",
        "  label = torch.tensor(line[1]).long()\n",
        "\n",
        "  valid.append((idxs, label))\n",
        "\n",
        "val_l = TweetBatcher(valid, batch_size=1)  \n",
        "\n",
        "# passing data through model and calculating accuracy\n",
        "accuracy_sum = 0\n",
        "for i, data in enumerate(val_l):\n",
        "  tweet, label = data\n",
        "  tweet, label = tweet.to(device), label.to(device)\n",
        "  out= network3(tweet)\n",
        "  pred = [round(percent,3) for percent in F.softmax(out, dim=-1).tolist()[0]]\n",
        "  label_onehot = onehot_labels[label].tolist()[0]\n",
        "\n",
        "  print(\"Pred :\",pred, \"Label :\",label_onehot, end=\" Tweet :\\t\")  \n",
        "  for w in tweet[0]:\n",
        "    print(glove.itos[w], end=\" \")\n",
        "  print(\"\")\n",
        "\n",
        "  accuracy_sum += (pred.index(max(pred)) == label_onehot.index(max(label_onehot)))\n",
        "  \n",
        "accuracy = accuracy_sum/len(data_orig)\n",
        "\n",
        "print(\"accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9InvQeKVJoV",
        "outputId": "8843867e-27b8-437b-f056-0ff77a25b3df"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred : [0.804, 0.196] Label : [0.0, 1.0] Tweet :\tgod dam my house was blown away . jpg \n",
            "Pred : [0.815, 0.185] Label : [1.0, 0.0] Tweet :\ttango marathon this sunday 8am , hope to see everyone there running \n",
            "Pred : [0.026, 0.974] Label : [0.0, 1.0] Tweet :\tthe series of underwater earthquakes off the andaman and nicobar islands last week has shaken local disaster officials in conducting a full review of the system and the readiness of local officials to quickly evacuate risk areas in case the need arises \n",
            "Pred : [0.733, 0.267] Label : [1.0, 0.0] Tweet :\tin an unexpected breakthrough , sen . joe manchin announced he will support a bill that includes major investments to drive down drug prices as well as provisions to address climate change and taxes on the wealthy . \n",
            "Pred : [0.893, 0.107] Label : [1.0, 0.0] Tweet :\tman who goes to the gym regardless of how he feels will always beat someone who goes to the gym when they feel like it . \n",
            "Pred : [0.058, 0.942] Label : [0.0, 1.0] Tweet :\tu . s . officials plan to declare monkeypox a public health emergency , as cases top 6 , 600 nationwide , two sources familiar with the matter tell nbc news . \n",
            "Pred : [0.042, 0.958] Label : [0.0, 1.0] Tweet :\trep . jackie was killed in a car accident , house minority leader mccarthy says . \n",
            "Pred : [0.028, 0.972] Label : [0.0, 1.0] Tweet :\tat least 15 people are dead and number is going to grow to probably more than as devastating rainfall continues in eastern kentucky , gov . beshear says . \n",
            "Pred : [0.084, 0.916] Label : [0.0, 1.0] Tweet :\thuge smoke spotted in the forest , seems to be a wild fire going on . . jpg \n",
            "Pred : [0.016, 0.984] Label : [0.0, 1.0] Tweet :\tmoderate magnitude 4 . 3 earthquake 56 km southwest of , turkey . \n",
            "Pred : [0.159, 0.841] Label : [1.0, 0.0] Tweet :\twnba star brittney griner sentenced to 9 years in jail on drug charges in russian court . \n",
            "Pred : [0.906, 0.094] Label : [1.0, 0.0] Tweet :\tpresident biden has tested negative for and will leave isolation , the white house says . biden will wear a mask for 10 days when around others , according to white house doctor kevin o’connor \n",
            "Pred : [0.746, 0.254] Label : [1.0, 0.0] Tweet :\tivana trump , donald first wife and the mother of his three oldest children , has died , the former president says . \n",
            "Pred : [0.877, 0.123] Label : [1.0, 0.0] Tweet :\tlook at . nike . ? \n",
            "Pred : [0.498, 0.502] Label : [1.0, 0.0] Tweet :\tlover is war is fire \n",
            "Pred : [0.179, 0.821] Label : [0.0, 1.0] Tweet :\tomg the volcano just erupted , all dark , ashes everywhere \n",
            "Pred : [0.024, 0.976] Label : [0.0, 1.0] Tweet :\tukraine there are concerns of a new disaster following reports of shelling near largest nuclear power plant that was seized by russia in march . \n",
            "Pred : [0.019, 0.981] Label : [0.0, 1.0] Tweet :\toil spill in south atlantic ocean following an unexpected explosion at an oil plant . \n",
            "Pred : [0.891, 0.109] Label : [1.0, 0.0] Tweet :\trather be fat and happy then this 6 pack and sad all day \n",
            "Pred : [0.777, 0.223] Label : [1.0, 0.0] Tweet :\tbreaking donald trump was just elected as the next president of america , what a disaster \n",
            "accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network3 = torch.load(\"/content/drive/MyDrive/APS360/network3\")\n",
        "#network3.load_state_dict(torch.load(\"//content//best2\")\n",
        "network3.eval()\n",
        "test = torch.load(\"best3_test_set.csv\")\n",
        "valid = torch.load(\"best3_valid_set.csv\")\n",
        "train = torch.load(\"best3_train_set.csv\")\n",
        "#train, valid, test = get_tweet_words(glove)\n",
        "print(len(train), len(test), len(valid))\n",
        "def get_data_loader(batch_size):\n",
        "  train_loader = TweetBatcher(train, batch_size=batch_size, drop_last=False)  \n",
        "  val_loader = TweetBatcher(valid, batch_size=batch_size, drop_last=False)  \n",
        "  test_loader = TweetBatcher(test, batch_size=batch_size, drop_last=False)  \n",
        "  return train_loader, val_loader, test_loader\n",
        "train_l, val_l, test_l = get_data_loader(64)\n",
        "a,b,c,d=get_accuracy(network3, test_l, criterion=nn.CrossEntropyLoss())\n",
        "\n",
        "#print(get_accuracy(network3, val_l, criterion=nn.CrossEntropyLoss()))\n",
        "#print(get_accuracy(network3, test_l, criterion=nn.CrossEntropyLoss()))\n",
        "#print(get_accuracy(network3, train_l, criterion=nn.CrossEntropyLoss()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t65AYMe0uNWb",
        "outputId": "1547d107-6df9-4983-c815-755d10a18cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5702 950 950\n",
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r                                                     \rtensor([[839, 111],\n",
            "        [312, 638]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for j, twt in enumerate(c,0):\n",
        "#  twt2 = []\n",
        "#  for i, word in enumerate(twt[0],0):\n",
        "#    twt2.append(glove.itos[word])\n",
        "#  c[j][0] = twt2\n",
        "  #twt[0] = glove.itos[torch.cuda.LongTensor(twt[0])]\n",
        "# for j, twt in enumerate(c,0):\n",
        "#    #twt2 = twt[1].cpu().detach().numpy()\n",
        "#    #c[j][1] = twt2\n",
        "#    c[j][0] = np.array(c[j][0])\n",
        "#    c[j][2] = np.array(c[j][2])\n",
        "#    #for i, word in enumerate(twt[0],0):\n",
        "#     #twt2.append(glove.itos[word])\n",
        "# #  c[j][0] = twt2\n",
        "  #twt[0] = glove.itos[torch.cuda.LongTensor(twt[0])]\n",
        "#for i in range(len(c)):\n",
        "#  c\n",
        "import csv\n",
        "with open(\"correct.csv\", \"w\") as f:\n",
        "    wr = csv.writer(f)\n",
        "    wr.writerows(c)"
      ],
      "metadata": {
        "id": "Sqvh9P9Rehgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copy_d = d.copy()\n",
        "d=q[2]\n",
        "#d=q[3]"
      ],
      "metadata": {
        "id": "E-e48MYQmJlx"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j, twt in enumerate(d,0):\n",
        "  twt2 = []\n",
        "  for i, word in enumerate(twt[0],0):\n",
        "    twt2.append(glove.itos[word])\n",
        "    d[j][0] = twt2\n"
      ],
      "metadata": {
        "id": "F4v6pxLeejrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "7b3335f6-d69f-4480-b0cf-9e2d22e7c813"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-a13675c36243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtwt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtwt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not numpy.str_"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZtEBo56WX4u",
        "outputId": "9fe3273d-8351-4782-f0da-b409e0f87123"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array(['.', 'the', 'anniversary', 'of', 'the', 'devastation', 'wrought',\n",
              "         'by', 'the', 'first', 'military', 'use', 'of', 'an', 'atomic',\n",
              "         'weapon'], dtype='<U11'),\n",
              "  array([0.00269166, 0.9973084 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'added', 'a', 'video', 'to', 'a', 'playlist', '.', 'gta', '5',\n",
              "         'funny', 'moments', '-', '5', 'online', 'funny'], dtype='<U8'),\n",
              "  array([9.9995375e-01, 4.6237452e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['3', 'bedrooms', '1', 'baths', 'for', 'sale', 'in', '29', 'palms',\n",
              "         'ca', '.', '.', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.9900755 , 0.00992443], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['shot', 'in', 'horror', 'hijacking', 'johannesburg', '.', ';', ';',\n",
              "         'four', 'men', 'were', 'shot', 'dead', 'in', 'free', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([4.4819815e-05, 9.9995518e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['-', '4:30', 'p', '.', 'm', '.', '-', 'progress', 'being', 'made',\n",
              "         'on', 'boise', 'forest', 'fires', '.', '.'], dtype='<U8'),\n",
              "  array([3.4887547e-05, 9.9996507e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['okinawa', 'island', 'region', 'm4', '.', '0', 'depth', '10km',\n",
              "         'maximum', 'seismic', 'intensity', '3', 'jst', '#', '?', '?'],\n",
              "        dtype='<U9'),\n",
              "  array([0.00157473, 0.99842525], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['c-130', 'specially', 'modified', 'to', 'land', 'in', 'a',\n",
              "         'stadium', 'and', 'rescue', 'hostages', 'in', 'iran', 'in', '1980',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([2.0965093e-05, 9.9997902e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['violent', 'record', 'breaking', 'el', 'reno', 'oklahoma',\n",
              "         'tornado', 'nearly', 'runs', 'over', '.', '.', '.', '-', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.0491388e-04, 9.9989510e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['you', 'get', 'me', 'sis', '.', 'this', 'planet', 'could', 'do',\n",
              "         'with', 'a', 'huge', 'dose', 'of', 'obliteration', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([0.1083395 , 0.89166045], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['new', 'technology', 'designed', 'to', 'help', 'prevent',\n",
              "         'dangerous', 'police', 'in', 'an', 'effort', 'to', 'reduce',\n",
              "         'injuries', 'milwaukee', '.'], dtype='<U10'),\n",
              "  array([0.9986584, 0.0013416], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wreckage', 'as', 'from', 'malaysia', 'investigators', 'and',\n",
              "         'the', 'families', 'of', 'those', 'who', 'were', '.', '.', '.',\n",
              "         '.'], dtype='<U13'),\n",
              "  array([3.7815742e-04, 9.9962187e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wow', 'fatality', 'on', '101', 'big', 'rig', 'hit',\n",
              "         'motorcyclist', 'blood', 'everywhere', '?', '?', 'wow', '.',\n",
              "         'sick', '.'], dtype='<U12'),\n",
              "  array([0.01914933, 0.9808507 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['if', 'a', 'nigga', 'was', 'a', 'threat', 'then', 'that', 'boy',\n",
              "         'ah', 'be', 'thru', '?', '?', '?', '?'], dtype='<U6'),\n",
              "  array([0.9914541 , 0.00854594], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['-', '4:30', 'p', '.', 'm', '.', '-', 'progress', 'being', 'made',\n",
              "         'on', 'boise', 'forest', 'fires', '.', '.'], dtype='<U8'),\n",
              "  array([3.4887547e-05, 9.9996507e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['liable', 'to', 'sound', 'like', 'a', 'wounded', 'animal',\n",
              "         'during', 'sex', 'if', 'the', '?', '?', 'is', 'good', 'lol'],\n",
              "        dtype='<U7'),\n",
              "  array([0.9979528 , 0.00204716], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['black', 'eye', 'a', 'space', 'battle', 'occurred', 'at', 'star',\n",
              "         'involving', '3', 'fleets', 'totaling', 'ships', 'with', '17',\n",
              "         'destroyed'], dtype='<U9'),\n",
              "  array([9.9956161e-01, 4.3836032e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hazard', '-', 'hazardous', 'condition', 'at', 'sb', 'i5', 'at',\n",
              "         '/', 'sw', 'terwilliger', 'blvd', 'portland', 'or', 'police',\n",
              "         '17:26'], dtype='<U11'),\n",
              "  array([0.01274486, 0.9872551 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['pm', 'abe', 'pledged', 'to', 'make', 'every', 'effort', 'to',\n",
              "         'seek', 'a', 'world', 'without', 'nuclear', 'weapons', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.00290927, 0.9970907 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'crocodile', 'tears', 'wash', 'with', 'me', 'more', 'upset',\n",
              "         'that', 'the', 'gravy', 'train', 'has', 'been', 'derailed', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([8.3501154e-04, 9.9916506e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['classic', 'www', 'atomic', 'devastation', 'hidden', 'for', 'the',\n",
              "         'people', 'of', 'hiroshima', 'and', 'nagasaki', '.', '.', '.', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([7.700852e-05, 9.999230e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['emergency', 'units', 'simulate', 'a', 'chemical', 'explosion',\n",
              "         'at', 'suppose', 'a', 'student', 'in', 'the', 'research', 'labs',\n",
              "         'at', '.'], dtype='<U9'),\n",
              "  array([0.00108269, 0.99891734], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['nout', 'like', 'salt', 'in', 'the', 'wounds', 'dad', '.', '.',\n",
              "         '?', '?', '?', '?', '?', '?', '.'], dtype='<U6'),\n",
              "  array([0.7790762, 0.2209238], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'chick', 'i', 'work', 'with', 'chews', 'chewing', 'gum',\n",
              "         'so', 'loud', '?', '?', 'feel', 'to', 'bang', 'her'], dtype='<U7'),\n",
              "  array([0.9729249 , 0.02707514], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'storm', 'prediction', 'center', 'has', 'expanded', 'the',\n",
              "         'area', 'to', 'include', 'more', 'of', 'central', 'nc', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([4.334995e-05, 9.999566e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['great', 'one', 'time', 'deal', 'on', 'all', 'avalanche', 'music',\n",
              "         'and', 'with', 'purchase', 'get', 'a', 'neal', 'shirt', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.8795506 , 0.12044946], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'watch', 'tat', 'show', 'its', 'like', 'a', 'horror', 'movie',\n",
              "         'to', 'me', 'i', 'get', 'flashbacks', 'an', 'everything'],\n",
              "        dtype='<U10'),\n",
              "  array([0.99898404, 0.00101591], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['100', 'mix', 'new', 'flat', 'double', 'sided', 'bottle', 'caps',\n",
              "         'you', 'choose', 'mix', 'flattened', '-', 'full', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.99089104, 0.00910902], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wreckage', 'as', 'from', 'malaysia', 'investigators', 'and',\n",
              "         'the', 'families', 'of', 'those', 'who', 'were', '.', '.', '.',\n",
              "         '.'], dtype='<U13'),\n",
              "  array([3.7815742e-04, 9.9962187e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['they', 'died', 'horrible', 'deaths', 'trapped', 'in', 'the',\n",
              "         'ships', 'but', 'they', 'knew', 'that', 'was', 'a', 'risk', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00555701, 0.994443  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['okay', 'i', 'welcome', 'the', 'rain', '.', 'gave', 'you', 'all',\n",
              "         'the', 'storm', 'that', 'you', 'could', 'weather', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.996797  , 0.00320304], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['because', '12', \"o'clock\", 'and', 'my', 'mom', 'said', 'everyone',\n",
              "         'has', 'to', 'go', 'home', 'because', 'of', 'curfew', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.19181068, 0.8081894 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['pov', 'video', 'captures', 'violent', 'landing', 'at',\n",
              "         'amsterdam', 'airport', 'schiphol', 'during', 'a', 'storm', '.',\n",
              "         '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.3402445e-04, 9.9976593e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'police', 'had', 'previously', 'died', 'in', 'a', 'road',\n",
              "         'accident', 'they', 'were', 'not', 'killed', 'by', 'explosion',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([4.2091833e-06, 9.9999583e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['someone', 'walk', 'with', 'me', 'to', 'dq', '?', '?', 'i',\n",
              "         'wanna', 'butterfinger', 'blizzard', 'so', 'bad', '?', '?'],\n",
              "        dtype='<U12'),\n",
              "  array([0.98823696, 0.01176301], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['black', 'eye', 'a', 'space', 'battle', 'occurred', 'at', 'star',\n",
              "         'involving', '2', 'fleets', 'totaling', 'ships', 'with', '13',\n",
              "         'destroyed'], dtype='<U9'),\n",
              "  array([9.9965024e-01, 3.4971102e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['two', 'trains', 'have', 'collided', 'in', 'india', '.', 'please',\n",
              "         'pray', 'for', 'victims', 'their', 'families', 'and', 'rescuers',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([5.027420e-05, 9.999497e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['where', 'you', 'being', 'electrocuted', 'all', 'the', 'way',\n",
              "         'round', '?', 'the', 'map', 'sure', 'looks', 'like', 'it', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([0.86061084, 0.13938914], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['never', 'dies', 'a', 'big', 'crime', 'like', 'rabaa', 'massacre',\n",
              "         'as', 'long', 'the', 'revolution', 'is', 'being', 'observed', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.00880114, 0.99119884], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wreckage', 'as', 'from', 'malaysia', 'investigators', 'and',\n",
              "         'the', 'families', 'of', 'those', 'who', 'were', '.', '.', '.',\n",
              "         '.'], dtype='<U13'),\n",
              "  array([3.7815742e-04, 9.9962187e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['nigerian', 'military', 'rescue', '178', 'hostages', 'from',\n",
              "         'boko', 'haram', '-', 'florida', 'sentinel', 'florid', '.', '.',\n",
              "         '.', '.'], dtype='<U8'),\n",
              "  array([0.0022278 , 0.99777216], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['for', 'the', 'people', 'who', 'died', 'in', 'human',\n",
              "         'experiments', 'by', 'unit', '731', 'of', 'japanese', 'military',\n",
              "         '.', '.'], dtype='<U11'),\n",
              "  array([6.689372e-04, 9.993311e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['pic', 'of', 'old', 'pkk', 'suicide', 'bomber', 'who', 'detonated',\n",
              "         'bomb', 'in', 'turkey', 'army', 'trench', 'released', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([6.0018567e-05, 9.9993992e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['would', 'get', 'destroyed', 'on', 'twitter', '.', 'his',\n",
              "         'comments', 'are', 'emotionally', 'driven', 'rants', 'with',\n",
              "         'little', 'factual', 'basis'], dtype='<U11'),\n",
              "  array([9.9987900e-01, 1.2096989e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['george', 'njenga', 'the', 'hero', 'saved', 'his', 'burning',\n",
              "         'friend', 'from', 'a', 'razing', 'wildfire', '.', '.', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00311775, 0.9968823 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['obama', 'declares', 'disaster', 'for', 'obama', 'signs',\n",
              "         'disaster', 'declaration', 'for', 'northern', 'marians', 'a', '.',\n",
              "         '.', '.', '.'], dtype='<U11'),\n",
              "  array([0.00235676, 0.9976432 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wreckage', 'as', 'from', 'malaysia', 'investigators', 'and',\n",
              "         'the', 'families', 'of', 'those', 'who', 'were', '.', '.', '.',\n",
              "         '.'], dtype='<U13'),\n",
              "  array([3.7815742e-04, 9.9962187e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['morgan', 'silver', 'dollar', '1880', 's', 'gem', 'bu', 'cameo',\n",
              "         'rev', 'blazing', 'high', '-', 'full', 'read', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.997556  , 0.00244402], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['turbine', 'hurricane', 'h', 'bluetooth', '4', '.', '1',\n",
              "         'wireless', 'stereo', 'headphones', 'headset', 'blk', '-', 'full',\n",
              "         '.', '.'], dtype='<U10'),\n",
              "  array([0.9888554 , 0.01114452], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['pov', 'video', 'captures', 'violent', 'landing', 'at',\n",
              "         'amsterdam', 'airport', 'schiphol', 'during', 'a', 'storm', '-',\n",
              "         'daily', 'mail', '.'], dtype='<U9'),\n",
              "  array([5.3875125e-04, 9.9946123e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'rate', 'hazard', 'very', 'highly', 'but', 'his', 'fanboys',\n",
              "         'are', 'among', 'the', 'worst', 'accounts', 'on', 'twitter', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.6154425 , 0.38455746], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['obama', 'declares', 'disaster', 'for', 'obama', 'signs',\n",
              "         'disaster', 'declaration', 'for', 'northern', 'marians', 'a', '.',\n",
              "         '.', '.', '.'], dtype='<U11'),\n",
              "  array([0.00235676, 0.9976432 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['this', 'sale', 'and', 'demolition', 'trend', 'near', 'metrotown',\n",
              "         'is', 'sure', 'resulting', 'in', 'some', 'poorly', 'maintained',\n",
              "         'apartments', '.'], dtype='<U10'),\n",
              "  array([0.98592585, 0.01407421], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['pov', 'video', 'captures', 'violent', 'landing', 'at',\n",
              "         'amsterdam', 'airport', 'schiphol', 'during', 'a', 'storm', '.',\n",
              "         '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.3402445e-04, 9.9976593e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['guns', 'are', 'for', 'protection', '.', '.', 'that', 'shit',\n",
              "         'really', 'be', 'used', 'unless', 'your', 'life', 'in', 'danger'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9962375, 0.0037625], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wild', 'fires', 'in', 'california', '.', '.', '.', 'must', 'be',\n",
              "         'global', 'warming', '.', 'just', 'be', 'extreme', 'heat',\n",
              "         'combined', 'with', 'dry', 'foliage', 'ignited', 'by', 'some',\n",
              "         'hiker', '.'], dtype='<U10'),\n",
              "  array([0.00644777, 0.9935522 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wondering', 'if', 'gold', 'could', 'gap', 'up', 'on', 'the',\n",
              "         'jobs', 'numbers', 'tomorrow', 'and', 'just', 'obliterate', 'the',\n",
              "         'shorts', '.', 'a', 'big', 'player', 'with', 'guys', 'could',\n",
              "         'smash', 'them'], dtype='<U10'),\n",
              "  array([0.99350137, 0.00649859], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['cos', 'sanity', 'brings', 'no', 'reward', 'for', 'one', 'more',\n",
              "         'hit', 'and', 'one', 'last', 'score', '.', '.', '.', 'be', 'a',\n",
              "         'casualty', 'cut', 'the', 'cord', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.01901673, 0.9809833 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['gates', 'not', 'body', 'bagging', 'nobody', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?', 'niggas', 'in', 'br', 'really', 'know', 'who',\n",
              "         'he', 'is', '?', '?', '?', '?'], dtype='<U7'),\n",
              "  array([0.99611217, 0.00388792], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wild', 'night', 'in', 'the', 'village', 'of', 'pugwash', 'every',\n",
              "         'fire', 'truck', 'is', 'out', 'that', 'the', 'town', 'has',\n",
              "         'which', 'is', 'like', 'a', 'fire', 'truck', 'for', 'every',\n",
              "         'house'], dtype='<U7'),\n",
              "  array([0.01751378, 0.98248625], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['but', 'no', 'lies', 'though', '.', 'pays', 'to', 'be', 'the',\n",
              "         'oldest', 'sometimes', '.', 'like', 'being', 'the', 'first', 'to',\n",
              "         'get', 'a', 'car', 'and', 'have', 'no', 'curfew', '.'], dtype='<U9'),\n",
              "  array([0.6128787 , 0.38712135], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['it', 'partially', 'has', 'something', 'to', 'do', 'with', 'my',\n",
              "         'trauma', 'as', 'well', '.', 'but', 'a', 'long', 'story', 'and',\n",
              "         'honestly', 'i', 'like', 'to', 'talk', 'about', 'it', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.99617153, 0.00382851], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['omg', 'nixon', 'that', 'is', 'richard', 'm', '.', 'nixon',\n",
              "         'tricky', 'dicky', 'right', 'there', 'in', 'the', 'picture', 'it',\n",
              "         '.', 'hiding', 'in', 'calgary', 'he', '.', '.', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.02695161, 0.9730483 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['businesses', 'are', 'deluged', 'with', 'invoices', '.', 'make',\n",
              "         'yours', 'stand', 'oup', 'with', 'colour', 'or', 'shame', 'and',\n",
              "         'likely', 'to', 'rise', 'to', 'the', 'top', 'of', 'the', 'pile',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([0.99834037, 0.00165963], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['as', 'a', 'cycling', 'fan', 'i', 'feel', 'sorry', 'for', 'world',\n",
              "         'athletics', 'is', 'a', 'blight', 'exacerbated', 'monetary',\n",
              "         'reward', '.', 'a', 'lot', 'of', 'soul', 'searching', 'will', 'be',\n",
              "         'required'], dtype='<U11'),\n",
              "  array([0.99132216, 0.00867785], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['on', 'the', 'flip', 'side', 'at', 'walmart', 'and', 'there', 'is',\n",
              "         'a', 'bomb', 'and', 'everyone', 'had', 'to', 'evacuate', 'so',\n",
              "         'stay', 'tuned', 'if', 'i', 'blow', 'up', 'or', 'not'], dtype='<U8'),\n",
              "  array([0.03557028, 0.96442974], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['when', 'the', 'last', 'tree', 'is', 'cut', 'down', 'the', 'last',\n",
              "         'fish', 'eaten', 'and', 'the', 'last', 'stream', 'poisoned', 'you',\n",
              "         'will', 'realize', 'that', 'you', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.98872197, 0.01127797], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['you', 'until', 'you', 'drown', 'by', 'water', 'entering', 'the',\n",
              "         'lungs', '.', 'you', 'being', 'alive', 'has', 'caused', 'this',\n",
              "         'great', 'country', 'to', 'fall', 'to', 'shit', 'because', 'a',\n",
              "         'pussy'], dtype='<U8'),\n",
              "  array([0.95003396, 0.04996602], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['families', 'to', 'sue', 'over', 'more', 'than', '40', 'families',\n",
              "         'affected', 'by', 'the', 'fatal', 'outbreak', 'of', '.', '.', '.',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([5.3445896e-04, 9.9946553e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['nine', 'giant', 'body', 'sized', 'garbage', 'bags', 'later', '.',\n",
              "         '.', '.', 'just', 'going', 'to', 'start', 'throwing', 'things',\n",
              "         'away', '.'], dtype='<U8'),\n",
              "  array([0.9985108 , 0.00148921], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['connor', 'damn', 'sirens', 'i', 'hope', 'everyone', 'is', 'okay',\n",
              "         '.', 'dan', 'can', 'you', 'please', 'get', 'murdered', 'on',\n",
              "         'another', 'street'], dtype='<U8'),\n",
              "  array([0.00139779, 0.9986022 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'strongly', 'support', 'our', 'military', ';', 'their',\n",
              "         'families', 'just', 'not', 'the', 'cock', 'suckers', 'in', 'dc',\n",
              "         'they', 'work', 'for'], dtype='<U8'),\n",
              "  array([0.96714807, 0.03285192], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['please', 'please', 'u', 'gotta', 'listen', 'to', '#', 'and',\n",
              "         'thunder', 'major', '?', '?', '?', '?', '?', '?', '?', '?'],\n",
              "        dtype='<U7'),\n",
              "  array([0.99842924, 0.00157074], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['disaster', 'control', 'teams', 'are', 'studying', 'ways', 'to',\n",
              "         'evacuate', 'the', 'port', 'area', 'in', 'response', 'to', 'tidal',\n",
              "         'wave', 'warnings', '.'], dtype='<U8'),\n",
              "  array([5.5781315e-06, 9.9999440e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['carolina', 'motorcyclist', 'dies', 'in', 'i-540', 'crash', 'with',\n",
              "         'car', 'that', 'crossed', 'a', 'motorcycle', 'rider', 'traveling',\n",
              "         '.', '.', '.', '.'], dtype='<U12'),\n",
              "  array([0.00283767, 0.9971623 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['as', 'per', 'previous', 'behaviour', 'would', 'deal', 'with',\n",
              "         'the', 'kidnapped', 'hostages', 'not', 'particularly',\n",
              "         'pleasantly', 'if', 'div', '30', 'fought', '.'], dtype='<U12'),\n",
              "  array([9.2125766e-04, 9.9907875e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['be', 'careful', 'anyone', 'who', 'lives', 'west', 'of',\n",
              "         'beaverton', '.', 'forest', 'grove', 'has', 'a', 'rapidly',\n",
              "         'spreading', 'fire', 'heading', 'east'], dtype='<U9'),\n",
              "  array([3.1633076e-04, 9.9968374e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['let', 'derail', 'your', 'get', 'a', 'text', 'every', 'morn',\n",
              "         'when', 'you', 'wake', 'up', 'with', 'the', 'best', 'route', 'to',\n",
              "         '.'], dtype='<U6'),\n",
              "  array([0.9966337 , 0.00336634], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rainstorm', 'destroys', '600', 'houses', 'in', 'yobe',\n",
              "         'rainstorm', 'destroys', '600', 'houses', 'in', 'yobe', 'state',\n",
              "         '.', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([5.9983435e-05, 9.9994004e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['murderer', 'chose', 'not', '2', 'testify', 'in', 'final', 'phase',\n",
              "         '3', 'so', 'he', 'therefore', 'b', 'subject', '2', 'or', 'jury',\n",
              "         'questions'], dtype='<U9'),\n",
              "  array([0.1465104 , 0.85348964], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', '1st', 'time', 'someone', 'blew', 'up', 'my', 'phone', '30',\n",
              "         'times', 'they', 'would', 'be', 'blocked', '.', 'believe', 'it',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([0.7524945, 0.2475055], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['be', 'careful', 'anyone', 'who', 'lives', 'west', 'of',\n",
              "         'beaverton', '.', 'forest', 'grove', 'has', 'a', 'rapidly',\n",
              "         'spreading', 'fire', 'heading', 'east'], dtype='<U9'),\n",
              "  array([3.1633076e-04, 9.9968374e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['we', 'are', 'having', 'forest', 'fires', 'out', 'here', 'in',\n",
              "         'but', 'the', 'only', 'fire', 'you', 'should', 'watch', 'for',\n",
              "         'is', '.'], dtype='<U6'),\n",
              "  array([0.00840963, 0.99159044], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['air', 'group', 'is', 'here', 'to', 'the', 'we', 'have', '24/7',\n",
              "         'emergency', 'learn', 'more', 'about', 'it', 'here', '-', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.90052605, 0.09947401], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', 'offensive', 'reddit',\n",
              "         'co-founder', 'and', 'ceo', 'steve', 'huffman', 'has', 'unveiled',\n",
              "         'more', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.99157894, 0.00842107], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['two', 'people', 'dead', '60', 'houses', 'destroyed', 'in', 'two',\n",
              "         'people', 'have', 'been', 'reportedly', 'killed', 'an', '.', '.',\n",
              "         '.', '.'], dtype='<U10'),\n",
              "  array([2.3653982e-04, 9.9976343e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['24', 'killed', 'in', 'two', 'simultaneous', 'rail', 'crash', 'as',\n",
              "         'acute', 'floods', 'derail', 'the', 'two', 'trains', '.', '.', '.',\n",
              "         '.'], dtype='<U12'),\n",
              "  array([1.21009594e-04, 9.99879003e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dr', '.', 'what', 'may', 'have', 'caused', 'a', 'metro', 'train',\n",
              "         'to', 'derail', 'in', 'downtown', 'd', '.', 'c', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00122204, 0.9987779 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bomb', 'squad', 'set', 'to', 'detonate', 'backpack', 'antioch',\n",
              "         'tenn', '.', 'theater', 'gunman', 'had', 'on', 'him', 'officials',\n",
              "         'say', '-', '.'], dtype='<U9'),\n",
              "  array([0.00233307, 0.99766695], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['happy', 'birthday', 'big', 'i', 'miss', 'you', 'girl', 'hope',\n",
              "         'you', 'have', 'a', 'bomb', 'one', '?', '?', '?', '?', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9914813 , 0.00851872], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', 'offensive', 'reddit',\n",
              "         'co-founder', 'and', 'ceo', 'steve', 'huffman', 'has', 'unveiled',\n",
              "         'more', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.99157894, 0.00842107], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['then', 'you', 'have', 'rise', 'of', 'coates', 'charleston',\n",
              "         'massacre', 'walter', 'scott', 'and', 'black', 'twitter', 'more',\n",
              "         'broadly', 'as', 'well', '.'], dtype='<U10'),\n",
              "  array([0.06618094, 0.9338191 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['obviously', 'aware', 'that', 'not', 'all', 'as', 'are', 'from',\n",
              "         'countries', 'we', 'have', 'bombed', 'but', 'a', 'lot', 'are',\n",
              "         'fleeing', 'conflict'], dtype='<U9'),\n",
              "  array([0.01361519, 0.9863848 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'liked', 'a', 'video', '.', 'homeless', 'dog', 'living', 'in',\n",
              "         'a', 'cardboard', 'box', 'gets', 'rescued', ';', 'has', 'a',\n",
              "         'heartwarming'], dtype='<U12'),\n",
              "  array([0.83661264, 0.1633873 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['severe', 'thunderstorm', 'warnings', 'have', 'been', 'cancelled',\n",
              "         'in', 'central', 'oklahoma', '.', 'still', 'expect', '50', 'mph',\n",
              "         'winds', 'penny', 'sized', 'hail'], dtype='<U12'),\n",
              "  array([3.1081907e-04, 9.9968922e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['islamic', 'state', 'claims', 'suicide', 'bombing', 'at', 'saudi',\n",
              "         'arabian', 'ten', 'members', 'of', 'emergency', 'service', '.',\n",
              "         '.', '.', '.', 'via'], dtype='<U9'),\n",
              "  array([4.3322117e-04, 9.9956673e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['today', 'is', 'the', 'day', 'hiroshima', 'got', 'atomic', 'bomb',\n",
              "         '70', 'years', 'ago', '.', '-', 'the', 'of', 'atomic', 'bombing',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([4.5968676e-07, 9.9999952e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['fallen', 'powerlines', 'on', 'fire', 'crews', 'have', 'evacuated',\n",
              "         'up', 'to', '30', 'passengers', 'who', 'were', 'tr', '.', '.', '.',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([2.4607137e-04, 9.9975389e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['ok', 'ok', 'what', 'if', 'i', 'make', 'the', 'close', 'quarters',\n",
              "         'an', 'abandoned', 'cabin', 'in', 'the', 'woods', 'in', 'a',\n",
              "         'thunderstorm'], dtype='<U12'),\n",
              "  array([0.00148158, 0.9985184 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['why', 'did', 'god', 'order', 'obliteration', 'of', 'ancient',\n",
              "         'canaanites', '?', '.', 'via', 'is', 'the', 'downfall', 'of', 'a',\n",
              "         'society', '.'], dtype='<U12'),\n",
              "  array([0.9984792 , 0.00152077], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['not', 'even', 'the', 'berlin', 'wall', 'survived', 'the', 'i',\n",
              "         'ever', 'be', 'a', 'generation', 'like', 'the', '.', '.', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.96573067, 0.03426931], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['so', 'yeah', 'is', 'still', 'lots', 'of', 'fun', 'and', 'default',\n",
              "         'jr', 'is', 'still', 'the', 'only', 'weapon', 'layout', 'good',\n",
              "         'at'], dtype='<U7'),\n",
              "  array([0.99768806, 0.00231191], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['debris', 'confirmed', 'from', ';', 'relatives', 'hope', 'for',\n",
              "         'discovery', 'of', 'crash', 'malaysian', 'officials', 'confirm',\n",
              "         'a', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.8448406e-04, 9.9971551e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['burst', 'water', 'pipe', 'floods', 'apartments', 'at', 'nycha',\n",
              "         'senior', 'center', '-', 'water', 'pipe', 'floods', 'a', '.', '.',\n",
              "         '.', '.'], dtype='<U10'),\n",
              "  array([0.00160881, 0.9983912 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['cherokee', 'road', 'and', 'road', '22', 'sisters', 'there', 'are',\n",
              "         'two', 'roads', 'closed', 'to', 'the', 'general', '.', '.', '.',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([0.00951021, 0.99048984], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['17', 'people', 'displaced', 'after', 'fire', 'tore', 'through',\n",
              "         '2', 'apartment', 'buildings', 'on', 'second', 'street', 'in',\n",
              "         'manchester', '.', '--', '.'], dtype='<U10'),\n",
              "  array([0.00273908, 0.9972609 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['get', 'on', 'south', '.', '.', '.', 'huge', 'wreck', 'and',\n",
              "         'airlift', 'and', 'maybe', 'some', 'deaths', 'interstate', 'is',\n",
              "         'completely', 'blocked'], dtype='<U10'),\n",
              "  array([7.314637e-04, 9.992686e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hundreds', 'of', 'migrants', 'feared', 'drowned', 'off',\n",
              "         'migrants', 'stand', 'next', 'to', 'their', 'tent', 'at', 'a',\n",
              "         'camp', 'set', 'near', '.'], dtype='<U8'),\n",
              "  array([7.4172637e-04, 9.9925822e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['some', 'jewish', 'ppl', 'agree', 'tht', 'israel', 'is', 'a',\n",
              "         'bully', 'nd', 'a', 'terrorist', 'state', 'killin', 'palestine',\n",
              "         'kids', 'nd', 'women'], dtype='<U9'),\n",
              "  array([3.4050806e-04, 9.9965954e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'walking', 'dead', '.', 'good', 'characters', ';', 'story',\n",
              "         'but', 'no', 'real', 'gameplay', 'and', 'too', 'many',\n",
              "         'performance', 'issues', '.'], dtype='<U11'),\n",
              "  array([0.9930737, 0.0069263], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['-', 'british', 'trekkers', 'rescued', 'amid', 'flash', 'floods',\n",
              "         'in', 'a', 'group', 'of', 'british', 'tr', '.', '.', '.', '.', '-'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00128972, 0.9987103 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['are', 'you', 'another', '?', 'if', 'you', 'are', 'i', 'will',\n",
              "         'have', 'to', 'detonate', 'you', 'with', 'my', 'killer', 'queen',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([0.99792504, 0.0020749 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['24', 'killed', 'in', 'two', 'simultaneous', 'rail', 'crash', 'as',\n",
              "         'acute', 'floods', 'derail', 'the', 'two', 'trains', '.', '.', '.',\n",
              "         '.'], dtype='<U12'),\n",
              "  array([1.21009594e-04, 9.99879003e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dust', 'in', 'the', 'paratroopers', 'move', 'to', 'a', 'loading',\n",
              "         'zone', 'during', 'a', 'dust', 'storm', 'in', 'support', 'of',\n",
              "         'operation', '.'], dtype='<U12'),\n",
              "  array([0.00754715, 0.9924528 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['storm', 'blitzes', 'traverse', 'city', 'disrupts', 'management',\n",
              "         'briefing', 'a', 'violent', 'summer', 'storm', 'blitzed',\n",
              "         'through', 'tra', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.00778698, 0.99221295], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['fallen', 'powerlines', 'on', 'fire', 'crews', 'have', 'evacuated',\n",
              "         'up', 'to', '30', 'passengers', 'who', 'were', 'tr', '.', '.', '.',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([2.4607137e-04, 9.9975389e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['three', 'days', 'off', 'from', 'work', 'and', 'pretty', 'much',\n",
              "         'all', 'been', 'wrecked', 'shoutout', 'to', 'my', 'family', 'for',\n",
              "         'that', 'one'], dtype='<U8'),\n",
              "  array([0.9885345 , 0.01146548], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['families', 'to', 'sue', 'over', 'more', 'than', '40', 'families',\n",
              "         'affected', 'by', 'the', 'fatal', 'outbreak', 'of', '.', '.', '.',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([5.3445896e-04, 9.9946553e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'lord', 'the', 'soul', 'of', 'his', 'and', 'none', 'of',\n",
              "         'them', 'that', 'trust', 'in', 'him', 'shall', 'be', 'desolate',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([9.9964309e-01, 3.5686445e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['bloody', 'on', 'july', '20', 'a', 'suicide', 'bombing', 'in',\n",
              "         'turkey', 'took', 'the', 'lives', 'of', '31', 'socialists', 'in',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([1.4016301e-04, 9.9985981e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'did', 'we', 'have', 'a', 'hurricane', 'tornado', 'tsunami',\n",
              "         '?', 'someone', 'please', 'tell', 'me', 'what', 'the', 'hell',\n",
              "         'happened'], dtype='<U9'),\n",
              "  array([0.00299366, 0.99700636], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hiroshima', 'and', 'nagasaki', 'i', 'remember', 'all', 'those',\n",
              "         'killed', 'in', 'alleged', 'us', 'war', 'crimes', 'using',\n",
              "         'nuclear', 'weapons', '.'], dtype='<U9'),\n",
              "  array([2.4743806e-05, 9.9997520e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['spot', 'flood', 'combo', 'curved', 'cree', 'led', 'work', 'light',\n",
              "         'bar', '4x4', 'offroad', 'fog', 'lamp', '-', 'full', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.88026845, 0.11973155], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['-', 'two', 'families', 'displaced', 'by', 'mechanicsburg',\n",
              "         'blaze', '-', 'no', 'one', 'was', 'injured', 'in', 'the', 'fire',\n",
              "         '.', '.'], dtype='<U13'),\n",
              "  array([0.00155442, 0.9984456 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['does', 'homeowners', 'insurance', 'cover', 'water', 'damage', '?',\n",
              "         'here', 'are', 'some', 'good', 'things', 'to', 'know', '.', '.',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([0.00661167, 0.9933883 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['aquarium', 'ornament', 'wreck', 'sailing', 'boat', 'sunk', 'ship',\n",
              "         'destroyer', 'fish', 'tank', 'cave', 'decor', '-', 'full', 'read',\n",
              "         '.', '.'], dtype='<U9'),\n",
              "  array([0.00774077, 0.9922592 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['service', 'on', 'the', 'green', 'line', 'has', 'resumed', 'after',\n",
              "         'an', 'earlier', 'derailment', 'near', 'garfield', 'with',\n",
              "         'residual', 'delays', '.'], dtype='<U10'),\n",
              "  array([2.1971214e-04, 9.9978036e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['do', 'he', 'love', 'me', 'do', 'he', 'love', 'me', 'not', 'i',\n",
              "         'a', 'playa', 'i', 'just', 'crush', 'a', 'lot'], dtype='<U5'),\n",
              "  array([0.98681784, 0.01318217], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['udhampur', 'terror', 'militants', 'attack', 'police', 'post', '2',\n",
              "         'suspected', 'militants', 'tonight', 'attacked', 'a', 'p', '.',\n",
              "         '.', '.', '.'], dtype='<U9'),\n",
              "  array([9.047682e-04, 9.990952e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hollywood', 'movie', 'about', 'trapped', 'miners', 'released',\n",
              "         'in', 'hollywood', 'movie', 'about', 'trapped', 'miners',\n",
              "         'starring', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.6718118 , 0.32818818], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['with', 'a', 'two-out', 'single', 'up', 'the', 'middle', '.',\n",
              "         'fourth', 'hit', 'of', 'the', 'night', 'for', 'altamonte',\n",
              "         'springs', '.'], dtype='<U9'),\n",
              "  array([0.99322623, 0.00677376], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['were', 'you', 'opening', 'regular', 'or', 'master', 'packs', '?',\n",
              "         'mil', 'credits', 'into', 'light', 'sure', 'about', 'those',\n",
              "         'odds', '?'], dtype='<U7'),\n",
              "  array([0.997106  , 0.00289399], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['dysfunctional', 'mcconnell', 'plans', 'on', 'holding', 'judicial',\n",
              "         'nominations', 'hostage', '.', 'another', 'example', 'of', 'how',\n",
              "         'gop', 'govern', '.', '.'], dtype='<U13'),\n",
              "  array([0.7197404 , 0.28025964], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'fire', 'in', 'the', 'catalinas', '.', 'looks', 'kinda',\n",
              "         'cool', '.', 'this', 'picture', 'do', 'it', 'justice', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.27662098, 0.723379  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['if', 'my', 'monty', 'python', 'is', 'up', 'to', 'date', 'as',\n",
              "         'bloody', 'far', 'as', 'he', 'wants', 'to', 'go', '.'], dtype='<U6'),\n",
              "  array([0.97482693, 0.0251731 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['louis', 'vuitton', 'monogram', 'sophie', 'limited', 'edition',\n",
              "         'clutch', 'cross', 'body', 'bag', '-', 'full', 'read', 'by',\n",
              "         'ebay', '.', '.'], dtype='<U8'),\n",
              "  array([0.98354256, 0.01645748], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['louis', 'vuitton', 'monogram', 'sophie', 'limited', 'edition',\n",
              "         'clutch', 'cross', 'body', 'bag', '-', 'full', 'read', 'by',\n",
              "         'ebay', '.', '.'], dtype='<U8'),\n",
              "  array([0.98354256, 0.01645748], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'most', 'generous', 'bride', 'on', 'couple', 'feeds',\n",
              "         '4000', 'syrian', 'refugees', 'on', 'their', 'wedding', 'day', '.',\n",
              "         'via', 'love'], dtype='<U8'),\n",
              "  array([0.57450616, 0.42549384], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['haha', 'so', 'would', 'you', 'say', 'its', 'so', 'hot', 'your',\n",
              "         'balls', 'are', 'burning', 'off', '?', '?', '?', '?'], dtype='<U7'),\n",
              "  array([0.3449114 , 0.65508866], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rt', 'fedex', 'no', 'longer', 'to', 'transport', 'research',\n",
              "         'specimens', 'of', 'bioterror', 'pathogens', 'in', 'wake', 'of',\n",
              "         'anthrax', 'lab', 'mishaps'], dtype='<U9'),\n",
              "  array([0.8645559 , 0.13544403], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'just', 'nearly', 'crashed', 'my', 'car', 'typing', 'rudd',\n",
              "         'attacked', 'by', 'flying', 'into', 'notes', 'on', 'my', 'phone',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([0.7628646 , 0.23713541], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['cat', 'of', 'nine', 'irons', 'this', 'nightmarishly', 'brutal',\n",
              "         'weapon', 'is', 'used', 'in', 'ritualistic', 'country', 'club',\n",
              "         'de', '.', '.'], dtype='<U13'),\n",
              "  array([8.2802866e-04, 9.9917197e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['crazy', 'mom', 'threw', 'teen', 'daughter', 'a', 'nude',\n",
              "         'twister', 'sex', 'party', 'according', 'to', 'her', 'more',\n",
              "         'pics', '.', '.'], dtype='<U9'),\n",
              "  array([0.98903847, 0.01096153], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['for', 'some', 'reason', 'im', 'listening', 'to', 'curfew',\n",
              "         'overtime', 'and', 'stuck', 'in', 'a', 'kodak', 'over', 'and',\n",
              "         'over', 'again'], dtype='<U9'),\n",
              "  array([0.99652123, 0.00347878], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['looks', 'like', 'a', 'bowl', 'of', 'weather', 'cereal', '.',\n",
              "         'sugar', 'stays', 'crunchy', 'even', 'in', 'milk', '.', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.9769176 , 0.02308241], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['talk', 'some', 'more', 'about', 'your', 'goof', 'guild',\n",
              "         'saunders', '.', 'come', 'right', 'up', 'here', 'on', 'stage', '.',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([0.9419965 , 0.05800346], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['4', 'dead', 'dozens', 'injured', 'in', 'gaza', 'blast', 'near',\n",
              "         'house', 'leveled', 'in', 'summer', 'war', '-', 'washington',\n",
              "         'post', '.'], dtype='<U10'),\n",
              "  array([3.6622453e-04, 9.9963379e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['sundays', 'during', 'football', 'about', '9', 'am', '-', '11',\n",
              "         'pm', 'women', 'even', 'log', 'be', 'a', 'complete', 'war', 'zone'],\n",
              "        dtype='<U8'),\n",
              "  array([0.99408925, 0.00591077], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['pakistan', 'disowned', 'kasab', 'now', 'disowns', 'state', 'of',\n",
              "         'denial', '?', ':', 'naved', 'the', 'terrorist', 'captured',\n",
              "         'alive', 'after', '.'], dtype='<U9'),\n",
              "  array([2.721494e-04, 9.997278e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'have', 'the', 'biggest', 'crush', 'on', 'you', ';', 'i',\n",
              "         'dont', 'know', 'if', 'ever', 'know', 'it', '?', '?'], dtype='<U7'),\n",
              "  array([0.9872442 , 0.01275576], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array([';', ';', 'aftershock', ':', 'protect', 'yourself', 'and',\n",
              "         'profit', 'in', 'the', 'next', 'global', 'financial', '.', '.',\n",
              "         '.', '.'], dtype='<U10'),\n",
              "  array([0.98279715, 0.01720283], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['we', 'even', 'want', 'to', 'think', 'about', 'it', 'or',\n",
              "         'mention', 'it', 'so', 'not', 'do', 'anything', 'that', 'leads',\n",
              "         'to'], dtype='<U8'),\n",
              "  array([0.85176027, 0.14823973], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'see', 'the', 'option', 'to', 'buy', 'the', 'full',\n",
              "         'collapse', 'vinyl', 'with', 'tee', 'bundle', 'just', 'the',\n",
              "         'waiting', '?'], dtype='<U8'),\n",
              "  array([0.9577864, 0.0422136], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['yet', 'another', 'company', 'trying', 'to', 'censor', 'the',\n",
              "         'internet', '.', 'reddit', 'has', 'started', 'to', 'quarantine',\n",
              "         'their', '.', '#cc'], dtype='<U10'),\n",
              "  array([9.9980241e-01, 1.9764791e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['one', 'direction', 'is', 'taking', 'a', 'break', 'after', 'this',\n",
              "         'next', 'album', '.', 'my', 'heart', 'has', 'sunk', 'it', 'hurts',\n",
              "         'and', 'very', 'upset', '.', 'they', 'deserve', 'a', 'break', '.',\n",
              "         'my', 'heart', 'hurts'], dtype='<U9'),\n",
              "  array([0.9508132 , 0.04918684], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['guys', 'he', 'can', 'run', 'so', 'fast', 'he', 'creates', 'a',\n",
              "         'tornado', 'without', 'breaking', 'a', 'sweat', '.', 'he', 'makes',\n",
              "         'superman', 'look', 'like', 'a', 'slowpoke', '.', 'he', 'can',\n",
              "         'be', 'a', 'poc', '.'], dtype='<U8'),\n",
              "  array([0.9649527 , 0.03504728], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['niggas', 'favorite', 'question', 'is', 'why', 'you', 'single',\n",
              "         '?', '?', 'bitch', 'i', 'know', 'pussy', 'too', 'wet', 'almost',\n",
              "         'drowned', 'a', 'nigga', '?', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?', '?'], dtype='<U8'),\n",
              "  array([0.99857485, 0.00142512], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'pray', 'any', 'attack', 'of', 'the', 'enemy', '2', 'derail',\n",
              "         'ur', 'destiny', 'is', 'blocked', 'by', 'the', 'lord', ';', 'that',\n",
              "         'he', 'floods', 'ur', 'life', 'blessings'], dtype='<U9'),\n",
              "  array([0.86733264, 0.13266738], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['dad', '.', 'i', 'chase', 'you', 'constantly', ';', 'all', 'the',\n",
              "         'time', 'but', 'frequently', '.', 'with', 'a', 'great', 'deal',\n",
              "         'of', 'danger', 'and', 'distraction', ';', '3'], dtype='<U11'),\n",
              "  array([0.9730472 , 0.02695278], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['businesses', 'are', 'deluged', 'with', '.', 'make', 'yours',\n",
              "         'stand', 'out', 'with', 'colour', 'or', 'shape', 'and', 'to',\n",
              "         'rise', 'to', 'the', 'top', 'of', 'the', 'pile', '.'], dtype='<U10'),\n",
              "  array([0.99839056, 0.00160943], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['could', 'a', 'drone', 'cause', 'an', 'airplane', 'accident', '?',\n",
              "         'pilots', 'worried', 'about', 'use', 'of', 'drones', 'esp', '.',\n",
              "         'in', 'close', 'vicinity', 'of', 'airports', '.', '#'], dtype='<U8'),\n",
              "  array([0.00565937, 0.99434066], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['st', 'steel', 'coffee', 'exploded', 'this', 'am', 'with', 'loud',\n",
              "         'bang', 'hot', 'coffee', ';', 'grounds', 'shot', 'over', 'table',\n",
              "         'clean', 'crockery', 'phone', 'tablet', '.', 'how', '?'],\n",
              "        dtype='<U8'),\n",
              "  array([0.03512534, 0.9648747 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array([':', 'general', 'raheel', 'sharif', 'visits', 'he', 'also',\n",
              "         'lauded', 'the', 'efforts', 'of', 'fwo', 'army', 'troops', 'and',\n",
              "         'army', 'aviation', 'in', 'rescue', 'opera', '.', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([2.5693295e-04, 9.9974304e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['been', 'raining', 'since', 'you', 'left', 'me', 'now', 'drowning',\n",
              "         'in', 'the', 'flood', 'you', 'see', 'always', 'been', 'a',\n",
              "         'fighter', 'but', 'without', 'you', 'i', 'give', 'up'], dtype='<U8'),\n",
              "  array([0.9652624 , 0.03473761], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['u', 'better', 'learn', 'derivative', 'of', 'formula', 'seismic',\n",
              "         'rather', 'than', 'thinking', 'about', 'things', 'like', 'that',\n",
              "         'or', 'you', 'are', 'a', 'things', 'like', 'that', '?', 'haha'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9986066 , 0.00139344], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['but', 'if', 'you', 'build', 'an', 'army', 'of', '100', 'dogs',\n",
              "         'and', 'their', 'leader', 'is', 'a', 'lion', 'all', 'dogs', 'will',\n",
              "         'fight', 'like', 'a', 'lion', '.'], dtype='<U6'),\n",
              "  array([0.01398453, 0.98601544], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wipp', 'facility', 'in', 'nm', 'investigating', 'a', 'site',\n",
              "         'filter', 'radiation', 'reading', ';', 'has', 'activated', 'its',\n",
              "         'emergency', 'ops', 'center', ';', 'says', 'no', 'offsite',\n",
              "         'release', '.'], dtype='<U13'),\n",
              "  array([0.9371466 , 0.06285339], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['he', 'thrusts', 'a', 'little', 'more', 'before', 'he', 'jams',\n",
              "         'his', 'cock', 'deep', 'inside', 'her', 'flooding', 'her', 'womb',\n",
              "         'and', 'pussy', 'with', 'his', 'hot', 'thick', 'cum'], dtype='<U8'),\n",
              "  array([0.8730103 , 0.12698977], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['this', 'sounds', 'like', 'a', 'song', 'you', 'would', 'hear',\n",
              "         'in', 'a', 'movie', 'where', 'they', 'are', 'walking', 'away',\n",
              "         'from', 'burning', 'buildings', 'and', 'cars', 'and', 'shit'],\n",
              "        dtype='<U9'),\n",
              "  array([0.9864314 , 0.01356856], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['businesses', 'are', 'deluged', 'with', 'invoices', '.', 'make',\n",
              "         'yours', 'stand', 'with', 'or', 'shape', 'and', 'likely', 'to',\n",
              "         'rise', 'to', 'the', 'top', 'of', 'the', 'pile', '.'], dtype='<U10'),\n",
              "  array([0.9980009 , 0.00199904], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['play', 'the', 'floor', 'is', 'lava', 'but', 'instead', 'of',\n",
              "         'just', 'the', 'floor', 'play', 'with', 'the', 'whole', 'world',\n",
              "         'and', 'never', 'get', 'out', 'of', 'bed', '.'], dtype='<U7'),\n",
              "  array([0.95634544, 0.04365454], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['our', 'builder', 'is', 'having', 'a', 'dental', 'emergency', '.',\n",
              "         'which', 'has', 'ruined', 'my', 'plan', 'to', 'emotionally',\n",
              "         'blackmail', 'him', 'this', 'afternoon', 'with', 'my', 'bump', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.04068957, 0.9593105 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array([';', 'the', 'stat', 'of', 'high', 'auto', 'deaths', 'applies',\n",
              "         'to', 'children', 'in', 'a', 'vehicle', '.', 'i', 'guess', 'they',\n",
              "         'can', 'out', 'run', 'better', 'than', 'adult'], dtype='<U8'),\n",
              "  array([0.9974801, 0.0025199], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['jun', '2015', '.', 'yemenis', 'search', 'for', 'survivors',\n",
              "         'under', 'the', 'rubble', 'of', 'houses', 'in', 'the', 'old',\n",
              "         'city', 'of', 'following', 'an', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00282501, 0.997175  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['stock', 'market', 'are', 'there', 'gems', 'in', 'the', 'rubble',\n",
              "         '?', ':', 'stock', 'market', 'crash', 'this', 'summer', 'h', '.',\n",
              "         '.', '.', '.', 'by', '.', 'forbes'], dtype='<U6'),\n",
              "  array([0.9948487 , 0.00515129], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['literally', 'just', 'picked', 'up', 'her', 'new', 'car', 'today',\n",
              "         'and', 'flattened', 'the', 'battery', 'already', 'trying', 'to',\n",
              "         'sort', 'out', 'the', 'bluetooth', '?', '?', '?', '?'], dtype='<U9'),\n",
              "  array([0.9828158 , 0.01718421], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'reputation', 'and', 'prestige', 'has', 'sunk', 'ever',\n",
              "         'lower', 'and', 'prosser', 'who', 'has', 'served', 'on', 'the',\n",
              "         'court', 'since', '1998', 'has', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.98473907, 0.01526093], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['as', 'of', 'the', '6-month', 'mark', 'there', 'were', 'a',\n",
              "         'total', 'of', '662', 'fatalities', '-', '114', 'more', 'than',\n",
              "         'the', 'first', 'half', 'of', 'last', 'year', '.'], dtype='<U10'),\n",
              "  array([0.01380081, 0.98619914], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['think', 'become', 'a', 'businessman', 'a', 'demolish', 'a',\n",
              "         'community', 'centre', 'and', 'build', 'condos', 'on', 'it', 'but',\n",
              "         'foiled', 'by', 'a', 'troupe', 'of', 'multi-racial',\n",
              "         'breakdancers', '.'], dtype='<U12'),\n",
              "  array([0.9844906 , 0.01550939], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'just', 'remembered', 'the', 'that', 'burned', 'down', 'used',\n",
              "         'to', 'have', 'the', 'coolest', 'play', 'ground', ';', 'the',\n",
              "         'new', 'one', 'got', 'shit', 'but', 'video', 'games'], dtype='<U10'),\n",
              "  array([0.9688158 , 0.03118416], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['bigamist', 'and', 'his', 'wife', 'are', 'charged', 'in', 'the',\n",
              "         'deaths', 'of', 'his', 'pregnant', 'wife', 'her', 'child', '8',\n",
              "         'her', 'mother', 'her', 'nephew', '1', 'and', 'their'], dtype='<U8'),\n",
              "  array([0.9088709, 0.0911291], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['we', 'allow', 'farrakhan', 'to', 'to', 'challenge', '10000',\n",
              "         'males', 'to', 'rise', 'up', ';', 'commit', 'mass', 'murder', 'as',\n",
              "         'he', 'just', 'did', 'in', 'miami', '?', '.'], dtype='<U9'),\n",
              "  array([0.02038856, 0.97961146], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'agree', 'but', 'i', 'knew', 'be', 'going', 'to', 'the',\n",
              "         'deep', 'roads', 'again', 'because', 'they', 'found', 'blight',\n",
              "         'in', 'red', '.', 'it', 'over', 'yet', ';', ';'], dtype='<U7'),\n",
              "  array([0.98204136, 0.01795865], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['we', 'know', 'this', 'is', 'bad', 'for', 'the', 'bees', '-',\n",
              "         'give', 'in', 'to', 'pressure', 'from', 'short', 'term', 'profit',\n",
              "         'obsessed', 'chemical', 'companies', '.', '.', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.9962528, 0.0037472], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'back', 'to', 'school', 'commercial', 'came', 'on', 'and',\n",
              "         'my', 'sister', 'had', 'a', 'meltdown', '.', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?', '?', '?'], dtype='<U10'),\n",
              "  array([0.99874425, 0.00125568], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['why', 'do', 'u', 'ruin', 'everything', '?', 'u', 'ruined', 'the',\n",
              "         'sour', 'cream', 'and', 'u', 'put', 'a', 'brick', 'of', 'cheese',\n",
              "         'in', 'the', 'freezer', '.', '.', 'dummy'], dtype='<U10'),\n",
              "  array([0.9955533 , 0.00444667], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['if', 'bored', 'with', 'life', 'if', 'you', 'get', 'up', 'every',\n",
              "         'morning', 'with', 'a', 'burning', 'desire', 'to', 'do', 'things',\n",
              "         '-', 'you', 'have', 'enough', 'goals', '.', 'holtz'], dtype='<U7'),\n",
              "  array([0.99791306, 0.00208697], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['at', 'the', 'lake', 'a', 'dead', 'poor', 'little', 'guy', 'i',\n",
              "         'wonder', 'what', 'happened', 'maybe', 'it', 'drowned', 'wtf', '?',\n",
              "         '?', '?', '?', '?', '?', '?', '?'], dtype='<U8'),\n",
              "  array([0.9225369 , 0.07746306], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'person', 'who', 'blows', 'himself', 'up', 'to', 'kill',\n",
              "         'others', 'has', 'no', 'life', 'in', 'heaven', 'because', 'his',\n",
              "         'ethereal', 'body', 'gets', 'destroyed', 'by', 'doing', 'it', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.9535436 , 0.04645638], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i-10', 'eb', 'at', 'ms', 'line', 'offloading', 'the', 'hazardous',\n",
              "         'material', 'is', 'going', 'much', 'slower', 'than', 'expected',\n",
              "         '.', 'road', 'could', 'stay', 'closed', 'until', 'tomorrow', 'am',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([0.00439374, 0.99560624], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['have', 'kids', 'cuz', 'i', 'got', 'in', 'a', 'bicycle',\n",
              "         'accident', ';', 'split', 'my', 'testicles', '.', 'impossible',\n",
              "         'for', 'me', 'to', 'have', 'michael', 'you', 'are', 'the',\n",
              "         'father'], dtype='<U10'),\n",
              "  array([0.97244185, 0.02755818], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['how', 'long', 'o', 'lord', 'the', 'sixth', 'seal', 'opens', 'the',\n",
              "         'events', 'of', 'revelation', '12', '.', 'the', 'political',\n",
              "         'upheaval', 'in', 'the', 'roman', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.00557986, 0.9944201 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['most', 'members', 'of', 'congress', 'who', 'want', 'this', 'deal',\n",
              "         'have', 'any', 'kids', 'who', 'would', 'b', 'coming', 'home', 'in',\n",
              "         'body', 'bags', '.', 'war', 'makes', 'them', 'money'], dtype='<U8'),\n",
              "  array([0.9951493 , 0.00485075], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['w/o', 'giving', 'up', 'too', 'much', 'of', 'nana', 'france',\n",
              "         'reminds', 'me', 'of', 'america', 'right', 'before', 'the', 'war',\n",
              "         'in', 'iraq', '.', 'a', 'restlessness', 'leading', 'to',\n",
              "         'disaster'], dtype='<U12'),\n",
              "  array([3.4150464e-04, 9.9965847e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'will', 'never', 'support', 'looting', 'or', 'the', 'burning',\n",
              "         'of', 'buildings', 'but', 'when', 'seeing', 'the', 'people',\n",
              "         'fight', 'back', 'against', 'the', 'police', '.', 'i', 'was',\n",
              "         'proud'], dtype='<U9'),\n",
              "  array([0.01748502, 0.982515  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'would', 'like', 'to', 'electrocute', 'everyone', 'who',\n",
              "         'uses', 'the', 'word', 'in', 'connection', 'with', 'income', 'tax',\n",
              "         'policies', '.', '-', 'william', 'f', '.', 'buckley', 'jr', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.9981622 , 0.00183785], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sweater', 'stretcher', '.', '.'], dtype='<U9'),\n",
              "  array([0.94976676, 0.05023327], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['trapped', 'in', 'its', 'disappearance'], dtype='<U13'),\n",
              "  array([0.55388397, 0.44611606], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['some', 'crazy', 'lightning', 'outside'], dtype='<U9'),\n",
              "  array([0.88738495, 0.11261498], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['anti', 'collision', '.', 'via'], dtype='<U9'),\n",
              "  array([0.9949563 , 0.00504373], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['tent', 'collapse', 'story', '.'], dtype='<U8'),\n",
              "  array([0.39680997, 0.60319006], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['screamed', ';', ';', '.'], dtype='<U8'),\n",
              "  array([0.99136823, 0.00863172], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['caught', 'in', 'a', 'landslide'], dtype='<U9'),\n",
              "  array([0.01606797, 0.983932  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['fear', '-', 'youtube', '.'], dtype='<U7'),\n",
              "  array([0.998123  , 0.00187702], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hungry', 'as', 'a', 'hostage'], dtype='<U7'),\n",
              "  array([0.9972429 , 0.00275706], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['earthquake', 'drill', '?', '?'], dtype='<U10'),\n",
              "  array([0.3339212 , 0.66607875], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hit', 'me', 'up', 'and'], dtype='<U3'),\n",
              "  array([0.99006534, 0.00993469], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['straight', 'body', 'bagging', '.'], dtype='<U8'),\n",
              "  array([0.9982576 , 0.00174239], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['uncontrollable', 'meltdown', 'number', '2'], dtype='<U14'),\n",
              "  array([0.8982449 , 0.10175502], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['first', 'man', 'gets', 'the', 'oyster', 'the', 'second', 'man',\n",
              "         'gets', 'the', 'shell', '.', \"'\", 'andrew', 'carnegie'],\n",
              "        dtype='<U8'),\n",
              "  array([9.998222e-01, 1.778762e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['pakpattan', 'city', 'man', 'electrocuted', 'from', 'our',\n",
              "         'correspondent', 'a', 'man', 'was', 'electrocuted', '.', '.', '.',\n",
              "         '.'], dtype='<U13'),\n",
              "  array([0.00609916, 0.9939009 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['crushed', 'the', 'gym', 'then', 'crushed', 'a', 'butterfinger',\n",
              "         'flurry', 'clearly', 'my', 'priorities', 'are', 'straight', '?',\n",
              "         '?'], dtype='<U12'),\n",
              "  array([0.9968407, 0.0031593], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['new', 'de', 'thomas', 'on', 'being', 'a', 'cyclone', '-', 'ames',\n",
              "         'ames', 'tribune', 'new', 'de', 'thomas', '.'], dtype='<U7'),\n",
              "  array([0.9956201 , 0.00437988], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['back', 'to', 'the', 'future', 'in', 'how', 'cyclone', 'pam',\n",
              "         'has', 'encouraged', 'traditional', 'ways', 'of', '.', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.09208256, 0.90791744], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'had', '2', 'regular', 'coffees', 'and', 'a', 'rockstar', '+',\n",
              "         'coffee', 'today', 'and', 'still', 'tired', '.'], dtype='<U8'),\n",
              "  array([0.99598616, 0.0040138 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['to', 'what', 'degree', 'has', 'efforts', 'to', 'institute',\n",
              "         'sharia', 'law', 'exacerbated', 'the', 'california', 'wild',\n",
              "         'fires', '?'], dtype='<U11'),\n",
              "  array([1.4188265e-05, 9.9998581e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['1', 'of', 'the', 'major', 'reason', 'of', 'suicide', 'bombing',\n",
              "         'is', 'the', 'absence', 'of', 'sexual', 'interactions', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([0.02373773, 0.9762623 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['this', 'guy', 'just', 'made', 'me', 'his', 'woman', 'crush', '?',\n",
              "         '?', 'first', 'one', 'ever', '?', '?'], dtype='<U5'),\n",
              "  array([0.9810946 , 0.01890546], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['traffic', 'collision', '-', 'no', 'i5', 's', 'at', 'i5', 's',\n",
              "         '43rd', 'ave', 'offramp', 'south', 'sac', '.'], dtype='<U9'),\n",
              "  array([1.2965083e-05, 9.9998701e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'completely', 'understand', 'because', 'i', 'just', 'woke',\n",
              "         'up', 'like', '15', 'minutes', 'ago', 'and', 'im', 'burning'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9971034 , 0.00289655], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['believe', 'more', 'people', 'in', 'their', 'mid', 'have', 'high',\n",
              "         'blood', 'pressure', '.', 'life', 'is', 'stressful', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.00475158, 0.9952485 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'this', 'storm', 'just', 'came', 'out', 'of', 'no', 'where',\n",
              "         '.', '.', 'fuck', 'me', 'its', 'cool'], dtype='<U5'),\n",
              "  array([0.1110395, 0.8889605], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['oh', 'no', '.', 'the', 'boots', ';', 'hearts', 'social', 'media',\n",
              "         'inundation', 'is', 'starting', '.', 'please', 'no'], dtype='<U10'),\n",
              "  array([0.98733354, 0.01266645], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['ceo', 'stresses', 'that', 'a', 'board', 'revolt', 'at', 'united',\n",
              "         'spirits', 'has', 'not', 'impacted', 'indian', 'operations', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.99578446, 0.00421551], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['online', 'infantryman', 'experimental', 'military', 'training',\n",
              "         'tutorials', 'shower', 'down', 'upon', 'intelligence', 'as',\n",
              "         'regard', '.', '.', '.'], dtype='<U12'),\n",
              "  array([0.9658229 , 0.03417714], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'wish', 'i', 'was', 'good', 'enough', 'to', 'add', 'flames',\n",
              "         'to', 'my', 'nails', 'im', 'on', 'fire'], dtype='<U6'),\n",
              "  array([0.06377253, 0.93622744], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['25', 'killed', 'as', 'express', 'janata', 'express', 'derail',\n",
              "         'in', 'madhya', 'pradesh', ';', 'ex', 'gratia', 'announced', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([6.1580335e-04, 9.9938416e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wait', 'until', 'i', 'tell', 'my', 'college', 'friend', 'who',\n",
              "         'bloody', 'mary', 'too', 'about', 'the', 'drama', 'cd'],\n",
              "        dtype='<U7'),\n",
              "  array([0.9977627, 0.0022373], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['was', 'the', 'forecast', 'i', 'based', 'my', 'dressing', 'on',\n",
              "         '.', 'light', '.', 'rain', '.', 'not', 'incessant'], dtype='<U9'),\n",
              "  array([0.94212884, 0.05787117], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['?', '?', '?', '?', '?', '?', 'how', 'are', 'you', 'going', 'to',\n",
              "         'survive', 'this', 'devastation', '?'], dtype='<U11'),\n",
              "  array([0.09494416, 0.9050559 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['why', 'you', 'so', 'salty', 'and', 'scared', 'when', 'we', 'have',\n",
              "         'a', 'drought', 'like', 'you', 'said', '?'], dtype='<U7'),\n",
              "  array([0.93551314, 0.06448681], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['fedex', 'no', 'longer', 'to', 'transport', 'bioterror', 'germs',\n",
              "         'in', 'wake', 'of', 'anthrax', 'lab', 'mishaps', '.', 'via'],\n",
              "        dtype='<U9'),\n",
              "  array([0.1005626 , 0.89943737], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['gd', 'ideas', '.', '77', 'hard', 'now', 'have', 'almost',\n",
              "         'nothing', 'fear', 'lives', 'with', 'poor', 'fran', 'reed'],\n",
              "        dtype='<U7'),\n",
              "  array([0.9066885 , 0.09331142], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'bar', 'method', 'integrates', 'the', 'fat', 'burning',\n",
              "         'format', 'of', 'interval', 'training', 'the', 'muscle', 'shaping',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([9.9934477e-01, 6.5522903e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'possible', 'new', 'jerseys', 'for', 'the', 'avalanche',\n",
              "         'next', 'year', '.', '?', '?', '?', '?', '.'], dtype='<U9'),\n",
              "  array([0.9963742 , 0.00362584], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['suites', 'offices', 'are', 'coming', 'to', 'bistro', 'the',\n",
              "         'former', 'bistro', 'will', 'soon', 'be', 'demolished', 'to', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.99874425, 0.00125574], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'stephen', 'ave', 'flower', 'pots', 'got', 'a', 'little',\n",
              "         'ripped', 'up', 'in', 'the', 'hailstorm', 'today', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.01616854, 0.9838314 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['update', 'california', 'hwy', '.', '20', 'closed', 'in', 'both',\n",
              "         'directions', 'due', 'to', 'lake', 'county', 'fire', '-'],\n",
              "        dtype='<U10'),\n",
              "  array([2.3444007e-04, 9.9976557e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dt', 'rt', 'col', 'police', 'can', 'catch', 'a', 'pickpocket',\n",
              "         'in', 'liverpool', 'stree', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.07036486, 0.9296351 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['not', 'sure', 'that', 'covering', 'my', 'head', 'in', 'wounds',\n",
              "         'and', 'scabs', 'is', 'the', 'solution', ';', ')'], dtype='<U8'),\n",
              "  array([0.9449752 , 0.05502477], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['railways', 'caught', 'unawares', 'by', 'mp', 'tragedy', ';',\n",
              "         'accident', 'spot', 'never', 'marked', 'as', '-', 'times', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00740734, 0.99259263], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['pic', 'of', 'old', 'pkk', 'suicide', 'bomber', 'who', 'detonated',\n",
              "         'bomb', 'in', 'turkey', 'army', 'trench', 'released', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([1.15000685e-05, 9.99988556e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'trapped', 'this', 'cat', 'in', 'my', 'room', 'and', 'going',\n",
              "         'insane', 'but', 'not', 'leaving', 'too', '.'], dtype='<U7'),\n",
              "  array([0.6271001 , 0.37289992], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['also', 'are', 'you', 'aware', 'of', 'the', 'casualty',\n",
              "         'estimates', 'for', 'an', 'invasion', 'of', 'home', 'islands', '?'],\n",
              "        dtype='<U9'),\n",
              "  array([0.0829608, 0.9170392], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['indeed', 'and', 'a', 'remarkably', 'puny', 'idea', 'to', 'place',\n",
              "         'at', 'the', 'epicentre', 'of', 'a', 'new', 'epoch'], dtype='<U10'),\n",
              "  array([9.9985719e-01, 1.4275844e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wow', '.', 'has', 'pre', 'season', 'tournaments', 'in', 'career',\n",
              "         'mode', '.', 'bloody', 'hell', 'evacuate', 'the', 'building'],\n",
              "        dtype='<U11'),\n",
              "  array([0.9977793 , 0.00222072], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['some', 'poor', 'sods', 'arriving', 'in', 'amman', 'during',\n",
              "         'dust', 'storm', 'were', 'diverted', 'to', 'ben', 'gurion', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([3.5514229e-06, 9.9999642e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['you', 'better', 'make', 'all', 'your', 'shots', 'tomorrow',\n",
              "         'cause', 'recording', 'and', 'flames', 'will', 'be', 'thrown',\n",
              "         'tomorrow'], dtype='<U9'),\n",
              "  array([0.99585354, 0.00414645], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['her', 'eyes', 'and', 'words', 'are', 'so', 'icy', 'but', 'she',\n",
              "         'burns', 'like', 'rum', 'on', 'the', 'fire'], dtype='<U5'),\n",
              "  array([0.9948849 , 0.00511507], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['given', 'the', 'us', 'fondness', 'for', 'backing',\n",
              "         'totalitarianism', 'a', 'surprise', 'they', 'copied', '.', '.',\n",
              "         '.', '.'], dtype='<U15'),\n",
              "  array([0.98855805, 0.01144192], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['no', 'lives', 'lost', 'except', 'those', 'of', 'first',\n",
              "         'responders', 'or', 'the', 'public', 'charged', 'with',\n",
              "         'protecting', '?'], dtype='<U10'),\n",
              "  array([0.02982466, 0.97017527], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['brunette', 'beauty', 'night', 'a', 'stretches', 'out', 'on', 'a',\n",
              "         'victorian', 'sofa', '.', 'view', 'and', 'download', 'video'],\n",
              "        dtype='<U9'),\n",
              "  array([9.9972051e-01, 2.7947195e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['that', 'day', 'remember', 'the', 'nuclear', 'weapon', 'power',\n",
              "         '.', '.', '.', '.', '.', '.', 'hiroshima', '70th'], dtype='<U9'),\n",
              "  array([0.00169228, 0.9983077 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array([';', 'suicide', 'bombing', 'of', 'european', 'union', 'car',\n",
              "         'kills', 'at', 'least', 'three', 'in', 'kabul', 'on', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([7.507597e-05, 9.999249e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['in', '2014', 'i', 'will', 'only', 'smoke', 'if', 'i', 'a',\n",
              "         'mayor', '.', 'this', 'includes', 'foursquare', '.'], dtype='<U10'),\n",
              "  array([0.95448536, 0.04551465], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['slow', 'clap', 'for', 'this', 'pilot', '.', 'dramatic', 'video',\n",
              "         'shows', 'plane', 'landing', 'during', 'violent', 'storm', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00199849, 0.9980015 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['new', 'mad', 'max', 'screenshots', 'show', 'off', 'a', 'lovely',\n",
              "         'dust', 'storm', 'combat', 'magnum', 'opus', '.', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.9779729 , 0.02202703], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['motor', 'vehicle', 'collision', 'at', 'n', '35', 'st', '/',\n",
              "         'fremont', 'av', 'n', 'reported', 'on', '6:52', 'pm'], dtype='<U9'),\n",
              "  array([0.01064808, 0.9893519 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['insurance', 'rates', 'up', 'in', 'after', 'several', 'months',\n",
              "         'of', 'no', 'movement', 'commercial', '.', '.', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.25271866, 0.7472813 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['why', 'not', 'even', 'more', 'awesome', 'norse', 'landscapes',\n",
              "         'with', 'loads', 'of', 'atmosphere', 'and', 'life', 'than',\n",
              "         'wastelands'], dtype='<U10'),\n",
              "  array([9.997434e-01, 2.565457e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'added', 'a', 'video', 'to', 'a', 'playlist', '.',\n",
              "         'volcanoes', 'and', 'earthquakes', '-', 'inside', 'the', 'volcano'],\n",
              "        dtype='<U11'),\n",
              "  array([0.02522782, 0.9747722 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['some', 'poor', 'sods', 'arriving', 'in', 'amman', 'during',\n",
              "         'dust', 'storm', 'were', 'diverted', 'to', 'ben', 'gurion', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([3.5514229e-06, 9.9999642e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['put', 'this', 'in', 'detroit', 'niggas', 'gone', 'be', 'acting',\n",
              "         'out', '?', '?', 'tryna', 'fuck', 'n', 'drown', 'mfs', '?', '?',\n",
              "         '?', '?', '?', '?', '?', '?', 'loose', 'they', 'buffs', 'in',\n",
              "         'the', 'water', '?', '?', '.'], dtype='<U7'),\n",
              "  array([0.95723975, 0.04276022], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['so', 'i', 'had', 'my', 'phone', 'charging', 'and', 'lightening',\n",
              "         'struck', 'in', 'my', 'backyard', 'and', 'i', 'was', 'holding',\n",
              "         'my', 'phone', 'and', 'it', 'electrocuted', 'my', 'hand', '?', '?',\n",
              "         '?', '?', 'hurts', 'so', 'bad', 'man', '?', '?'], dtype='<U12'),\n",
              "  array([0.8544681 , 0.14553195], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['was', 'a', 'small', 'earthquake', 'in', 'la', 'but', 'worry',\n",
              "         'emily', 'rossum', 'is', 'is', 'great'], dtype='<U10'),\n",
              "  array([0.00465725, 0.99534273], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['too', 'slow', 'report', 'the', 'sinking', 'boat', 'in', 'the',\n",
              "         'mediterranean', 'sea', 'what', 'a', 'shame'], dtype='<U13'),\n",
              "  array([0.01996891, 0.980031  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'got', 'electrocuted', 'this', 'morning', 'how', 'is', 'your',\n",
              "         'day', 'going', '?', '?', '?'], dtype='<U12'),\n",
              "  array([0.98911697, 0.01088309], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'spread', 'of', 'conflict', 'has', 'sparked', 'an',\n",
              "         'increase', 'in', 'fires', 'destroying', 'throughout', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([4.538332e-05, 9.999546e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['how', 'to', 'restore', 'vinyl', 'siding', 'and', 'make', 'it',\n",
              "         'look', 'new', 'again', '.', '.'], dtype='<U7'),\n",
              "  array([0.9874816 , 0.01251837], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['dry', 'thunderstorms', 'with', 'lightning', 'possible', 'in',\n",
              "         'the', 'pinpoint', 'valley', 'forecast', '.', '.', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([1.4112753e-04, 9.9985886e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['m', '0', '.', '9', '-', 'northern', 'utc', 'at', 'epicenter', '.',\n",
              "         '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00171286, 0.99828714], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['debris', 'confirmed', 'from', ';', 'relatives', 'hope', 'for',\n",
              "         'discovery', 'of', 'crash', 'site', '.', 'via'], dtype='<U9'),\n",
              "  array([1.4361259e-04, 9.9985635e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'love', 'love', 'without', 'tragedy', 'by', 'i', 'wish',\n",
              "         'she', 'made', 'the', 'whole', 'song'], dtype='<U7'),\n",
              "  array([0.9943973 , 0.00560271], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['apparently', 'if', 'bleeding', 'people', 'look', 'at', 'you',\n",
              "         'weird', 'lol', 'well', 'fine', 'keep', 'walking'], dtype='<U10'),\n",
              "  array([0.9963862 , 0.00361383], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['no', 'bc', 'we', 'always', 'got', 'in', 'trouble', 'for',\n",
              "         'laughing', 'too', 'much', '?', '?'], dtype='<U8'),\n",
              "  array([0.9362344 , 0.06376554], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['old', 'pkk', 'suicide', 'bomber', 'who', 'detonated', 'bomb',\n",
              "         'in', 'turkey', 'army', 'trench', 'released', '.'], dtype='<U9'),\n",
              "  array([9.355485e-06, 9.999907e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dk', 'eyewitness', 'travel', 'travel', 'guide', 'ebay',\n",
              "         'auctions', 'you', 'should', 'keep', 'an', 'eye', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9975612 , 0.00243878], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['israeli', 'helicopters', 'that', 'attacked', 'civilians', 'in',\n",
              "         'gaza', 'just', 'completed', 'exercises', 'in', 'greece', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([3.8657938e-05, 9.9996138e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['ee', 'recalls', 'power', 'bar', 'phone', 'chargers', 'after',\n",
              "         'explosion', 'burns', 'woman', 'the', 'register', '.'], dtype='<U9'),\n",
              "  array([0.00292461, 0.99707544], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['snap', 'on', 'tools', 'black', 'baseball', 'embroidered', 's',\n",
              "         'logo', 'flames', '-', 'full', '.', '.'], dtype='<U11'),\n",
              "  array([0.9947635 , 0.00523644], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['both', 'kids', 'got', 'haircuts', 'w', 'minimal', 'trauma', '.',\n",
              "         'clearly', 'that', 'calls', 'for', 'wine'], dtype='<U8'),\n",
              "  array([0.99567103, 0.004329  ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['global', 'precipitation', 'measurement', 'satellite', 'captures',\n",
              "         '3-d', 'image', 'of', 'typhoon', 'soudelor', '-', '.', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([6.4725078e-05, 9.9993527e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hellfire', 'is', 'surrounded', 'by', 'desires', 'so', 'be',\n",
              "         'careful', 'and', 'let', 'your', 'desires', 'control'],\n",
              "        dtype='<U10'),\n",
              "  array([0.8302368 , 0.16976316], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['chinese', 'rescue', 'team', 'arrives', 'in', 'myanmar', 'to',\n",
              "         'help', 'flood', 'victims', '.', 'sittway', '.'], dtype='<U7'),\n",
              "  array([2.0570465e-05, 9.9997938e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['you', 'wanna', 'ruin', 'a', 'relationship', '?', 'just', 'ask',\n",
              "         'are', 'your', 'and', 'do', 'it'], dtype='<U12'),\n",
              "  array([0.8864899 , 0.11351007], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['he', 'did', 'get', 'a', 'of', 'approval', 'which', 'is',\n",
              "         'probably', 'why', 'blown', 'up', '.'], dtype='<U8'),\n",
              "  array([0.9987029 , 0.00129713], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['5', 'rejected', 'mortal', 'kombat', 'mortal', 'kombat', 'has',\n",
              "         'stretched', 'the', 'boundaries', 'of', '.', '.'], dtype='<U10'),\n",
              "  array([0.96472645, 0.03527351], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['ashley', 'and', 'i', 'on', 'going', 'to', 'hurricane', 'harbor',\n",
              "         'friday', '.', '?', '?', '.'], dtype='<U9'),\n",
              "  array([3.3723595e-04, 9.9966276e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['womens', 'handbags', 'cross', 'body', 'geometric', 'pattern',\n",
              "         'satchel', 'totes', 'shoulder', 'bags', 'white', '.', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.99583495, 0.00416501], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['spring', 'oil', 'spill', 'estimate', 'grows', \"'\", 'by', 'the',\n",
              "         'associated', 'press', 'via', 'nyt', '.'], dtype='<U10'),\n",
              "  array([0.00357507, 0.996425  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rcmp', 'confirm', 'fatalities', 'in', 'tch', 'remains', 'closed',\n",
              "         'at', 'whitbourne', 'due', 'to', 'accident', '.'], dtype='<U10'),\n",
              "  array([6.1893770e-05, 9.9993813e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['mp', 'trains', 'the', 'of', 'freak', 'mp', 'trains', 'the', 'of',\n",
              "         '.', '.', '.', '.'], dtype='<U6'),\n",
              "  array([3.9867454e-04, 9.9960130e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bore', 'him', 'with', 'minutiae', 'serve', 'bad', 'champagne',\n",
              "         '.', 'he', 'may', 'just', 'explode', '.'], dtype='<U9'),\n",
              "  array([0.9924252 , 0.00757478], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['new', 'content', 'policy', 'shows', 'that', 'maybe', 'reddit',\n",
              "         'have', 'it', 'all', '.', 'via', '.'], dtype='<U7'),\n",
              "  array([0.9891361, 0.0108639], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wftv', 'eyewitness', 'tn', 'school', 'psychologist', 'arrested',\n",
              "         'in', 'florida', 'on', 'child', 'porn', 'charges', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([0.99644583, 0.00355417], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['tension', 'in', 'bayelsa', 'as', 'patience', 'jonathan', 'plans',\n",
              "         'to', 'hijack', 'apc', 'pdp', '.', '.'], dtype='<U8'),\n",
              "  array([0.00215806, 0.99784195], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bombed', 'on', 'kanye', 'in', 'that', '?', '?', '?', '?', '?',\n",
              "         '?', '?', '?'], dtype='<U6'),\n",
              "  array([0.01128228, 0.9887177 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['threw', 'a', 'chicken', 'nugget', 'at', 'my', 'sisters', 'lip',\n",
              "         'and', 'now', 'bleeding', '?', '?'], dtype='<U8'),\n",
              "  array([9.9916458e-01, 8.3542854e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hostages', 'are', 'meaningless', 'might', 'as', 'well', 'just',\n",
              "         'play', 'cod', 'search', 'and', 'destroy', '.'], dtype='<U11'),\n",
              "  array([0.94289887, 0.0571012 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['and', 'she', 'wrapped', 'his', 'coat', 'around', 'herself', '.',\n",
              "         'it', 'practically', 'engulfed', 'her', '.'], dtype='<U11'),\n",
              "  array([0.44837624, 0.55162376], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['debris', 'confirmed', 'from', ';', 'relatives', 'hope', 'for',\n",
              "         'discovery', 'of', 'crash', 'site', '.', 'via'], dtype='<U9'),\n",
              "  array([1.4361259e-04, 9.9985635e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['da', 'judge', 'gave', 'dis', 'girl', '5pm', 'curfew', '?', '?',\n",
              "         '?', '?', '?', '?'], dtype='<U6'),\n",
              "  array([0.9986052 , 0.00139484], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', 'family', 'mourns', 'drowning', 'of', 'toddler', 'with',\n",
              "         'rare', 'epilepsy', '-', 'chicago', 'tribune', '.'], dtype='<U8'),\n",
              "  array([0.0028455, 0.9971545], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['discovered', 'plane', 'debris', 'is', 'from', 'missing',\n",
              "         'malaysia', 'airlines', 'flight', '370', '|', 'time', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([2.7359251e-04, 9.9972636e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['julie', '+', 'r', 'is', 'the', 'apocalypse', 'version', 'of',\n",
              "         'romeo', '+', 'juliet'], dtype='<U10'),\n",
              "  array([9.990472e-01, 9.528175e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['dramatic', 'video', 'shows', 'plane', 'landing', 'during',\n",
              "         'violent', 'storm', '-', '.', '.'], dtype='<U8'),\n",
              "  array([1.2602181e-04, 9.9987400e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'see', 'people', 'are', 'panicking', 'about', 'orpik', 'all',\n",
              "         'over', 'again', '.'], dtype='<U9'),\n",
              "  array([0.99890697, 0.00109306], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', 'twelve', 'feared', 'killed', 'in', 'pakistani', 'air',\n",
              "         'ambulance', 'helicopter', 'crash', '.'], dtype='<U10'),\n",
              "  array([5.113680e-06, 9.999949e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['kosciusko', 'police', 'investigating', 'pedestrian', 'fatality',\n",
              "         'hit', 'by', 'a', 'train', 'thursday', '.'], dtype='<U13'),\n",
              "  array([4.3876233e-04, 9.9956125e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'good', 'piece', 'on', 'israeli', 'incitement', 'and',\n",
              "         'jewish', 'terrorism', 'by', '.'], dtype='<U10'),\n",
              "  array([1.8884331e-05, 9.9998116e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['alabama', 'home', 'quarantined', 'over', 'possible', 'ebola',\n",
              "         'case', '.', '.', 'related', '.'], dtype='<U11'),\n",
              "  array([8.2884956e-04, 9.9917114e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['property', 'losses', 'from', 'california', 'wildfire', 'nearly',\n",
              "         'double', 'as', 'blaze', 'rages', '.'], dtype='<U10'),\n",
              "  array([1.3309498e-05, 9.9998665e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['fitz', 'and', 'the', 'tantrums', '-', 'out', 'of', 'my', 'league',\n",
              "         'on', '.'], dtype='<U8'),\n",
              "  array([9.9924231e-01, 7.5771566e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'spent', '15', 'minutes', 'lifting', 'weights', '.', '43',\n",
              "         'calories', 'burned', '.'], dtype='<U8'),\n",
              "  array([9.9979717e-01, 2.0287222e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rt', 'wired', ':', 'reddit', 'will', 'now', 'quarantine',\n",
              "         'offensive', 'content', '.', '.'], dtype='<U10'),\n",
              "  array([0.99273974, 0.0072603 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['what', 'is', 'the', 'biggest', 'regret', 'you', 'have', 'in',\n",
              "         'hearthstone', '?', '.'], dtype='<U11'),\n",
              "  array([0.98808646, 0.01191351], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', '.', 'get', 'demolished', 'by', 'like', 'and', 'whine', 'to',\n",
              "         'about', '.'], dtype='<U10'),\n",
              "  array([0.9986064 , 0.00139361], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['slash-and-burn', 'blamed', 'for', 'bush', 'fires', 'in',\n",
              "         'western', 'st', 'thomas', '-', '.'], dtype='<U14'),\n",
              "  array([0.0020558, 0.9979442], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['refugio', 'oil', 'spill', 'may', 'have', 'been', 'costlier',\n",
              "         'bigger', 'than', 'projected', '.'], dtype='<U9'),\n",
              "  array([1.0238184e-05, 9.9998975e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'vintage', 'coach', 'purse', 'camera', 'bag', 'cross', 'body',\n",
              "         '.', '99', '.'], dtype='<U7'),\n",
              "  array([0.9808257 , 0.01917429], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['louis', 'in', 'red', 'jacket', 'round', '2', 'aka', 'drowning',\n",
              "         'in', 'my', 'tears'], dtype='<U8'),\n",
              "  array([0.97927135, 0.02072857], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['he', 'was', 'injured', '.', 'he', 'is', 'a', 'pro', 'bowl',\n",
              "         'back', '.'], dtype='<U7'),\n",
              "  array([0.99842   , 0.00157999], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['if', 'i', 'press', 'on', 'the', 'twitch', 'will', 'my', 'head',\n",
              "         'explode', '?'], dtype='<U7'),\n",
              "  array([0.90919524, 0.09080473], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'more', 'homes', 'razed', 'by', 'northern', 'california',\n",
              "         'wildfire', '-', '.', '.'], dtype='<U10'),\n",
              "  array([1.9344952e-05, 9.9998069e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hm', 'mt', 'alabama', 'home', 'quarantined', 'over', 'possible',\n",
              "         'ebola', 'case', '.', '.'], dtype='<U11'),\n",
              "  array([1.234567e-04, 9.998765e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'twelve', 'feared', 'killed', 'in', 'pakistani', 'air',\n",
              "         'ambulance', 'helicopter', 'crash', '.'], dtype='<U10'),\n",
              "  array([5.113680e-06, 9.999949e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['refugio', 'oil', 'spill', 'may', 'have', 'been', 'costlier',\n",
              "         'bigger', 'than', 'projected', '.'], dtype='<U9'),\n",
              "  array([1.0238184e-05, 9.9998975e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['two', 'giant', 'cranes', 'holding', 'a', 'bridge', 'collapse',\n",
              "         'into', 'nearby', 'homes', '.'], dtype='<U8'),\n",
              "  array([3.6236863e-06, 9.9999642e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'twelve', 'feared', 'killed', 'in', 'pakistani', 'air',\n",
              "         'ambulance', 'helicopter', 'crash', '.'], dtype='<U10'),\n",
              "  array([5.113680e-06, 9.999949e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'many', 'specs', 'so', 'much', 'fan', 'service', 'so',\n",
              "         'much', 'lore', 'destruction'], dtype='<U11'),\n",
              "  array([0.99681985, 0.00318011], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['parents', 'of', 'colorado', 'theater', 'shooting', 'victim',\n",
              "         'fear', 'copycat', 'massacre', '.', '.'], dtype='<U8'),\n",
              "  array([5.7563648e-05, 9.9994242e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'detonate', 'by', 'ft', '.', 'm', '.', 'o', '.', 'p', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9475558, 0.0524442], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sends', 'a', 'message', 'of', 'condolence', 'to', 'vietnam',\n",
              "         'following', 'natural', 'disaster', '.'], dtype='<U10'),\n",
              "  array([1.677079e-04, 9.998323e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['mourning', 'notices', 'for', 'stabbing', 'arson', 'victims',\n",
              "         'stir', 'of', 'in', 'israel', '.'], dtype='<U8'),\n",
              "  array([5.1532261e-04, 9.9948466e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['alabama', 'home', 'quarantined', 'over', 'possible', 'ebola',\n",
              "         'case', '.', '.', 'related', '.'], dtype='<U11'),\n",
              "  array([8.2884956e-04, 9.9917114e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['you', 'made', 'my', 'mood', 'go', 'from', 'shitty', 'af', 'to',\n",
              "         'panicking', 'af'], dtype='<U9'),\n",
              "  array([0.9266702 , 0.07332982], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['how', 'many', 'baskets', 'did', 'a', 'charming', 'fatality', 'by',\n",
              "         'get', '?', '.'], dtype='<U8'),\n",
              "  array([0.99176383, 0.00823618], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['white', 'twister', 'black', 'shift', 'knob', '.', '00', 'thread',\n",
              "         'size', '.', '.'], dtype='<U7'),\n",
              "  array([0.9951468 , 0.00485313], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['attack', 'ii', 'volleyball', 'training', 'machine', '-', 'sets',\n",
              "         'simulation', '-', '.', '.'], dtype='<U10'),\n",
              "  array([0.00304726, 0.9969528 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['us', 'govt', 'refuses', 'to', 'evacuate', '1000s', 'of',\n",
              "         'americans', 'from', 'yemen', '.'], dtype='<U9'),\n",
              "  array([1.4887190e-06, 9.9999857e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['blasts', 'accused', 'yeda', 'yakub', 'dies', 'in', 'karachi',\n",
              "         'of', 'heart', 'attack', '.'], dtype='<U7'),\n",
              "  array([3.0122802e-04, 9.9969876e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'more', 'homes', 'razed', 'by', 'northern', 'california',\n",
              "         'wildfire', '-', '.', '.'], dtype='<U10'),\n",
              "  array([1.9344952e-05, 9.9998069e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'storm', 'over', 'cairo', 'in', 'the', 'latest', 'set',\n",
              "         'photo', '.', 'via'], dtype='<U6'),\n",
              "  array([0.00150042, 0.99849963], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'wanna', 'touchdown', 'just', 'wanna', 'make', 'our',\n",
              "         'worlds', 'collide', '?', '?'], dtype='<U9'),\n",
              "  array([0.85850847, 0.14149155], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['top', 'spend', 'wedding', 'day', 'feeding', '4000', 'syrian', '.',\n",
              "         'see', 'more', '.'], dtype='<U7'),\n",
              "  array([0.9973254 , 0.00267459], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['|', 'do', 'not', 'kill', '|', 'flags', 'only', '|', 'fast', 'for',\n",
              "         'reason'], dtype='<U6'),\n",
              "  array([0.8125667 , 0.18743327], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['texas', 'seeks', 'comment', 'on', 'rules', 'for', 'changes', 'to',\n",
              "         'windstorm', 'insurer', '.'], dtype='<U9'),\n",
              "  array([0.99821633, 0.00178369], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['refugio', 'oil', 'spill', 'may', 'have', 'been', 'costlier',\n",
              "         'bigger', 'than', 'projected', '.'], dtype='<U9'),\n",
              "  array([1.0238184e-05, 9.9998975e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['nueva', 'emergency', 'feat', '.', 'the', 'chemical', 'brothers',\n",
              "         '/', 'my', 'bits', '.'], dtype='<U9'),\n",
              "  array([0.98434097, 0.01565902], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['islamic', 'state', 'group', 'in', 'egypt', 'threatens', 'to',\n",
              "         'kill', 'croat', 'hostage', '.'], dtype='<U9'),\n",
              "  array([4.4552007e-06, 9.9999559e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'risk', 'assessment', 'and', 'optimization', 'for', 'routing',\n",
              "         'hazardous', 'waste', 'collection', 'environmental'], dtype='<U13'),\n",
              "  array([0.9974842 , 0.00251577], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['7', '.', 'beyonce', 'is', 'my', 'pick', 'for', '.', 'fan', 'army',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([0.93678993, 0.06321009], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['bend', 'post', 'office', 'roofers', 'cut', 'gas', 'line',\n",
              "         'prompt', 'evacuation', '-', '.'], dtype='<U10'),\n",
              "  array([2.8881843e-05, 9.9997115e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['gps', 'app', 'guides', 'rescuers', 'to', 'injured', 'biker', 'in',\n",
              "         'marin', 'county', '.'], dtype='<U8'),\n",
              "  array([1.0777564e-04, 9.9989223e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['no', 'harm', 'no', 'foul', 'and', 'somebody', 'needed', 'to',\n",
              "         'say', 'it', '.'], dtype='<U8'),\n",
              "  array([0.9214587 , 0.07854132], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['everything', 'must', 'be', 'ok', 'because', 'listening', 'to',\n",
              "         'now', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.912259  , 0.08774102], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['construction', 'of', 'bridge', 'collapse', '.', '.'], dtype='<U12'),\n",
              "  array([4.832076e-05, 9.999517e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['2', 'terrorist', 'shot', 'dead', '.', '.'], dtype='<U9'),\n",
              "  array([9.800432e-05, 9.999020e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['lava', 'cakes', 'are', 'my', 'fav', '.'], dtype='<U5'),\n",
              "  array([0.9973671 , 0.00263289], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'twins', 'ego', 'is', 'now', 'wrecked'], dtype='<U7'),\n",
              "  array([0.96125126, 0.03874871], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['12000', 'nigerian', 'refugees', 'repatriated', 'from', 'cameroon'],\n",
              "        dtype='<U11'),\n",
              "  array([4.439893e-06, 9.999956e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['when', 'trouble', 'you', 'know', 'who', 'to'], dtype='<U7'),\n",
              "  array([0.96904963, 0.03095034], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['britons', 'rescued', 'amid', 'himalaya', 'floods', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.30271155e-05, 9.99987006e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'fear', 'not', 'for', 'a', 'while'], dtype='<U5'),\n",
              "  array([0.8104763 , 0.18952365], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['meg', 'issues', 'hazardous', 'weather', 'outlook', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.00442931, 0.9955707 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['reportedly', 'to', 'test', 'hamstring', 'via', '.'], dtype='<U10'),\n",
              "  array([0.9934934 , 0.00650668], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['everyone', 'is', 'setting', 'flames', 'upon', 'me'], dtype='<U8'),\n",
              "  array([0.9733087 , 0.02669124], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['truth', '.', '.', '.', '.', '.'], dtype='<U5'),\n",
              "  array([0.43301365, 0.5669864 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', '.', '.'], dtype='<U10'),\n",
              "  array([0.97711825, 0.02288172], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'sinkhole', 'in', 'brooklyn', '?', '!'], dtype='<U8'),\n",
              "  array([0.00198265, 0.9980173 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['just', 'demolished', 'a', 'snowball', '?', '?'], dtype='<U10'),\n",
              "  array([0.9937192 , 0.00628077], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['asbury', 'park', 'shooting', 'reported', '.', 'via'], dtype='<U8'),\n",
              "  array([3.7174884e-04, 9.9962819e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['ignition', 'knock', 'sensor', 'motorcraft', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.95184153, 0.04815843], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'have', 'a', '32', 'inch', 'dynasty'], dtype='<U7'),\n",
              "  array([9.9982315e-01, 1.7686584e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['is', 'da', 'bomb', '?', '?', '.'], dtype='<U4'),\n",
              "  array([0.8063485 , 0.19365147], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['gov', '.', 'on', 'drought', 'wildfires', '.'], dtype='<U9'),\n",
              "  array([1.7979892e-06, 9.9999821e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dazzle', 'destroy', 'the', 'fun', '?', '?'], dtype='<U7'),\n",
              "  array([0.99825996, 0.00174008], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['an', 'emotional', 'wreck', 'right', 'now', '.'], dtype='<U9'),\n",
              "  array([0.98449266, 0.01550732], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', '.', '.'], dtype='<U10'),\n",
              "  array([0.97711825, 0.02288172], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['nothing', 'like', 'a', 'good', 'fire', '.'], dtype='<U7'),\n",
              "  array([0.06705857, 0.93294144], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'cant', 'breathe', 'my', 'lungs', 'collapsed'], dtype='<U9'),\n",
              "  array([0.98531437, 0.01468562], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['truth', '.', '.', '.', '.', '.'], dtype='<U5'),\n",
              "  array([0.43301365, 0.5669864 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['california', 'and', 'fireworks', 'explosion', 'incidents', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([3.2675002e-06, 9.9999678e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['school', 'of', 'seven', 'bells', '-', 'windstorm'], dtype='<U9'),\n",
              "  array([0.9973013 , 0.00269872], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['does', 'renovation', 'mean', 'obliteration', '?', '.'],\n",
              "        dtype='<U12'),\n",
              "  array([0.994337  , 0.00566291], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['photo', 'of', 'the', 'storm', 'chaser', '.'], dtype='<U6'),\n",
              "  array([9.112177e-05, 9.999089e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['check', 'will', 'now', 'quarantine', 'offensive', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([9.9909902e-01, 9.0106035e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['currency', 'transgress', 'before', 'ward', 'payment', 'unsecured'],\n",
              "        dtype='<U10'),\n",
              "  array([9.9912292e-01, 8.7709504e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['#', '?', '?', '?', '#', '?', '?', '#', '?', '?', '?', '#', '?',\n",
              "         '?', '?', 'aircraft', 'debris', 'found', 'on', 'la', 'reunion',\n",
              "         'is', 'from', 'missing', 'malaysia', 'airlines', '.', '.', '.',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([4.7504462e-05, 9.9995244e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['#', '?', '?', '#', '?', '?', '?', '?', '#', '?', '?', '?', '#',\n",
              "         '?', '?', '?', 'aircraft', 'debris', 'found', 'on', 'la',\n",
              "         'reunion', 'is', 'from', 'missing', 'malaysia', 'airlines', '.',\n",
              "         '.', '.', '.'], dtype='<U8'),\n",
              "  array([4.7190882e-05, 9.9995279e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'when', 'r', 'u', 'getting', 'oh', 'finally', 'jennifer',\n",
              "         'aniston', 'got', 'married', '?', '?', '?', '?', '?', '?', '.',\n",
              "         '.', '.', 'so', 'happy', 'for', 'her', '?', '?', '?', '?', '?',\n",
              "         '?', \"'\"], dtype='<U8'),\n",
              "  array([0.99776113, 0.0022388 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['okay', 'the', 'cat', 'has', 'been', 'quarantined', 'in', 'my',\n",
              "         'bathroom', '.', '.', '.', 'its', 'meowing', 'really', 'loud',\n",
              "         'but', 'i', 'turned', 'up', 'the', 'tv', 'louder', '.', '.', '.',\n",
              "         'things', 'just', 'might', 'work', 'out', 'okay'], dtype='<U11'),\n",
              "  array([0.9768389 , 0.02316115], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['first', 'wreck', 'today', '.', 'so', 'so', 'glad', 'me', 'and',\n",
              "         'mom', 'are', 'okay', '.', 'been', 'a', 'lot', 'worse', '.', 'so',\n",
              "         'happy', 'the', 'lord', 'was', 'with', 'us', 'today', '?', '?',\n",
              "         '?', '?', '?', '?'], dtype='<U5'),\n",
              "  array([0.9977412 , 0.00225877], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'was', 'on', 'my', 'way', 'to', 'gary', 'but', 'all', 'the',\n",
              "         'chicago', 'entrances', 'was', 'closed', 'due', 'to', 'a',\n",
              "         'bridge', 'collapsed', '?', '?', '?', '?', '?', '?', 'i', 'hope',\n",
              "         'they', 'let', 'us', 'through', 'tomorrow'], dtype='<U9'),\n",
              "  array([0.0140023, 0.9859977], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['when', 'ur', 'friend', 'and', 'u', 'are', 'talking', 'about',\n",
              "         'forest', 'fires', 'in', 'a', 'forest', 'and', 'he', 'tells', 'u',\n",
              "         'to', 'drop', 'ur', 'mix', 'tape', 'out', 'there', '.', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.01584022, 0.98415977], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['great', 'song', '.', '15', 'years', 'getting', 'loaded', '.',\n",
              "         '15', 'years', 'till', 'his', 'liver', 'exploded', '.', 'now',\n",
              "         'bob', 'going', 'to', 'do', 'now', 'that', 'he', '.', '.', '.',\n",
              "         \"'\"], dtype='<U8'),\n",
              "  array([0.9932707 , 0.00672928], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['my', 'pc', 'account', 'got', 'hacked', '.', 'someone', 'tried',\n",
              "         'to', 'pull', 'out', 'over', '1200', 'bucks', 'which', 'there',\n",
              "         'now', 'i', 'have', 'an', 'nsf', ';', 'no', 'idea', 'who', 'or',\n",
              "         'why'], dtype='<U7'),\n",
              "  array([0.88301146, 0.11698858], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array([';', 'on', 'the', 'rare', 'occasion', 'i', 'do', 'go', 'out',\n",
              "         'complete', 'obliterated', 'the', 'next', 'day', '.', 'throwing',\n",
              "         'up', 'and', 'passing', 'out', '.', 'my', 'body', 'is',\n",
              "         'accustomed', 'to', 'alcohol'], dtype='<U11'),\n",
              "  array([0.9980934 , 0.00190653], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hail', 'mary', 'full', 'of', 'grace', 'the', 'lord', 'is', 'with',\n",
              "         'thee', '.', 'blessed', 'art', 'thou', 'among', 'women', 'and',\n",
              "         'blessed', 'is', 'the', 'fruit', 'of', 'thy', '.', '.', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.925047, 0.074953], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['signing', 'a', 'petition', 'to', 'seek', 'mercy', 'on', 'a',\n",
              "         'death', 'punishment', 'for', 'a', 'terrorist', 'is', 'a', 'job',\n",
              "         'well', 'done', 'in', 'india', '.', 'but', 'asking', 'a',\n",
              "         'foreign', 'govt', '1/n'], dtype='<U10'),\n",
              "  array([0.00126273, 0.9987373 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['just', 'had', 'a', 'panic', 'attack', 'bc', 'i', 'have', 'enough',\n",
              "         'money', 'for', 'all', 'the', 'drugs', 'and', 'alcohol', 'i',\n",
              "         'wanted', 'to', 'buy', 'this', 'year', 'let', 'alone', 'my',\n",
              "         'fall', 'bills'], dtype='<U7'),\n",
              "  array([0.95157266, 0.04842735], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['shark', 'boy', 'and', 'lava', 'girl', 'for', 'the', 'third',\n",
              "         'time', 'today', '.', 'i', 'guess', 'this', 'is', 'what', 'having',\n",
              "         'kids', 'feelings', 'like', '.', '?', '?', '?', '?', '?', '?'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9980171, 0.0019829], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['even', 'when', 'i', 'was', 'a', 'kid', 'haha', 'super', 'late',\n",
              "         'but', 'folks', 'used', 'to', 'bash', 'me', 'for', 'that', 'shit',\n",
              "         'i', 'understand', 'he', 'survived', 'cancer', 'but', 'he',\n",
              "         'still', 'cheated'], dtype='<U10'),\n",
              "  array([0.9593073 , 0.04069265], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['bomb', 'head', '?', 'explosive', 'decisions', 'dat', 'produced',\n",
              "         'more', 'dead', 'children', 'than', 'dead', 'bodies', 'trapped',\n",
              "         'tween', 'buildings', 'on', 'that', 'day', 'in', 'september',\n",
              "         'there'], dtype='<U9'),\n",
              "  array([1.323410e-04, 9.998677e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['am', 'the', 'ass', 'british', 'insurers', 'says', 'rioting',\n",
              "         'will', 'cost', ';', 'millions', '.', 'but', 'police', 'numbers',\n",
              "         'are', 'reduced', 'by', 'blind', 'fat', 'controllers', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.09530147, 0.9046985 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['if', 'anyone', 'were', 'to', 'harm', 'the', 'boys', 'they',\n",
              "         'would', 'get', 'taken', 'down', 'immediately', 'not', 'by',\n",
              "         'security', 'but', 'by', 'the', 'fans', 'real', 'quick'],\n",
              "        dtype='<U11'),\n",
              "  array([0.7906432 , 0.20935683], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'understand', 'you', 'wanting', 'to', 'hang', 'out', 'with',\n",
              "         'your', 'guy', 'friends', 'give', 'you', 'your', 'space', 'but',\n",
              "         'ruin', 'my', 'trust', 'with', 'you', '.'], dtype='<U10'),\n",
              "  array([0.99306667, 0.00693336], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['this', 'is', 'lara', 'she', 'likes', 'sinking', 'her', 'teeth',\n",
              "         'into', 'my', 'flesh', 'and', 'clawing', 'my', 'arms', '?', '?',\n",
              "         '?', '?', '?', '?', '.'], dtype='<U7'),\n",
              "  array([0.9941749, 0.0058251], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['story', 'of', 'the', 'power', 'animal', 'rescuers', 'a',\n",
              "         'starving', 'homeless', 'dog', 'with', 'no', 'future', 'was',\n",
              "         'rescued', 'by', 'a', 'person', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.01469608, 0.98530394], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['trying', 'to', 'electrocute', 'ya', 'ass', 'lol', 'hell', 'no',\n",
              "         'i', 'fucking', 'with', 'emilio', 'no', 'more', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?'], dtype='<U11'),\n",
              "  array([0.99870014, 0.00129982], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['more', 'than', '40', 'families', 'affected', 'by', 'the', 'fatal',\n",
              "         'outbreak', 'of', 'disease', 'in', 'edinburgh', 'are', 'to', 'sue',\n",
              "         'two', 'comp', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00388511, 0.99611485], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', '.', '.', 'gone', '.', 'you', 'can', 'relax', '.', 'i',\n",
              "         'thought', 'the', 'wife', 'who', 'wrecked', 'her', 'cake', 'was',\n",
              "         'a', 'goner', 'mind', 'lol'], dtype='<U7'),\n",
              "  array([9.9980193e-01, 1.9807200e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['gunman', 'reported', 'dead', 'at', 'nashville', 'area', 'a',\n",
              "         'suspect', 'who', 'carried', 'a', 'gun', 'and', 'a', 'hatchet',\n",
              "         'at', 'the', 'carmi', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00549336, 0.99450666], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'apparently', 'there', 'were', 'bush', 'fires', 'near',\n",
              "         'where', 'i', 'live', 'over', 'the', 'weekend', 'that', 'i', 'was',\n",
              "         'totally', 'oblivious', 'to', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.0096903 , 0.99030966], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bayelsa', 'tension', 'in', 'bayelsa', 'as', 'patience',\n",
              "         'jonathan', 'plans', 'to', 'hijack', 'apc', 'pdp', 'plans', 'by',\n",
              "         'former', 'first', 'lady', 'and', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.98483187, 0.01516808], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['if', 'a', 'chance', 'will', 'get', 'a', 'gander', 'of', 'the',\n",
              "         'sinking', 'ship', 'that', 'is', 'too', '.', 'help', 'but',\n",
              "         'appease', 'my', 'morbid', 'curiosity', '.'], dtype='<U9'),\n",
              "  array([0.64280844, 0.35719153], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['salem', '2', 'nuclear', 'reactor', 'shut', 'down', 'over',\n",
              "         'electrical', 'circuit', 'failure', 'on', 'the', 'salem', '2',\n",
              "         'nuclear', 'reactor', 'had', 'bee', '.', '.', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.01483727, 0.9851627 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['it', 'was', 'finally', 'demolished', 'in', 'the', 'spring', 'of',\n",
              "         '2013', 'and', 'the', 'property', 'has', 'sat', 'vacant', 'since',\n",
              "         '.', 'the', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.99361837, 0.0063817 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['driver', 'rams', 'car', 'into', 'israeli', 'soldiers', 'wounds',\n",
              "         'a', 'driver', 'rammed', 'a', 'car', 'into', 'a', 'group', 'of',\n",
              "         'israeli', 'soldi', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([8.243034e-04, 9.991757e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'seen', 'judas', 'priest', 'in', '2005', 'when', 'rob',\n",
              "         'came', 'back', ';', 'scorpions', 'as', 'support', '.', 'fucking',\n",
              "         'annihilated', 'the', 'place', '.', 'astonishing', 'gig'],\n",
              "        dtype='<U11'),\n",
              "  array([0.9975916 , 0.00240841], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'brief', 'violent', 'storm', 'swept', 'through', 'the',\n",
              "         'chicago', 'area', 'sunday', 'afternoon', 'leading', 'to', 'one',\n",
              "         'death', 'and', 'an', 'evacuation', 'of', 'lollapalooza', 'and',\n",
              "         'more'], dtype='<U12'),\n",
              "  array([0.06607278, 0.93392724], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['storm', 'headed', 'towards', 'idaho', 'falls', 'with', 'blowing',\n",
              "         'dust', ';', 'winds', 'to', '60', 'mph', '.', 'us', 'hwy', '20',\n",
              "         ';', 'look', 'out', '.', '.'], dtype='<U7'),\n",
              "  array([0.00270309, 0.99729687], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['he', 'still', 'has', 'his', 'beard', '-', 'has', 'he', 'been',\n",
              "         'visited', 'by', 'while', 'in', 'prison', '?', 'if', 'he', 'keeps',\n",
              "         'that', 'hideous', 'beard', 'electrocute'], dtype='<U11'),\n",
              "  array([0.00493732, 0.99506265], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['if', ';', 'colluded', '2', 'take', 'wht', 'f', 'auth', ';', '2',\n",
              "         'make', 'her', 'look', 'blk', ';', 'use', 'her', 'idis', 'id',\n",
              "         'still', 'hers', '?'], dtype='<U8'),\n",
              "  array([0.03114676, 0.9688532 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['suicide', 'bomber', 'kills', '15', 'in', 'saudi', 'security',\n",
              "         'site', 'mosque', '-', 'reuters', 'via', 'world', '-', 'google',\n",
              "         'news', '-', 'wall', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([7.1324152e-04, 9.9928683e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['govt', 'plan', 'for', 'lifeline', 'to', 'fci', 'waste', 'of',\n",
              "         'money', 'ask', 'people', 'to', 'store', 'grains', 'fr', 'months',\n",
              "         'fr', 'emergency', 'enough', 'capacity', 'available', 'nw'],\n",
              "        dtype='<U9'),\n",
              "  array([0.9872772 , 0.01272282], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['breaking', 'i', 'just', 'heard', 'a', 'loud', 'bang', 'nearby',\n",
              "         '.', 'in', 'what', 'appears', 'to', 'be', 'a', 'blast', 'of',\n",
              "         'wind', 'from', 'my', 'ass', '.'], dtype='<U8'),\n",
              "  array([0.8923117 , 0.10768826], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['17', 'dead', 'as', 'afghanistan', 'aircraft', 'an', 'afghan',\n",
              "         'military', 'helicopter', 'has', 'crashed', 'in', 'a', 'remote',\n",
              "         'region', 'of', 'the', 's', '.', '.', '.', '.'], dtype='<U11'),\n",
              "  array([0.00545374, 0.9945463 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['etp', 'bengal', 'cm', 'mamata', 'banerjee', 'blames', 'dvc',\n",
              "         'bjp', 'claims', 'state', 'failed', 'to', 'use', 'relief', 'even',\n",
              "         'as', 'flood', 'w', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.00358183, 0.9964181 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'it', 'hit', 'the', 'wall', 'behind', 'him', 'with', 'a',\n",
              "         'loud', 'bang', '.', 'drake', 'shouted', 'at', 'him', 'before',\n",
              "         'getting', 'up', '.', 'going', 'out'], dtype='<U7'),\n",
              "  array([0.04555067, 0.9544493 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['69', 'dead', 'due', 'to', 'floods', 'in', 'naypyidaw', 'aug', '5',\n",
              "         'the', 'death', 'toll', 'rose', 'today', 'to', '69', 'in',\n",
              "         'myanmar', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([1.1849891e-04, 9.9988151e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['condemning', 'of', 'deaths', 'more', 'than', '1000', 'due', 'to',\n",
              "         'heat', 'wave', 'in', 'karachi', '.', 'may', 'allah', 'gv',\n",
              "         'patience', 'to', 'their', 'heirs', '.', '.'], dtype='<U10'),\n",
              "  array([0.00570138, 0.9942986 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['this', 'from', 'the', 'city', 'of', 'calgary', '-', 'city', 'of',\n",
              "         'calgary', 'has', 'activated', 'municipal', 'emergency', 'plan',\n",
              "         'the', 'municipal', 'emergency', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([9.8332809e-04, 9.9901664e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'u', '.', 's', '.', 'also', 'flew', 'over', 'each', 'bomb',\n",
              "         'site', 'in', 'world', 'war', 'ii', 'with', 'warning', 'letters',\n",
              "         'telling', 'people', 'to', 'evacuate'], dtype='<U8'),\n",
              "  array([7.0883904e-04, 9.9929118e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['huh', '?', '?', 'me', 'you', 'and', 'leo', 'started', 'that',\n",
              "         'last', 'year', 'and', 'ever', 'since', 'people', 'blaze', 'it',\n",
              "         'in', 'the', 'back', '?', '?'], dtype='<U7'),\n",
              "  array([0.9889721 , 0.01102787], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['yay', 'for', 'sirens'], dtype='<U6'),\n",
              "  array([0.9976815 , 0.00231852], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['-', 'collide', '.'], dtype='<U7'),\n",
              "  array([0.9091541, 0.0908459], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['beautiful', 'disaster', '.'], dtype='<U9'),\n",
              "  array([0.8851403 , 0.11485973], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['worry', 'about', 'yourself'], dtype='<U8'),\n",
              "  array([9.990710e-01, 9.289945e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'feel', 'attacked'], dtype='<U8'),\n",
              "  array([0.9981166 , 0.00188345], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['strengthening', 'partnerships', '.'], dtype='<U13'),\n",
              "  array([0.03924965, 0.96075034], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['she', 'harm', 'you'], dtype='<U4'),\n",
              "  array([0.9987864, 0.0012136], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['deaths', '7', '.'], dtype='<U6'),\n",
              "  array([0.31060684, 0.68939316], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['u', 'on', 'dick'], dtype='<U4'),\n",
              "  array([0.94944   , 0.05055997], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['best', 'grill', 'u'], dtype='<U5'),\n",
              "  array([0.99829406, 0.00170591], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['when', 'taking', 'a', 'shower', 'and', 'someone', 'flushes',\n",
              "         'the', 'toilet', 'and', 'you', 'have', '.', '1', 'second', 'to',\n",
              "         'or', 'you', 'get', 'burned', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?', '?', '?', '?'], dtype='<U7'),\n",
              "  array([0.99895895, 0.00104101], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['if', 'a', 'war', 'you', 'came', 'to', 'see', 'you', 'will',\n",
              "         'never', 'see', 'a', 'waved', 'white', 'flag', 'in', 'front', 'me',\n",
              "         '.', 'i', 'end', 'up', 'dead', 'i', 'wont', 'be', 'misled', '.'],\n",
              "        dtype='<U6'),\n",
              "  array([0.99884003, 0.00116004], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sinking', 'down', 'in', 'the', 'darkest', 'dream', 'so', 'deep',\n",
              "         'so', 'cold', 'this', 'pain', 'inside', 'of', 'me', 'my', 'love',\n",
              "         'for', 'you', 'is', 'more', 'dan', 'i', 'can', 'jota', 'esse', '?',\n",
              "         '?'], dtype='<U7'),\n",
              "  array([0.9059511 , 0.09404893], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['in', 'the', 'beginning', 'of', 'summer', 'my', 'mom', 'made',\n",
              "         'my', 'curfew', '1', 'now', 'back', 'to', '12', 'and', 'i', 'can',\n",
              "         'never', 'go', 'out', 'and', 'she', 'wonders', 'why', 'always',\n",
              "         'at', 'home'], dtype='<U9'),\n",
              "  array([0.9963707 , 0.00362938], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['yes', 'a', 'lot', 'more', 'harm', 'then', 'good', 'if', 'there',\n",
              "         'are', 'guardrails', 'up', 'now', 'why', 'cant', 'we', 'go', '50',\n",
              "         '.', 'their', 'will', 'be', 'a', 'big', 'problem', 'when',\n",
              "         'school', 'starts'], dtype='<U10'),\n",
              "  array([0.98160124, 0.01839882], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['and', 'even', 'if', 'the', 'stars', 'and', 'moon', 'collide',\n",
              "         'oh', 'i', 'never', 'want', 'you', 'back', 'to', 'my', 'life',\n",
              "         'you', 'can', 'take', 'your', 'words', 'and', 'all', '.', '.', '.',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([0.9896024 , 0.01039758], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'prophet', 'be', 'upon', 'said', 'yourself', 'from',\n",
              "         'hellfire', 'even', 'if', 'it', 'is', 'by', 'giving', 'half', 'a',\n",
              "         'date', 'in', 'charity', '.', \"'\"], dtype='<U8'),\n",
              "  array([0.66088194, 0.33911806], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sooo', 'police', 'dispatch', 'said', 'there', 'was', 'a',\n",
              "         'person', 'threatening', 'to', 'shoot', 'up', 'the', 'walmart',\n",
              "         'on', 'rutherford', ';', 'they', 'had', 'to', 'evacuate'],\n",
              "        dtype='<U11'),\n",
              "  array([3.0124583e-04, 9.9969876e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['landslide', 'in', 'italian', 'alps', 'kills', 'rome', '-',\n",
              "         'three', 'people', 'were', 'killed', 'when', 'a', 'severe',\n",
              "         'rainstorm', 'in', 'th', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00128148, 0.9987185 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['can', 'only', 'be', 'rescued', 'from', 'where', 'you', 'actually',\n",
              "         'are', 'and', 'not', 'from', 'where', 'you', 'pretend', 'you',\n",
              "         'are', '.', \"'\", 'giorgio', 'hiatt'], dtype='<U8'),\n",
              "  array([9.9982762e-01, 1.7230191e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['place', 'out', '.', 'it', 'was', 'ex', 'pars', 'defender', 'andy',\n",
              "         'tod', 'in', 'full', 'uniform', '.', 'it', 'was', 'instant',\n",
              "         'pandemonium', '.', 'utter', 'mayhem'], dtype='<U11'),\n",
              "  array([9.9995518e-01, 4.4767738e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['in', 'the', 'shower', 'and', 'i', 'went', 'to', 'go', 'change',\n",
              "         'the', 'song', 'and', 'of', 'course', 'i', 'get', 'fucking',\n",
              "         'electrocuted', 'by', 'the', 'cord'], dtype='<U12'),\n",
              "  array([0.99770135, 0.00229868], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['next', 'man', 'screw', 'so', 'tired', 'of', 'injuries', '.',\n",
              "         'what', 'happened', 'to', 'camp', 'cupcake', '?', 'more', 'like',\n",
              "         'camp', 'cramp', 'and', 'break', '.'], dtype='<U8'),\n",
              "  array([0.992782, 0.007218], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['have', 'you', 'ever', 'remembered', 'an', 'old', 'song',\n",
              "         'something', 'you', 'for', 'years', '?', 'words', 'that', 'carry',\n",
              "         'floods', 'of', 'memories', 'all', 'along', '.'], dtype='<U10'),\n",
              "  array([0.99866366, 0.00133632], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['coaches', 'were', 'devastated', 'to', 'hear', 'of', 'the',\n",
              "         'death', 'of', 'their', 'second', 'driver', 'mr', 'chance', 'who',\n",
              "         'was', 'jam', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.00714972, 0.9928503 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'last', 'time', 'a', 'high', 'profile', 'name', 'was',\n",
              "         'due', 'to', 'be', 'signing', 'for', 'the', 'city', 'was',\n",
              "         'wesley', 'verhoek', 'now', 'a', 'household'], dtype='<U9'),\n",
              "  array([0.05590589, 0.9440942 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['it', 'is', 'not', 'always', 'friendship', 'when', 'kisses',\n",
              "         'show', 'up', 'neither', 'is', 'it', 'always', 'that', 'shows',\n",
              "         'up', 'when', 'wounds', 'show', 'up', '.'], dtype='<U10'),\n",
              "  array([0.9919276 , 0.00807241], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['investigators', 'say', 'a', 'fatal', 'virgin', 'galactic',\n",
              "         'spaceship', 'crash', 'last', 'year', 'was', 'caused', 'by',\n",
              "         'structural', 'failure', 'after', 'the', '.', '.', '.', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([0.00591857, 0.99408144], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'tell', 'my', 'cousins', 'i', 'wanna', 'hang', 'out', 'and',\n",
              "         'they', 'text', 'me', 'saying', 'coming', 'honestly', 'do', 'you',\n",
              "         'have', 'a', 'death', 'wish'], dtype='<U8'),\n",
              "  array([0.9698742 , 0.03012577], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['japan', 'on', 'thursday', 'marks', 'the', '70th', 'anniversary',\n",
              "         'of', 'the', 'atomic', 'bombing', 'of', 'hiroshima', 'with', 'the',\n",
              "         'most', 'senior', 'official', 'from', 'washington', 'ever'],\n",
              "        dtype='<U11'),\n",
              "  array([4.5836816e-04, 9.9954164e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['happy', 'no', 'one', 'was', 'hurt', 'when', 'train', 'derailed',\n",
              "         '.', 'also', 'the', 'express', 'bus', 'is', 'so', 'much', 'better',\n",
              "         'than', 'metro', 'rail', '.'], dtype='<U8'),\n",
              "  array([1.5348745e-04, 9.9984646e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['prices', 'here', 'are', 'insane', '.', 'our', 'dollar', 'has',\n",
              "         'collapsed', 'against', 'the', 'us', 'and', 'punishing', 'us', '.',\n",
              "         'thanks', 'for', 'the', 'info', '.'], dtype='<U9'),\n",
              "  array([0.0039661 , 0.99603385], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['we', 'enjoyed', 'the', 'show', 'today', '.', 'great', 'fun', '.',\n",
              "         'the', 'emergency', 'non', 'evacuation', 'was', 'interesting', '.',\n",
              "         'have', 'a', 'great', 'run', '.'], dtype='<U11'),\n",
              "  array([0.99438924, 0.00561077], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['my', 'instagram', 'just', 'blew', 'up', 'apparently', 'i', 'was',\n",
              "         'featured', 'on', 'i', 'am', 'jazz', 'tonight', '.', 'how', 'cool',\n",
              "         'is', 'that', 'love', 'her'], dtype='<U10'),\n",
              "  array([0.98602015, 0.01397987], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['yelp', 'bolsters', 'health', 'care', 'reviews', 'with',\n",
              "         'investigative', 'sick', 'and', 'injured', 'patients', 'at', 'a',\n",
              "         'local', 'er', 'are', 't', '.', '.', '.', '.'], dtype='<U13'),\n",
              "  array([0.00964503, 0.990355  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['russia', 'may', 'have', 'played', 'into', 'reason', 'but', 'that',\n",
              "         'link', 'is', 'bs', '.', 'was', 'bloody', 'and', 'mainline',\n",
              "         'invasion', 'looked', 'like', 'a', 'bloody'], dtype='<U8'),\n",
              "  array([0.0276262, 0.9723737], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['70', 'years', 'after', 'atomic', 'bombs', 'japan', 'still',\n",
              "         'struggles', 'with', 'war', 'the', 'anniversary', 'of', 'the',\n",
              "         'devastation', 'wrought', 'b', '.', '.', '.', '.'], dtype='<U11'),\n",
              "  array([5.9920532e-04, 9.9940073e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dtn', 'rly', 'tragedy', 'in', 'some', 'live', 'to', 'recount',\n",
              "         'i', 'saw', 'coaches', 'of', 'my', 'train', 'plunging', 'into',\n",
              "         'water', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.00300581, 0.99699414], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['humboldt', 'cty', 'office', 'has', 'issued', 'an', 'evacuation',\n",
              "         'advisory', 'for', '10', 'residence', 'in', 'the', 'area', '.',\n",
              "         '.', '.', 'more', 'info', 'at', '.'], dtype='<U10'),\n",
              "  array([0.00445289, 0.99554706], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['70', 'years', 'after', 'atomic', 'bombs', 'japan', 'still',\n",
              "         'struggles', 'with', 'war', 'the', 'anniversary', 'of', 'the',\n",
              "         'devastation', 'wrought', 'b', '.', '.', '.', '.'], dtype='<U11'),\n",
              "  array([5.9920532e-04, 9.9940073e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['water', 'now', 'tops', 'the', 'charts', 'for', 'highest',\n",
              "         'global', 'risk', 'in', 'terms', 'of', 'ahead', 'of', 'nuclear',\n",
              "         'war', 'or', 'a', 'global', 'pandemic', '.'], dtype='<U8'),\n",
              "  array([4.465036e-05, 9.999553e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hey', 'guys', 'thanks', 'for', 'a', 'rock', 'in', 'my', 'world',\n",
              "         'and', 'for', 'the', 'follow', '?', '?', '?', '?', '?', '?', '?',\n",
              "         '?'], dtype='<U6'),\n",
              "  array([0.99812895, 0.00187104], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['come', 'to', 'the', 'realization', 'that', 'i', 'just', 'have',\n",
              "         'the', 'attention', 'span', 'for', 'mass', 'battle', 'games', '.',\n",
              "         'both', 'painting', 'and', 'playing', '.'], dtype='<U11'),\n",
              "  array([0.98206514, 0.0179349 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['now', 'that', 'a', 'piece', 'of', 'wreckage', 'from', 'flight',\n",
              "         'has', 'been', 'confirmed', 'on', 'island', 'is', 'it', 'possible',\n",
              "         't', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.01023455, 0.9897655 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'always', 'felt', 'like', 'the', 'were', 'black', 'people',\n",
              "         'and', 'felt', 'played', 'when', 'they', 'died', 'and', 'the',\n",
              "         'planet', 'got', 'destroyed', '?', '?'], dtype='<U9'),\n",
              "  array([0.99888927, 0.0011108 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['severe', 'storm', 'weakening', 'as', 'it', 'moves', 'se',\n",
              "         'towards', 'lubbock', 'area', '.', 'outflow', 'boundary', 'may',\n",
              "         'create', 'dust', 'and', '50', 'mph', 'gusts', '.'], dtype='<U9'),\n",
              "  array([7.979206e-06, 9.999920e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['aircraft', 'debris', 'found', 'on', 'la', 'reunion', 'is', 'from',\n",
              "         'missing', 'malaysia', 'airlines', '.', '.', '.', '-', 'abc', '.',\n",
              "         '.', '.', '.', 'g'], dtype='<U8'),\n",
              "  array([2.653125e-04, 9.997347e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['august', '5', '1620', 'one', 'pilgrims', 'from', 'england', 'and',\n",
              "         'holland', 'set', 'sail', 'for', 'the', 'new', 'world', '.',\n",
              "         'they', 'were', 'unimpressed', '.', '.'], dtype='<U11'),\n",
              "  array([0.81261134, 0.18738864], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['im', 'not', 'home', '.', 'i', 'need', 'to', 'watch', '.'],\n",
              "        dtype='<U5'),\n",
              "  array([0.97796327, 0.0220367 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hiroshima', 'survivors', 'fight', 'nuclear', 'industry', 'in',\n",
              "         'brazil', 'video', '.'], dtype='<U9'),\n",
              "  array([2.8017384e-04, 9.9971980e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['sousse', 'beach', 'massacre', 'linked', 'to', 'tunis', 'museum',\n",
              "         'attack', '.'], dtype='<U8'),\n",
              "  array([9.8176224e-07, 9.9999905e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['firefighters', 'headed', 'to', 'california', 'to', 'fight',\n",
              "         'wild', 'fires', '.'], dtype='<U12'),\n",
              "  array([1.1493227e-05, 9.9998856e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['trains', 'the', 'of', 'freak', '-', 'the', 'indian', 'express',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([6.697667e-05, 9.999330e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['who', 'gon', 'get', 'in', 'this', 'rap', 'battle', 'with', 'me'],\n",
              "        dtype='<U6'),\n",
              "  array([0.9975883 , 0.00241176], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['food', 'crematoria', 'provokes', 'outrage', 'amid', 'crisis',\n",
              "         'famine', 'memories', '.'], dtype='<U10'),\n",
              "  array([1.9836545e-05, 9.9998021e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['firefighters', 'battling', 'blaze', 'at', 'east', 'cary', 'condo',\n",
              "         'building', '.'], dtype='<U12'),\n",
              "  array([4.9662543e-04, 9.9950337e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'blew', 'up', 'snapchat', 'for', 'no', 'reason', '?', '?'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9824849 , 0.01751516], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reddit', 'updates', 'content', 'policy', 'promises', 'to',\n",
              "         'quarantine', 'communities', '.'], dtype='<U11'),\n",
              "  array([9.9943346e-01, 5.6646497e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reopens', 'hours', 'after', 'truck', 'fire', 'in', '?', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.00264148, 0.9973585 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['price', 'of', 'vegetables', 'rises', 'on', 'typhoon', 'soudelor',\n",
              "         'concerns', '.'], dtype='<U10'),\n",
              "  array([5.827237e-05, 9.999417e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['food', 'crematoria', 'provokes', 'outrage', 'amid', 'crisis',\n",
              "         'famine', 'memories', '.'], dtype='<U10'),\n",
              "  array([1.9836545e-05, 9.9998021e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['credit', 'to', 'for', 'inspiring', 'me', 'to', 'rediscover',\n",
              "         'this', '.'], dtype='<U10'),\n",
              "  array([0.94461393, 0.05538604], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['injuries', 'may', 'be', 'forgiven', 'but', 'not', 'forgotten',\n",
              "         '.', 'aesop'], dtype='<U9'),\n",
              "  array([9.9983335e-01, 1.6668315e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['nepal', 'earthquake', '3', 'months', 'women', 'fear', 'abuse',\n",
              "         '.', 'via'], dtype='<U10'),\n",
              "  array([0.00138124, 0.9986187 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['prince', 'of', 'wales', 'are', 'nearing', '.', 'demand',\n",
              "         'emergency', '.'], dtype='<U9'),\n",
              "  array([0.02118409, 0.9788159 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['american', 'lives', 'first', '|', 'the', 'chronicle', 'held',\n",
              "         'by', '.'], dtype='<U9'),\n",
              "  array([0.00458613, 0.9954139 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['check', 'out', 'this', 'preview', 'of', 'danger', 'zone',\n",
              "         'coming', '.'], dtype='<U7'),\n",
              "  array([0.9985083 , 0.00149169], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['provoke', 'outrage', 'in', 'country', 'poverty', 'famine',\n",
              "         'memory', '.', '.'], dtype='<U7'),\n",
              "  array([1.08863904e-04, 9.99891162e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['been', 'great', 'if', 'just', 'flattened', 'that', 'little',\n",
              "         'rat', '.'], dtype='<U9'),\n",
              "  array([0.99642783, 0.00357218], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['broken', 'powerlines', 'evacuate', 'gold', 'coast', 'tram',\n",
              "         'suspend', 'services', '.'], dtype='<U10'),\n",
              "  array([5.155910e-05, 9.999484e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['true', 'because', 'of', 'the', 'truck', 'that', 'caught', 'fire',\n",
              "         '?'], dtype='<U7'),\n",
              "  array([0.00180094, 0.99819905], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['be', 'so', 'bomb', 'if', 'u', 'guys', 'won', '?', '?'],\n",
              "        dtype='<U4'),\n",
              "  array([0.9478317 , 0.05216826], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['horrible', 'accident', 'man', 'died', 'in', 'wings', 'of',\n",
              "         'airplane', '.'], dtype='<U8'),\n",
              "  array([2.1024238e-05, 9.9997902e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['screams', 'and', 'gets', 'a', 'face', 'full', 'of', 'saku',\n",
              "         'genitals'], dtype='<U8'),\n",
              "  array([0.98799884, 0.01200121], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sitting', 'around', 'a', 'fire', 'sounds', 'great', 'right',\n",
              "         'about', 'now'], dtype='<U7'),\n",
              "  array([0.99637634, 0.00362361], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['japan', 'marks', '70th', 'anniversary', 'of', 'hiroshima',\n",
              "         'atomic', 'bombing', '.'], dtype='<U11'),\n",
              "  array([2.3915246e-07, 9.9999976e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['three', 'dead', 'after', 'landslide', 'in', 'the', 'italian', '.',\n",
              "         'via'], dtype='<U9'),\n",
              "  array([3.5423515e-04, 9.9964571e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['cancels', 'flash', 'flood', 'warning', 'for', 'bell', 'harlan',\n",
              "         'knox', '.'], dtype='<U7'),\n",
              "  array([1.1719115e-04, 9.9988282e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'let', 'david', 'electrocute', 'himself', 'so', 'the',\n",
              "         'asshole', '.'], dtype='<U11'),\n",
              "  array([0.87674916, 0.12325082], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rly', 'tragedy', 'in', 'some', 'live', 'to', 'recount', 'horror',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([0.00417476, 0.9958253 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['40', 'displaced', 'by', 'ocean', 'township', 'apartment', 'fire',\n",
              "         '-', '.'], dtype='<U9'),\n",
              "  array([8.9882145e-04, 9.9910116e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'latest', 'from', 'reveals', 'is', 'a', 'queen', 'in', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.04664207, 0.95335793], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['police', 'officer', 'wounded', 'suspect', 'dead', 'after',\n",
              "         'exchanging', 'shots', '.'], dtype='<U10'),\n",
              "  array([2.8012282e-05, 9.9997199e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['have', 'collapsed', 'attempting', 'to', 'munch', 'an',\n",
              "         'endangered', 'species', '.'], dtype='<U10'),\n",
              "  array([9.9998629e-01, 1.3742869e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['you', 'are', 'listening', 'to', 'tu', '-', 'twister', 'el', 'rey'],\n",
              "        dtype='<U9'),\n",
              "  array([0.99507266, 0.00492726], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['drunk', 'meals', 'what', 'to', 'cook', 'when', 'totally',\n",
              "         'obliterated', '.'], dtype='<U11'),\n",
              "  array([0.61505353, 0.38494647], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reality', 'train', 'falls', 'off', 'elevated', 'tracks', 'during',\n",
              "         'windstorm', '.'], dtype='<U9'),\n",
              "  array([1.4777505e-04, 9.9985218e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rt', 'adaptation', 'charlie', 'apocalypse', 'now', 'now',\n",
              "         'optioned', 'for', 'film'], dtype='<U10'),\n",
              "  array([9.9963200e-01, 3.6795207e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['city', 'of', 'calgary', 'activates', 'municipal', 'emergency',\n",
              "         'plan', '-', '.'], dtype='<U9'),\n",
              "  array([8.5324042e-05, 9.9991465e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'think', 'a', 'typhoon', 'just', 'passed', 'through', 'here',\n",
              "         'lol'], dtype='<U7'),\n",
              "  array([7.326726e-04, 9.992673e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['does', 'anyone', 'know', 'why', 'was', 'evacuated', 'this',\n",
              "         'evening', '?'], dtype='<U9'),\n",
              "  array([0.00213686, 0.9978631 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['trains', 'the', 'of', 'freak', '-', 'the', 'indian', 'express',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([6.697667e-05, 9.999330e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'these', 'super', 'strong', 'magnets', 'destroy',\n",
              "         'everyday', '.', '.'], dtype='<U8'),\n",
              "  array([0.01669301, 0.983307  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['13', ',', '000', 'people', 'receive', 'evacuation', 'orders',\n",
              "         'in', 'california'], dtype='<U10'),\n",
              "  array([4.2502441e-05, 9.9995744e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['thanks', 'i', 'narrowly', 'averted', 'death', 'that', 'was',\n",
              "         'fun', 'right'], dtype='<U8'),\n",
              "  array([0.00599049, 0.9940095 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['japan', 'marks', '70th', 'anniversary', 'of', 'hiroshima',\n",
              "         'atomic', 'bombing', '.'], dtype='<U11'),\n",
              "  array([2.3915246e-07, 9.9999976e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hazard', 'made', 'his', 'move', 'permanent', 'go', 'gladbach',\n",
              "         'this', 'summer'], dtype='<U9'),\n",
              "  array([0.978519  , 0.02148097], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['no', 'more', ';', 'which', 'devastated', ';', '1000', 'by', ';'],\n",
              "        dtype='<U10'),\n",
              "  array([0.00728353, 0.9927165 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['calgary', 'area', 'tornado', 'warnings', 'end', 'as',\n",
              "         'thunderstorms', 'move', 'eastward'], dtype='<U13'),\n",
              "  array([1.0603198e-06, 9.9999893e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['lost', 'control', 'of', 'car', 'after', 'overtaking', 'and',\n",
              "         'collided', '.'], dtype='<U10'),\n",
              "  array([0.31303626, 0.6869638 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['chilli', 'heat', 'wave', 'doritos', 'never'], dtype='<U7'),\n",
              "  array([0.9939971 , 0.00600284], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['lmfao', 'fucking', 'luis', 'im', 'dead'], dtype='<U7'),\n",
              "  array([0.8416768 , 0.15832323], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'train', 'derailed', 'this', 'morning'], dtype='<U8'),\n",
              "  array([1.422424e-04, 9.998578e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['to', 'electrocute', 'self', 'with', 'phone'], dtype='<U11'),\n",
              "  array([0.99216014, 0.00783982], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hello', 'important', 'please', 'be', '.'], dtype='<U9'),\n",
              "  array([0.26208195, 0.737918  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['oil', 'and', 'gas', 'exploration', '.'], dtype='<U11'),\n",
              "  array([0.00547396, 0.99452597], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['dealing', 'with', 'disaster', '-', '.'], dtype='<U8'),\n",
              "  array([0.0251277 , 0.97487223], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['californian', 'bush', 'fires', '2015', '.'], dtype='<U11'),\n",
              "  array([1.18783326e-04, 9.99881148e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['there', 'engulfed', 'in', 'the', 'fire'], dtype='<U8'),\n",
              "  array([0.63091546, 0.36908454], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['wreckage', 'as', 'from', 'malaysia', 'pm'], dtype='<U8'),\n",
              "  array([1.9500521e-06, 9.9999809e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['skype', 'just', 'crashed', 'u', 'host'], dtype='<U7'),\n",
              "  array([0.7012587 , 0.29874134], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['an', 'emotional', 'wreck', 'watching', 'emmerdale'], dtype='<U9'),\n",
              "  array([9.992737e-01, 7.262556e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['ball', 'has', 'no', 'curfew', '.'], dtype='<U6'),\n",
              "  array([0.9922053 , 0.00779471], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['crash', 'reported', 'on', 'johns', '.'], dtype='<U8'),\n",
              "  array([0.0026368 , 0.99736315], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['cabin', 'fever', '2', 'flames', '.'], dtype='<U6'),\n",
              "  array([0.63503104, 0.364969  ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['im', 'screaming', 'hes', 'my', 'favourite'], dtype='<U9'),\n",
              "  array([0.9842594, 0.0157406], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['mass', 'murder', 'here', 'we', 'come'], dtype='<U6'),\n",
              "  array([0.00201223, 0.99798775], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['edwin', 'wow', '.', 'crushed', '.'], dtype='<U7'),\n",
              "  array([0.9899116, 0.0100884], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hope', 'cake', 'wins', '?', '?'], dtype='<U4'),\n",
              "  array([0.98996234, 0.01003763], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['slightly', 'traumatised', 'after', 'this', 'one'], dtype='<U11'),\n",
              "  array([0.99229676, 0.00770318], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['my', 'chemical', 'romance', 'desolation', 'row'], dtype='<U10'),\n",
              "  array([9.9979931e-01, 2.0072302e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['damage', 'from', 'abandoning', 'the', 'deal', 'could', 'well',\n",
              "         'create', 'a', 'new', 'level', 'of', 'uncertainty', '.', '.', '.',\n",
              "         'economic', 'upheaval', ';', 'military'], dtype='<U11'),\n",
              "  array([0.99804175, 0.00195819], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['christian', 'attacked', 'by', 'muslims', 'at', 'the', 'temple',\n",
              "         'mount', 'after', 'waving', 'israeli', 'flag', 'via', 'pamela',\n",
              "         'geller', '-', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.1072828e-04, 9.9978930e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'have', 'been', 'bleeding', 'into', 'this', 'typewriter',\n",
              "         'all', 'day', 'but', 'so', 'far', 'all', 'written', 'is', 'a',\n",
              "         'bunch', 'of', 'gunk', '.'], dtype='<U10'),\n",
              "  array([0.99790454, 0.00209545], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['indiana', 'state', 'police', 'reopening', 'i-65', 'near',\n",
              "         'lafayette', 'following', 'emergency', 'bridge', 'repairs', 'that',\n",
              "         'closed', 'key', 'highway', 'for', 'about', '28', 'hours', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([1.9972303e-04, 9.9980026e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['we', 'have', 'different', 'moral', 'systems', '.', 'mine',\n",
              "         'rejects', 'the', 'mass', 'murder', 'of', 'innocents', 'yours',\n",
              "         'explicitly', 'endorses', 'such', 'behavior', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.03495138, 0.9650486 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'apologise', 'sincerely', 'for', 'the', 'inevitable',\n",
              "         'deluge', 'of', 'tweets', 'to', 'come', '.', 'i', 'hold', 'any',\n",
              "         'grudges', 'if', 'you', 'decide', 'to'], dtype='<U10'),\n",
              "  array([0.99599326, 0.0040067 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['go', 'look', 'at', 'grizzly', 'peak', 'right', 'now', '.', '.',\n",
              "         '.', 'it', 'looks', 'like', 'the', 'beginning', 'of', 'an',\n",
              "         'dystopian', 'apocalypse', 'movie'], dtype='<U10'),\n",
              "  array([9.992816e-01, 7.184569e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['maratha', 'raiders', 'scorched', 'their', 'lands', ';', 'punjab',\n",
              "         'refused', 'them', 'food', 'aid', 'during', 'the', '1943',\n",
              "         'famine', 'wonder', 'if', 'bengalis', 'harbor', 'some'],\n",
              "        dtype='<U8'),\n",
              "  array([2.8598719e-05, 9.9997139e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['my', 'niece', 'just', 'asked', 'me', 'you', 'be', 'scared', 'if',\n",
              "         'there', 'was', 'an', 'apocalypse', 'here', '?', \"'\", '?', '?',\n",
              "         '?', '?'], dtype='<U10'),\n",
              "  array([0.99502134, 0.00497871], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hailstorm', 'hey', 'there', 'is', 'a', 'secret', 'trick', 'to',\n",
              "         'get', '375', '.', '000', 'gems', 'clash', 'check', 'them', 'now',\n",
              "         'on', 'my', 'profile'], dtype='<U9'),\n",
              "  array([0.99077106, 0.00922894], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['california', 'man', 'facing', 'manslaughter', 'charge', 'in',\n",
              "         'wrong-way', 'fatal', 'crash', 'in', '.', '.', '.', '-', '.', 'ca',\n",
              "         '.', '.', '.', '.'], dtype='<U12'),\n",
              "  array([0.00397022, 0.99602985], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['investigators', 'have', 'said', 'a', 'virgin', 'galactic',\n",
              "         'spaceship', 'crash', 'was', 'caused', 'by', 'structural',\n",
              "         'failure', 'after', 'the', 'co-pilot', '.', '.', '.', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([6.7811809e-04, 9.9932194e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['today', 'is', 'the', '70th', 'anniversary', 'of', 'a-bomb',\n",
              "         'been', 'dropped', 'on', 'hiroshima', '.', '70000', 'killed',\n",
              "         'outright', 'as', 'the', 'city', 'was', 'flattened'], dtype='<U11'),\n",
              "  array([0.0032798 , 0.99672025], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'the', 'seventies', 'terrorism', 'episode', '.', 'iran',\n",
              "         'has', 'always', 'hated', 'the', 'u', '.', 's', '.', 'they',\n",
              "         'want', 'us', 'obliterated', '.'], dtype='<U11'),\n",
              "  array([0.02048231, 0.9795177 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['injury', 'woes', 'took', 'claiborne', 'from', 'first', 'round',\n",
              "         'to', 'trying', 'to', 'stick', 'around', ';', 'can', 'he', 'do',\n",
              "         'it', '?', ':', '.'], dtype='<U9'),\n",
              "  array([0.99683446, 0.00316552], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['ml', '2', '.', '4', 'near', 'the', 'coast', 'of', 'western', '2',\n",
              "         '.', 'the', 'coast', 'of', 'western', 'turkey', '.', '.', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.00127879, 0.9987212 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['calgary', 'area', 'tornado', 'warnings', 'end', 'as',\n",
              "         'thunderstorms', 'move', 'eastward', '-', 'cbc', '.', 'cbc', '.',\n",
              "         'ca', 'calgary', 'area', 'tornado', 'warnings', '.'], dtype='<U13'),\n",
              "  array([1.6855226e-06, 9.9999833e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['my', 'tears', 'drowned', 'out', 'the', 'terrible', 'taste',\n",
              "         'also', 'nataly', 'gave', 'me', 'her', 'steak', 'and', 'cheese',\n",
              "         'thing', 'to', 'cheer', 'me', 'up'], dtype='<U8'),\n",
              "  array([0.998483  , 0.00151696], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['whenever', 'i', 'have', 'a', 'meltdown', 'and', 'need', 'someone',\n",
              "         'is', 'always', 'like', 'in', 'and', 'i', 'know', 'how', 'i',\n",
              "         'got', 'so', 'lucky'], dtype='<U8'),\n",
              "  array([0.9856344 , 0.01436564], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['your', 'for', 'made', 'me', 'a', 'new', 'fan', 'of', 'yours',\n",
              "         'fam', '.', 'crazy', 'skills', 'beyond', 'keep', 'blazing', 'dude',\n",
              "         'made', 'love', 'and'], dtype='<U7'),\n",
              "  array([0.9946991 , 0.00530085], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['bin', 'laden', 'family', 'plane', 'crashed', 'after',\n",
              "         'microlight', 'and', 'landing', 'too', 'far', 'down', 'three',\n",
              "         'members', 'of', 't', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.00144924, 0.9985507 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['loan', 'upheaval', 'is', 'the', 'way', 'in', 'which', 'oneself',\n",
              "         'can', 'save', 'your', 'house', 'leaving', 'out', 'being',\n",
              "         'foreclosed', 'on', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.9961926 , 0.00380736], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['angry', 'woman', 'openly', 'accuses', 'nema', 'of', 'stealing',\n",
              "         'relief', 'materials', 'meant', 'for', 'an', 'angry', 'internally',\n",
              "         'displaced', 'wom', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.9178391 , 0.08216088], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['should', 'be', 'renamed', 'italian', 'goonda', 'party', '.',\n",
              "         'they', 'are', 'a', 'motley', 'crowd', 'of', 'hooligans', 'and',\n",
              "         'crooks', 'determined', 'to', 'derail', 'democracy'], dtype='<U10'),\n",
              "  array([0.99175864, 0.0082414 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['japan', 'had', 'a', 'nuke', 'program', 'and', 'the', 'casualty',\n",
              "         'estimates', 'for', 'a', 'ground', 'war', 'were', 'in', 'the',\n",
              "         'tens', 'of', 'millions', '.'], dtype='<U9'),\n",
              "  array([0.00347924, 0.99652076], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['helping', 'in', 'mumbai', '2', 'take', 'charge', 'of', 'helpline',\n",
              "         'to', 'calm', 'anxious', 'relatives', '-', 'the', 'indian', 'exp',\n",
              "         '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([9.817254e-04, 9.990183e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['investigators', 'have', 'said', 'a', 'virgin', 'galactic',\n",
              "         'spaceship', 'crash', 'was', 'caused', 'by', 'structural',\n",
              "         'failure', 'after', 'the', 'co-pilot', '.', '.', '.', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([6.7811809e-04, 9.9932194e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hi-res', 'doppler', 'showing', 'storm', 'just', 'ne', 'of',\n",
              "         'edmond', 'is', 'now', 'severe', 'with', '1', '.', 'hail', 'and',\n",
              "         'wind', 'possible', '.', '.'], dtype='<U8'),\n",
              "  array([0.00604614, 0.9939539 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['picking', 'up', 'bodies', 'from', 'rescuers', 'are', 'searching',\n",
              "         'for', 'hundreds', 'of', 'migrants', 'in', 'the', 'mediterranean',\n",
              "         'after', 'a', 'boat', '.', '.', '.'], dtype='<U13'),\n",
              "  array([4.2581695e-04, 9.9957412e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['?', '?', 'warfighting', 'robots', 'could', 'reduce', 'civilian',\n",
              "         'casualties', 'so', 'calling', 'for', 'a', 'ban', 'now', 'is',\n",
              "         'premature', '-', 'ieee', 'spectrum', '.'], dtype='<U11'),\n",
              "  array([0.0463305, 0.9536694], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'mad', 'catastrophe', ':', 'the', 'outbreak', 'of', 'world',\n",
              "         'war', 'i', 'and', 'the', 'collapse', 'of', 'the', '.', '.', '.',\n",
              "         '.', '.'], dtype='<U11'),\n",
              "  array([0.00880517, 0.99119484], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['to', 'let', 'my', 'life', 'be', 'reduced', 'to', 'rubble', '.',\n",
              "         'when', 'the', 'shit', 'keeps', 'piling', 'up', 'get', 'a',\n",
              "         'shovel', '.', \"'\"], dtype='<U7'),\n",
              "  array([0.87296176, 0.12703824], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['deepwater', 'horizon', 'oil', 'spill', 'distribution', 'of',\n",
              "         'funds', 'from', 'bp', 'settlement', 'road', 'and', 'bridge',\n",
              "         'projects', 'in', 'bal', '.', '.', '.', '.'], dtype='<U12'),\n",
              "  array([0.00112955, 0.99887043], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['look', 'like', 'a', 'murder', 'scene', 'just', '1', 'cops', 'a',\n",
              "         'fire', 'truck', 'and', '2', 'fire', 'assistance', 'cars', 'along',\n",
              "         'with', 'a', 'helicopter'], dtype='<U10'),\n",
              "  array([0.00365535, 0.9963446 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'want', 'to', 'be', 'with', 'you', 'forever', 'stay', 'by',\n",
              "         'my', 'side', 'on', 'this', 'special', 'night', 'fear', 'and',\n",
              "         'loathing', 'in', 'las'], dtype='<U8'),\n",
              "  array([9.997340e-01, 2.660618e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['people', 'in', 'sydney', 'woke', 'up', 'to', 'the', 'whole',\n",
              "         'sky', 'being', 'red', 'after', 'a', 'dust', 'storm', '.', '.',\n",
              "         'like', 'unreal', '.'], dtype='<U6'),\n",
              "  array([0.0129336 , 0.98706645], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bounty', 'hunters', 'try', 'to', 'raid', 'phoenix', 'police', 'a',\n",
              "         'group', 'of', 'armed', 'bounty', 'hunters', 'surrounded', 'the',\n",
              "         'h', '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.15999642, 0.84000355], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['illegal', 'alien', 'released', 'by', '4', 'times', 'charged',\n",
              "         'with', 'rape', ';', 'murder', 'of', 'santa', 'maria', 'ca',\n",
              "         'woman', 'had', 'prior', 'offenses', '.'], dtype='<U8'),\n",
              "  array([0.00506571, 0.99493426], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wait', 'i', 'thought', 'fecal', 'hurricane', 'was', 'on', 'scifi',\n",
              "         '?', 'maybe', 'that', 'was', '.', 'been', 'up', 'a', 'shit',\n",
              "         'storm', 'lately', '.'], dtype='<U9'),\n",
              "  array([0.20480804, 0.79519194], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['maj', 'pilot', 'of', 'mi-17', 'crashed', 'near', 'mansehra',\n",
              "         'today', '.', 'may', 'almighty', 'give', 'strength', 'to',\n",
              "         'family', 'to', 'bear', 'the', 'loss', '.'], dtype='<U8'),\n",
              "  array([0.00399174, 0.9960083 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['is', 'claims', 'suicide', 'bombing', 'against', 'saudi', 'an',\n",
              "         'islamic', 'state', 'group', 'suicide', 'bomber', 'on', 'thursday',\n",
              "         'detonated', 'an', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([1.7733325e-04, 9.9982268e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['following', 'a', 'catastrophic', 'injury', 'acute', 'medical',\n",
              "         'care', 'takes', 'precedent', '.', 'ptsd', 'often', 'follows',\n",
              "         'in', 'wake', 'undetected', '.', '.', '.', '.'], dtype='<U12'),\n",
              "  array([0.00386586, 0.99613416], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['last', 'time', 'i', 'checked', 'lots', 'of', 'injuries', 'over',\n",
              "         'the', 'course', 'of', 'time', '=', 'injury', 'prone', '.', 'am',\n",
              "         'i', 'wrong', '?'], dtype='<U8'),\n",
              "  array([9.9932694e-01, 6.7305838e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['add', 'these', 'items', 'to', 'your', 'everyday', 'eating',\n",
              "         'habits', '.', 'please', 'do', 'the', 'research', 'on', 'how',\n",
              "         'to', 'take', 'with', 'your', '.'], dtype='<U8'),\n",
              "  array([0.64913493, 0.35086507], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'flight', 'to', 'burma', 'when', 'country', 'is', 'enduring',\n",
              "         'political', 'unrest', 'and', 'a', 'natural', 'no', 'wonder', 'it',\n",
              "         'was', 'so', 'cheap', 'ay'], dtype='<U9'),\n",
              "  array([0.24186347, 0.7581366 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['can', 'you', 'recommend', 'anyone', 'for', 'this', '?', 'rn',\n",
              "         'emergency', 'services', 'full', 'time', '3p', '-', 'rose', 'de',\n",
              "         'lima', 'campus', '-', '.'], dtype='<U9'),\n",
              "  array([0.9983375, 0.0016625], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['fedex', 'no', 'longer', 'to', 'transport', 'bioterror', 'germs',\n",
              "         'in', 'wake', 'of', 'anthrax', 'lab', 'mishaps', 'what', '?', 'no',\n",
              "         '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.02862369, 0.97137636], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rly', 'tragedy', 'in', 'some', 'live', 'to', 'recount', 'i',\n",
              "         'saw', 'coaches', 'of', 'my', 'train', 'plunging', 'into', 'wa',\n",
              "         '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.00435649, 0.9956435 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['working', 'at', 'zumiez', 'is', 'the', '.', 'which', 'location',\n",
              "         '?', '?'], dtype='<U8'),\n",
              "  array([0.8430022 , 0.15699777], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'look', 'at', 'state', 'actions', 'a', 'year', 'after',\n",
              "         'upheaval', '.'], dtype='<U8'),\n",
              "  array([0.2670896, 0.7329104], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['investigators', 'shift', 'focus', 'to', 'cause', 'of', 'fatal',\n",
              "         'waimate', 'fire', '.'], dtype='<U13'),\n",
              "  array([1.7278692e-04, 9.9982721e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['photographer', 'brian', 'endures', 'climb', 'to', 'capture',\n",
              "         'bride', 'and', 'groom', '.'], dtype='<U12'),\n",
              "  array([0.9337694, 0.0662306], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hill', 'hill', 'mountain', 'volcano', 'of', 'hell', 'mountain',\n",
              "         'hill', 'hil', '.'], dtype='<U8'),\n",
              "  array([5.0014351e-05, 9.9994993e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['radar', 'widespread', 'but', 'moving', 'over', 'the', 'same',\n",
              "         'flooding', 'possible', '.'], dtype='<U10'),\n",
              "  array([4.9530267e-04, 9.9950469e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['myanmar', '.', 'and', 'international', 'needs', '.', 'and',\n",
              "         'care', 'aust', 'appeals'], dtype='<U13'),\n",
              "  array([0.26836798, 0.73163205], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['historic', 'flooding', 'across', 'asia', 'leaves', 'hundreds',\n",
              "         'dead', 'millions', '.', '.'], dtype='<U8'),\n",
              "  array([8.821615e-05, 9.999118e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['swansea', 'hijack', 'transfer', 'move', 'for', 'southampton',\n",
              "         'target', 'virgil', 'van', '.'], dtype='<U11'),\n",
              "  array([0.00540202, 0.9945979 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hiroshima', '-', 'one', 'of', 'worst', 'examples', 'of', 'mass',\n",
              "         'murder', '.'], dtype='<U9'),\n",
              "  array([1.615498e-05, 9.999838e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['why', 'does', 'arabia', 'and', 'get', 'away', 'with', 'mass',\n",
              "         'murder', '?'], dtype='<U6'),\n",
              "  array([4.5344652e-05, 9.9995470e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['arrested', 'for', 'setting', 'many', 'fires', '.', 'watch',\n",
              "         'other', '.', '.'], dtype='<U8'),\n",
              "  array([1.4896116e-04, 9.9985099e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['black', 'ops', '3', 'search', 'and', 'destroy', 'snd',\n",
              "         'competitive', '.', 'via'], dtype='<U11'),\n",
              "  array([0.99033386, 0.00966613], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['photos', 'collapse', 'entire', 'sunsets', 'into', 'single',\n",
              "         'mesmerizing', 'images', '.', '.'], dtype='<U11'),\n",
              "  array([0.99653697, 0.00346302], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', 'picking', 'up', 'bodies', 'from', 'rescuers', 'are',\n",
              "         'searching', 'for', '.'], dtype='<U9'),\n",
              "  array([7.924422e-05, 9.999207e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'drown', 'my', 'demons', 'they', 'know', 'how', 'to', 'swim',\n",
              "         '.'], dtype='<U6'),\n",
              "  array([0.9651729 , 0.03482711], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'hate', 'that', 'im', 'so', 'awkward', 'and', 'i', 'ruin',\n",
              "         'things'], dtype='<U7'),\n",
              "  array([0.9983683 , 0.00163169], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['epa', 'begins', 'demolition', 'of', 'homes', 'in', 'toxic',\n",
              "         'area', '-', '.'], dtype='<U10'),\n",
              "  array([2.9370074e-05, 9.9997067e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['insane', 'bush', 'fires', 'in', 'california', '.', 'be', 'safe',\n",
              "         '.', '.'], dtype='<U10'),\n",
              "  array([3.7165248e-04, 9.9962831e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['alabama', 'firefighters', 'quarantined', 'after', 'possible',\n",
              "         'ebola', 'exposure', '.', 'reports', '.'], dtype='<U12'),\n",
              "  array([2.5117336e-04, 9.9974877e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['oh', 'fuck', 'sake', 'he', 'is', 'dead', '?', '?', '?', '?'],\n",
              "        dtype='<U4'),\n",
              "  array([0.99556446, 0.00443553], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['now', 'realized', 'i', 'honestly', 'survive', 'without', 'these',\n",
              "         'glasses', 'now', 'lol'], dtype='<U8'),\n",
              "  array([0.9791716 , 0.02082844], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['world', 'class', 'ass', '02', '-', 'scene', '4', '-',\n",
              "         'pandemonium', '.'], dtype='<U11'),\n",
              "  array([9.9989629e-01, 1.0367611e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['would', 'have', 'just', 'flattened', 'the', 'little', 'midget',\n",
              "         '?', '?', '.'], dtype='<U9'),\n",
              "  array([0.96598744, 0.03401258], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['my', 'girl', 'got', 'a', 'girlfriend', 'chevy', 'blue', 'like',\n",
              "         'whirlwind', '.'], dtype='<U10'),\n",
              "  array([0.99161583, 0.00838414], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['check', 'out', 'confirms', 'plane', 'wreckage', 'is', 'from',\n",
              "         'flight', 'at', '.'], dtype='<U8'),\n",
              "  array([1.239775e-05, 9.999876e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['16', 'business', 'owners', 'share', 'what', 'they', 'would', 'do',\n",
              "         'differently', '.'], dtype='<U11'),\n",
              "  array([0.9858662 , 0.01413382], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['two', 'great', 'dak', 'and', 'jak', '!!!', 'hail', 'state', '!!!',\n",
              "         '.'], dtype='<U5'),\n",
              "  array([0.9824203 , 0.01757969], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['car', 'engulfed', 'in', 'flames', 'backs', 'up', 'traffic', 'at',\n",
              "         'summit', '.'], dtype='<U8'),\n",
              "  array([6.7251109e-05, 9.9993277e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['isis', 'claims', 'responsibility', 'for', 'saudi', 'mosque',\n",
              "         'suicide', 'bombing', '.', '.'], dtype='<U14'),\n",
              "  array([5.2434311e-06, 9.9999475e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['before', 'your', 'town', 'is', 'obliterated', 'and', 'the',\n",
              "         'earth', 'is', 'salted'], dtype='<U11'),\n",
              "  array([0.9755411 , 0.02445885], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'dress', 'memes', 'have', 'officially', 'exploded', 'on',\n",
              "         'the', 'internet', '.'], dtype='<U10'),\n",
              "  array([0.33575094, 0.6642491 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['alabama', 'home', 'quarantined', 'over', 'possible', 'ebola',\n",
              "         'case', '-', 'abc', 'news'], dtype='<U11'),\n",
              "  array([2.7763625e-04, 9.9972230e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['property', 'losses', 'from', 'northern', 'california', 'wildfire',\n",
              "         'nearly', 'double', '.', 'via'], dtype='<U10'),\n",
              "  array([9.604653e-05, 9.999039e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['radioactive', 'weapons', '.', 'scandals', 'murders', 'and',\n",
              "         'environmental', '-', 'video', '.'], dtype='<U13'),\n",
              "  array([0.00790375, 0.9920962 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'sarah', 'palin', 'obliterate', 'planned', 'parenthood',\n",
              "         'for', 'targeting', 'minority', '.'], dtype='<U10'),\n",
              "  array([0.5234344, 0.4765656], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['oh', 'wow', 'my', 'heart', 'collapsed', 'cool', 'im', 'crying',\n",
              "         'cool', 'cool'], dtype='<U9'),\n",
              "  array([0.13315283, 0.86684716], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['cuban', 'leader', 'extends', 'sympathy', 'to', 'vietnam', 'over',\n",
              "         'flooding', 'at', '.'], dtype='<U8'),\n",
              "  array([4.6590038e-05, 9.9995339e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['senator', 'john', 'whoops', 'moment', ':', 'photographed',\n",
              "         'chilling', 'with', '.', '.'], dtype='<U12'),\n",
              "  array([0.98906505, 0.01093494], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['2', 'great', 'new', 'recipes', ';', 'mudslide', 'cake', 'and',\n",
              "         'so', 'sorry'], dtype='<U8'),\n",
              "  array([9.992415e-01, 7.585892e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['apc', 'chieftain', 'tasks', 'dickson', 'on', 'floods', 'donation',\n",
              "         'to', 'bayelsa', '.'], dtype='<U9'),\n",
              "  array([5.3970434e-04, 9.9946028e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['twelve', 'feared', 'killed', 'in', 'pakistani', 'air',\n",
              "         'ambulance', 'helicopter', 'crash', '.'], dtype='<U10'),\n",
              "  array([4.5652041e-06, 9.9999547e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['that', 'song', 'have', 'a', 'cool', 'beat', 'like', 'nothing',\n",
              "         'but', 'trouble'], dtype='<U7'),\n",
              "  array([0.7652321 , 0.23476791], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hijacking', 'computers', 'to', 'send', 'data', 'as', 'sound',\n",
              "         'waves', 'hat', '.'], dtype='<U9'),\n",
              "  array([0.82546484, 0.17453523], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['joel', '2:28', '?', 'and', 'book', 'of', 'acts', '2:17', '?', '.'],\n",
              "        dtype='<U4'),\n",
              "  array([0.9891053 , 0.01089476], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['alabama', 'home', 'quarantined', 'over', 'possible', 'ebola',\n",
              "         'case', '-', 'washington', 'times'], dtype='<U11'),\n",
              "  array([0.00136875, 0.9986312 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['my', 'good', 'you', 'stay', 'in', 'ny', '?', '?', '?', '?'],\n",
              "        dtype='<U4'),\n",
              "  array([0.9812749, 0.0187251], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['twelve', 'feared', 'killed', 'in', 'pakistani', 'air',\n",
              "         'ambulance', 'helicopter', 'crash', '.'], dtype='<U10'),\n",
              "  array([4.5652041e-06, 9.9999547e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['ice', 'cream', '+', 'cupcake', 'wars', '+', 'storm', '=',\n",
              "         'content', 'sara'], dtype='<U7'),\n",
              "  array([9.9995565e-01, 4.4346023e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['crushed'], dtype='<U7'),\n",
              "  array([0.94412804, 0.05587189], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['drown'], dtype='<U5'),\n",
              "  array([0.94975615, 0.05024389], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['then'], dtype='<U4'),\n",
              "  array([0.9425637 , 0.05743628], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['thinking', 'of', 'the', 'time', 'that', 'my', 'friend', 'bailed',\n",
              "         'the', 'nite', 'b4', 'a', 'dead', 'show', '.', '.', '.', 'went',\n",
              "         'alone', ';', 'had', 'a', 'great', 'time', '.', 'all', 'alone',\n",
              "         'and', 'free', 'to', 'dance', '.', 'front', 'row'], dtype='<U8'),\n",
              "  array([0.842153  , 0.15784696], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['hints', 'and', 'snippets', 'will', 'be', 'the', 'death', 'of',\n",
              "         'me', '.'], dtype='<U8'),\n",
              "  array([0.99604815, 0.00395188], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['crying', 'that', 'song', 'just', 'ended', 'setting', 'myself',\n",
              "         'on', 'fire', '.'], dtype='<U7'),\n",
              "  array([0.9656223 , 0.03437766], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['saw', 'that', 'pileup', 'on', 'tv', 'keep', 'racing', 'even',\n",
              "         'bleeding'], dtype='<U8'),\n",
              "  array([9.5953517e-05, 9.9990404e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['u', '.', 's', '.', 'in', 'record', 'hurricane', 'drought', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([6.668301e-07, 9.999993e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['disaster', 'police', 'kill', 'gunman', 'with', 'at', 'cinema',\n",
              "         '.', 'via'], dtype='<U8'),\n",
              "  array([2.4515341e-04, 9.9975485e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['russian', 'provoke', 'outrage', 'amid', 'crisis', 'famine',\n",
              "         'memories', '.', 'via'], dtype='<U8'),\n",
              "  array([8.7995526e-05, 9.9991202e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['wider', 'variety', 'of', 'therapies', 'could', 'help', 'vets',\n",
              "         'troops', 'with', 'ptsd', '|', '.', '.', 'via'], dtype='<U9'),\n",
              "  array([0.9916932 , 0.00830681], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['all', 'the', 'loves', 'be', 'screaming', 'at', 'this', 'one', '?',\n",
              "         '?', '?', '?', '?', '?'], dtype='<U9'),\n",
              "  array([0.99844545, 0.00155454], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['do', 'texts', 'use', 'data', '?', 'she', 'was', 'inundated', 'by',\n",
              "         'a', 'group', 'text', 'yesterday', '.'], dtype='<U9'),\n",
              "  array([0.9454844, 0.0545156], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', '.', '.', '.', '.', '.', '.', '12000', 'nigerian', 'refugees',\n",
              "         'repatriated', 'from', 'cameroon', '.'], dtype='<U11'),\n",
              "  array([3.2654912e-06, 9.9999678e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['udhampur', 'terror', 'nia', 'takes', 'over', 'probe', 'pakistani',\n",
              "         'terrorist', 'quizzed', ';', 'pak', 'denies', 'link', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([5.9340159e-06, 9.9999404e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['gop', 'debate', 'tonight', 'but', 'no', 'jon', 'stewart', 'next',\n",
              "         'week', 'to', 'obliterate', 'them', '?', '?'], dtype='<U10'),\n",
              "  array([0.9987136 , 0.00128636], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['nazi', 'mass', 'murderer', 'became', 'chairman', 'at', 'vaccine',\n",
              "         'drug', 'company', 'in', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([0.00331236, 0.9966877 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['red', 'flag', 'warning', 'for', 'fire', 'danger', ';', 'dry',\n",
              "         'thunderstorms', 'in', 'bay', 'area', '.', 'by'], dtype='<U13'),\n",
              "  array([6.6695146e-05, 9.9993324e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'this', 'airport', 'get', 'swallowed', 'up', 'by', 'a',\n",
              "         'sandstorm', 'in', 'under', 'a', 'minute', '.'], dtype='<U9'),\n",
              "  array([1.6151222e-04, 9.9983847e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['womens', 'flower', 'printed', 'shoulder', 'handbags', 'cross',\n",
              "         'body', 'metal', 'chain', 'satchel', 'bags', 'blue', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9940002 , 0.00599988], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['to', 'that', 'time', 'my', 'best', 'friend', 'and', 'i',\n",
              "         'panicked', 'at', 'the', 'disco', '.', '.'], dtype='<U8'),\n",
              "  array([0.98719704, 0.01280295], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['17', 'people', 'killed', 'and', 'over', '25', 'injured', 'in',\n",
              "         'deadly', 'saudi', 'mosque', 'suicide', 'attack', '.'], dtype='<U7'),\n",
              "  array([1.7867962e-06, 9.9999821e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['draw', 'day', 'demolition', 'daily', 'football', 'selection',\n",
              "         'service', 'that', 'consistently', 'makes', 'money', 'lay', '.',\n",
              "         '.'], dtype='<U12'),\n",
              "  array([0.9971673 , 0.00283272], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['70', 'years', 'ago', 'today', 'the', 'united', 'states', 'of',\n",
              "         'america', 'bombed', 'hiroshima', 'in', 'japan', '.'], dtype='<U9'),\n",
              "  array([7.011500e-05, 9.999299e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hell', 'is', 'just', 'a', 'fraction', 'of', 'his', 'belief', 'of',\n",
              "         'total', 'annihilation', 'destruction', 'of', 'usa'], dtype='<U12'),\n",
              "  array([0.00826019, 0.99173975], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['weather', 'forecast', 'for', 'thailand', 'a', 'whirlwind', 'is',\n",
              "         'coming', '.', '.', '.', '2', 'september', '.'], dtype='<U9'),\n",
              "  array([0.0027559, 0.9972441], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'this', 'airport', 'get', 'swallowed', 'up', 'by', 'a',\n",
              "         'sandstorm', 'in', 'under', 'a', 'minute', '.'], dtype='<U9'),\n",
              "  array([1.6151222e-04, 9.9983847e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['usgs', 'm', '0', '.', '6', '-', '8km', 'ssw', 'of', 'anza', '.',\n",
              "         '.', '.', '.'], dtype='<U4'),\n",
              "  array([8.939292e-04, 9.991060e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['one', 'year', 'on', 'from', 'the', 'sinjar', 'massacre', 'blast',\n",
              "         'lack', 'of', 'action', 'over', 'hostages', '.'], dtype='<U8'),\n",
              "  array([4.902721e-05, 9.999510e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'got', 'evacuated', 'from', 'the', 'cinema', '30', 'mins',\n",
              "         'through', 'inside', 'out', 'kill', 'me', 'please'], dtype='<U9'),\n",
              "  array([9.994653e-01, 5.346669e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['fedex', 'no', 'longer', 'to', 'transport', 'bioterror', 'germs',\n",
              "         'in', 'wake', 'of', 'anthrax', 'lab', 'mishaps', '.'], dtype='<U9'),\n",
              "  array([0.09493018, 0.9050698 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['things', 'actually', 'can', 'explode', 'with', 'a', 'loud',\n",
              "         'bang', '.', '.', '.', 'in', 'space', '.'], dtype='<U8'),\n",
              "  array([0.9982718 , 0.00172813], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['men', 'escape', 'car', 'engulfed', 'in', 'flames', 'in', 'canyon',\n",
              "         'crews', 'investigating', 'cause', '-', '.', '.'], dtype='<U13'),\n",
              "  array([1.1227466e-04, 9.9988770e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['good', 'thing', 'there', 'was', 'actually', 'just', 'a', 'legit',\n",
              "         'fire', 'in', 'the', 'mall', 'and', 'nobody'], dtype='<U8'),\n",
              "  array([0.00472716, 0.9952728 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['and', 'i', 'have', 'any', 'classes', 'together', 'and', 'not',\n",
              "         'sure', 'if', 'be', 'able', 'to', 'survive'], dtype='<U8'),\n",
              "  array([0.9867181 , 0.01328182], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'martyrs', 'who', 'kept', 'udhampur', 'terrorists', 'at',\n",
              "         'bay', 'averted', 'a', 'it', 'was', 'two', '.'], dtype='<U10'),\n",
              "  array([3.1333676e-04, 9.9968672e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['2', 'vehicles', 'collided', 'at', 'lock', 'and', 'lansdowne',\n",
              "         'sts', 'in', '.', 'crews', 'on', 'their', 'way'], dtype='<U9'),\n",
              "  array([2.7563234e-04, 9.9972433e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['new', 'tempered', 'glass', 'screen', 'protector', 'film', 'for',\n",
              "         'blackberry', 'z10', '-', 'full', 'read', '.', '.'], dtype='<U10'),\n",
              "  array([0.9978684 , 0.00213159], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['do', 'you', 'feel', 'like', 'you', 'are', 'sinking', 'in',\n",
              "         'unhappiness', '?', 'take', 'the', '.', '.'], dtype='<U11'),\n",
              "  array([0.9477642 , 0.05223576], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['one', 'day', 'this', 'heart', 'gone', 'get', 'me', 'zipped', 'up',\n",
              "         'in', 'a', 'body', 'bag', '.'], dtype='<U6'),\n",
              "  array([0.99789894, 0.00210101], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['violent', 'forces', 'now', 'playing', 'acid', 'storm', '-', 'of',\n",
              "         'the', 'gods', 'tunein', 'player', '@', '.'], dtype='<U7'),\n",
              "  array([0.03729803, 0.96270204], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['womens', 'handbags', 'cross', 'body', 'geometric', 'pattern',\n",
              "         'satchel', 'totes', 'shoulder', 'bags', 'white', '.', '.', 'rt'],\n",
              "        dtype='<U9'),\n",
              "  array([0.9976793, 0.0023207], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['children', 'in', 'myanmar', 'face', 'a', 'as', 'floods', 'hit',\n",
              "         'the', 'most', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([3.8366960e-04, 9.9961627e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['watch', 'this', 'airport', 'get', 'swallowed', 'up', 'by', 'a',\n",
              "         'sandstorm', 'in', 'under', 'a', 'minute', '.'], dtype='<U9'),\n",
              "  array([1.6151222e-04, 9.9983847e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['outcomes', 'in', 'long-term', 'survivors', 'of', 'metastatic',\n",
              "         'colorectal', 'cancer', '-', 'british', 'journal', 'of', 'surgery',\n",
              "         '.'], dtype='<U10'),\n",
              "  array([0.00472323, 0.9952768 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['join', '10k', '11am', 'start', 'sun', '20', 'sept', '2015',\n",
              "         'castle', 'donington', 'community', 'first', 'responders', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9030382, 0.0969618], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['m', '1', '.', '4', '-', '4km', 'e', 'of', 'interlaken', '-07',\n",
              "         '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.0163028 , 0.98369724], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'hope', 'he', 'does', '.', 'and', 'i', 'hope', 'you', 'die',\n",
              "         'in', 'the', 'explosion', 'too'], dtype='<U9'),\n",
              "  array([0.03305611, 0.9669439 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bulgarian', 'twister', 'by', 'produced', 'by', 'pathfinders', 'm',\n",
              "         '.', '.', '.', ':', '.', 'via', 'youtube'], dtype='<U11'),\n",
              "  array([9.9917114e-01, 8.2890649e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['going', 'to', 'redo', 'my', 'nails', 'and', 'watch', 'behind',\n",
              "         'the', 'scenes', 'of', 'desolation', 'of', 'smaug'], dtype='<U10'),\n",
              "  array([0.05847563, 0.9415243 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['i', 'liked', 'a', 'video', 'from', '.', 'minecraft', '-', 'o',\n",
              "         'blaze', 'que', 'usa', 'hack', 'e'], dtype='<U9'),\n",
              "  array([9.9983704e-01, 1.6290252e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['watch', 'this', 'airport', 'get', 'swallowed', 'up', 'by', 'a',\n",
              "         'sandstorm', 'in', 'under', 'a', 'minute', '.'], dtype='<U9'),\n",
              "  array([1.6151222e-04, 9.9983847e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['children', 'in', 'myanmar', 'face', 'a', 'as', 'floods', 'hit',\n",
              "         'the', 'most', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([3.8366960e-04, 9.9961627e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['forest', 'fires', 'could', 'delay', 'but', 'officials', 'say',\n",
              "         'it', 'could', 'be', 'a', 'good', 'thing', '.'], dtype='<U9'),\n",
              "  array([0.00397016, 0.99602985], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['slightly', 'diff', 'catastrophe', ';', 'barry', 'was', 'running',\n",
              "         'solo', 'but', 'generally', 'the', 'same', 'thing', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([0.9624036 , 0.03759639], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'agree', 'with', 'background', 'checks', '.', 'i', 'just',\n",
              "         'think', 'guns', 'or', 'weapons', 'in', 'general', 'are', 'the',\n",
              "         'great', 'equalizer', '.'], dtype='<U10'),\n",
              "  array([0.9978346 , 0.00216534], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['criminals', 'who', 'hijack', 'lorries', 'and', 'buses',\n",
              "         'arrested', 'in', 'according', 'to', 'the', 'nigerian', 'police',\n",
              "         'force', '.', '.', '.', '.', 'via'], dtype='<U9'),\n",
              "  array([0.00618964, 0.99381036], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['put', 'the', 'right', 'person', 'up', 'on', 'the', 'block', '?',\n",
              "         '?', '?', 'the', 'sense', 'of', 'entitlement', 'is', 'ridiculous',\n",
              "         '.', '.'], dtype='<U11'),\n",
              "  array([0.97119755, 0.02880251], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['services', 'are', 'returning', 'to', 'normal', 'after', 'a',\n",
              "         'medical', 'emergency', 'at', 'and', 'urgent', 'track',\n",
              "         'equipment', 'repairs', 'at', 'cabramatta', 'earlier', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([3.704150e-04, 9.996296e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['survived', 'another', 'tube', 'strike', 'with', 'the', 'last',\n",
              "         'person', 'at', 'office', 'reaching', 'home', '.', 'we', 'are',\n",
              "         'getting', 'better', 'at', 'navigating'], dtype='<U10'),\n",
              "  array([0.9934121, 0.0065879], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'started', 'writing', 'when', 'i', 'talk', 'about', 'my',\n",
              "         'trauma', 'in', 'therapy', 'it', 'was', 'the', 'only', 'way', 'i',\n",
              "         'could', 'communicate'], dtype='<U11'),\n",
              "  array([0.9797752 , 0.02022476], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['a', 'reverse', 'situation', 'i', 'know', '9/11', '?', ')',\n",
              "         'where', 'us', 'civilian', 'deaths', 'were', 'specifically',\n",
              "         'utilized', 'to', 'make', 'a', 'political'], dtype='<U12'),\n",
              "  array([0.00383976, 0.99616027], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['officer', 'wounded', 'suspect', 'killed', 'in', 'exchange', 'of',\n",
              "         'richmond', 'police', 'officer', 'wounded', 'suspect', 'killed',\n",
              "         'in', 'exc', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([2.8660748e-04, 9.9971336e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['how', 'can', 'we', 'help', 'save', 'a', 'beautiful', 'town', 'in',\n",
              "         'ontario', 'from', 'destruction', 'by', 'a', 'power', 'plant',\n",
              "         'developer', '?', '.'], dtype='<U11'),\n",
              "  array([0.99784994, 0.00215011], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['how', 'do', 'people', 'not', 'know', 'who', 'kendall', 'jenner',\n",
              "         'is', '?', 'she', 'has', '6', 'times', 'the', 'instagram',\n",
              "         'followers', 'of', 'screaming'], dtype='<U9'),\n",
              "  array([0.976919  , 0.02308099], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['unr', 'continues', 'severe', 'thunderstorm', 'warning', '60',\n",
              "         'mph', ';', '.', '75', 'for', 'weston', 'and', 'custer', 'fall',\n",
              "         'river', 'pennington', 'till', '7:15'], dtype='<U12'),\n",
              "  array([6.4842956e-05, 9.9993515e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['isis', 'are', '.', 'but', 'they', 'have', 'the', 'ability', 'to',\n",
              "         'massacre', 'civilians', 'far', 'from', 'the', 'frontlines',\n",
              "         'like', 'the', 'tyrant', '.'], dtype='<U10'),\n",
              "  array([0.00103748, 0.9989625 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['russia', 'and', 'that', 'back', 'fired', 'now', '2015', 'look',\n",
              "         'what', 'happened', 'of', 'marine', 'barracks', 'suicide',\n",
              "         'bombers', 'attacks', 'on', 'world', 'sites'], dtype='<U8'),\n",
              "  array([1.332870e-04, 9.998667e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['still', 'get', 'over', 'the', 'we', 'were', 'woken', 'up', 'to',\n",
              "         'yesterday', '.', 'half', 'the', 'street', 'is', 'still', 'in',\n",
              "         'the', '.'], dtype='<U9'),\n",
              "  array([0.00147538, 0.9985246 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['sioux', 'city', 'fire', 'officials', 'believe', 'bridge',\n",
              "         'collapse', 'lead', 'to', 'cement', 'truck', 'roll', 'over', '-',\n",
              "         'siouxland', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.01047288, 0.9895271 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['fire', 'crews', 'evacuate', 'passengers', 'from', 'a', 'gold',\n",
              "         'coast', 'tram', 'trapped', 'when', 'powerlines', 'fell', 'across',\n",
              "         'a', 'carriage', '.', '5pm', '.'], dtype='<U10'),\n",
              "  array([0.00374965, 0.99625033], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'paci', '?', 'c', 'media', 'centre', '|', 'rsf', 'protests',\n",
              "         'over', 'new', 'security', 'gag', 'over', 'reporting', 'on', '.',\n",
              "         '.', '.'], dtype='<U9'),\n",
              "  array([0.99692106, 0.00307901], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'fall', 'of', 'leaves', 'from', 'a', 'poplar', 'is', 'as',\n",
              "         'fully', 'ordained', 'as', 'the', 'tumbling', 'of', 'an',\n",
              "         'avalanche', '-', 'spurgeon'], dtype='<U9'),\n",
              "  array([9.993549e-01, 6.450618e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rp', 'said', 'they', 'can', 'see', 'smoke', 'coming', 'from',\n",
              "         'the', 'silo', 'on', '260th', 'street', 'in', 'hartford', 'but',\n",
              "         'no', 'flames', '.'], dtype='<U8'),\n",
              "  array([0.03113862, 0.96886134], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['evacuation', 'order', 'lifted', 'for', 'town', 'of', 'roosevelt',\n",
              "         'wash', '.', 'though', 'residents', 'warned', 'to', 'be', 'ready',\n",
              "         'to', 'leave', 'quickly', '.'], dtype='<U10'),\n",
              "  array([0.00193849, 0.9980615 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['ogun', 'smugglers', 'engage', 'customs', 'in', 'several',\n",
              "         'persons', 'were', 'allegedly', 'injured', 'on', 'wednesday',\n",
              "         'when', 'men', 'o', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([0.00268473, 0.9973152 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['isis', 'are', '.', 'but', 'they', 'have', 'the', 'ability', 'to',\n",
              "         'massacre', 'civilians', 'far', 'from', 'the', 'frontlines',\n",
              "         'like', 'the', 'tyrant', '.'], dtype='<U10'),\n",
              "  array([0.00103748, 0.9989625 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['new', 'warning', 'for', 'central', 'hills', 'hail', '60', 'mph',\n",
              "         'winds', '.', 'not', 'affecting', 'sturgis', 'but', 'could',\n",
              "         'later', 'tonight', '.', '.'], dtype='<U9'),\n",
              "  array([0.00125099, 0.998749  ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['secrets', 'of', 'the', 'world', 'collide', 'but', 'i', 'leave',\n",
              "         'the', 'past', 'behind', 'been', 'so', 'long', 'now', 'and', 'i',\n",
              "         'go', 'without'], dtype='<U7'),\n",
              "  array([0.9470525, 0.0529476], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['so', 'name', 'all', 'the', 'countries', 'aside', 'libya', 'in',\n",
              "         'north', 'africa', 'in', 'last', '5', 'years', '.', '.', '.', '.',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([0.00569347, 0.9943065 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['glad', 'when', 'i', 'call', 'someone', 'not', 'an', 'emergency',\n",
              "         'since', 'they', 'never', 'answer', 'their', 'phones', 'or',\n",
              "         'call', 'back', '?', '?'], dtype='<U9'),\n",
              "  array([0.9716215 , 0.02837848], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['yeah', 'i', 'know', 'but', 'blaze', 'blue', 'dont', 'have', 'a',\n",
              "         'twitter', 'lol', 'i', 'drew', 'this', 'a', 'few', 'weeks', 'ago',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([9.9941373e-01, 5.8631453e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['experts', 'in', 'france', 'begin', 'examining', 'airplane',\n",
              "         'debris', 'found', 'on', 'reunion', 'french', 'air', 'accident',\n",
              "         'experts', 'on', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.5099624e-04, 9.9974900e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['experts', 'in', 'france', 'begin', 'examining', 'airplane',\n",
              "         'debris', 'found', 'on', 'reunion', 'french', 'air', 'accident',\n",
              "         'experts', 'on', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([2.5099624e-04, 9.9974900e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['deputies', 'are', 'waiting', 'for', 'the', 'bomb', 'squad', 'to',\n",
              "         'detonate', 'grenade', 'like', 'this', 'one', 'found', 'in',\n",
              "         'stearns', 'lake', 'today', '.'], dtype='<U8'),\n",
              "  array([3.227056e-04, 9.996773e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['if', 'gop', 'want', 'to', 'destroy', 'america', 'then', 'obama',\n",
              "         'is', 'i', 'should', 'be', 'institutionalize', 'or', 'sued', 'for',\n",
              "         'slander', '.', '.'], dtype='<U16'),\n",
              "  array([9.9928552e-01, 7.1451714e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['texas', 'seeks', 'comment', 'on', 'rules', 'for', 'changes', 'to',\n",
              "         'windstorm', 'the', 'texas', 'department', 'of', 'insurance', 'is',\n",
              "         '.', '.', '.', '.'], dtype='<U10'),\n",
              "  array([0.0115136, 0.9884864], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['myanmar', 'heavy', 'monsoon', 'rains', 'during', 'the', 'month',\n",
              "         'of', 'july', 'have', 'caused', 'flooding', 'flash', 'floods',\n",
              "         'and', '.', '.', '.', '.'], dtype='<U8'),\n",
              "  array([5.916661e-05, 9.999409e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['drought', 'fuels', 'bush', 'fires', 'in', 'jamaica', '-', '.',\n",
              "         '.', '-', 're', '.'], dtype='<U7'),\n",
              "  array([0.00708857, 0.9929114 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['contruction', 'upgrading', 'ferries', 'to', 'earthquake',\n",
              "         'standards', 'in', 'vashon', 'mukilteo', '-', 'fox', '.'],\n",
              "        dtype='<U11'),\n",
              "  array([2.410454e-04, 9.997589e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'poignant', 'reminder', 'that', 'in', 'war', 'there', 'are',\n",
              "         'many', 'casualties', '.', '.'], dtype='<U10'),\n",
              "  array([1.0556297e-04, 9.9989438e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['gotta', 'try', 'to', 'let', 'go', 'of', 'so', 'many', 'bloody',\n",
              "         'things', '.', 'smh'], dtype='<U6'),\n",
              "  array([9.998964e-01, 1.036180e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'method', 'lite', 'version', '-', 'anxiety', 'panic',\n",
              "         'cure', '.', 'the', 'lind', '.'], dtype='<U7'),\n",
              "  array([0.9503926 , 0.04960741], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['smoke', 'alot', 'of', 'weed', 'like', 'fuck', 'kidneys', 'put',\n",
              "         'a', 'dutch', 'in', 'me'], dtype='<U7'),\n",
              "  array([9.9923706e-01, 7.6298183e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['suicide', 'bomber', 'kills', '15', 'in', 'saudi', 'security',\n",
              "         'site', 'mosque', '-', 'reuters', '.'], dtype='<U8'),\n",
              "  array([4.8663574e-06, 9.9999511e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['no', 'reported', 'cases', 'of', 'people', 'drowning', 'in',\n",
              "         'sweat', '.', '.', '.', 'fyi'], dtype='<U8'),\n",
              "  array([0.4180292, 0.5819708], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['crazy', 'how', 'a', 'phone', 'can', 'do', 'so', 'much', 'damage',\n",
              "         'to', 'a', 'person'], dtype='<U6'),\n",
              "  array([0.9722106 , 0.02778945], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['malaysian', 'officials', 'say', 'debris', 'found', 'on',\n",
              "         'reunion', 'island', 'is', 'from', '.', '.'], dtype='<U9'),\n",
              "  array([5.644053e-05, 9.999436e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['global', 'precipitation', 'measurement', 'satellite', 'captures',\n",
              "         '3-d', 'image', 'of', 'typhoon', 'soudelor', '-', '.'],\n",
              "        dtype='<U13'),\n",
              "  array([6.283962e-05, 9.999372e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['old', 'pkk', 'suicide', 'bomber', 'who', 'detonated', 'bomb',\n",
              "         'in', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([1.7099307e-04, 9.9982893e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['do', 'you', 'know', 'where', 'abouts', 'as', 'i', 'heard',\n",
              "         'emergency', 'services', 'near', 'by'], dtype='<U9'),\n",
              "  array([0.0117455 , 0.98825455], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'more', 'homes', 'razed', 'by', 'northern', 'california',\n",
              "         'wildfire', '-', 'abc', 'news', '.'], dtype='<U10'),\n",
              "  array([3.052190e-05, 9.999695e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['1', '.', '94', 'earthquake', 'occurred', '5km', 's', 'of',\n",
              "         'volcano', 'hawaii', 'at', '.'], dtype='<U10'),\n",
              "  array([2.9567789e-06, 9.9999702e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['last', 'chance', 'animal', 'rescue', 'has', '3', 'new', 'posts',\n",
              "         '.', '.', '|', '.'], dtype='<U6'),\n",
              "  array([9.9982554e-01, 1.7454152e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['sharp', 'rise', 'in', 'women', 'and', 'children', 'casualties',\n",
              "         'in', 'first', 'half', 'of', '.'], dtype='<U10'),\n",
              "  array([0.0020318 , 0.99796814], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['of', 'disaster', 'in', 'western', 'will', 'be', 'beyond', '500',\n",
              "         'thousand', 'at', 'least', '.'], dtype='<U8'),\n",
              "  array([0.00146095, 0.9985391 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['.', 'yep', 'considering', 'that', 'of', 'japanese', 'fatalities',\n",
              "         'were', 'projected', 'for', 'downfall', '.'], dtype='<U11'),\n",
              "  array([0.026212  , 0.97378796], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['thousands', 'of', 'hipsters', 'feared', 'giant', 'sinkhole',\n",
              "         'devours', 'brooklyn', '.', '.', '.', '.'], dtype='<U9'),\n",
              "  array([3.4757002e-04, 9.9965239e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array([';', 'marks', '70th', 'anniversary', 'of', 'atomic', 'bombing',\n",
              "         '.', 'read', 'more', ';', '.'], dtype='<U11'),\n",
              "  array([2.2709620e-04, 9.9977297e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['egyptian', 'militants', 'tied', 'to', 'isis', 'threaten', 'to',\n",
              "         'kill', 'croatian', 'hostage', 'york', '.'], dtype='<U9'),\n",
              "  array([8.2855666e-04, 9.9917150e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['causes', 'in', 'gilgit', 'damage', 'to', '20', 'homes',\n",
              "         'farmland', 'roads', 'and', 'bridges', '.'], dtype='<U8'),\n",
              "  array([4.4449797e-04, 9.9955553e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['what', 'it', 'was', 'like', 'to', 'survive', 'the', 'atomic',\n",
              "         'bombing', 'of', 'hiroshima', '.'], dtype='<U9'),\n",
              "  array([2.2331471e-06, 9.9999774e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['whirlwind', 'medusa', 'audio', '16', 'microphone', 'inputs', '0',\n",
              "         'returns', '150', 'ft', '.', '.'], dtype='<U10'),\n",
              "  array([1.742761e-04, 9.998258e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['romantic', 'dramatic', 'but', 'never', 'panic', 'original',\n",
              "         'sensei', 'write', 'rhymes', 'in', 'the', 'attic'], dtype='<U8'),\n",
              "  array([9.9901414e-01, 9.8582136e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['weyburn', 'police', 'warn', 'public', 'after', 'fentanyl',\n",
              "         'deaths', 'in', 'province', '-', '.', '.'], dtype='<U8'),\n",
              "  array([1.6920543e-05, 9.9998307e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['owner', 'of', 'chicago-area', 'gay', 'bar', 'admits', 'to',\n",
              "         'arson', 'scheme', '.', '|', '.'], dtype='<U12'),\n",
              "  array([0.989403, 0.010597], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['seems', 'gov', 'moonbeam', 'between', 'tokes', 'blames', 'bush',\n",
              "         'for', 'all', 'the', 'fires', '.'], dtype='<U8'),\n",
              "  array([4.3840013e-05, 9.9995613e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['in', '179', 'fatalities', 'involving', 'on-duty', 'nypd', 'cops',\n",
              "         'in', '15', 'years', 'only', '.'], dtype='<U10'),\n",
              "  array([0.01048278, 0.98951715], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['debris', 'confirmed', 'from', ';', 'relatives', 'hope', 'for',\n",
              "         'discovery', 'of', 'crash', 'site', '.'], dtype='<U9'),\n",
              "  array([5.145595e-05, 9.999485e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['pop', 'which', 'do', 'you', 'feminist', 'revolution', 'or',\n",
              "         'fried', 'porcini', 'and', '.', '.'], dtype='<U10'),\n",
              "  array([0.99166226, 0.00833778], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['apollo', 'brown', 'detonate', 'ft', '.', '.', 'o', '.', 'p', '.',\n",
              "         '.', '.'], dtype='<U8'),\n",
              "  array([0.9962404 , 0.00375959], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'liked', 'a', 'video', '.', 'us', 'canada', 'radiation',\n",
              "         'update', 'emergency', 'fishing', 'closures'], dtype='<U9'),\n",
              "  array([0.08698362, 0.9130164 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['and', 'last', 'year', 'it', 'was', 'just', 'a', 'lot', 'of',\n",
              "         'drums', 'are', 'and'], dtype='<U5'),\n",
              "  array([0.97381693, 0.02618312], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['blonde', 'teen', 'courtney', 'teases', 'in', 'her', 'panties',\n",
              "         '.', 'view', 'and', 'download', 'video'], dtype='<U8'),\n",
              "  array([9.9958557e-01, 4.1446523e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array([':', 'lake', 'is', 'a', 'crater', 'lake', 'located', 'in', 'the',\n",
              "         '.', 'with', '.'], dtype='<U7'),\n",
              "  array([0.9626121 , 0.03738792], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['and', 'survive', 'without', 'referring', '.', 'without', 'mr',\n",
              "         'modi', 'they', 'are', 'big', 'zeros'], dtype='<U9'),\n",
              "  array([9.9936694e-01, 6.3308043e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'more', 'homes', 'razed', 'by', 'northern', 'california',\n",
              "         'wildfire', '-', 'abc', 'news', '.'], dtype='<U10'),\n",
              "  array([3.052190e-05, 9.999695e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hello', '911', 'yeah', 'we', 'have', 'someone', 'drowning',\n",
              "         'here', 'send', 'a', 'medic', '.'], dtype='<U8'),\n",
              "  array([0.00331911, 0.9966809 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['md', '2', '.', '9', 'off', 'coast', 'of', 'northern',\n",
              "         'california', '.', 'g', '.'], dtype='<U10'),\n",
              "  array([0.00111581, 0.99888414], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['granted', 'like', 'half', 'my', 'town', 'floods', 'when', 'it',\n",
              "         'rains', 'but', 'still', 'whatever'], dtype='<U8'),\n",
              "  array([7.6696611e-05, 9.9992335e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['oh', 'not', 'too', 'bad', 'then', 'haha', '.', 'i', 'been',\n",
              "         'panicking', 'tho', '.'], dtype='<U9'),\n",
              "  array([0.8983065 , 0.10169346], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', '-', 'cleveland', 'heights', 'shaker', 'heights', 'fight',\n",
              "         'the', 'house', 'next', 'door', '.'], dtype='<U9'),\n",
              "  array([0.9863479 , 0.01365204], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'am', 'not', 'in', 'danger', 'skyler', '.', 'i', 'am', 'the',\n",
              "         'danger', '.'], dtype='<U6'),\n",
              "  array([0.9863349 , 0.01366505], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'came', 'had', 'he', 'fucking', 'moved', 'his', 'entire',\n",
              "         'existence', 'been', 'obliterated', '.'], dtype='<U11'),\n",
              "  array([0.9986656 , 0.00133445], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['checkout', 'all', 'the', 'rules', ';', 'features', 'that',\n",
              "         'snuck', 'in', 'on', '.', '.'], dtype='<U8'),\n",
              "  array([0.9871885 , 0.01281147], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['want', 'to', 'work', 'at', 'swedish', 'health', 'services', '?',\n",
              "         'in', 'click', 'for', '.'], dtype='<U8'),\n",
              "  array([0.99629575, 0.0037043 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['1', '.', '9', 'earthquake', 'occurred', '15km', 'e', 'of',\n",
              "         'anchorage', 'alaska', 'at', '.'], dtype='<U10'),\n",
              "  array([2.3837540e-05, 9.9997616e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['looks', 'like', 'a', 'year', 'of', 'writing', 'and', 'computers',\n",
              "         'is', 'ahead', '.', '.'], dtype='<U9'),\n",
              "  array([0.98558885, 0.0144111 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['though', 'serious', 'increased', 'in', 'safety', 'standard', 'is',\n",
              "         'far', 'inferior', 'to', 'standard', '.'], dtype='<U9'),\n",
              "  array([0.39278156, 0.60721844], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['my', 'son', 'sleep', 'all', '?', '?', 'so', 'finally', 'at',\n",
              "         '4am', 'i', 'laid', 'him', 'with', 'me', 'on', 'my', 'bed', 'and',\n",
              "         'he', 'crashed', 'out', '?', '?', '?', '?'], dtype='<U7'),\n",
              "  array([0.9831093 , 0.01689075], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['there', 'are', 'no', 'four', 'pain', 'of', 'desire', 'that', 'is',\n",
              "         'the', 'origin', 'of', 'pain', 'of', 'the', 'obliteration', 'of',\n",
              "         'that', 'desire', 'of', 'the', 'pain', 'to', 'that',\n",
              "         'obliteration', '.'], dtype='<U12'),\n",
              "  array([0.9962668 , 0.00373318], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['deadpool', 'is', 'already', 'one', 'of', 'my', 'favourite',\n",
              "         'marvel', 'characters', 'and', 'all', 'i', 'know', 'is', 'he',\n",
              "         'wears', 'a', 'red', 'suit', 'so', 'the', 'bad', 'guys', 'tell',\n",
              "         'if', 'bleeding'], dtype='<U10'),\n",
              "  array([0.57782793, 0.4221721 ], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['just', 'thought', 'let', 'you', 'all', 'know', '.', '.', '.',\n",
              "         'probably', 'not', 'a', 'good', 'idea', 'to', 'plug', 'in', 'your',\n",
              "         'hairdryer', 'when', 'wet', 'you', 'will', 'be', 'electrocuted',\n",
              "         '.'], dtype='<U12'),\n",
              "  array([0.99893147, 0.00106849], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'throw', 'the', 'word', 'hero', 'around', 'lightly', '.', '.',\n",
              "         '.', 'usually', 'reserved', 'for', 'first', 'responders', 'and',\n",
              "         'military', '.', '.', '.', 'but', 'a', 'hero', '.', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9549776, 0.0450224], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['what', 'progress', 'we', 'are', 'making', '.', 'in', 'the',\n",
              "         'middle', 'ages', 'they', 'would', 'have', 'burned', 'me', '.',\n",
              "         'now', 'they', 'are', 'content', 'with', 'burning', 'my', 'books',\n",
              "         '.', 'freud'], dtype='<U8'),\n",
              "  array([0.99836844, 0.00163158], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['#', '?', '?', '#', '?', '?', '#', '?', '?', '?', '#', '?', '?',\n",
              "         '?', 'suicide', 'bomber', 'kills', '15', 'in', 'saudi', 'security',\n",
              "         'site', 'mosque', '-', 'reuters', '.'], dtype='<U8'),\n",
              "  array([7.6124343e-06, 9.9999237e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['honestly', 'tho', 'modibo', 'maiga', 'is', 'stealing', 'a',\n",
              "         'living', '-', 'fuck', 'all', 'about', 'him', '-', 'im', 'past',\n",
              "         'my', 'best', 'but', 'still', 'more', 'of', 'a', 'danger', 'than',\n",
              "         'that'], dtype='<U8'),\n",
              "  array([0.05720218, 0.94279784], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['all', 'i', 'need', 'in', 'this', 'life', 'of', 'sin', 'is',\n",
              "         'just', 'me', 'and', 'my', 'girlfriend', 'down', 'to', 'ride',\n",
              "         'till', 'the', 'bloody', 'end', 'just', 'me', 'and', 'my',\n",
              "         'girlfriend'], dtype='<U10'),\n",
              "  array([0.9933088 , 0.00669117], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['death', 'on', 'railway', 'why', 'rains', 'cannot', 'take', 'all',\n",
              "         'the', 'blame', '?', ':', 'derailment', 'is', 'not', 'very',\n",
              "         'common', '.', 'last', 'year', 'less', 'th', '.', '.', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.01311799, 0.98688203], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['we', 'want', 'to', 'see', 'no', 'more', 'hiroshima', 'and',\n",
              "         'nagasaki', 'nuclear', 'bomb', 'disaster', 'in', 'this',\n",
              "         'beautiful', 'world', '.', 'lets', 'be', 'peaceful', ';', 'save',\n",
              "         'this', 'human', 'civilization', '.'], dtype='<U12'),\n",
              "  array([0.03925724, 0.9607427 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['talk', 'to', 'please', 'harm', 'your', 'self', 'in', 'any', 'way',\n",
              "         'shape', 'or', 'form', 'please', 'we', 'care', 'about', 'you',\n",
              "         'and', 'if', 'i', 'saw', 'u', 'right', 'now', 'u', 'better'],\n",
              "        dtype='<U6'),\n",
              "  array([0.8844093 , 0.11559065], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['you', 'know', 'you', 'hate', 'your', 'body', 'when', 'you', 'buy',\n",
              "         '2', 'bags', 'of', 'chips', 'and', 'a', 'variety', 'pack', 'of',\n",
              "         'fruit', 'snacks', 'and', 'a', 'redbull', 'as', 'a', 'snack'],\n",
              "        dtype='<U7'),\n",
              "  array([0.998256  , 0.00174398], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['#', '?', '?', '#', '?', '?', '#', '?', '?', '?', '#', '?', '?',\n",
              "         '?', 'suicide', 'bomber', 'kills', '15', 'in', 'saudi', 'security',\n",
              "         'site', 'mosque', '-', 'reuters', '.'], dtype='<U8'),\n",
              "  array([7.6124343e-06, 9.9999237e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['so', 'now', 'that', 'di', 'maria', 'has', 'left', 'my', 'dear',\n",
              "         'back', 'to', 'the', 'maria', 'argument', '.', '.', '.', '.',\n",
              "         'say', 'hazard', 'is', 'way', 'better', '?', '?', 'idc'],\n",
              "        dtype='<U8'),\n",
              "  array([9.9971777e-01, 2.8218442e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['interested', 'to', 'see', 'who', 'will', 'win', 'this', 'battle'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9771015 , 0.02289846], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['these', 'wild', 'fires', 'out', 'west', 'are', 'crazy', '.'],\n",
              "        dtype='<U5'),\n",
              "  array([7.815626e-05, 9.999218e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['oso', 'washington', 'mudslide', 'response', 'interview', 'part',\n",
              "         '1', '.'], dtype='<U10'),\n",
              "  array([1.4660145e-04, 9.9985337e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array([';', ';', '.', ';', ';', 'prod', ';', ';'], dtype='<U4'),\n",
              "  array([0.9771797 , 0.02282024], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['edge', 'jimmy', '-', 'summer', 'rainstorm', '.', 'via', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.97157794, 0.02842203], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['and', 'the', 'fact', 'that', 'i', 'have', 'a', 'curfew'],\n",
              "        dtype='<U6'),\n",
              "  array([9.9962986e-01, 3.7013349e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['market', 'activision', 'blizzard', 'cognizant', 'technology',\n",
              "         'first', 'solar', '.'], dtype='<U10'),\n",
              "  array([0.9497865 , 0.05021352], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['new', 'york', 'city', 'what', 'is', 'disease', '?', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.01345603, 0.98654395], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['what', 'if', 'he', 'committed', 'a', 'mass', 'murder', '?'],\n",
              "        dtype='<U9'),\n",
              "  array([0.0450689 , 0.95493114], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['that', 'traumatised', 'that', 'i', 'even', 'spell', 'excuse',\n",
              "         'the'], dtype='<U11'),\n",
              "  array([0.90825427, 0.09174577], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rainstorm', 'destroys', '600', 'houses', 'in', 'yobe', 'damaturu',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([8.8116047e-07, 9.9999917e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['not', 'forget', 'our', 'wounded', 'female', 'veterans', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([7.3857669e-04, 9.9926144e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['lying', 'clinton', 'donald', 'trump', 'make', 'america', 'great',\n",
              "         '.'], dtype='<U7'),\n",
              "  array([0.97497106, 0.02502893], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['300k', 'exotic', 'car', 'wrecked', 'in', 'train', 'accident', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([3.0859355e-05, 9.9996912e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['destroy', 'oppa', 'image', '?', 'nothing', 'left', 'right', '?'],\n",
              "        dtype='<U7'),\n",
              "  array([0.98240143, 0.01759859], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rescue', '-', 'scott', 'road', '@', 'ypres', 'road', 'york'],\n",
              "        dtype='<U6'),\n",
              "  array([1.403687e-04, 9.998596e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['amazon', 'deal', '-', 'wait', 'or', 'buy', '?', '.'], dtype='<U6'),\n",
              "  array([0.9677424 , 0.03225756], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['suspected', 'serial', 'arsonist', 'arrested', 'in', 'calif', '.',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([6.881062e-05, 9.999312e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['migrants', 'rescued', 'after', 'boat', 'capsizes', 'off', 'libya',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([1.8046932e-05, 9.9998200e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rainstorm', 'destroys', '600', 'houses', 'in', 'yobe', 'state',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([3.2413395e-06, 9.9999678e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['think', 'i', 'can', 'take', 'anymore', 'emotional', 'wreck',\n",
              "         'watching'], dtype='<U9'),\n",
              "  array([9.9962115e-01, 3.7884826e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['tell', 'the', 'united', 'plantations', 'are', 'not', '.', 'via'],\n",
              "        dtype='<U11'),\n",
              "  array([0.7262373, 0.2737627], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['us', 'military', 'and', 'nato', 'are', 'fighting', 'talibans',\n",
              "         'too'], dtype='<U8'),\n",
              "  array([0.02964434, 0.97035563], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['8th', 'person', 'dies', 'in', 'ny', 'disease', 'outbreak', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.0361317e-05, 9.9998963e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['georgia', 'sinkhole', 'closes', 'road', 'swallows', 'whole',\n",
              "         'pond', '.'], dtype='<U8'),\n",
              "  array([0.0018263, 0.9981737], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['the', 'twitter', 'update', 'pretty', 'much', 'wrecked', 'the',\n",
              "         'app'], dtype='<U7'),\n",
              "  array([0.92153126, 0.07846873], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['evacuation', 'order', 'lifted', 'for', 'town', 'of', '.', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([6.7170848e-05, 9.9993277e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'blizzard', 'would', 'be', 'clutch', 'asf', '?', '?'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9778472 , 0.02215274], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['alabama', 'home', 'quarantined', 'over', 'possible', 'ebola',\n",
              "         'case', '.'], dtype='<U11'),\n",
              "  array([1.7548187e-05, 9.9998248e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['hijacking', 'electric', 'skateboards', 'to', 'make', 'them', '|',\n",
              "         '.'], dtype='<U11'),\n",
              "  array([9.9977368e-01, 2.2629472e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['my', 'first', 'staining', 'attempt', 'was', 'a', 'disaster', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.97436476, 0.02563524], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['c/o', 'on', 'a', 'dupe', 'the', 'press', 'overdrive', ';'],\n",
              "        dtype='<U9'),\n",
              "  array([0.995095  , 0.00490502], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['casualty', 'insurance', 'jobs', 'against', 'hunt', 'up', 'rpn',\n",
              "         '.'], dtype='<U9'),\n",
              "  array([9.994186e-01, 5.813581e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['dying', 'of', 'lyme', 'case', 'fatality', 'rate', 'nearly', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00719921, 0.99280083], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['-', 'acrylic', '08', '.', '05', '.', '15', '.'], dtype='<U7'),\n",
              "  array([0.0221504, 0.9778496], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['rubber', 'still'], dtype='<U6'),\n",
              "  array([0.9514692 , 0.04853084], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rioting', '.'], dtype='<U7'),\n",
              "  array([0.34475565, 0.6552443 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['photo', 'bombed'], dtype='<U6'),\n",
              "  array([0.9954952 , 0.00450478], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['screaming', '.'], dtype='<U9'),\n",
              "  array([0.9817655 , 0.01823452], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['aftershock', '.'], dtype='<U10'),\n",
              "  array([0.9480205 , 0.05197946], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['crash', 'it'], dtype='<U5'),\n",
              "  array([0.17588782, 0.8241122 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['bad', 'day'], dtype='<U3'),\n",
              "  array([0.9578828 , 0.04211713], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', 'death'], dtype='<U5'),\n",
              "  array([0.79841393, 0.20158602], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['.', 'death'], dtype='<U5'),\n",
              "  array([0.79841393, 0.20158602], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['let', 'it'], dtype='<U3'),\n",
              "  array([0.94570994, 0.05429005], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['natural', 'lubrication'], dtype='<U11'),\n",
              "  array([0.9863326 , 0.01366744], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['social', 'casualty'], dtype='<U8'),\n",
              "  array([0.9604018, 0.0395982], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['if', 'not', 'paying', 'attention', 'to', 'your', 'influencers',\n",
              "         'burning', 'money', '|', '.'], dtype='<U11'),\n",
              "  array([9.9968159e-01, 3.1842882e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['family', 'furious', 'the', 'media', 'was', 'told', 'about',\n",
              "         'wreckage', 'confirmation', 'first', '.'], dtype='<U12'),\n",
              "  array([4.6539825e-04, 9.9953461e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['motorcyclist', 'bicyclist', 'injured', 'in', 'denver',\n",
              "         'collision', 'on', 'at', 'least', 'two', 'people', 'were', 'taken',\n",
              "         'to', 'a', '.'], dtype='<U12'),\n",
              "  array([5.6461123e-04, 9.9943537e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['yes', ';', 'especially', 'new', 'clients', 'that', 'walk', 'in',\n",
              "         'and', 'think', 'a', 'wart', 'is', 'an', 'emergency', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.9907707 , 0.00922922], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['this', 'la', 'startup', 'is', 'so', 'hot', 'that', 'their',\n",
              "         'flowers', 'come', 'straight', 'from', 'a', 'volcano', '.', 'via'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9348597 , 0.06514035], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['interview', 'with', 'actor', 'randy', 'irwin', 'a', '.', 's', '.',\n",
              "         'k', 'what', 'could', 'be', 'the', 'harm', '.'], dtype='<U9'),\n",
              "  array([0.995729  , 0.00427092], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['violent', 'record', 'breaking', 'el', 'reno', 'oklahoma',\n",
              "         'tornado', 'nearly', 'runs', 'over', '.', '.', '.', '-', '.', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.0491378e-04, 9.9989510e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['but', 'if', 'the', 'apocalypse', 'lol', 'gf', 'm8'], dtype='<U10'),\n",
              "  array([9.9999750e-01, 2.5250242e-06], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'seismic', 'summary', ';', 'history', '.', '.'], dtype='<U7'),\n",
              "  array([0.01529614, 0.9847039 ], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['only', 'weapon', 'im', 'scared', 'off', 'is', 'karma'],\n",
              "        dtype='<U6'),\n",
              "  array([0.99166393, 0.00833604], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['ml', '2', '.', '0', 'sicily', 'italy', '.'], dtype='<U6'),\n",
              "  array([0.6160103 , 0.38398963], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['when', 'your', 'cake', 'is', 'engulfed', 'in', 'flames'],\n",
              "        dtype='<U8'),\n",
              "  array([0.9966768 , 0.00332323], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['just', 'watched', 'episode', 'of', 'bloody', '.', '.'],\n",
              "        dtype='<U7'),\n",
              "  array([0.9970214 , 0.00297858], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['okay', 'i', 'find', 'it', 'so', 'kinda', 'panicking'], dtype='<U9'),\n",
              "  array([0.9969927 , 0.00300732], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', 'offensive', 'content', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([9.9943143e-01, 5.6860008e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'for', 'the', 'deluge', 'of', 'hell', 'vines'], dtype='<U6'),\n",
              "  array([0.9983777 , 0.00162228], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['post', 'a', 'pic', 'of', 'your', 'wounds', 'please'], dtype='<U6'),\n",
              "  array([9.9982029e-01, 1.7971946e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['california', 'school', 'bus', 'hijacker', 'parole', 'stands', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.03277772, 0.96722233], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['reddit', 'will', 'now', 'quarantine', 'offensive', 'content', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([9.9943143e-01, 5.6860008e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['burning', 'buildings', '?', 'media', 'outrage', '?', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([0.00126236, 0.99873763], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['beyond', 'all', 'bounds', ';', 'till', 'inundation', 'rise'],\n",
              "        dtype='<U10'),\n",
              "  array([0.98897624, 0.01102383], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['chiasson', 'sens', 'come', 'to', 'deal', '.', '.'], dtype='<U8'),\n",
              "  array([0.04334748, 0.95665246], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['brain', 'twister', 'let', 'drop', 'up', 'telly', 'structuring'],\n",
              "        dtype='<U11'),\n",
              "  array([9.9947506e-01, 5.2492972e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['let', 'a', 'few', 'assholes', 'ruin', 'your', 'night'],\n",
              "        dtype='<U8'),\n",
              "  array([0.98806435, 0.01193564], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['whoa', 'a', 'train', 'derailed', 'at', 'smithsonian', '?'],\n",
              "        dtype='<U11'),\n",
              "  array([3.079920e-04, 9.996921e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['me', 'from', 'my', 'self', 'let', 'me', '.'], dtype='<U4'),\n",
              "  array([0.9960219 , 0.00397806], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['on', 'the', 'bright', 'side', 'i', 'wrecked', '.'], dtype='<U7'),\n",
              "  array([9.990489e-01, 9.510842e-04], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['i', 'hope', 'you', 'get', 'batista', 'bombed', 'lauren'],\n",
              "        dtype='<U7'),\n",
              "  array([9.9994957e-01, 5.0471826e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['rescued', 'med', 'migrants', 'arrive', 'in', 'sicily', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.4490896e-05, 9.9998546e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['no', 'bags', 'in', 'the', 'trunk', 'a', 'body'], dtype='<U5'),\n",
              "  array([0.99702126, 0.00297876], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['stretcher', 'in', '5', 'min', '.', 'fujiwara', 'shunichiro'],\n",
              "        dtype='<U10'),\n",
              "  array([9.9995852e-01, 4.1442476e-05], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['from', 'al', 'jackson', '.', '.', '.', '.'], dtype='<U7'),\n",
              "  array([0.8886336 , 0.11136638], dtype=float32),\n",
              "  array([1., 0.])],\n",
              " [array(['the', 'murderous', 'story', 'of', 'first', 'hijacking', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([1.0848752e-04, 9.9989152e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['adult', 'dies', 'of', 'plague', 'in', 'colorado', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([0.00330032, 0.99669963], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['when', ';', ';', '.', 'war', 'humanitarian', 'bombing'],\n",
              "        dtype='<U12'),\n",
              "  array([2.1395148e-05, 9.9997866e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['turkish', 'troops', 'killed', 'in', 'kurdish', 'militant', '.'],\n",
              "        dtype='<U8'),\n",
              "  array([1.6243572e-06, 9.9999833e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['industry', 'clueless', 'on', 'driverless', 'cars', ':', '.'],\n",
              "        dtype='<U10'),\n",
              "  array([0.00542814, 0.99457186], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['richmond', 'police', 'officer', 'wounded', 'suspect', 'killed',\n",
              "         '.'], dtype='<U8'),\n",
              "  array([7.1758595e-06, 9.9999285e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['a', 'gpm', 'satellite', 'in', 'typhoon', 'soudelor', '.'],\n",
              "        dtype='<U9'),\n",
              "  array([3.5966527e-06, 9.9999642e-01], dtype=float32),\n",
              "  array([0., 1.])],\n",
              " [array(['they', 'detonate', 'unless', 'they', 'touch', 'the', 'ground'],\n",
              "        dtype='<U8'),\n",
              "  array([0.964421  , 0.03557903], dtype=float32),\n",
              "  array([1., 0.])]]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j, twt in enumerate(d,0):\n",
        "    twt2 = twt[1].cpu().detach().numpy()\n",
        "    d[j][1] = twt2\n",
        "    d[j][0] = np.array(d[j][0])\n",
        "    d[j][2] = np.array(d[j][2])\n",
        "    #for i, word in enumerate(twt[0],0):\n",
        "     #twt2.append(glove.itos[word])\n",
        " #  c[j][0] = twt2\n",
        "  #twt[0] = glove.itos[torch.cuda.LongTensor(twt[0])]\n",
        "#for i in range(len(c)):\n",
        "#  c\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "ElG4aHqwmmAf",
        "outputId": "c9b84935-5486-4dd1-eff4-227b76353353"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-7b532f10fc38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtwt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "nvpepSg8Wh6z"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"correct_balanced.csv\", \"w\") as f:\n",
        "    wr = csv.writer(f)\n",
        "    wr.writerows(d)"
      ],
      "metadata": {
        "id": "236KfWjOm2km"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(network3, \"network3\")"
      ],
      "metadata": {
        "id": "Lyet1OZ4_UbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_cor = torch.load(\"best3_test_set.csv\")\n",
        "test_set_cor"
      ],
      "metadata": {
        "id": "zeiUCux55pxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3PR5YZZd7Tw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy = copy.deepcopy(valid)\n",
        "\n",
        "for data in train_copy:\n",
        "  data = [data[0].tolist(), data[1].tolist()]\n",
        "  np.array(data)\n",
        "train_copy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAO_I6Y-5prT",
        "outputId": "6b577acc-2cdc-42ed-8ecb-120f466a42d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 5956,    43,  1361,     0,   140,    69,    12,     0,   973,     3,\n",
              "              0,  4005,     6,   545,  5295,    13,   601,  2141,     4,   455,\n",
              "           1376,     7, 28470,    10,  4005,     2]), tensor(1)),\n",
              " (tensor([1083,   31,   84, 9292,    2]), tensor(0)),\n",
              " (tensor([9388, 5648,   14,   74,   41,  120, 5717,    2,    2,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([  41, 5572,    7,  974,   25,    2, 8823, 7920,   11,  418,   50,  736,\n",
              "            11,   50, 3464,   11]), tensor(0)),\n",
              " (tensor([ 266, 8349,  188,  188,  188,  188,    2]), tensor(0)),\n",
              " (tensor([   41,   263,    40,    18, 48271,   554,    26,  1452,  3794,    51,\n",
              "          32207,     2]), tensor(0)),\n",
              " (tensor([6008, 1311,   25,   89, 2903,  824,   10, 3358,    3, 2005,  576,    2,\n",
              "          1957]), tensor(1)),\n",
              " (tensor([14187,  5259,    34,    36, 11955,    30, 12767,   106,   314,   188,\n",
              "            188]), tensor(0)),\n",
              " (tensor([18697,     6,     0,  5577,    45, 19153,     6,     0,   838,    98,\n",
              "          10350,  4371,     5, 30965,     2]), tensor(0)),\n",
              " (tensor([   18,    16,    19,    18, 10556,    26,   621,    75,   392,  7463,\n",
              "            433,    20, 56947]), tensor(0)),\n",
              " (tensor([308013,   4667,      6,     77,    682,      4,   9548,     41,    822,\n",
              "            3733,      3,    192,   1470,  12259,     75,    430,     41,    175,\n",
              "               2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([ 2061,  4564,    89,  5249,    79,   232,   743,    36,  5227,     2,\n",
              "           1948,   511, 21169,    32,   187,     2]), tensor(1)),\n",
              " (tensor([  50,  582,    3, 4005, 2292,   10, 8000,    2]), tensor(0)),\n",
              " (tensor([  224,  1960,  3158, 51889,  2091,  8336,    29, 84427,     5,    29,\n",
              "          14015, 10857,     5,     2]), tensor(1)),\n",
              " (tensor([ 1377,  2143,    21,  2479,    22,     0,  2610,  2787,    49,  8885,\n",
              "            406,  2808,  1957, 14502, 39045,    11,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 871, 2528, 1836,    2, 2175,    3,   84, 5220, 4385,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([  917,   615,  4355,     4, 13633,  1288,  1197,     2]), tensor(0)),\n",
              " (tensor([   41,  1435,     0,  4411,  5187,  2984,   813,    25, 14876,     5,\n",
              "          15998,    26,   311,    22,     0,   153,     3,     0,   813,     5,\n",
              "           7731,   192,  5591]), tensor(0)),\n",
              " (tensor([ 197, 2552, 2511, 7357,  192, 4184,    2, 1957]), tensor(0)),\n",
              " (tensor([    2, 22042]), tensor(1)),\n",
              " (tensor([  41,   86, 4526, 6479]), tensor(0)),\n",
              " (tensor([  102,    54,    20,   662,   117,    83, 13053,  1211,   416,  2369,\n",
              "            188,    45,   184,  2583,     0, 23897,  2349,     3,     0,   104,\n",
              "           1534,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([14663,   881,     7,   569, 14397,    20, 10556,     6]), tensor(0)),\n",
              " (tensor([  332,  3136, 74293,   269, 69407,     7,  4159,   117, 10696,   413]),\n",
              "  tensor(0)),\n",
              " (tensor([1523, 4469, 5059,   56,   73,    7, 2068,    6, 1643, 1643, 2779,   33,\n",
              "           551, 9661,   77, 1376,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([  459, 28212,    13,    45,    45,   246,     2]), tensor(0)),\n",
              " (tensor([74366,    30, 90264, 78724,    17,  5149,  3112,    73,    39,  1115,\n",
              "            719,   188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([224917,   5327,     19,    628,   5743,    838,   6255,      4,   1753,\n",
              "            1288,      2,      2,      2]), tensor(1)),\n",
              " (tensor([    41,    295,      7,    974,      4,      7,  37742,      2,   3020,\n",
              "               5, 155277,  23703,      7,   1752,  71488,   3045,     11]),\n",
              "  tensor(0)),\n",
              " (tensor([ 473,  299, 2462,   56,    5,   56,    7,  572,  118,  631,    5, 9936,\n",
              "             2]), tensor(0)),\n",
              " (tensor([   53,    33,    55, 19982,    13,     0,  5847,   535,  1429,    95,\n",
              "              2,  2905,     2,   188,   188]), tensor(0)),\n",
              " (tensor([  77, 5578, 6226,  587]), tensor(0)),\n",
              " (tensor([9225,    5, 3202,  192, 1533,    2]), tensor(0)),\n",
              " (tensor([   32, 11713,  7859,   188,     2,     2]), tensor(0)),\n",
              " (tensor([   7,  129,    3,  950, 2061,  270, 5743,   94,   30, 3466,    4,  628,\n",
              "             4,  275, 3540, 4564,    2, 1125,   22,    2]), tensor(1)),\n",
              " (tensor([    0,    96,  1034,   300,   116,  2395,     6,   473,   299,     2,\n",
              "              2,     2, 12392,     3,  6478,  2955,     2]), tensor(1)),\n",
              " (tensor([1744,    6,  276, 4853,  495,    2,    3,    2,    5]), tensor(0)),\n",
              " (tensor([113120,     43,    114,  12142,   2024,   2768,     11, 113120,  15854,\n",
              "               5,   3695,   1926,  34437,     31,   5533,     56,  15976,      2,\n",
              "               2,      2,      2]), tensor(0)),\n",
              " (tensor([     0,    567,    995,     14,    738,     14,      0,  10192,  24445,\n",
              "             222,    138,      6, 152246,    188]), tensor(1)),\n",
              " (tensor([ 2546, 71109,     6,  1368,    74,  2592, 10700,   386,     2,     2,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([  3832,    280,     37,   3832, 100425,   1534,      2,  61113,      5,\n",
              "             280,    842,     10,   4478,      5,   1002,   9220]), tensor(1)),\n",
              " (tensor([   41,  5281,   298,    69, 11008]), tensor(1)),\n",
              " (tensor([   20,   107,  1914,   117,   162,   484,    31,    51,     7,   333,\n",
              "          11039,    66,     2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([154265,    188,    188,    188,    188,    188,    188,      2,      2,\n",
              "              32,     81,    588,  10396,  34980,      4,      0,   1357,  86908,\n",
              "            1077,     59,     60,    392,    261]), tensor(0)),\n",
              " (tensor([   81,    32,   222,     4,   159,     0,   925, 12565,    17,    37,\n",
              "           6456,     2,  3370,     2,     2,     2,     2,    15,    18,  1485,\n",
              "             46,    15,    63,     7,  1482,   188, 73048]), tensor(0)),\n",
              " (tensor([ 2675,     3,  8076,  1948,   511, 30965,  1329, 19153,     3,  9032,\n",
              "           1871,    17,    68,   214,  4162, 15687, 63106,   405,    20,  1673]),\n",
              "  tensor(0)),\n",
              " (tensor([38732,    14,   582,  2011,     4,   578,   271,  1876,     6,  1627,\n",
              "           1634,     2,   190,     7,   662,    22,     0,  7542,   569,  1633,\n",
              "              2]), tensor(0)),\n",
              " (tensor([7472,  436,  188,  188]), tensor(0)),\n",
              " (tensor([  100,   181, 34855,    31,  1579,   373, 87091,   197,    41,  3981,\n",
              "             20,    64]), tensor(1)),\n",
              " (tensor([10312,  1042,    11, 20886,     2,  1993,     2,  4868,     2,  3420,\n",
              "              2,    24,     2]), tensor(0)),\n",
              " (tensor([  5176, 126389,   2005,    445,      4,   6731,   1899,     61,  20949,\n",
              "             278,  28084,    199,      2,   1957]), tensor(1)),\n",
              " (tensor([    0,    56,  1288, 19596,    21,   529,   628, 19904,    11,  3086,\n",
              "            172,     2]), tensor(1)),\n",
              " (tensor([5993,   60, 1741,   25,   11, 7692,   32, 4691,   10, 1150,    3, 7516,\n",
              "             6,    0, 4878,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([ 5817, 12230,  7516,  3704,     6, 12213,     2]), tensor(1)),\n",
              " (tensor([     0, 123039,   9225]), tensor(0)),\n",
              " (tensor([13263,   120,  5387,    60,     0,  2822,   388,    60,     6,  6255,\n",
              "             18,   405,    66,  4862]), tensor(0)),\n",
              " (tensor([  142,  1916,  8015,    38,   768,   484,  1038,  6574,  1005, 21475,\n",
              "              2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([2271, 1077,   13,  197,    4, 1566,  869,    3, 9998,    6,  182,  422,\n",
              "             2]), tensor(0)),\n",
              " (tensor([    0,  5839,     3,    64,  8413,     3,   645,    89, 92367,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([12884,  6130,    55,  1277,   208,  2669,  6425,   362,     3,     0,\n",
              "           2696,  3218,   142,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([13408, 39120,     2,  1533,  2031,     4,    50,  1425,    14,   690,\n",
              "          21654,    19, 34855,    89,    41,  5281,    20,   100,   181,     2,\n",
              "          81715,     2,   591,  3732,     7,   306,   246]), tensor(0)),\n",
              " (tensor([   69,    32,  1229, 38610,    59,  2378,   816,     2,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([  445,     4,     0, 35067,    76,   364, 61766, 22724,    14,  4841,\n",
              "            114,    22,     0, 43340,    11,  6941,     4,     2]), tensor(0)),\n",
              " (tensor([   765,  11546,   2395,     10,    765,   1867,   2395,   3616,     10,\n",
              "             529, 148896,      7,      2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([  197,     4,  3614, 11192, 16067,     5,   159,    20,   662,    50,\n",
              "            378,     2,     2]), tensor(0)),\n",
              " (tensor([134688,    135,     74,  15173,     13,  23080,   1883,      2,   1892,\n",
              "              33,    120,     51,   5327,      2]), tensor(1)),\n",
              " (tensor([  197,     4,  5381,  8640,     5, 54691,     2]), tensor(0)),\n",
              " (tensor([740,   2]), tensor(0)),\n",
              " (tensor([  134,   339,    13,     7, 22861,   188,   188,   303,     4,   253,\n",
              "             12,     2]), tensor(0)),\n",
              " (tensor([  81,  439,  159,   64,  392, 2316, 4002, 1157, 2683,    5, 6255,   43,\n",
              "            30, 4459, 4002]), tensor(0)),\n",
              " (tensor([ 1523,  4469,  5059,   404,     6,  1643,   194,   576,  3913,    11,\n",
              "          10851,  1957,    85,    11,  4361,   172,    11,  1015,     2,     2,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([31262,    14,   192,  2065,    10,     2,  3267,   330,     2,  5599]),\n",
              "  tensor(0)),\n",
              " (tensor([  2146,    117,     20,    107,     33,     51, 243332,    811,   2740,\n",
              "             595,      4,   4885,   2865,      0,  11845]), tensor(0)),\n",
              " (tensor([    41,    408,     29,  13388,  11663,   5054,     34, 103591,     14,\n",
              "            3920,     89,     91,    797,  92367,      2,    151,    987,      7,\n",
              "           13211,    698,     83,     39,     64,  36437,     13,   5555]),\n",
              "  tensor(0)),\n",
              " (tensor([ 5220, 13367,  2718]), tensor(0)),\n",
              " (tensor([ 442,  378,  521,  301,  159,   20,   12,  179,    2,  298,  301,  119,\n",
              "           100,  738,   32,  521,  301,  881, 2143,    2]), tensor(0)),\n",
              " (tensor([56840,     2,   149, 10556,     6,     2,   188,   188,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([11035,     6,  1857, 34268, 12122,  1585,   934,   124,  1546, 10306,\n",
              "              4, 22496, 33105,     2]), tensor(0)),\n",
              " (tensor([ 1544,  1726,   881,  2474,     3, 39549,   971,    13,    44,  2114,\n",
              "           1264,   188,    51]), tensor(0)),\n",
              " (tensor([ 915,    4, 6415,   74,   56,   73,  800,  915, 2085,   21,    0, 5553,\n",
              "          3853,    3,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([  989,   331,   270,    13,   139,   437,  9294,    49, 52496,  1470,\n",
              "          57419,  1892,  5327,     2,     2,     2]), tensor(1)),\n",
              " (tensor([5856,   10, 8547,  535,    2]), tensor(0)),\n",
              " (tensor([ 228,   69,   35,  256,  184,   61,    7, 1323, 1523, 4469, 9652,   29,\n",
              "          2575,  587,    7,  142, 3990,    6,  828]), tensor(1)),\n",
              " (tensor([  34,    2,    2,    2,  805,  197, 1727,    0, 3878,  188,  805,  197,\n",
              "          5205,    0,  188]), tensor(0)),\n",
              " (tensor([  137,    25,  2556, 18988,     5,  5137,     2,     2]), tensor(1)),\n",
              " (tensor([15917,   114,    41,   913, 38610]), tensor(0)),\n",
              " (tensor([    81,    116,    192,   5030,    242,     25, 193595,  18813,      4,\n",
              "           38610,  18813]), tensor(0)),\n",
              " (tensor([  886,    69, 11083,    14,    84, 94624,  1255,     2,    36,   117,\n",
              "              0,  1497,    14,    46,   661,    43,    30, 18824,    17, 18992,\n",
              "              2]), tensor(0)),\n",
              " (tensor([ 811, 6920,    2]), tensor(0)),\n",
              " (tensor([   0,   56,   41, 4927,    4,   20,    0,   56,   41,  733, 3107,    3,\n",
              "          3451,   14,   48,    3,    0,  254, 3619,   63,  661,   15,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([    41,    408,   6479,      4,  22941,     37,    106,     41,    465,\n",
              "            8782,     75,    192,    951,      5, 164272,   3261,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([2641,   20,  242,   60,    6, 6255]), tensor(1)),\n",
              " (tensor([ 33222, 206694,  25532]), tensor(0)),\n",
              " (tensor([    7, 13174,     2,    46,    29,  1718,  6542,   124,     7,  8555,\n",
              "              6, 39509,  4851,  6801,    21,     2]), tensor(1)),\n",
              " (tensor([8918,   19,   25, 1796, 2255,    5,    0,  915,    3,  155,   38,   35,\n",
              "             2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([ 1369, 42773,     3,   167,  8402,  1523,  4469,    38,  9652,  1211,\n",
              "              6,  1130,   330, 16816,   356,     2]), tensor(1)),\n",
              " (tensor([ 3278,   119,    81,   203,     4,   188,   805,   188,   805,   188,\n",
              "              5,  4192,  1403,  3838,    13,     0, 13975, 28169, 25012,    17,\n",
              "              7,  1687,  2641,   103,  6583,  3400]), tensor(0)),\n",
              " (tensor([  192, 15075,  7731,     3,     0, 10696,   188,   188,   188,   188]),\n",
              "  tensor(0)),\n",
              " (tensor([ 9250,  4610,  3278,  7878, 24858, 24014,     2,   188,   188,    21,\n",
              "              2]), tensor(0)),\n",
              " (tensor([6226, 3158,  228,   50, 4564,   13,    2]), tensor(1)),\n",
              " (tensor([ 1329, 12871, 19227, 21991, 13903,     7,   787,     6,   193,   574,\n",
              "              2]), tensor(1)),\n",
              " (tensor([    41,     54,    117,      4, 164272,   1402,     38,   2054,      0,\n",
              "            1388,      6,   2540,     17,   1017,    693,   1742,      2,     11,\n",
              "            1074,   3880,      2,  15290,  16659,      2]), tensor(0)),\n",
              " (tensor([  41,  835, 8640]), tensor(0)),\n",
              " (tensor([93163,   316,  6830,   107,    33,    51, 54617,  3112,    73,  5254,\n",
              "              2,  4851,     2]), tensor(1)),\n",
              " (tensor([  41, 6326,    7, 5423,    2]), tensor(1)),\n",
              " (tensor([13116,   232,     2,   790,   138,   954,     3,   529,   628,     2,\n",
              "           3410,     2]), tensor(1)),\n",
              " (tensor([  120,  4042,     0, 35404,    66,     3,   192, 14574,  5795, 12611,\n",
              "              2,  1085,  3467,    41,    40,     7,   306,   214,  3142,  8154,\n",
              "             66,    21,   114,     2,     2,     2]), tensor(0)),\n",
              " (tensor([235947,  19496,    300,     38,   8396,     95,   6842,  15153,  10471,\n",
              "              10,   1739,      2]), tensor(0)),\n",
              " (tensor([   61,   392,   117,     4, 35690,     4,  4294,     5,   392,   117,\n",
              "             29,  1357,   394,    10,   359,  1132,  2395]), tensor(1)),\n",
              " (tensor([  220,    50,  2768,   527,  1432,    75,  1261,   109, 10230,  2524,\n",
              "             46, 24584,     2]), tensor(0)),\n",
              " (tensor([ 2546, 26456,  1975,    10,  3551,   386,     6,  4862,   207, 52355,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  32,   81, 2185,  248,    4,  218]), tensor(0)),\n",
              " (tensor([  9183, 145506,   4377,   3832,    913,    100,  15002]), tensor(0)),\n",
              " (tensor([  142,   941,  1391,  2508,   767,    49, 16027,  2316,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([     7,     50,  10374,    216,  12970,  17729,    166,  56655,   1062,\n",
              "           60319, 184177,     21,      2,     13]), tensor(0)),\n",
              " (tensor([  405, 38335,    76,   364,    22,   161,    10,     0,    58,    79,\n",
              "              6,   192,   214,     2,     2,     2,     2, 34855,    15, 10267,\n",
              "            188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([   41,  2472,     4,    30,  1515, 32207,    37,  1175]), tensor(0)),\n",
              " (tensor([ 738,  339,   66,    7,  484,  149, 4471,  188]), tensor(0)),\n",
              " (tensor([25048,  5467,    13,   653, 17815,  1427,  5414,   691,  5188,    89,\n",
              "           3254,  2811,     2]), tensor(0)),\n",
              " (tensor([ 739, 1752,  719, 6424, 8308, 5149,  168,    2,    2,    2,  120,  222,\n",
              "             4,  465, 4558,  654,  420,    2]), tensor(0)),\n",
              " (tensor([ 3708,  3653,  1101,   510, 17260,    22,  5724,    21, 69316,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  965,     7,   767, 12217,  2693,  1152,     5,     7,   343,    49,\n",
              "              0, 43188,     3,     0,    76,   728,     2,     2,     2,     2,\n",
              "              2]), tensor(0)),\n",
              " (tensor([16463,  1836,    17,  1971,  2486,     5,   114,     7,   268, 23179,\n",
              "              6, 11096,   386,     2]), tensor(1)),\n",
              " (tensor([ 7942, 10945,  6332,    33,    81, 64823,   285,   188,    51, 50045,\n",
              "           4647,   161]), tensor(0)),\n",
              " (tensor([  81,   32, 2860,    4,    0, 9920, 2421,  740,  770,  510, 5091,  185,\n",
              "          9470, 2663, 1110, 5549,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([ 22922,   7492,   1224,  10094,  28966, 156163,    232,      2,      2,\n",
              "               2]), tensor(0)),\n",
              " (tensor([ 6137, 93307,    43, 55211,     0,   121,  1389,    11,     5,   455,\n",
              "           4231,     3,    50,  1913,    11,    21,  1481,  7078,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([219634,   5628,  77868,   2401]), tensor(1)),\n",
              " (tensor([23092,  1829,     7, 56185,     5,   127, 12713,    71,  4376,    10,\n",
              "              7, 55918, 14583,     2,  1139,     5,  8355,   974]), tensor(0)),\n",
              " (tensor([    4,   838, 30965,  2699,     2]), tensor(0)),\n",
              " (tensor([ 5545,  3164,  1229,  9006,    89, 32027,  2940,    25, 64076,  2349,\n",
              "           1563, 17721,  4851,     7,  3366,   214,     2]), tensor(0)),\n",
              " (tensor([    34,     83,     39,     40,    673,     73,    696,     41,     54,\n",
              "              33,   1527,    151,    489, 275977,      2,     37,     94,    588,\n",
              "             807,    138,      7,   8525,      2]), tensor(1)),\n",
              " (tensor([14229,  2802,     4,  1545,   933,    19,  1507,  4977,  5625,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 3467,    41,    40,     7,   894,  3017, 33601]), tensor(0)),\n",
              " (tensor([   41,  5572,     7,   974,    25,     2,  7620, 12791,    11,   336,\n",
              "           1935]), tensor(0)),\n",
              " (tensor([   81,    32,   222,     4,  2874,  8637,     6,   365,   654,    81,\n",
              "           1790,     0,  9549,     6,   333,  3072,     2,     2,     2,     2,\n",
              "             57, 46768,   346,     0,  1715]), tensor(0)),\n",
              " (tensor([  81,  242,   13,   17,   37,  490, 1300,  572,   64,   81,   32,  222,\n",
              "             4,   88,   14,  159,    0, 7860, 9781,    2,   57,  188, 8156, 9959]),\n",
              "  tensor(0)),\n",
              " (tensor([   41,  2271,     0, 61958,    41,  2271,     0, 92382,    41,   405,\n",
              "          23608,  7731,  7277, 38610]), tensor(0)),\n",
              " (tensor([  807,   138,     7,  8525,    75,  5613, 28645]), tensor(0)),\n",
              " (tensor([ 2923,    41,   120,  1435,     7,  6662,  9200,  1482,     2,     6,\n",
              "            102,  1658,     4,    30,     7,  2426,     3,  2486,    25,   192,\n",
              "          25495,     2]), tensor(0)),\n",
              " (tensor([     0,    641,   3521,   5359,     54,    242,      4,      7,   8740,\n",
              "               6,      7,     84,    188, 256536]), tensor(0)),\n",
              " (tensor([  1925,   9268,    569,     75,    406,    666,   5690,      7,   1925,\n",
              "           17424,      7,    569,     75,      7,    129,      3,    406, 249882,\n",
              "               2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([  409,   142,  1037,   898,    10, 13249,   271,    22, 10002,  1176,\n",
              "              6,   614,  4234, 36857, 27672,     2,    11,     2]), tensor(1)),\n",
              " (tensor([   69,   303,     4,  2271,     0,  2745,   113,    39,   303,    44,\n",
              "          20402,  1950,     2,     2]), tensor(0)),\n",
              " (tensor([   41,  5572,     7,   974,     2,  6526,    11,  5423,     5, 55854,\n",
              "           5711]), tensor(0)),\n",
              " (tensor([5993,   60, 1741,   25, 7692,   32, 4691,   10, 1150,    3, 7516,    6,\n",
              "             2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([    13,   2332,      4,  10593, 141327,      5,   4603,      2,      2,\n",
              "               2,   2220,     66,    272,   4564,    188,     36,    100,    181,\n",
              "             188,    188,      2]), tensor(0)),\n",
              " (tensor([ 7128,  1921, 85399,    21,  6364,  4667,    89,  1960,  1845,   332,\n",
              "           2380,    19,    11,   246,     2]), tensor(1)),\n",
              " (tensor([ 2923,    41,   120,  1435,     7,  6662,  9200,  1482,     2,     6,\n",
              "            102,  1658,     4,    30,     7,  2426,     3,  2486,    25,   192,\n",
              "          25495,     2]), tensor(0)),\n",
              " (tensor([ 855, 1438, 5658,   17,  409, 1996, 4105, 1262,    6, 5553, 1739,  436,\n",
              "             2]), tensor(1)),\n",
              " (tensor([  38,  768,  484,   22, 3538, 1005, 2248,  256,   21, 1544, 2508,  188]),\n",
              "  tensor(1)),\n",
              " (tensor([ 36811,    158,     32,    858,    219,     10,     81,     17,      0,\n",
              "            1813,      2,  17843, 236295,  20292,  17175,  23525,      2,      2,\n",
              "               2,      2]), tensor(0)),\n",
              " (tensor([7692,  596, 3649,    3, 3759, 3117, 2880,    2,    2,    2,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([    0,  2291,  1955,     4,   282,     0, 24837,     6, 20398,  4002,\n",
              "           1357,  1255,   237, 56655,  2089,     0, 64522,     2,     2,     2,\n",
              "              2]), tensor(0)),\n",
              " (tensor([ 3119,     3,     0,  1836, 41727,     2]), tensor(1)),\n",
              " (tensor([   41,  5572,     7,   974,     2, 92834, 11865,    10,  3551, 10192,\n",
              "           1216]), tensor(1)),\n",
              " (tensor([ 4541, 13224]), tensor(0)),\n",
              " (tensor([  662,    10,   192,   527,  3072,  1992,   255,    13,     5, 47809,\n",
              "            386, 29153,     5, 44798,  8832,  4240,     2]), tensor(0)),\n",
              " (tensor([13095,  1027,     6,   767,  2266,   214,   108,     0,   490,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([14977,   394,    10, 19115,     4, 81446,  3631,     3,   308,  1712,\n",
              "             69,     4,  1612, 13200, 15988,   265, 15988,  1357,   575,  1928,\n",
              "            779, 19659]), tensor(0)),\n",
              " (tensor([1313, 6008, 1870,   13, 8816,  583, 6276,    4, 1248, 4035, 3345,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 10805,    110,     81,     35,  28125,     41,   1764,      4,   9347,\n",
              "            1402,     66,      3,    187,    144, 178479,    100,    100,    242,\n",
              "             707,      5]), tensor(1)),\n",
              " (tensor([    2, 42037, 66274,  5423,   725,  2353,   115,  1497,   324,  3640,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  504,     0, 26103,     3, 13168,   162,   300,    14,   149,  2193,\n",
              "           3640,    11,   113,   117,    12,     2]), tensor(0)),\n",
              " (tensor([2123,   81, 3711, 2778,    5, 1421,   75, 4471, 1490,  738,   32,   81,\n",
              "           433, 8233,   10,   12,  300,  964,  188,  805]), tensor(0)),\n",
              " (tensor([   13,     0,   639,  9293,    22,     7, 16966,    10,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([    0,    56,  1288, 19596,    21,   529,   628, 19904,    11,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  89,  654,    2,    5,  102,   83,   53,  169, 2143,  188]),\n",
              "  tensor(0)),\n",
              " (tensor([   12,  2146,   100, 27329,     5,   120,     2,     2,     2, 19320]),\n",
              "  tensor(1)),\n",
              " (tensor([ 9183,  1718,  5161,  4720,  6668, 13247,   131,   565,   459,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([  3937, 119676,      3,  16013,    117,  35690,  22064,    339,      7,\n",
              "            1692,      6,    285]), tensor(0)),\n",
              " (tensor([    7,   219,  2365,    13,   406, 22999,     5,  1316,  1291,    21,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  269,   197,  6250,    20,    43,   662,    61,     0, 31781,  5879,\n",
              "          55211,     0,   298,   166,     2]), tensor(1)),\n",
              " (tensor([22074,    82,    20,    15,   554,     4,     2,    37, 55477,  3037,\n",
              "          13053,    34,    47,   523,    15,   573,   402,     2,  1957]),\n",
              "  tensor(1)),\n",
              " (tensor([  84,   56,   89,   42, 6925,   89, 7228,   21,   89]), tensor(1)),\n",
              " (tensor([  164,     3,   438,  9427,    11, 72362]), tensor(0)),\n",
              " (tensor([    0, 11461,  2115,     3, 13053,     5, 20937,  4065,  2947,   149,\n",
              "            134,  1349,   373,     2]), tensor(1)),\n",
              " (tensor([94881,  5574, 14691,  2528,  3443,    25,  1038,  1313,   105,  1836,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  1676,   6870,     21,  91498,  46460,    764,   2398,      3,   8738,\n",
              "            8738, 108784,   3278,  54261,      2]), tensor(0)),\n",
              " (tensor([88617,     2,   992, 35924,     2,   102,     7, 10267,  2528,  1836,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 2772,   300,    41,    15,   518,     7,   978,   147,   100,   372,\n",
              "             34,   958,  3278,     7, 26103,     3,    33,   852,    20,   248,\n",
              "            204]), tensor(0)),\n",
              " (tensor([ 1836,  1814,  1811,  7857,  2625,    17,  9335,  6211,    89,  3684,\n",
              "              4,  1116,  5135,     2,    95, 43776,   324,    89,   662,    66,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([ 60, 300, 188]), tensor(0)),\n",
              " (tensor([   51, 24150,   108,    81,   218,   285,   114, 15095,     6,     0,\n",
              "           3708,    81,   253,   690,    51,     7,  3510,    34,   296,    81,\n",
              "             41,   455,    60]), tensor(0)),\n",
              " (tensor([ 2747,  3014, 12950,    54,    30,   372,    56,  3782]), tensor(1)),\n",
              " (tensor([ 192, 2926, 2143,  285,   10,  192,  565]), tensor(0)),\n",
              " (tensor([ 29864,   1042,    120,    119,      7, 243913,      5,     18,   4042,\n",
              "               0,   6458,      5,   5844,      0,   1627,   4364,    317,    720,\n",
              "               5,    116,      7,  16849,   7351,      2]), tensor(0)),\n",
              " (tensor([  41,  390,   30, 9953,    0, 4471, 1490,  188]), tensor(1)),\n",
              " (tensor([ 208,    7,   50,  384,    2,    2,    2,    2,  632,  112,    6,  409,\n",
              "           249,    2,   41,  151,  346,  111,   41,  913,   61,   41, 3050,   60,\n",
              "          5717,    2,  102,    7, 8842,  359, 1214,  413,    2]), tensor(0)),\n",
              " (tensor([ 1965,  2686,     6, 15151,  1106,  1640,     5,    84, 64269,    11,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 6456,     2,   102,   107,    33,  1098,     7,  5083,  1470,     4,\n",
              "          13633,     6,  2522,  1968,     2,  1864,     2,     2]), tensor(1)),\n",
              " (tensor([29162,   881,  4950,     6,     0,  8642,   992,  1749,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 3285,     7,  4298, 41773,    22,   192,  4731, 12547,     5,   114,\n",
              "           9862,   188,   188]), tensor(0)),\n",
              " (tensor([   562,  26456,    409,    679,    193,      3,   1233,   7366,     22,\n",
              "             579,   5135,      2,    426,  11895,      5,   2486,  20354,     60,\n",
              "               4,    692,   5135, 159942,      2,      2,      2,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 219,  260,  392,  213,   33,   29, 1357,  394,  188,    2,    2,    2,\n",
              "             2,    2]), tensor(0)),\n",
              " (tensor([279683,     40,     51,  12157,     60,      6,     29,   2996,   1612,\n",
              "              17,    201,     68,   3649,   6376,   8341,   8356,  44126,      5,\n",
              "           29471,      2,     65]), tensor(1)),\n",
              " (tensor([   36,     4,  3862,     7,   224, 10420,     4,     0, 32482,     3,\n",
              "            315]), tensor(1)),\n",
              " (tensor([ 656,  325, 9214, 3134, 2005, 5059,  739,    2]), tensor(1)),\n",
              " (tensor([    0,   902,     3,   155,   256,    35,  1787,    13,     0,   817,\n",
              "             49,     0,  3423,    58,  8266,     0,   444,   491,   127,  5897,\n",
              "          11348]), tensor(1)),\n",
              " (tensor([ 37212,   4036,  10894,      6, 154788,    948,    717,     22, 339409,\n",
              "             445,      4,   1960,      2]), tensor(1)),\n",
              " (tensor([ 3278,    88,  1096,     4,  5054,    12,     2,     3,     0,   306,\n",
              "             69,    18,    40,   359, 10040,     6,    26,   214,  1301,    15,\n",
              "             48,     3,     0,  3107,     2]), tensor(1)),\n",
              " (tensor([113120,     43,    114,  12142,   2024, 113120,  15854,      5,   3695,\n",
              "            1926,  34437,     31,   5533,     56,      2,      2,      2,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([  117,     4,   269, 52754,    34,   359,    79,    41,   253,     7,\n",
              "          42773,    17,   285,     6,    20,    41,   120,   269,     4,  3261,\n",
              "            102,     7, 66906]), tensor(0)),\n",
              " (tensor([    41,     15,      7,  60269,    964,      2,     13,    177,   4853,\n",
              "            6283,     10,    184, 130944,    186,      2,     37,     14,     37,\n",
              "             517,      2, 167152]), tensor(0)),\n",
              " (tensor([   88,    81,   998,   117,    81,    32,  7940,     6, 27209,   188,\n",
              "            190,     0,     2,     2]), tensor(0)),\n",
              " (tensor([131246,   2370,     14,     59,      4,   2357,    805,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 1861, 13712,   226,  4034,    22,   140,  3134,     2,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([   69,    17,     7,    66,    63,     2,     2,    32,  6479,   887,\n",
              "              4, 10462,  1454,     5,  1653,  1454,    19,   143,    46,    36,\n",
              "            188]), tensor(1)),\n",
              " (tensor([13234,  5637,    74,  7595,  2788,    22,  9302,  7850, 22551, 17228,\n",
              "           6302,   803,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([22964,  9823,  5869,     4,   607,     6,     7,  1352,     5,  1894,\n",
              "           4005,     6,   545,     6,  2454,     2]), tensor(1)),\n",
              " (tensor([  79,    4, 1680, 2019, 1933,    2]), tensor(1)),\n",
              " (tensor([79221, 48034, 88525, 14544,   990,     4,     0,    67,    86,  2168,\n",
              "           1208,     2]), tensor(0)),\n",
              " (tensor([   192,  11231,     10,      0,  10510,    186,     37,    240,      2,\n",
              "               2,      2,      2,  46768,   1543,      7,   1115,    530,      2,\n",
              "          240203,     41,    269,  22536,    715,     14,      2,      2,      2,\n",
              "               2,   1553,    415,   2693,    186]), tensor(1)),\n",
              " (tensor([ 4728, 18364,     2,    81,    91,    33,     4,    30,  4042,   442,\n",
              "              4,   346,   484, 11567,     2, 11879,  4139,   189,  3375,   163,\n",
              "            307,  5009,     6,     0,    64,   753,   186]), tensor(0)),\n",
              " (tensor([  1825,   1470,   1780,   3649,      3,      0,  14582, 119230,   2626,\n",
              "            5427,   6591,   1957,      2]), tensor(1)),\n",
              " (tensor([   41,   326, 22146,   595,     4,   662,    19,  1973,    19,   555,\n",
              "              6,   669,     3,   192,  6075,     5, 91375, 19356,   188,   188,\n",
              "            188,   188, 18364,   188,   188,   188,    57,    84,   188,   188,\n",
              "            188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 2575,   484, 59455,  7441,   586,     2]), tensor(1)),\n",
              " (tensor([   41, 10008,     6,     0, 43118,  3216,     5,    41,   402,   192]),\n",
              "  tensor(0)),\n",
              " (tensor([1139,    3, 3937, 3235, 1537, 1069,    0,  139,  156,    3,    0, 6580,\n",
              "           484,  385, 2061,  586,  176,    2,    2]), tensor(1)),\n",
              " (tensor([   41,   169,     4,  3937,   192, 34855,     6,   349]), tensor(1)),\n",
              " (tensor([ 1497,   119,  1441,     4,   192, 34855]), tensor(1)),\n",
              " (tensor([    0,    56,  1288, 19596,    21,   529,   628, 19904,    11,  3086,\n",
              "            172,     2]), tensor(1)),\n",
              " (tensor([136410,  19712,  29349,      2,   7296,      2,   1186,   3410,      2,\n",
              "           12978,     19,    393,      3,      0,   4049,    620,    627,      2,\n",
              "            2368,     56,     59,      0,      2]), tensor(0)),\n",
              " (tensor([   738,     32,     81,  44690,     17,    653, 105269,    188,    190,\n",
              "               0,      2,      2]), tensor(1)),\n",
              " (tensor([  314,    82,    49,     0, 15759,  2610,  4912,  4636,    14,   638,\n",
              "           4851,     2,     2]), tensor(1)),\n",
              " (tensor([33222,    55,  1490,   791,     6,   484,    13,  2766,   491,     6,\n",
              "              2,     2,  1957]), tensor(1)),\n",
              " (tensor([10230,  1960,  4851,   300,   431,     6,  4698,     3,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([1751, 4158,  365,   41, 2214,   81, 1749,  824,   81,   33,    7, 1211,\n",
              "            48,  188,  188,  188,  188,    2]), tensor(0)),\n",
              " (tensor([    6,    69,    33,   492,  5125,     6,     0, 67850,  1825,  3094,\n",
              "              0,    78,    31,   208,    60,    49,     0,     2]), tensor(1)),\n",
              " (tensor([ 1164,     4,    10, 13767,   285,     4, 42286,    37,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([11083,  6332,    10,     0,  2676,     2,  2008, 18824,    17,  3310,\n",
              "             22,     0, 11008,    34,    53,    33, 16402,     5,    43,   169,\n",
              "            137,     4,    81]), tensor(0)),\n",
              " (tensor([  149,   346,    61,  1185,    89,  3200,  1330,    43,  8876,     2,\n",
              "           3920,  2790,   569, 14582,  5611,   422,     7,     2,  1993,     2,\n",
              "             36,     7,    50,     2]), tensor(1)),\n",
              " (tensor([ 3692,   441, 23689,   301,  1262,     6,   163,  2650,   142,   862,\n",
              "             10, 35227,     2,    11,     2]), tensor(1)),\n",
              " (tensor([ 5054,  8979,     2, 22226,  1203,   131,  7155, 97501,  6843,   115,\n",
              "             19,    20, 62230,  3085,  1357,   394,     2]), tensor(1)),\n",
              " (tensor([  753,  3129,   268,     3,     0, 31135,  1720,   176,   903, 60598,\n",
              "          25017,    11,   549,  1465,    21, 10891,     2,     2]), tensor(1)),\n",
              " (tensor([    0,  2370,     0,  4184,     3,    26,     5,  2125,     3,   101,\n",
              "             12,  1853,     6,   103,  5284,    30, 27329,     2]), tensor(0)),\n",
              " (tensor([10851,   220,     0,  5916,   484,    31,  2846,    75,    96,     2,\n",
              "              2,     2,    11,     2,     2]), tensor(1)),\n",
              " (tensor([   37,    14,   208,     4,   399,     7,  1324,    48,   229,  4284,\n",
              "              2,   127,    43,    30, 18824,     2,     2,     2,     2,    24,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  188,   188,    50,  7313,  3950, 39505, 21925,  7006, 55976, 11979,\n",
              "           1007,   719,  4769,     2,     2]), tensor(1)),\n",
              " (tensor([14417,    75,   866,    49, 13477,     5, 11099,    10]), tensor(1)),\n",
              " (tensor([   765,  11546,   2395,     10,    765,   1867,   2395,   3616,     10,\n",
              "             529, 148896,     49,   8321,   2042,     95,   1456]), tensor(1)),\n",
              " (tensor([ 843,  821,  286,   17,    0, 2513, 1062,    3,   43,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([18590, 94881,  5574, 14691,  2528,  3443,    25,  1038,     7,  2790,\n",
              "           3423,   105,     7,  1836,     6,  6113,     2]), tensor(1)),\n",
              " (tensor([  192,  1749,   405,     7,  6315, 17882,  1185,   117, 21365,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   50,  7313,  3950, 39505, 21925,  7006, 55976, 11979,  1007,   719,\n",
              "           4769,     2,     2, 33222]), tensor(0)),\n",
              " (tensor([ 1609,   141, 59334,   971,  6364, 30559,     7,  1132, 22262,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([11883,    12, 11346,    12,    50,   569,  9332,   188,   188,   188,\n",
              "            188]), tensor(0)),\n",
              " (tensor([14229,  2802,     4,  1545,   933,    19,  1507,  4977,  5625,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   51,    13,   725,     6,     0,   122,     4, 45520,    54,   835,\n",
              "              4,  3974,     0,   241]), tensor(0)),\n",
              " (tensor([2664, 1027,    6,  266,    5,  271, 3107,    6,   58,  343,    3,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([56403, 39505, 21925,  7006, 32907,  3950,  1007,   719,   220,  3436,\n",
              "           5149,   486,     2,     2]), tensor(0)),\n",
              " (tensor([2290, 1005,   59, 4799, 5644,  356,    6, 3500,    2]), tensor(0)),\n",
              " (tensor([1446,  113,    3,    0, 2575,   12, 1921,  484,  188]), tensor(1)),\n",
              " (tensor([ 96932,  43776,  30640,     14,    717,    118, 138791,      5, 150743,\n",
              "           10032,  23869,    113,      3,   6920,      2,  52221,     14,    118,\n",
              "           18089,   3345,      5,  20079,   3345,      2]), tensor(1)),\n",
              " (tensor([  408,     4,   837, 24600,   654,    60,   113,    61,  1174,  1181,\n",
              "          20139,     0,  3107,   120,   578,   881,   609,     5,   609]),\n",
              "  tensor(1)),\n",
              " (tensor([ 8038,  5099,    10,   881,  2888,    13,     0, 14582,  1470,   373,\n",
              "             11,  1712,   101,    59,  1005,   364,     5,  1177,   511,     0]),\n",
              "  tensor(1)),\n",
              " (tensor([    0,    56,  1288, 19596,    21,   529,   628, 19904,    11,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([13053,  3649,   838,   490,   459,     6,  1342,   974,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([11425,  4647, 53405]), tensor(0)),\n",
              " (tensor([4, 0, 2]), tensor(0)),\n",
              " (tensor([   897,  31312,      2,    409,      2,    409,   3117,     11,     11,\n",
              "           22221,      3, 173257,    656,     13,      2,      2,      2,      2,\n",
              "            1957]), tensor(1)),\n",
              " (tensor([  468,   187,    32, 14916,     2,   162,   678,    31,  3838,    98,\n",
              "              0,    95,     5, 13709,    95,     2,  3124,    10,     0, 14035,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  966,   317,   109,   606,  7940,    75,     0, 23275,   955,  6965,\n",
              "              3,  8412,     5,  8412,   819,     6,   192,   214,     2,  5856,\n",
              "             10,   170, 13702,     2]), tensor(0)),\n",
              " (tensor([43188,     6, 20293,    19,   787, 11174,  2232,   296,   621,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 2322,     0,    85,     3,  3828,  6886,   790,  1562,    60,     5,\n",
              "             75,     0, 26865,   620,     2]), tensor(0)),\n",
              " (tensor([   41,   189,    33,   225,   439,    73,     4,   269,   169,  1096,\n",
              "            751,    49,     7,   232,  1152, 69730,   905,     2]), tensor(0)),\n",
              " (tensor([  61,   89,   89,    2,  136, 2717, 1763]), tensor(1)),\n",
              " (tensor([  543, 23753,    37,    11,  3476,     2,     2]), tensor(0)),\n",
              " (tensor([   40,     7,  1214,  1485,    17,   192,  8349,   188,   188,     2,\n",
              "              2,     2,    20,    15,    29, 41524,  1221,     2,     2,     2,\n",
              "          96216]), tensor(0)),\n",
              " (tensor([    0, 37742,  3281,     5, 15638,     6,     2]), tensor(0)),\n",
              " (tensor([    0,  2718, 35541, 12055,   117,     0, 30514,   133, 65718,     2,\n",
              "            188,   188,   188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 11379,      3,   1933,     56,     73,   7228,    445,      4,   1965,\n",
              "            2686,      6,   7217,      2,    107,  14272, 129434,   8063,      4,\n",
              "              44,  13822,      2,      2]), tensor(1)),\n",
              " (tensor([ 41, 408,  37,   2]), tensor(0)),\n",
              " (tensor([10871,  3552,    10,  3677,    46,    58, 33345,     5,    13,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 2923,    41,   120,  1435,     7,  6662,  9200,  1482,     2,     6,\n",
              "            102,  1658,     4,    30,     7,  2426,     3,  2486,    25,   192,\n",
              "          25495,     2]), tensor(0)),\n",
              " (tensor([ 22922,   7492,   1224,  10094, 182998,   1941, 154078,    409,      2,\n",
              "               2,      2]), tensor(0)),\n",
              " (tensor([113120,     43,    114,  12142,   2024,   2768,      2]), tensor(0)),\n",
              " (tensor([ 1645,  2474,     3,  5455,  1089,  6762,    93,   230, 10008,     6,\n",
              "              2,     2,     2,     2,     2,   114,     7,   140,  5648]),\n",
              "  tensor(1)),\n",
              " (tensor([   58, 33345, 12557,    10,   121,  1070,     5,  1542,    13, 27191,\n",
              "            732,     2]), tensor(0)),\n",
              " (tensor([ 3714,  2370,     2,  2788,    19,   192, 10197]), tensor(0)),\n",
              " (tensor([    20, 173832,      7,    191,    365,  19761,     34,     20,     15,\n",
              "               7,   1479,  19761,      5, 123797,    117,   1454]), tensor(1)),\n",
              " (tensor([  187,    53, 48271,   242,    17,     0,  2091,   378,   182,   188,\n",
              "              2]), tensor(0)),\n",
              " (tensor([57883]), tensor(0)),\n",
              " (tensor([   91,    83,  6479,   886,   285, 23344,    81,   188,   188]),\n",
              "  tensor(0)),\n",
              " (tensor([    0,  4632,   437,     3,   285,     2,    84,  2565,  1595,     2,\n",
              "             34,    20,    86,    30,   751,     2,    41,   998,   117,     0,\n",
              "            290,    43, 29747,    13,   475,     2]), tensor(0)),\n",
              " (tensor([ 1377,  2143,    21,  2479,    22,     0,  2610,  2787,    49,  8885,\n",
              "            406,  2808,  1957, 14502, 39045,    11,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  20,   31, 3732,  100,  109,  246,    0,  341, 1334,  606]),\n",
              "  tensor(0)),\n",
              " (tensor([28811,     2]), tensor(0)),\n",
              " (tensor([48021,    15,    13,    26,   179,     4,     7,   439,   432,    73,\n",
              "          29270,     5,    12, 14582,   207,  6644,     2,  8287,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   89,    89, 28811,    45,  1508,  4961,     5,  1269,     6,     0,\n",
              "            182,   701,   395,     2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([ 676,  194, 2075,  256,    6,  233, 1523, 1763, 4851,    2,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 4885, 12786,  7681,  1351,   721, 10968, 13697,   467,   908,   149,\n",
              "              2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([   11,  1903,  5690,    74,   167, 17155,   336,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  452,   211,    32,    63, 16820,     6,     0,  7860,   188,    45,\n",
              "            452,   211,  2005,    37,   740,  5918,     2,     2,     2,     2,\n",
              "             21,     2,  7109]), tensor(0)),\n",
              " (tensor([   45,     0,    56,  1288, 19596,    21,   529,   628, 19904,    11,\n",
              "             50,   196,   246,     2]), tensor(1)),\n",
              " (tensor([     7, 167784,   2805,      6,   8321, 255063,      2]), tensor(1)),\n",
              " (tensor([  41,  998, 2143]), tensor(0)),\n",
              " (tensor([    0, 14343,  4414,    89,   299,     2,     2]), tensor(1)),\n",
              " (tensor([5180, 4175,  256,    6, 2329,  325, 9214, 3134, 2005,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([71328,  1977,     6,   214, 56770,     6,  4562,     4, 25373, 38826]),\n",
              "  tensor(0)),\n",
              " (tensor([    0,  4747,   188,   188, 32853]), tensor(0)),\n",
              " (tensor([  300,    14,  2185,     7,   674,     3,  1613,  4722,    38,  4827,\n",
              "            490,   268,     2,     2,     2, 14397,  1528,   906,     2,    39,\n",
              "            390,   346,     7,   530,    59, 14343,  3343,     2,     2,     2,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  151,   127,   162,  1374,  6201,     5, 11713, 12945, 26832,    73,\n",
              "          60073, 13585,   120,    19,    53, 23753,     2]), tensor(0)),\n",
              " (tensor([  25,  318, 1754,    2,    2,    2,    2]), tensor(0)),\n",
              " (tensor([ 317, 2049,  255,    0, 7940, 2377,    6,    0, 4878,  937,  102,    7,\n",
              "          8287]), tensor(1)),\n",
              " (tensor([    0, 13854, 12791,     3,  2354,     2]), tensor(0)),\n",
              " (tensor([171383,      2,    197,      4,   3807,      7,  11099,   3631,      5,\n",
              "               0,      2]), tensor(1)),\n",
              " (tensor([ 4526, 10360,    17,   326,    13,  8235,    88,    20,     6,   766,\n",
              "             17]), tensor(0)),\n",
              " (tensor([   41,   107,    30, 38610,     7,   333,    41,    19,  1605, 19044,\n",
              "              0,   683,    19,    41,  1140,   913]), tensor(0)),\n",
              " (tensor([10696,  1696,   193,  1432,   521,     7,  1479, 33626,    13,     0,\n",
              "           5778,  2486, 14529,    47,  2901,     2,     7,   740,  1836,    31,\n",
              "              7,  1595,   214,   636,  2528,     2]), tensor(1)),\n",
              " (tensor([     0,    365,   1201,   3229,   5149,      2, 100666,    953,      4,\n",
              "            1252,      2,      2,      2,     11,    777,   1339,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 15747,   2718,   5918,  29096,    409,      2,    176,   4869,  14098,\n",
              "           29598,  38734, 138251,     11,    549,      2,      2]), tensor(0)),\n",
              " (tensor([ 6842,     3,     0,    85, 23753,    34,    41,   891,     0,   341,\n",
              "            561,    51,   100,   173,   114,     5,    41,   242,   296]),\n",
              "  tensor(0)),\n",
              " (tensor([24455,   588,    66,   187, 27089,     2]), tensor(1)),\n",
              " (tensor([  111,    81,   134, 38335,    64,     0,   179,   469,   188,     0,\n",
              "           3464,  1085,  2146,   117,    20,     2]), tensor(0)),\n",
              " (tensor([   17,  4527,  8183,  4359,  1245,    11, 13116, 24605,  1891,  1509]),\n",
              "  tensor(1)),\n",
              " (tensor([33222,    53,   189,  1190,     7,  1015,    12,  4215,  4471,   300,\n",
              "          17762,    25,   781,   163,     2,     2]), tensor(0)),\n",
              " (tensor([ 120,  134, 2022,    4, 3646, 3158, 1553,    2]), tensor(1)),\n",
              " (tensor([    0, 11461,  2115,     3, 13053,     5, 20937,  4065,  2947,   149,\n",
              "            134,  1349,   373,     2]), tensor(1)),\n",
              " (tensor([ 231,  865, 4651, 1614,    6,   29,   14,   14,    0, 2264,  454,    4,\n",
              "          2502,    7]), tensor(0)),\n",
              " (tensor([  41,   54, 7033,    6,    4,  192,  490, 6172, 9283]), tensor(0)),\n",
              " (tensor([   77,     3,     0, 17363,    86,    30,   120,    19,   365,    19,\n",
              "              0,  1824,  3117,     2,  5611,     2]), tensor(1)),\n",
              " (tensor([   19,   628,  4564,  9012,  2061,   270,  4076,     0,  7203,    59,\n",
              "           3381,  1537, 19904,  1138,     2,     2]), tensor(1)),\n",
              " (tensor([1899,   14,    7, 6743,   14,    7, 9936]), tensor(0)),\n",
              " (tensor([91571,  1680, 14317,  1933,    17,     7, 12009,  1883,  2280,   728,\n",
              "             19,    17,   359,    68,  1907,    12,  2054,     7,   586,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  14,   63,    7,  364, 9292,   13, 2554,  188,  596,   66,    2,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([  738, 12250,    14,  3338,  1488,    10,  1376]), tensor(1)),\n",
              " (tensor([  12,  247,  179, 1078,   73,   41,  287]), tensor(0)),\n",
              " (tensor([37294,  4137,   869,     3,  3389,  1840,   773,     3,  6584,     7,\n",
              "          14058,  4318,  3330,    11,     2,  1957]), tensor(1)),\n",
              " (tensor([  61,   81,  346,   42,  179,   29, 9214,   14,  781,   25,   89,   89]),\n",
              "  tensor(1)),\n",
              " (tensor([   0, 4493,    3,  192,  261]), tensor(0)),\n",
              " (tensor([   37,    14,     0,  1132,     5, 22200,  8678,     3, 12034,  5337,\n",
              "             20,    31,    51,   977,     2,     2,     7]), tensor(1)),\n",
              " (tensor([  67,   16,    7,  306,  265,    2,   34,   41,  169,    7, 9292,   10,\n",
              "            66,   79]), tensor(0)),\n",
              " (tensor([   83,    81,  3823,   392,  1676,    17, 12634,     5, 88314,   127,\n",
              "             20,   190,    81,  3986,     2,    30,  5604,     3,   392,  2768]),\n",
              "  tensor(0)),\n",
              " (tensor([  553, 32798,    32, 38610,    59,     0,  2046,     2]), tensor(0)),\n",
              " (tensor([  157,  1637, 19596,     4,   159,   179,    10,    50,  1288,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 6370, 12956,  5546,    81,    66,     3,     0,  4471,  1490,     5,\n",
              "             81,   203,   455,    81,  1096,    34,    81,   332,   326,   131,\n",
              "              2]), tensor(0)),\n",
              " (tensor([   10,     0,    69,    38,   431,     6,   473,  6608,    21,  1207,\n",
              "          45812,     3,   623,   178,     2,     2]), tensor(1)),\n",
              " (tensor([  188,   188,   188,   188,   188,   188,   197,    32,    81,   222,\n",
              "              4,  3981,    37, 12950,   188]), tensor(1)),\n",
              " (tensor([ 1796,  1873,  1248, 16175,    12,  4932,   363,  6008,   238,   139,\n",
              "              3,     0,   792,  2561,    11,     2]), tensor(1)),\n",
              " (tensor([ 1993,  1343,     2,   790,    11,   529, 19983,    22, 13110,     2,\n",
              "              2,     2,     2]), tensor(1)),\n",
              " (tensor([   416,     89, 106399,   1441,     22, 137693,  23869]), tensor(1)),\n",
              " (tensor([    0,   104,  1859,     5,   387,    32,  1763,     6,  2035,    11,\n",
              "          35442,   849,     2]), tensor(1)),\n",
              " (tensor([   37,    14,    48,  2528,     5, 28240,  1836,     2,  7905,  2641,\n",
              "             20, 20584]), tensor(1)),\n",
              " (tensor([ 120, 1775,  170, 3185, 7942,  102,   59,   29, 1187,    4,  169]),\n",
              "  tensor(0)),\n",
              " (tensor([   41,   120,   822,   158, 45290,     5,    41,   998,   588,  2143]),\n",
              "  tensor(0)),\n",
              " (tensor([ 294,  635,    7, 8314,    2, 3834,   13,  669,   17, 4203,   13,  137,\n",
              "             2,   14, 1613,    2]), tensor(1)),\n",
              " (tensor([     3,    167,   2791,      6, 381534,    328,     25,   3621,     13,\n",
              "          128508,    422,   9256,   2490,      2,      2,      2,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 6114,    22,     0, 12970, 10723, 57849]), tensor(0)),\n",
              " (tensor([    13,      0,  14007,    453,     31,     95,  16265,      2,      7,\n",
              "            1132,   2395,     43,  11924, 167849,      2]), tensor(1)),\n",
              " (tensor([18265, 35933,    91, 29153]), tensor(0)),\n",
              " (tensor([16036,    41,   405,  4388,     5,    36,   151,     7, 10254]),\n",
              "  tensor(0)),\n",
              " (tensor([   0, 8555,   21,   20,  188,  188,  188,  188,  188,  188]),\n",
              "  tensor(0)),\n",
              " (tensor([ 457,   12,    7, 1971, 1836,   14, 1814, 1362,   10,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 2546,  1620,     5,     7,  2348, 71109, 71753,  1123,    11,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([     0,  24949,   5107,     48,     15,      4,   1716,      6,  79637,\n",
              "               2,     20,     15,    117,      7,   1470,  10031,      3, 274247,\n",
              "               5,      2]), tensor(0)),\n",
              " (tensor([   49,  1734,   770,    22,     0,  2248,    14,  1227,   415,  3424,\n",
              "              4,    64,    58, 33345,   142,    89,  5743,     2]), tensor(1)),\n",
              " (tensor([6904,  460, 3803,   10,  328,    3,    2,    2]), tensor(1)),\n",
              " (tensor([5993,   60, 1741,   25, 7692,   32, 4691,   10, 1150,    3, 7516,    6,\n",
              "             0,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([ 117, 2641,    7, 3986,  974, 1071,    2,    2,    2,   34,   36,  690,\n",
              "            23,   22,  338,   36]), tensor(0)),\n",
              " (tensor([  192, 55901,    22,   188,   188,   188,    57]), tensor(0)),\n",
              " (tensor([    13,    328,      3,   9507,     41,    120,  14863,   1718,  15936,\n",
              "            1832,  14663,      0,  55901, 141739]), tensor(0)),\n",
              " (tensor([3561,    4,  275,  162,  213,    2]), tensor(0)),\n",
              " (tensor([  628,   164,  1708, 21983,  9156,  2577,     2]), tensor(1)),\n",
              " (tensor([ 15729,     84,   1078,   4560,  75478,  25663,     11, 348505,   4851,\n",
              "               2]), tensor(0)),\n",
              " (tensor([ 11569, 253154,    120,   7539,      7,   1620,    515,    208,     60,\n",
              "              13,      7,   8416,    610,     17,      7,   2132,    610,    715,\n",
              "               2,    873,    120,   4322,     75,   2427,   9189,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([19130,   435,    10,   232, 10658,  6143,     4, 11297,  1957,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   58,    79,   881,    75,     5,  6416, 49031,    22,     0,  7931,\n",
              "           1581,   411,   179,   317, 10809,  5441,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([35690,  6844,    17, 17729,     2]), tensor(0)),\n",
              " (tensor([2167,   74, 1510, 7516,    6, 7692, 1468,   10, 3649,   49,    7, 2377,\n",
              "          1780,   19,  109,   19, 3575,    2]), tensor(1)),\n",
              " (tensor([   41, 15475,     4,  1679,     0,  4471,  1490,     5,  9225,  6324]),\n",
              "  tensor(1)),\n",
              " (tensor([20683,     5,   411, 38610,     5,  8782,  1832,   100,  2948,  3082]),\n",
              "  tensor(0)),\n",
              " (tensor([   656,  49870,  43909,    114, 152421,     92,      3,   9601,    188,\n",
              "              45,  62113,      0,   1376,   2053,   2977,     49,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([    47,    117, 123797,    484,      6,    192,   3825,      5,  14663,\n",
              "           15095,     25,    425,    188,    188,    188,    188]), tensor(1)),\n",
              " (tensor([ 2136,   390,  1508, 13483,  5228,  4066,  6843,   750,  2937,    11,\n",
              "              0,  3585,     2]), tensor(1)),\n",
              " (tensor([  378,   188,   188,   804,     3,    81,  2857,    61,    41,   822,\n",
              "             12, 97445, 10212, 11895,     2,   188]), tensor(1)),\n",
              " (tensor([  192, 17095,  5654,    32,  4471,    17,     0,   484,     3,     7,\n",
              "           4119, 26037,  1490,     2,   100]), tensor(1)),\n",
              " (tensor([ 2773,  8779,   436,    13, 61355,   172,   145,     6,  7217,     2,\n",
              "              7, 22822,   743,    98,   155,  1481,   595,     4,    88,    44]),\n",
              "  tensor(1)),\n",
              " (tensor([  81,   86,  578,   37,   11,  114, 2940, 4034, 1441,   25]),\n",
              "  tensor(1)),\n",
              " (tensor([ 192, 7636,  551, 9862,  378,    2,    2,    2]), tensor(0)),\n",
              " (tensor([  102,     0,  5613,    14,  1797,    17,    69,   188,  1067,    17,\n",
              "             29,  2906, 12294,  3317,     4,  2395,     2,  4923,    48,   122,\n",
              "              5,    36,     0,   182,     2]), tensor(0)),\n",
              " (tensor([    41,  21128,  43728,      7,  89669,     10,     36,    433,    285,\n",
              "              15,      4, 164272,  43728,     34,   7731,  36011,     20]),\n",
              "  tensor(0)),\n",
              " (tensor([  311,   934,    25,    29,  3853,     3, 10897,    22,     0,  1980,\n",
              "              6, 30344,     6,   431,    25,    20,     2]), tensor(1)),\n",
              " (tensor([10163]), tensor(1)),\n",
              " (tensor([  614,  2362,  1004,  1042,  2415,  9156,    10,   628,   164,  1708,\n",
              "          21983,     2]), tensor(0)),\n",
              " (tensor([  142,   941,  1391,  2508,   767,    49, 16027,  6301,   142,   941,\n",
              "           1391,  2508,   256,    49,   643,     3,  6990]), tensor(1)),\n",
              " (tensor([   83,    41, 43728,   777,   701,   490,    89, 65387, 46768,   757,\n",
              "             63,    14,    84,   824,   409,  5645,    89,     2]), tensor(1)),\n",
              " (tensor([ 8056,  4215,  2821,   285,    12,    41,   408,     4,    30, 38335]),\n",
              "  tensor(0)),\n",
              " (tensor([  2485,      5,  28201,  12763,   9936,      5,    808, 177578,    561,\n",
              "               0,   3468,      3,    978,   1454,      2,      2,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([    41,   5572,      7,    974,      2, 102222,    314,  13576,  48264,\n",
              "              11]), tensor(0)),\n",
              " (tensor([  914,     7,  1816, 11522,  4385, 14663,  9225,     3,  9811]),\n",
              "  tensor(0)),\n",
              " (tensor([149086,      5,     26,    702,     32,   1262,      6,      0,   1933,\n",
              "               3,     26,   5508,    702,     71,    964,    652,     71, 192937,\n",
              "               2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([  11, 1579,    6, 6364,  445,    4, 2788,    3, 1641,  114,   41, 1993,\n",
              "          4657,    4,  190,    7,  173, 2296, 1470,    2,    2]), tensor(1)),\n",
              " (tensor([  409,     2, 14315,  2426,   268,   639]), tensor(0)),\n",
              " (tensor([   41,    83,  1544,  3334,     4,  4747,   192, 61766, 48271,  3985,\n",
              "             81,   135,     4,     0,   156,     3,     0,  1828]), tensor(0)),\n",
              " (tensor([2414,   14,    7,  123,   17,    7, 3838,   78, 1730,   21,    7, 6498,\n",
              "           110,  109,  682, 1268,    0, 2294,  331,    2]), tensor(0)),\n",
              " (tensor([   628,     89,     89,     89,     89,    484,     14,   2925,     19,\n",
              "          224917,     32,    154,      4,   9347,      2]), tensor(1)),\n",
              " (tensor([ 1993,   733,   192,    36, 32939,   296,  4034,    43, 16286,   285,\n",
              "              2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([2772,   41,  835,   20]), tensor(0)),\n",
              " (tensor([ 2368,   197,    41,  1593,  1122,     4,     0,  6842,     3,     0,\n",
              "            220, 22183,    89,   180,   101,     4, 12565,   192,   163,   258,\n",
              "              2,  3832]), tensor(0)),\n",
              " (tensor([   81,   120,   405, 71497,  8266,     2]), tensor(0)),\n",
              " (tensor([5182,    6,    0, 2818,  111,   41, 9369,   66,   37,  766,  105, 1497,\n",
              "           307,    2, 2283, 5690,   13,  218, 9804,    5,  248, 3457,    2,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 2660,   101,     5,   615,    22, 28811,   188,   188]), tensor(0)),\n",
              " (tensor([    31,    719,  25283, 134595,  33222,  12456,     14,    719,  48881,\n",
              "           27089]), tensor(0)),\n",
              " (tensor([ 628,    5, 9239, 2421, 3999,    2]), tensor(1)),\n",
              " (tensor([ 1833, 24157, 54451, 13904,  1303,  2492, 14899,  1007,   719,  4769,\n",
              "             11,   549,  1465,    21, 10891,     2,     2]), tensor(0)),\n",
              " (tensor([17103, 44264,  1585,    14,    29,  4345, 10894,     5,     0,    96,\n",
              "           2905,   661,    40,    17,     7, 17103, 44264,  1062,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 3832, 17245,    53,   835,    81]), tensor(0)),\n",
              " (tensor([11338,   244,   220,  3158,     3,  3839,  5367,     2,     2,   569,\n",
              "           1960]), tensor(0)),\n",
              " (tensor([  114, 42475,     6,   142,  1090,  1274,  7154,   423,    17,  1475,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  100,     2,     2,     2,   111,    32,     0, 16557, 20727,     5,\n",
              "           4471,  1490,   188,   188,   188,   188,   298,   973]), tensor(1)),\n",
              " (tensor([   13,     0,   234,     3, 40715,  2427, 20689,  1908, 32523,  3310,\n",
              "              2]), tensor(0)),\n",
              " (tensor([33222, 15868,     4,     0,  3403,  2011,     5,     0,   219, 10322,\n",
              "             21,     0,   319,  1938,     0, 27329,  2637,    13,    64,   187,\n",
              "              2]), tensor(0)),\n",
              " (tensor([48495,    52,   965,    30,  1096,   117, 34849, 48495,     2,     5,\n",
              "             81, 20886,   101]), tensor(0)),\n",
              " (tensor([   41,  5917,  3029,    66,     3,     0,  3031,     5, 15998,   192,\n",
              "           4184,    31,    51, 10141]), tensor(0)),\n",
              " (tensor([  34,   63,   32,  219, 3193,    4,  733,   12,  178,   15,    7, 1340,\n",
              "          1061,    5, 1805,   21, 2051,    2]), tensor(1)),\n",
              " (tensor([    7,  5348,     3,    55, 43940,    11,   719, 17191,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([    41,   4284,    197,    662,      4,     33,     64,      0,   2153,\n",
              "               6, 116202,     88,  10894,     13,  60173,  15772,     89,     24]),\n",
              "  tensor(0)),\n",
              " (tensor([11955,   838,  2485,    19,   720,    19,    41,   169,    63,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([  222,     4, 30656,     4,   336]), tensor(0)),\n",
              " (tensor([1431,  864,   60,    6,   49,  201,  265,    3,   84,  926, 1196,    2,\n",
              "             2,    2,    2]), tensor(1)),\n",
              " (tensor([78550, 10230,  1960,   300,   431,     6,  4698,     3,  7350,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 300,  192, 7463,  998,  117,    7, 5775,  188,  188,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([   41, 46768,   151,  2715,  4841,    41,   120,  2715,   134,   117,\n",
              "          87091,     5,   127,     0,  4512,   852,   138,     5,  1402, 15998,\n",
              "             10,     0, 22925]), tensor(0)),\n",
              " (tensor([    0, 57850,     3,     0,  2421,  1930,     2,     2,   169,    20,\n",
              "          21702,     0,   179,    81,     2]), tensor(0)),\n",
              " (tensor([134593,  12741,  15904,      4,   3117,   1851,      6,  98857, 176655,\n",
              "              11,   2106,      2]), tensor(1)),\n",
              " (tensor([   86,    53,    33,     7,   198,   538,    10,     0,   182,   940,\n",
              "            633,  2395,   188,    41,   303,    29, 32939,  1134,    46,     7,\n",
              "            490,  1960,    89,   156,    37,  5429]), tensor(1)),\n",
              " (tensor([   22,   161,     7,  7329,     3, 65387,     5,  4575,   113,     0,\n",
              "           1470, 14582]), tensor(1)),\n",
              " (tensor([    83,     81,    269,    222,      4,  23703,    166,     74,     77,\n",
              "          140706,  34855,     81,    189,    346,     12,  28512,    973,    182,\n",
              "            1888,      2]), tensor(1)),\n",
              " (tensor([19715,   777,   903,     2]), tensor(0)),\n",
              " (tensor([17245,     3, 17527,   790,  3345, 39183,   274,     2,   232, 37789,\n",
              "              3,  1137,     4,   159,   392, 35358,   122,     2]), tensor(0)),\n",
              " (tensor([   41,   977,   433,     7,  6242,     5, 13943,  6458, 14315,  7931,\n",
              "            622,   192,  4814,  6597,  3634,     5,     2]), tensor(0)),\n",
              " (tensor([  759,   256,     6,  3913,  1523,  1763,     7,  1523,  4469,  2143,\n",
              "              7,  3913,     6, 21476,  1643,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([    2, 15729,    84,  1078,  2208,     4,  1878,   520, 11945,     3,\n",
              "           1156,     2]), tensor(0)),\n",
              " (tensor([  418,   666,   256,     6, 32939,  1523,  1211,     6,   325,   815,\n",
              "            322, 51414,  2035,   172,  4851, 34408,    11,     2]), tensor(1)),\n",
              " (tensor([ 7942,    63, 10678,  1749,   119,    81,    33,     4,  1361,   392,\n",
              "           1095,    59,     0,   179,    41,   405,    81,  9225,   192,   311,\n",
              "            188]), tensor(0)),\n",
              " (tensor([ 1707,   122, 10665,   777,   535,  3692,   270,    12,  6090,   907,\n",
              "            308,  2900,     2,     2]), tensor(0)),\n",
              " (tensor([  170,  6412,  5281,  1340, 16639,  6292,    44,   261,   166,   135,\n",
              "              2,   102,  1726,    14,    50,     2]), tensor(1)),\n",
              " (tensor([35404,     2,     0,  2768,  2253, 26103,     2,    21,     2,  1957]),\n",
              "  tensor(0)),\n",
              " (tensor([1496,   34, 1890,   21,    7,    2]), tensor(0)),\n",
              " (tensor([6008,  238,   13, 8816,  583,  934,   25, 4035, 3345,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 1906,    12,    63,    32,    84, 10894,    19,    84,    48,    15,\n",
              "           4799,  1038,     0,  7530,   211,     2,   652,   484,  4154,     5,\n",
              "            800,   484,  2347,    13,  1500,     2]), tensor(1)),\n",
              " (tensor([   45,  9427,  2493,     6, 13053,    19,   361,  2583,  1616,    82,\n",
              "            108,  4065,  1763,     2]), tensor(1)),\n",
              " (tensor([ 12556,  17123,     89, 109013,     11,   1779,   8854,     11,  10286,\n",
              "             407,   1279,      2]), tensor(0)),\n",
              " (tensor([  143,   114,    41,   346, 73048]), tensor(0)),\n",
              " (tensor([22964,  9823,  5869,     4,   607,     6,     7,  1352,     5,  1894,\n",
              "           4005,     6,   545,     6,  2454,     2]), tensor(1)),\n",
              " (tensor([   50,   342,  1160,    13,   134,     7,  8547,    11, 15209, 15209,\n",
              "           6822,    50,   342,  1160,     2]), tensor(0)),\n",
              " (tensor([  188,    50,  7313,  3950, 39505, 21925,  7006, 55976, 11979,  1007,\n",
              "            719,  4769,     2,     2]), tensor(0)),\n",
              " (tensor([ 4336, 59533,     0, 49922,     3,   514,  6490,     2,     2,     2,\n",
              "              2]), tensor(0)),\n",
              " (tensor([ 1004,  2415,  9156,    10,   164,  1708, 21983,     2]), tensor(1)),\n",
              " (tensor([  41,  913,   36,   29,  140,   34,   41,   33,  213,   38,   33,  724,\n",
              "             6,    0,  178,  161,    6,    0, 1357,  522,    5,  161,    6,    2,\n",
              "             2,    2,    2]), tensor(1)),\n",
              " (tensor([ 89669,     10,   1357,  13285,      2,      2,    409,    249,      5,\n",
              "              84,    394,      4,    169, 131479,      4,    155,     38,     33,\n",
              "              84,   1878,      2,     86,     81,   8169,    400,    188]),\n",
              "  tensor(1)),\n",
              " (tensor([ 1186,  2824,    49, 21365,   306,   249,     2]), tensor(1)),\n",
              " (tensor([ 3092,  1011,     4, 31921,  3523,  1267,    59,  8547, 16790,     2,\n",
              "           1957]), tensor(1)),\n",
              " (tensor([15750,   142,    32,  3463,     7,  5553, 97646,  1734,     6,   193,\n",
              "          15750,     2]), tensor(1)),\n",
              " (tensor([  111,    32,     0,  1920,   188,     0,  5879,   188,     0,  4471,\n",
              "           1490,   188,   197,   326,    81,   253,   130,     3,    12, 35404,\n",
              "           4841,    61,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([11011,   660,     4,   733,    39,    32,    56, 20422,     5,    39,\n",
              "          12313,  4747, 71444,     2,  9165,     0, 12072,     3,  3090,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([   41,    33,     7,  1537, 21717,   232,    56,  5201,     6,     0,\n",
              "            341,   147,     2,   169,   392, 15576,   248,   187,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   61,    18, 15733, 95308,     2,     2,     2,   119,    18,  1895,\n",
              "             12,   838,     2,     2, 43895,    18,   402,  6690,     4,  2284,\n",
              "             18,     3,   402,     4,    52]), tensor(1)),\n",
              " (tensor([  120,    40,     7,  1058,   436,   113,    41,   804,   192, 13748,\n",
              "             15,   767,     2,   188,   188,   188,   188,  3588,  3034,    14,\n",
              "          15917,     2,   188,   188]), tensor(0)),\n",
              " (tensor([14317,    38, 10857,    17,  4197,    13, 27201, 34860,  1890,   786,\n",
              "           4362,     2,  1957]), tensor(0)),\n",
              " (tensor([  323,  1329,     2,  4138,  2816,  2968,  1106,  1441,    49,  2486,\n",
              "          11895,     2]), tensor(1)),\n",
              " (tensor([ 3558,   514, 10322,  1894, 43157,  2719,     7,  5817,     2,     2,\n",
              "              2,     2]), tensor(0)),\n",
              " (tensor([1544, 1726,  269,   12, 2662, 4076,  117, 3763, 4159,   61,   18, 1666,\n",
              "          5856,  188,    0, 2333,  134,    2,    2,    2,   41, 1403,  117, 2662,\n",
              "             2]), tensor(0)),\n",
              " (tensor([    11, 104349,   6599,   6226,   2378,     11,  50944,      2,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([36143,   274, 52861,   583, 23869,     2]), tensor(1)),\n",
              " (tensor([  197,  2085,     0,    69,     6, 13053, 19496, 42285,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([21983,  5492,  4877, 21995,  8066,   281,  1278, 29747,     2,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([2005,    5, 6292,  188,  188,    2]), tensor(1)),\n",
              " (tensor([2745,    2,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([    7,  3034,     4,     0,  3377,   188,  6844,    17, 17729,   188,\n",
              "              7,  3034,     4,     0,  3377,   188,   188,   188,   188,   188,\n",
              "            188,   188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([   20,   149, 10556,     6,    12,    41,    43,   332,   253,   192,\n",
              "          14798,   378,   197,    31,    20,    51,   232,   265,   411,   188,\n",
              "            188]), tensor(0)),\n",
              " (tensor([7313,  197,    4, 4307,   25,    7,   81, 4366, 8266,    2,    2,    2,\n",
              "           200,    4,  301,    2,    2]), tensor(0)),\n",
              " (tensor([ 1715,   962, 13113,     3,   392,   214,    49, 10063,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([13927, 44690,    21,  1106,  8707,  4851,     2,     2]), tensor(1)),\n",
              " (tensor([ 73048,      2,      2,      2,  14663,    120,      7,   5142,  10031,\n",
              "          196551]), tensor(0)),\n",
              " (tensor([ 1465,    59,   162,   993,   875, 13427,  6794,  3251,   865,  1357,\n",
              "            522,    11,   549,    79,     2,     2,     2,    11,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 2255,    33,    16,     7,  5176, 26120, 24166,  2005,    15,  1098,\n",
              "             21,  6731,  1899,    49,     0, 71168,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  332,   804,    41,    94,    33,    12,   181,  2905,  4798, 13286,\n",
              "           3045,  4005,     2, 73048]), tensor(0)),\n",
              " (tensor([ 3202,     2, 92367,   469,   176,  1751,  4158,  4866,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 4779,   518, 62446,     5,  5440,     2,     2,     2,     2, 23703,\n",
              "           1402]), tensor(0)),\n",
              " (tensor([ 1316,   381, 14362,    22,     0,   726,   111,     7,   463,   213,\n",
              "             14,   134,  2713,    49, 11854,     2,  1957]), tensor(1)),\n",
              " (tensor([   37,    14,    59,     4,    30,     7,  1211, 25495, 50186,  1835,\n",
              "              2]), tensor(0)),\n",
              " (tensor([60259, 15475,   192, 29598,   197,   913,    41,  2837,     4,  3981,\n",
              "              7,   122,   296,   403]), tensor(0)),\n",
              " (tensor([  14, 1267, 1523, 1763,   98, 1643, 9939,   11,   29,  959,   92,  129,\n",
              "          1523, 4469,   13,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([  143,    16,  2699,     2,   192,  5591,    15,     7, 19590,     2,\n",
              "          16912,  2713,     2,  3037,    34,   332,  3607,    59,    20,     2,\n",
              "              0,  1763,    15,  8286,     2]), tensor(1)),\n",
              " (tensor([    14, 171785,   2605,   3052,    781,    720,      0,    597,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([7698,   32,   81, 4862,   88,   81,  408,  749, 2010,   41,   86,  580,\n",
              "            29, 9214,   83,   81,  408,  285,    4]), tensor(0)),\n",
              " (tensor([   77,   353,  5574,     3,   562,   161,    25,   614, 18873,   386,\n",
              "            484,    38,    14,    52,   500,     0,  2382,  4564,   248,   114,\n",
              "              2,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([    0,   232,  1277,   248,     6,   669,     3,   285, 10857,     5,\n",
              "             83,    41,  1821,     6,    79,    20,    51,   285,   317,     2,\n",
              "            188,   188,   188,   188]), tensor(1)),\n",
              " (tensor([1509,  316, 6830, 3470, 6313,   57,   21,    0,  986,  428, 1957, 6867,\n",
              "             2]), tensor(1)),\n",
              " (tensor([21784,     0,   167,    17,     0,    50,     6,     4,  3298,    10,\n",
              "            581,     2,     2]), tensor(0)),\n",
              " (tensor([22423,   837, 11647,   142, 17729,     5,   465, 11647,  9287,   813,\n",
              "              2,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 1576,   136,  8911,    95, 24952,  6904,   726, 12006, 14046,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([   41,   149,   253,     0,   389,     3,     7,  5178,  8439,   117,\n",
              "              0, 10031,    20,  6194,  8439]), tensor(0)),\n",
              " (tensor([  142,  2786,  1468,    10,  1510,  5508,   787,     6,   142,     6,\n",
              "             32,  4185, 14358,     2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([19394,  5400,  2258,  5509,     3, 13053,    53,   149,   408,   490,\n",
              "            736,     2]), tensor(1)),\n",
              " (tensor([  6479,    439,   2368,  14364,      3,   3406,  14343,    871,     73,\n",
              "            2412,     59,    654,    117,     12,     46,     81,     32,      7,\n",
              "             654,    117,     12,    188, 154265]), tensor(0)),\n",
              " (tensor([   83,    81,   661,   269,    81,   797,    66,     3,  5497,     6,\n",
              "            214,    12,  4313,    12,    31,    84,  1675,    34,  3433,     7,\n",
              "           1523,  1211, 16682]), tensor(0)),\n",
              " (tensor([ 2546,  1620,   374,  1101,   510, 17260,    22,  5724,    21,     2,\n",
              "              2,     2,     0,  2546, 26456,  1975,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  78,  116,  706,   12, 8054,   35,   36,    2,   57]), tensor(1)),\n",
              " (tensor([ 100,   81,   33,    7,   50, 4034,   12,   86, 1157, 2695,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([    83,      7, 116853,     15,      7,   1308,    127,     12,   1606,\n",
              "            3080,     30,  24204,    188,    188,    188,    188]), tensor(0)),\n",
              " (tensor([  41, 5572,    7,  974,   25,    2,  580,    3, 4809, 7265,    2,  790,\n",
              "          4722]), tensor(0)),\n",
              " (tensor([14815,  9540,   841,     4,  3333,  3608,   142,     7,   129,     3,\n",
              "           1102, 14815,  9540,  3973,     0,  5918,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 142, 3360,    4, 2005,  596,    2]), tensor(1)),\n",
              " (tensor([ 3201,  6903,  8547, 16535,  7721, 71353,   191,  3082,  2621, 16982,\n",
              "           3423, 16535,     2,     2]), tensor(0)),\n",
              " (tensor([    83,     81,     33,      0,     79,    606,    188,    188,     24,\n",
              "               0,    993,    281,     59, 162423,  11277,     10,  30817,     14,\n",
              "            2708,   4571,      2]), tensor(0)),\n",
              " (tensor([  2822,   1907,   6920,     22,   3814,   1678,   2696,    274,  23230,\n",
              "           25047,   3814,    293,     13, 157417,   3345]), tensor(1)),\n",
              " (tensor([   0,  167, 2791,  388,   13,   33,  645,    4, 1712,    3,   81,   11,\n",
              "             5,   81, 1485,    2,   57,    0,  781, 5775,    2]), tensor(0)),\n",
              " (tensor([  1984,  10574,    100,   4434,   6479,    189,    307,    409,     90,\n",
              "           10574,   2615,    140,     69,    835, 297614,    320,     21,      7,\n",
              "            8036]), tensor(0)),\n",
              " (tensor([ 690,  219,   10,    7, 1922, 2421,    2]), tensor(1)),\n",
              " (tensor([14663,  6332,    10,   192, 11845,    76,   364,    34,   881,   192,\n",
              "          13326,  3447,   185,   188,   188,   188,   188,   188,   188,   188,\n",
              "            188,   188,   188,   188,   188,   188,   188,   188,   188,   188,\n",
              "            188,   188,   188,   188,   188,   188,   188,   188,   188,   188,\n",
              "            188,   188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 5281,     4, 29506,   392, 36944,    34,     7, 36628,    14,     7,\n",
              "           3132,  4034, 28760,  7777,   352,     2]), tensor(0)),\n",
              " (tensor([  260,     0,   875,  1500,     3,  3215,  7654,     5,     0,   460,\n",
              "              3,     0,  3608,  9794,  1544,  1726,     3,     0,  1005, 33601,\n",
              "            188,   120,   285,   188, 15917]), tensor(0)),\n",
              " (tensor([56302,    81, 58544,   733,     6,     0,  4430, 56302, 28058,     2,\n",
              "              2,     2,     2]), tensor(0)),\n",
              " (tensor([    0,  6412,     3, 43339, 21714,     2]), tensor(1)),\n",
              " (tensor([  117,   333,  1606,    81,   439,  3162,   392, 25495,   135,   837,\n",
              "           9225,    22,   192,   808,   837,  5546,   392,  3017,    89,  8782,\n",
              "            117,     7,   314,    62,   167,    89,  2274, 20832,    60]),\n",
              "  tensor(0)),\n",
              " (tensor([   48,   122,    41,   303,  1318,     4,   307,    10,     0,  5006,\n",
              "            807,     5,  5182,    63,   621,   310,    10,   591, 10913,   285,\n",
              "             74,   120,     4,   169,    13,     7,  2377,   188,   188,   188,\n",
              "            188,   188,   188]), tensor(0)),\n",
              " (tensor([ 1515,  2948,  1515, 22900,    75,     0,  6579, 26783, 18648,     3,\n",
              "           1336, 10362,     3,    64,    34,  1357,   522,     6,   192,  2955]),\n",
              "  tensor(0)),\n",
              " (tensor([61234,    37,    82,  5847,   535,  3216,    66,     3,  1655,    41,\n",
              "            107,   320,  3814,   169,   192, 25495,  5311]), tensor(0)),\n",
              " (tensor([    6,     0,  1374,     3,  4975, 11139,    13,     0,  1611,   307,\n",
              "           2122,   307,     2,     2]), tensor(1)),\n",
              " (tensor([   2, 5180, 4175,  256,    6, 2329,  325, 9214, 3134, 2005,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 3028,     0,     2,     5, 10638, 21983,     2,     2]), tensor(0)),\n",
              " (tensor([  628, 18161,   352,   869,     4,     2,  1957]), tensor(1)),\n",
              " (tensor([   61, 17575, 23381,    81,     6, 31870,    22, 38018,   188,   188,\n",
              "            188,   188,     2]), tensor(0)),\n",
              " (tensor([  219, 69945,   978,   960,     5,  2981,     2,   799,   192,  1374,\n",
              "          27089,  4973,    14,   719, 48881,   103,   442,    18, 14544,     2,\n",
              "           3222,  3222,     2, 27089,    14,     7,   903]), tensor(0)),\n",
              " (tensor([    0,  1836,     2,     7,  2528, 17876,     3,  7650,   127,   936,\n",
              "              2]), tensor(0)),\n",
              " (tensor([40257,  2077,   359,  1395,    14,     2,     0,    85,    54, 12565,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  41,  253,   71, 5116,   22, 5121, 8263]), tensor(0)),\n",
              " (tensor([ 38610,    113,   1881,    192, 118399,    218,    285,     22,    132,\n",
              "            2069,     46,   1881,     13,      0,  10911,     10]), tensor(0)),\n",
              " (tensor([  1845,   3708,  24866,  16566,  36061,    321,    161,    897,   2069,\n",
              "           47246, 104377,   9667,  15880,     11,    549,      2,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([  176,     0, 11035,    12,   591,  3732,     0,  1536,    11,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([1896,  153,    3,    0,  447,  120, 3838,    2,  824, 1402,   14, 4862,\n",
              "             2]), tensor(1)),\n",
              " (tensor([  1606,    418,   1262,      6,   5553,   1734,      3, 133786,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([  314,   157,  2119,     4,    30, 10075,     6, 31031,   490,  2395,\n",
              "              2]), tensor(1)),\n",
              " (tensor([60259,  1211,  2232,   188,   188]), tensor(0)),\n",
              " (tensor([  87,  406,  666, 1391,    6,  259,  231, 1376,  436, 1957,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([   41,  4355,     4,   253,   197,    12,    54,    36,   938,     0,\n",
              "            223,     3,   586, 10894,   135, 19427]), tensor(0)),\n",
              " (tensor([5693,  490, 1189,    4,  483,  707,   49, 3844, 5167,    2, 1957]),\n",
              "  tensor(0)),\n",
              " (tensor([   41,   189,  4647,   824,   100,    16, 16621,    71,  1300,  2995,\n",
              "            137,     6,    71]), tensor(0)),\n",
              " (tensor([   32,     0,  1088,  5472,   134,   116,     4,  1314, 20497,     6,\n",
              "           4794,   914,    56,  4747,    73,   219,   188,     2]), tensor(0)),\n",
              " (tensor([7942,  378,    2,  130, 2194, 1734, 2011,   10,   61,   37, 3371,  188]),\n",
              "  tensor(0)),\n",
              " (tensor([ 5685,  1892,  5327,  7024,    49,   989,   331,  1470, 57419,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([     0,    937,     43, 164272,     95,     64,    188,    188]),\n",
              "  tensor(0)),\n",
              " (tensor([10729, 14397,     2,  7357,     2]), tensor(0)),\n",
              " (tensor([ 1894,    11,  1893,   586, 17527, 47517,   586,   196]), tensor(1)),\n",
              " (tensor([   700,      0,   4647, 264130,      2]), tensor(0)),\n",
              " (tensor([ 7940, 43171, 12605,  1393,   559,    94, 41979,  1496,   682,  1362,\n",
              "              7,   594,   179,     3]), tensor(0)),\n",
              " (tensor([  36, 4458,  162, 1391, 1632, 3677,    2,    2]), tensor(1)),\n",
              " (tensor([4184,  565, 1507,  100, 1211,  248,  114,   57]), tensor(0)),\n",
              " (tensor([ 11035,      6,   1857,  34268,  12122,   1585,    934,    124,   1546,\n",
              "           10306,      4,   9490,  21068,      2,      2,      2,     11,  37171,\n",
              "          140511,      2]), tensor(0)),\n",
              " (tensor([  149,     5,  1930,  7203,    10,     0,  1470, 30559,    22, 23029,\n",
              "              5, 48545,  1869,    66,    13,     0,  1949,     3,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 2322,     0,    85,     3,  3828,  6886,   790,  1562,    60,     5,\n",
              "             75,     0, 26865,   620,     2]), tensor(0)),\n",
              " (tensor([15919,     2,  1042,  2376,   855, 19904,     4,  5648,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([   6,    0, 1005, 2180,    5,  486,  150,   94,   33, 3163,   13,    0,\n",
              "          4836, 9197,  296,   20, 7940,    2]), tensor(0)),\n",
              " (tensor([  53,   32,  518, 2061, 4564,   66,  187,    6,   34,    0,   91,  484,\n",
              "            81,  189, 1716,   10,   14,    2]), tensor(1)),\n",
              " (tensor([ 1147, 37720,   149,    89,  1930,   394,    41, 23029,    89, 48545,\n",
              "             10,     0,  1467,  1470, 30559]), tensor(1)),\n",
              " (tensor([   807,    137,     37,     58,   1129, 109494,  40132,     12,     94,\n",
              "            2695]), tensor(0)),\n",
              " (tensor([134445,    142,   7019,    198,     49,  75694,   1933,      6,    624,\n",
              "              11,      2,      2]), tensor(1)),\n",
              " (tensor([13112,     4,   511,   162,  1032,   204,  1596, 10894,     2,    53,\n",
              "            408,     4,   242,   137,     4,     0,   581,     2]), tensor(0)),\n",
              " (tensor([   56,    73,  1855, 24235,  5327,    19,   628, 19904, 22295,    13,\n",
              "            148,   203,     2]), tensor(1)),\n",
              " (tensor([   37,    14, 10854,    67,  4913,  7940,    71,  6833,    75,   192,\n",
              "           9753,     5, 49953,   192,  1300,   188,   188,   188,   188,   188,\n",
              "            188,     2]), tensor(0)),\n",
              " (tensor([   53,    15,    64,   120,  9674,     5,  1901, 10632,   114,  1402,\n",
              "              6,  6114,  5711]), tensor(0)),\n",
              " (tensor([   41,    15,   719, 48881,    13,     0,   188,   188,   188,   188,\n",
              "            373,     2,     2,     2,     4,   658,   192,  1654,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([  870,   197,   978,  3858, 14187,  1183,     2,     2]), tensor(0)),\n",
              " (tensor([   41,   388,     4,  2065,    60,   192,  4153,   373,     5,     0,\n",
              "          23966,    15,  1383,   192,   511,  3986,   113,    18,   741,   192,\n",
              "            223,     2,   188,   188]), tensor(1)),\n",
              " (tensor([  50,  505,    3, 6067, 1553,    2,    2]), tensor(0)),\n",
              " (tensor([   886,    285,    255,     20,      4,   6479,     69,    773,   6380,\n",
              "               2,    765,    120,  11546, 117677,    347,   2395,    237,    658,\n",
              "            8321, 255063,      2,   6479,   2284,      2]), tensor(1)),\n",
              " (tensor([18255,  5400,  2571,    21,  3649,     2]), tensor(1)),\n",
              " (tensor([ 4885,    13, 88505,  5991,    12,   309,   350,  2766,  1376,   256,\n",
              "             21,   194,   340,     2,   194,   340,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  41, 2715,  114,    2,   63,   15,    7,  297,  300,   38, 3037,  150,\n",
              "            52,    2, 2715,   26,  311,  413,    2]), tensor(0)),\n",
              " (tensor([   232, 233371, 398587,   5178,  12041,    796,    930,   3947,   2404,\n",
              "            9428,   9279,  11243,   1063,      2]), tensor(0)),\n",
              " (tensor([  14,   20,   79,    4, 6114,  114,  188,    2]), tensor(0)),\n",
              " (tensor([ 1616,    82,    49,  4065,  3084,   361,   149,  7207,    17,   136,\n",
              "              0,  2349,     3,     0, 12950, 18097,  1556,     2,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 11083, 381085,     37,   6675,     14,    175,     14,      0,     48,\n",
              "              59,      0,  25893,     61,     53,    700,      6,    863,      5,\n",
              "              12,     48,     79,     20,  21202,      2,  89669,      2,  10574,\n",
              "            2641,   3205, 333193]), tensor(0)),\n",
              " (tensor([  102, 12895,  6008,     3,  1248,   238,    13,     2]), tensor(1)),\n",
              " (tensor([  104,    10,  2705,   189,  7037,   720,    46,  2357,    21, 30817,\n",
              "              2,     2]), tensor(0)),\n",
              " (tensor([225915,    152,    164,   3733,   3298,     10, 362335,   2091,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([     0,    331,     14,     13, 317389,     83,  22861,     14,    484,\n",
              "               2]), tensor(0)),\n",
              " (tensor([ 155,   55, 1490,   32,   13,  484]), tensor(1)),\n",
              " (tensor([  41, 5020,   81,   86,  203, 1355,  388,   60,    6, 6255]),\n",
              "  tensor(0)),\n",
              " (tensor([2146,  117,    7,  992,  188,  188]), tensor(1)),\n",
              " (tensor([23373,   563,  8749,    50,   394,     4,   700,  1357,   757,  2666,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  285,   188,  4851,    81,     2,  2747,     2,  4851,    88,    81,\n",
              "            346,   102,  1579,     4,  2663,   188,    18, 10008,     2,  4851,\n",
              "            197,     2,    21,    26,   629,     2]), tensor(0)),\n",
              " (tensor([ 7586,   460,    13, 11224,  6706,    22, 23122, 30559,   576,    11,\n",
              "          18846,   172, 17160,     2,     2]), tensor(1)),\n",
              " (tensor([  83,   81,   35,    7, 1132, 2395,  102,   54,   81,   30,  188]),\n",
              "  tensor(0)),\n",
              " (tensor([   96,     3,    95,   169,    37,   711, 33222,     0,    85,    14,\n",
              "          18824,    17, 51626,    69,  1087]), tensor(0)),\n",
              " (tensor([19734,     6,   993,    95,  1005,  2496,   436,    15,  5473,    40,\n",
              "           5607,   615,     2]), tensor(1)),\n",
              " (tensor([7740, 6344,  232, 6255,    2]), tensor(0)),\n",
              " (tensor([   12, 45520,   813,    25,     0, 51136,     3,  8405,  7191, 12910,\n",
              "            285,     7,   530,     3,   192,   166]), tensor(0)),\n",
              " (tensor([33222,  4574,   404,     6,  2609,  1974,    13,   463,  2591,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([169621,   2586,  12392,   1245,      4,    800,    139,  96238, 140169,\n",
              "            1907,   1960,  13382,     22,  56262,  87044,   3345]), tensor(1)),\n",
              " (tensor([1836,    5, 5236,   21]), tensor(0)),\n",
              " (tensor([   14,    20, 32342,    61,     7,   905,    14,  5327,     5,     7,\n",
              "            964,    14,   218,  1485,     6,     0,   905,     4,   352,  6811,\n",
              "            188]), tensor(1)),\n",
              " (tensor([   12,    15,     0, 10696,   661,  1435]), tensor(0)),\n",
              " (tensor([    2,  9259,   213,  4278,   600,    19,  2520,    14,  1061,    10,\n",
              "          18452,    38,     2,     2,     2,    11,     2]), tensor(0)),\n",
              " (tensor([14919,     5,  6081,  2473,     3,   408,     4,   234,  4065,  1211,\n",
              "              6,  3170,     2,   623,   178,  1285,  5157,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([5551,   81,   10, 1374,    3, 1975, 1765,    2, 1957]), tensor(0)),\n",
              " (tensor([ 378,   36,  588,    2,   88,   81,   33,  130, 1159,  197,  109,  246,\n",
              "            41,   33,   51, 5101,   10,    2,   81, 1543, 1096,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([     2, 109264,   1819,    639,    232,      2,   1343,    418,  13166,\n",
              "          138018,    639,    298,  22189,   1585,  21376,   6579,   8555,    232,\n",
              "               2]), tensor(0)),\n",
              " (tensor([   41,  4284,   197,   246,  1318,    31, 14187,   595,     4,    88,\n",
              "              0,     5,   483,    25,   232,  1605,   232,  9136]), tensor(0)),\n",
              " (tensor([    7,  8165,    12, 14259,  3037,  1616,    82,   108,    48,     3,\n",
              "              0,  1607,   249,     6,    47,   299,     2,    64, 11970,    32,\n",
              "            138,    83,    20,    43,  3981,     0,   182,  1616,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([    0,  1257,    10,     0,   713,     3, 49922,    14,   208,     2,\n",
              "           1087, 13830,    10,    56, 14035,   110,    53, 35753,     0,  2658,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  49,    7, 1523, 1763,    6,   12,  256, 2246,   69, 1130, 8338, 8257,\n",
              "            98,    5, 9733,  165, 3094,    6,  233,    2]), tensor(1)),\n",
              " (tensor([   51,   284,    81,    37, 10556,   772, 41687,    46]), tensor(0)),\n",
              " (tensor([1720,    3,    5,  974,    3,  259,  954, 2382, 4564,   21,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([  804,    20,    15,   185,    64,   122,   373,     2,    15,  1515,\n",
              "           6925,    61,    41, 15810,    20,   188,   188]), tensor(0)),\n",
              " (tensor([    41,    998,    117,    285,    914,      7, 216459,     14,     48,\n",
              "               3,      0,   4030,      3,      0,  20470,      2]), tensor(0)),\n",
              " (tensor([183499,  11606,      2,  43446,     12,   1083,      2]), tensor(0)),\n",
              " (tensor([3652,  310,  484,   13, 1708,  355, 1467,  351, 1028,  409,    7,  147,\n",
              "            49, 3688,  508,  256,  652, 1708,    2]), tensor(1)),\n",
              " (tensor([  188,    50,  7313,  3950, 39505, 21925,  7006, 55976, 11979,  1007,\n",
              "            719,  4769,     2,     2, 33222]), tensor(0)),\n",
              " (tensor([5553, 7289,   14,  861, 3814,  102,   53,   33,  861,   14,    2,    2,\n",
              "             2,    2,    2,    2]), tensor(0)),\n",
              " (tensor([  197,   109,  3318, 14582,    12,    31,     4,  2716,   135,     6,\n",
              "             96,     3,  8038,   188,     0, 21147,   116,   440,     3,     7,\n",
              "           7562]), tensor(1)),\n",
              " (tensor([8301, 2788,  523,    2]), tensor(1)),\n",
              " (tensor([ 6149,   270,  6143,     4,  1243,    36, 23703,  2522,   447,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 6146,     4, 32743,     5,    13,     0, 17210,  5277,  2788,    22,\n",
              "           9302,  1641, 12910,   285,   738,    41,   835,  5205]), tensor(0)),\n",
              " (tensor([19496,     4,  3828,   418,   659,   493,  4252,    12,   273,   120,\n",
              "            197,  5578,   654,     7,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([    6,  1153,     4, 10063,   271,     3, 15083,  1790,     7,  2820,\n",
              "           1496,    11,    48,    12, 17514, 13512,     2]), tensor(0)),\n",
              " (tensor([36102,    34, 11955,    30,  6408,  2407,     2]), tensor(0)),\n",
              " (tensor([    88,     81,    303,      4,   2271,     56,    188,   5228,    192,\n",
              "            1108,    207,    150,    431,      6,      0, 133516,    805]),\n",
              "  tensor(0)),\n",
              " (tensor([ 4215, 80038,   285,   102,    37,   889,    36,   117,    41,   405,\n",
              "              0,  5319,  2258,    83,    41,   203,     0,  1797,   873,    37,\n",
              "            414,   120,   890,    75,     7,  2395]), tensor(1)),\n",
              " (tensor([ 3289, 14522,    17,  6226,   555,     6,     0, 18118,  1458,  2635,\n",
              "              2,     2,     2]), tensor(1)),\n",
              " (tensor([   41,  2215,  1906,   113,    41,   120, 15204,    60,   117,   404,\n",
              "            599,   363,     5, 14663,  4471]), tensor(0)),\n",
              " (tensor([ 1716,   785,  1750,  3960,  4526,    37, 35172,    11]), tensor(0)),\n",
              " (tensor([    2,  5116,     3,  2477,  1098, 30559,  4768,     2]), tensor(1)),\n",
              " (tensor([149086,      5,     26,    702,     32,   1262,      6,      0,   1933,\n",
              "               3,     26,   5508,    702,     71,    964,    652,     71,      2,\n",
              "               2,      2,      2]), tensor(0)),\n",
              " (tensor([   50, 95481, 22922,  7492, 15470,     2,     2]), tensor(0)),\n",
              " (tensor([ 3538,  8898,  1334, 24234,  5281,  1340,     5,  1950,   261,   163,\n",
              "             17,     2]), tensor(1)),\n",
              " (tensor([ 3750, 10284,   115,   381,   190,   153,     6, 11490,  2718,   788,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([ 8738,    41,   346,    34,  7943,  1185, 46768,    33,     7, 10360,\n",
              "          73048,    41,  2417,    37,     7,   306,   517,   363,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 4798,     0,   115,     6,   167,     0,  1225, 10665,     3, 17832,\n",
              "            259,  7302,     2,    10]), tensor(1)),\n",
              " (tensor([ 28281,  17882,    484,   2575, 110974,  42052,    484,  68420,      2,\n",
              "             639,   5629, 387811,   3754,      2,      2]), tensor(0)),\n",
              " (tensor([14528, 32246, 10031,  7144,  2377, 10556,  1370, 10494,  2120,  3232,\n",
              "           6542, 22357,    11,   549,  1465,     2,     2]), tensor(1)),\n",
              " (tensor([  332,     7,   219,  1100,    61,    81,  2933,    60,     4,   161,\n",
              "             89,   174, 13067,    89,     7,   484,  2575,     6,     0,  1255,\n",
              "              2,    22,   338,   185]), tensor(1)),\n",
              " (tensor([ 3558,   514, 10322,  1894, 43157,  2719,     7,  2858,     2,     2,\n",
              "              2,     2,  4851,     2]), tensor(0)),\n",
              " (tensor([   41,    30,    13,    12, 34855]), tensor(0)),\n",
              " (tensor([ 5123,  5387, 20832,    60,   805,   188,   188,   188,   188,   188,\n",
              "            188,  2316,  1439,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([54107,    78,     4, 23703,  1438,  4531,    22,   146,   448,  1437,\n",
              "              2]), tensor(1)),\n",
              " (tensor([4547, 7063,  824, 1779,  736]), tensor(1)),\n",
              " (tensor([   52, 91571,   275,    95,   162,   398,     4,  7019,     0,   198,\n",
              "             59,     0, 11099, 84745,  7876,     2,     0,  2688, 19689, 77315]),\n",
              "  tensor(0)),\n",
              " (tensor([    0,  1207,  2143,    21,    14,    15,  1442,    10,  5627,  1172,\n",
              "           4654,     5, 47865,     0,  1875,     2,     2]), tensor(1)),\n",
              " (tensor([    0, 43182, 24445,  7826,    20,   120,   106,    18,  3029,    66,\n",
              "              2]), tensor(0)),\n",
              " (tensor([14343,  7011,  1343, 72325, 45609, 77983,  2749,   188,   188,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  102,    83,    41,   303,     4, 35690,     0,  7774,   207, 12565,\n",
              "              2,    20,    94,    30, 36317]), tensor(0)),\n",
              " (tensor([48501,   615, 11099,  1620,  4091,     2]), tensor(1)),\n",
              " (tensor([12441, 10857, 64029]), tensor(0)),\n",
              " (tensor([  676,  1311,   767,    19,  1523,  4469,   508,  1643, 10231,  3913,\n",
              "             11,     0,    41,     2,     2,     2,     2,    11,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([73048,    56,    73,  3143,   188,   188,   188,   188,   188,   188]),\n",
              "  tensor(0)),\n",
              " (tensor([    41,  21128,    253,     81,  41449,      0,   1903,   1781,      3,\n",
              "          109354,    938,    137,      0,    929,   1784,      5,   1174,     89,\n",
              "              88,    936,     12,     43,  11346,      0,    273,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([    0,  1655,     3,     0,  2370,    14,     0,   465,     3,    34,\n",
              "              0, 16434,    33,    84,   234,    10,  7151,     5,  3174]),\n",
              "  tensor(0)),\n",
              " (tensor([ 811, 6920,    2, 1957]), tensor(0)),\n",
              " (tensor([ 102,    7, 1716,    0,    3, 7446,  403,  974,   10,    2,  188,  188,\n",
              "           188,  188]), tensor(0)),\n",
              " (tensor([127,  41,  88,  37,   4,  48,   3, 101, 188, 188, 188, 188]),\n",
              "  tensor(0)),\n",
              " (tensor([   18,   175,    20,     7, 31870, 34849]), tensor(0)),\n",
              " (tensor([42254,    63,    32]), tensor(1)),\n",
              " (tensor([    41,    253,     69,     32,  38610,     59, 174278,     64,     74,\n",
              "             378,      2]), tensor(0)),\n",
              " (tensor([  41, 3732,  192,  569,   75,    7, 8837,  569,    0,   68,  122,    2,\n",
              "             2,    2]), tensor(0)),\n",
              " (tensor([   55,  1752, 17658,  1383,     7,  1641,  2788,    75,  1482,  1288,\n",
              "              2]), tensor(1)),\n",
              " (tensor([25408,  1357,  9547,     2,     0,  2291,  1955,   274,   192,  9189,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  5450,      3,    739,  21959,     37, 319171,   5975,   4034,     14,\n",
              "             180,      6,  54748,    123,    449,    342,      2,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([  41,   15, 2837,    4, 2432,    5,   41,  573,    2,    2,    2,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([   50,    13, 10891,  2046,   753,  3129,  1836, 20277, 11192, 77011,\n",
              "            362,  1265,  2564,     2,     2]), tensor(0)),\n",
              " (tensor([ 3952,    20,    14,   781,    25,   150,  1051,     2,  1881,   120,\n",
              "           1095,    13, 38783,  5140,    56, 25284,   100,   192,  4137,    14,\n",
              "          18824,  5140,  3523,  1267,     2,     2,     2]), tensor(0)),\n",
              " (tensor([ 3200,    89,  1185,   331,  1543,  5194,  2522,   445,     4,     7,\n",
              "          56302,  1154,     6,     0, 10790,     3,  4617,    89,  1864,   491,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 353,  813,    2,  404,   82,  881, 5575,    2,  404,   82, 6325,   26,\n",
              "          8508, 4322,    2,  114, 1862,  222,    4,   88,  114,   12,   18,    2,\n",
              "             2,    2,   57]), tensor(0)),\n",
              " (tensor([  192, 10675, 15039,  2706,   813,    14,     2,    37,   813,    31,\n",
              "           5042,   285,   131,     7,   530,     3,   413,   246,    89,     2,\n",
              "              2,     2,     2]), tensor(0)),\n",
              " (tensor([   41,  1906,    81,  7105,     4,  3927,    66,    17,   392,  1856,\n",
              "           1095,   455,    81,   392,   863,    34, 11346,   192,  1853,    17,\n",
              "             81,     2]), tensor(0)),\n",
              " (tensor([4477, 1317,  120,  416,  170, 1211,    2,  120, 7357,   20]),\n",
              "  tensor(0)),\n",
              " (tensor([   50,  7313,  3950, 39505, 36322, 21925,  7006, 55976, 11979,  1007,\n",
              "            719,  4769, 56403,    11,   549,     2,     2]), tensor(0)),\n",
              " (tensor([ 114,   16,   64,   37,  767,    5,   84,   48, 1726, 5376]),\n",
              "  tensor(0)),\n",
              " (tensor([ 4146,  1147,   100,   181,    12,    20,   186,   285,  5491,  2090,\n",
              "              2,   114,    41,  3162,     5,  1252,     6, 12142,     5,     6,\n",
              "              0,  2237,     2]), tensor(0)),\n",
              " (tensor([  1318,   2385,     17,    285,      4,  60535,    188,    188,     41,\n",
              "           21128, 201760,  17245,    100,    978,    188,    188]), tensor(0)),\n",
              " (tensor([  314,   157,  2119,     4,    30, 10075,     6, 31031,   490,     2,\n",
              "              0,     2,  1957]), tensor(1)),\n",
              " (tensor([ 7547,    14,     7,   355,   336, 20020,    10,   285,    13,     0,\n",
              "            586,     2,  5551,  1533,    14,    13,   192,   437,     2,   188,\n",
              "            188]), tensor(0)),\n",
              " (tensor([   41,  5917,  3450,    66,     3,  3827,   339,    13,  1497,  4000,\n",
              "              5,  1421,    66,   192,  1888,   117,    41,    40,     4,  9347,\n",
              "             10,    29, 20470]), tensor(0)),\n",
              " (tensor([ 192, 2706, 2829,    2]), tensor(0)),\n",
              " (tensor([    84,    439,   2518,     73,   2660,      5,    134,     13,    912,\n",
              "              17,    192,    122,   2001,      2,      2,      2,      2,      2,\n",
              "               2,    947,     62,  21560,      5,     53,    149,    719,  48881,\n",
              "          120960,    600,      2]), tensor(0)),\n",
              " (tensor([   41,   269,    41,   120,  5387,    60, 51033,     2,   242,  2375,\n",
              "             71,    66,   100,  4909,     4,   285,   188,   188,   188,   188,\n",
              "            835,    71,   188,   188]), tensor(0)),\n",
              " (tensor([  1071,    392, 222133,  60349,    131,    192,    951,   2491,      5,\n",
              "              41,  34879,      6,   1655]), tensor(0)),\n",
              " (tensor([  119,     0,    58,    85,   136,   661,  4702,   156,   188,     0,\n",
              "          33857,    32,    17,   149,     5,    33,    51,  3990,    75,   653,\n",
              "            505,  5775]), tensor(1)),\n",
              " (tensor([ 738,   14,   63,   29, 9214,  248,  587,  192,  161]), tensor(0)),\n",
              " (tensor([178759,   1751,      4,    253,    192,   5397,      5,    788,    605,\n",
              "             188,    188,  41253,  14886,      2,    188,    188,    188,    188,\n",
              "             188,    188,      2]), tensor(0)),\n",
              " (tensor([  238,    37,  3451,  3119,    36,  2398,  4784,  9199,  4453, 22647,\n",
              "            409,  3453,  1708,     2,  2611, 12121, 22226,   484,   358,  2575,\n",
              "              2,    64,     2]), tensor(1)),\n",
              " (tensor([ 1004,  2415,  9156,    10,   164,  1708, 21983,     2,   188,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([   5,   21,  914,   37, 9743,    0,  555, 2788,    3,    0,  459,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([11083,   684,     6,   782,    41,   822,     0,  2396,  2385,    75,\n",
              "              7,   136,    12,  1950,     0,   973,     3,  1884,     2,    81,\n",
              "             86,  1449,     7,  5148,     2]), tensor(1)),\n",
              " (tensor([3799,   22,   89, 5611,    3,    6,    2,    2]), tensor(1)),\n",
              " (tensor([ 5679,  1144, 14343,  3251,     6, 13441,     4,  3945,    11,     2,\n",
              "           2749,   188,   188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 1881,    83,     0,  1569,  9855,  1881,    83,   162,  6965, 23753]),\n",
              "  tensor(0)),\n",
              " (tensor([   0, 2061,  270,  114, 8167,   89,    3,   47,  832,  798, 4564,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([   91,    40,     7,   569,    10,    36,   151,     7,   147,     5,\n",
              "            405,     6,     7, 48271,   569,  1960,     2,     2, 42460, 48271,\n",
              "           1203,     2]), tensor(1)),\n",
              " (tensor([ 2319,    44,  2251,     4,    92,   358,  9140,     3,   687,   545,\n",
              "             14, 98758,   490,  1558,     2]), tensor(1)),\n",
              " (tensor([   81,    86,   837, 38610,   188,   188,   188,   188,   188,   188,\n",
              "              2]), tensor(0)),\n",
              " (tensor([   192,    137,     14,    100,  71232, 141352]), tensor(1)),\n",
              " (tensor([  12,   81,   32,  222,    4, 2357,   14,    0,  254,  179,   41,  346,\n",
              "             4, 1566,    0, 8784,    3, 2412,   81,   33,  645,    4, 1895,    2,\n",
              "            57, 1926, 1052]), tensor(0)),\n",
              " (tensor([   765,  11546,   2395,     10,    765,   1867,   2395,   3616,     10,\n",
              "             529, 148896,      7,      2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([6479,    2, 1534,    2,  384, 2718, 5648,    2,    2]), tensor(1)),\n",
              " (tensor([21365, 43819,  5110,   696, 13183, 21270,  1343,  2824,  2547,  8948,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([  1778,      3, 163166,   2424,   2069,   7022,      4,  11854,   2070,\n",
              "            8913,   4678,   2173,      4,   5858,     29,  55901,      4,      4,\n",
              "               2,      2,      2,      2]), tensor(0)),\n",
              " (tensor([3119, 8266,  188,  188,  188,  188,    2]), tensor(0)),\n",
              " (tensor([27089,    14,  3936,  3428,     3,   719, 48881,    26, 25495,    13,\n",
              "              0,  1008, 12456,    15,   120,  5222,    19, 35690,    17]),\n",
              "  tensor(0)),\n",
              " (tensor([   6, 7692,   32,  595,    4, 1753, 1150,    3, 7516,   49,    0,    2,\n",
              "             2,    2,    2, 1957]), tensor(1)),\n",
              " (tensor([ 7598, 44438, 23296, 22326, 31346,  1357,  1975, 12791,  5022,  6910,\n",
              "          48516,     2,     2]), tensor(0)),\n",
              " (tensor([  188,   188,  2716,    60,  6749,    47,   341, 10574,  9292,     2,\n",
              "           6479,   408,    77,  6479,  2025,   317,   181,     3, 10574,    79,\n",
              "           2641,   816,   773,     3,   222,   587,   188,   188]), tensor(0)),\n",
              " (tensor([7513, 7913, 4808,  164, 5327,   49,    2]), tensor(1)),\n",
              " (tensor([   738,    119,   1533,    460,  92367,      3,   2359, 115404,    188,\n",
              "               2,   1957]), tensor(0)),\n",
              " (tensor([ 300,  738, 6870,   60,  188,  149, 3681,    2]), tensor(0)),\n",
              " (tensor([   41,   269,     0,  1118,     3,  1529,     5,   881,    71,  5942,\n",
              "          15733,    31,     7,   530,     4,    88,    17,    20]), tensor(0)),\n",
              " (tensor([    41,    120,    303,   1402,      4,    346,     12, 132069,     15,\n",
              "            2962,     41,     15,    881,      7,  64592,     61,     53,     35,\n",
              "            2837,      4,   9347]), tensor(1)),\n",
              " (tensor([   63, 15221,     6,     0,   484]), tensor(0)),\n",
              " (tensor([  7940,    135,      6,      0,  23566,   2895,    100,   1479,    100,\n",
              "            1866,     37,   2901,   1038,      3,    285,    192,    835,     10,\n",
              "              81,     14,     56,   3020,     41,     86, 140299, 114931,    188,\n",
              "             188]), tensor(0)),\n",
              " (tensor([  52,  285, 3832,   41,   54,  191,  181,  117,    7, 2858]),\n",
              "  tensor(0)),\n",
              " (tensor([   12, 60269,    12,    41,   151,  6252,  8198,     0]), tensor(0)),\n",
              " (tensor([6479,    2, 1534,    2,    6,  384, 2718, 5648,    2]), tensor(1)),\n",
              " (tensor([3431,    7, 1484, 1173, 2005,  746,    2,    2]), tensor(1)),\n",
              " (tensor([ 172,  197, 6804,   14,  433,  628, 5648, 2771,   11, 1377, 1121, 3933,\n",
              "             2]), tensor(1)),\n",
              " (tensor([ 1591,    32, 44690,    17,     2,   159, 16402,  1346,    66,    17,\n",
              "           8237,    46,  3030,     2,     5,   647,     4,  1027,     4,     0,\n",
              "            220,     3,     0,  9623,     2]), tensor(0)),\n",
              " (tensor([  593,   426, 56302, 26874,  1452,  9104,     6, 58131,   386,  1532,\n",
              "              7,     2]), tensor(1)),\n",
              " (tensor([2472,  207,   41, 1361,  192,  499, 1409,   38, 4647, 1962,  317,   59,\n",
              "             0, 2692, 3537]), tensor(0)),\n",
              " (tensor([  361,  2583, 18256,  2349,     3, 13053,  4065,  1763,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([     0,   2333,    118,    923,      5,   1962,    192, 158715,   2146,\n",
              "             117,      7,     33,      7,   2518,    222,      4,   4374]),\n",
              "  tensor(0)),\n",
              " (tensor([  409,     2,   422,    66,     3,   422,  1569,    21, 15670, 17961,\n",
              "             10, 86883,    21,  9577,     2,     2]), tensor(0)),\n",
              " (tensor([3832, 4307,   25,    0, 8321,    2,  188,  188,  188,  188]),\n",
              "  tensor(1)),\n",
              " (tensor([    6, 65274,  2572,  1149, 65274]), tensor(1)),\n",
              " (tensor([    0,  2745,     2,    41,  2244,     7,   696,    66,     2,     5,\n",
              "           1896,     7,   947,     6,     0,  5578,  3314, 10063,     2,     5,\n",
              "             39, 20700,   285,    10,     0,   947,     2]), tensor(0)),\n",
              " (tensor([   34,     0, 11343,   309,  1996,     4,     0,   451,    10,     0,\n",
              "           5493,   100,    36,   588,   433,  1380,    22,    37]), tensor(1)),\n",
              " (tensor([   41,  5572,     7,   974,     2, 20500,  9547,     2, 16294, 27894,\n",
              "             11,  6325,    41,  2788]), tensor(0)),\n",
              " (tensor([  192,  5948,    16,    41,   662, 19275,    73,  3518,    34,   588,\n",
              "          14663,    74,   187,   117,     2]), tensor(1)),\n",
              " (tensor([  298,   213,  3102,   353,  2896,    24,  1666,  6870,    60,     6,\n",
              "              7, 10230, 32851,   490,  1134,     2,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  127,   886,     0, 48881,  1092, 73048,   188,   188,   188,   188,\n",
              "             41, 58556,   553,   100,    20,    30,    12]), tensor(0)),\n",
              " (tensor([89545,  1606,  1262,    17, 13452,     3,    29, 89545,  1606,    31,\n",
              "             51,  1262,    17, 13452,    74,     0,  5553, 24195,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  41, 5572,    7,  974,    2, 1942,  232, 1988]), tensor(0)),\n",
              " (tensor([ 3202,   192,  1058,  2263,     5,   192,  3987,    14, 19118,   131,\n",
              "              0,  4058,  1239,  8406]), tensor(0)),\n",
              " (tensor([  1993,    176,      2,    790,     11,  84154,   1534,      3,   8555,\n",
              "          214288,     22,   7265,      2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([  1465, 141996,   4389,   1840,  17192,     25,   7795,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([1229,    7, 1836]), tensor(0)),\n",
              " (tensor([ 8777,   237, 10192,  5301,   156,    19, 14522,   483, 15334]),\n",
              "  tensor(1)),\n",
              " (tensor([   83,    37, 49295,     4,   614, 19613,  1248,  1432,   135,     6,\n",
              "              7, 27329,  1249,    92,    51,   567, 10360,     2]), tensor(0)),\n",
              " (tensor([ 3558,   514, 10322,  1894, 43157,  2719,     7,  2858,     2,     2,\n",
              "              2,     2,  4851,     2]), tensor(0)),\n",
              " (tensor([  14,    0,   96, 1528, 4034,   42,   81,   86,  234,    4,  511,    0,\n",
              "            85,    2,   57, 3560,    2]), tensor(0)),\n",
              " (tensor([ 7092,  2431,  9515,  2431, 13875,   751,     2,     2, 34855,    15,\n",
              "            862,   117,     7,   136,  1498,     6,   187,   188,   188]),\n",
              "  tensor(0)),\n",
              " (tensor([ 7516,  5817,    49,  2377, 59194,   138,  4428,     2]), tensor(1)),\n",
              " (tensor([    0,  2301,    41,  2529,     0,    48,    12,  1165,   192,  4413,\n",
              "           1655, 33092,  4284,     2, 90726,  3161,     0,   897,     2,     2,\n",
              "              2,  9830,     2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([ 1812,    63,    35,    84,  1892,    13,   534,    61,     0,  1470,\n",
              "          14582,    37,   766,     2]), tensor(1)),\n",
              " (tensor([ 6844,    17, 17729, 61032, 55198, 69317, 15976]), tensor(0)),\n",
              " (tensor([   83,    41,   169,   192,   308,    21,  4002, 11343,   188,   188]),\n",
              "  tensor(0)),\n",
              " (tensor([38970,   115,  1749,   123, 40648,  7937,     6, 20963,  1611, 25893,\n",
              "              2]), tensor(0)),\n",
              " (tensor([   41,   913, 15917,  5551,    81,  2772,   392, 20524,    14,  5553,\n",
              "            413,   117,  2838, 14829,   505, 20524,     2]), tensor(0)),\n",
              " (tensor([   29,  3658,   355,    81,   234,    37,  7404,     2,    57,   197,\n",
              "            119,    81,   169,  3056,   188,   588,  1157,   433,   359,  5423,\n",
              "            821,   393,   662, 20022,     2]), tensor(0)),\n",
              " (tensor([   738,     32,     81,  44690,     17,    653, 105269,    188,    190,\n",
              "               0,      2,      2]), tensor(0)),\n",
              " (tensor([23159,  7695,  1470,   633,  1875,  4037,   109,     7,   129,     3,\n",
              "           5435,  4037,    74,  1616,   973,    49,    55,  1470,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([10696,     5,  6226,   555,     6,     0, 18118, 47885,  2635,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([   0,   58,  801,    6,    0,  336,    3,   15,  120, 5396,    2,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([   738,     14,     84,     48,   1901,     59,      0,   1118,      3,\n",
              "               7,   1523,   4469,   5191,   6835,      0,   7516, 114343,   3454,\n",
              "               0,  23361,   3318,    188]), tensor(1)),\n",
              " (tensor([ 1377,  2143,    21,  2479,    22,     0,  2610,  2787,    49,  8885,\n",
              "            406,  2808,  1957, 14502, 39045,    11,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 40650,   1553,   2009,      2,   1819,    152,  12049,  40650,  24834,\n",
              "          303820,      2]), tensor(0)),\n",
              " (tensor([  300,   635,   106, 11994,   163,   208, 17123,     2]), tensor(1)),\n",
              " (tensor([ 87091,    188,     71,   4390,    629,     14,   1383,     71,   3986,\n",
              "               5,     71,  22826,   1108,    151,   1803,     10,     71,      2,\n",
              "            1511,   5836,    405,    285, 107153,     60,      2]), tensor(0)),\n",
              " (tensor([   79,   309,    22,    76,     4, 55211,     0, 33564,     3,   192,\n",
              "           7203,    89,     2,     2,     2,    57,     2]), tensor(0)),\n",
              " (tensor([   0, 3158,    3,  347, 1899,   32, 3601, 6731,    5,   39,   43,   36,\n",
              "            30, 2407,    2]), tensor(0)),\n",
              " (tensor([   41,    15,  1797,     4,   580,    20, 51702,  1403,     2,     2,\n",
              "           2543,    20, 25975,  3838,    13,   285,    36,   191, 51702,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  467,  9718,  5625,    17,  1332, 13071,     2,     2]), tensor(0)),\n",
              " (tensor([   188,    188,    188,    188,  27298, 149344,    188,    188,    188,\n",
              "             188,    188,    188,     43,     81,    149,    835,    285,   4002,\n",
              "               2,    188,    188,    188,    188,    188,    188,      2]),\n",
              "  tensor(0)),\n",
              " (tensor([2146,    5, 4076,  117,    7,  136, 1498]), tensor(1)),\n",
              " (tensor([  10,  155, 5228,   21, 7921, 3007,    5,  830, 1416,  944,   66,    3,\n",
              "          1022,    2]), tensor(0)),\n",
              " (tensor([  426, 56302, 26874,  1452,  9104,     6, 58131,   386,   426,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 33222,     58,   1960,      6,     82,      2,   2531,   2178, 274954,\n",
              "              25,    355,  23660,      2,   7018,  17424,     75,    285,    110,\n",
              "              41,     15,   8352,    852,      2,   1402]), tensor(1)),\n",
              " (tensor([ 1881,    53,   189,   580,   315,     5,  1361,   101,  6332,    32,\n",
              "          74293,    31,   919,   101,   135,     0,   620,     4, 32482,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([   165,     10, 152067,   2005,   3122,    785,  41943,     13,    102,\n",
              "              54,     33,     51,     26,   5033,      2]), tensor(1)),\n",
              " (tensor([ 64736,   2843,   1975,     11,  71053,    583, 126134,  42490,      2,\n",
              "             555,   5545,      6,  46584,    619,     89,  13125,      6,   8411,\n",
              "             619,      2]), tensor(1)),\n",
              " (tensor([  289,   658,    11,   409,   767,  2209,  1002,     6,  1166,  2426,\n",
              "            355,   166, 12776,     6,   740,   136,     2]), tensor(1)),\n",
              " (tensor([    2,   511, 21068,   131,    12,  2858,  3361,     0, 21983,   138,\n",
              "              2]), tensor(0)),\n",
              " (tensor([ 915,    4, 6415,   74,   56,   73,  800,  915, 2085,   21,    0, 5553,\n",
              "          3853,    3,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([  100,    53,   189,  1545,    20,    64,   232,   103,   127,   188,\n",
              "          23344,   103,     6,    20,   188,    41,   117,     0,   179,  6479]),\n",
              "  tensor(0)),\n",
              " (tensor([   41, 27283, 19423,    10,     0,  7075, 26103,     3, 45290,     4,\n",
              "            326,     2,    41,   802,   130, 46547,    83,    81,  2099,     4]),\n",
              "  tensor(0)),\n",
              " (tensor([4153,   10,    0, 1694,   14,  116,    2,  364,  364,   51,    7,  173]),\n",
              "  tensor(0)),\n",
              " (tensor([ 3202,    84,     2,     0,  8846,    89,  5965,   659,   493, 65977,\n",
              "             14,  1187,     2,  3832,    84]), tensor(0)),\n",
              " (tensor([1616,   82,  363,  373,    0, 6479,    2, 1534,    2, 1200,    7,  490,\n",
              "          4034,   13,  361,    2,  187,   32,   77, 3550,   12,  593,  192, 2166,\n",
              "            13,   12]), tensor(1)),\n",
              " (tensor([   193,     89,  23973,  14238,    717,    422,      5,  12830,  70399,\n",
              "             445,      4,   2575,    484,      2,  33868,     14, 171913,   1596,\n",
              "               2]), tensor(1)),\n",
              " (tensor([  738,   119,    39,    33,     4, 10031,    20,    17,    13,  1563,\n",
              "            187,    89,    11,    89]), tensor(0)),\n",
              " (tensor([364382,    534,  10181,    422,     72,    571,      0,    745,  72362,\n",
              "            1431,    640,    534,      3,   3198,   2404,      2,      2,      2,\n",
              "               2]), tensor(0)),\n",
              " (tensor([   2,   14,    0, 1470,   46,  188]), tensor(1)),\n",
              " (tensor([    36,     83, 123797,      7,  20072,    188,    188,    188,    188,\n",
              "           46768,   2357,    106,     41,    169]), tensor(0)),\n",
              " (tensor([ 3020,  5543,    15,   492,   138,    13,     7, 22861,    49, 18472,\n",
              "           3761, 10857,   824,    39,    32,   150,  4862,    18,   175,    77,\n",
              "            290,    74,    82]), tensor(0)),\n",
              " (tensor([  1822,  46737,   5376,      6, 294800,   2005,     17,    569,     12,\n",
              "            4417,      7,   7213,   6765,   3686,      2,      2,      2,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([94881,   974, 14691,  2528,  3443,    22,  6113,   922, 37131,   105,\n",
              "              7,  1836,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([  84, 1832,   53,  690,  405,    6, 2194,   10, 9674,  317,  181,  188,\n",
              "           188]), tensor(0)),\n",
              " (tensor([17560,   188,  2219, 22496,  2397,   483,    10, 10046,  1488, 24083,\n",
              "           1461, 60813,   188,     2]), tensor(0)),\n",
              " (tensor([  365,   933,     5,   659,   419,     0,   354,    12,    94, 15297,\n",
              "            392,  2645,  1747,     2,     2,     2, 17101]), tensor(0)),\n",
              " (tensor([ 1313,  6114,   102,   921,     3,     2,  8808, 14784]), tensor(0)),\n",
              " (tensor([3733,   35, 6925,    4, 2271,    3,    0,  336,    3,   44,  126, 1925,\n",
              "          6380, 1019,   38,   15, 8202,    2,    2,    2,    2]), tensor(1)),\n",
              " (tensor([36021, 24526,    17,     7,  6662,  7033,   117,    29,  1357, 24445,\n",
              "              2,     2,     2,     2, 48271,     2]), tensor(0)),\n",
              " (tensor([19356,     2,   111,    14,  1402,     2,  3202,  2472,   164,  4862,\n",
              "          14663,  4862]), tensor(0)),\n",
              " (tensor([ 192,  261,  787, 8349,  188,  188,  188,  188]), tensor(0)),\n",
              " (tensor([   18,   116,   125,     7,   219,   389,     2,   298,   899, 59649,\n",
              "           1329,  1475, 18621,    19,  1511,  2342,   260,     0,   215,   873,\n",
              "              2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([  707,     3,  5807,   197,     7,   978,  1422,    86, 13633,     7,\n",
              "              2]), tensor(0)),\n",
              " (tensor([  100,  1896,    63,    35,   272,  4564,   355,   111,    41,   682,\n",
              "             74,     0,  1175,    12,    41,    15,  4366, 25342,     4,     2,\n",
              "              2,     2]), tensor(1)),\n",
              " (tensor([  189,    64,    64,     3,  1174,    11, 45128,    11]), tensor(0)),\n",
              " (tensor([  2636,  52717,    837,  50862,      2, 116853,   3037,      7,      6,\n",
              "           76895]), tensor(0)),\n",
              " (tensor([ 738,  260, 2779,    5,  169,  420,   17, 1329, 1475,  188]),\n",
              "  tensor(1)),\n",
              " (tensor([1106, 8707,    5, 5116,    6,  529, 4851,  794,  255,   84,    2,  232,\n",
              "             2,    2]), tensor(1)),\n",
              " (tensor([15729,    84,  1078,     4,  1878, 75478, 25663,     6,  3050,     3,\n",
              "           7789,  5577, 30663,     2]), tensor(0)),\n",
              " (tensor([5563,  149]), tensor(0)),\n",
              " (tensor([  3202,     36,    317,    978,    127, 154265,      2,     41,     51,\n",
              "           38610,  49036,      2]), tensor(0)),\n",
              " (tensor([    88,     81,    346,    111, 349297,     19,     41,   1435,   1357,\n",
              "             522,    355,     21]), tensor(1)),\n",
              " (tensor([   738,    100,    109, 205762,    301,     13,  10360,   4385,    188,\n",
              "             805,   3520,   7444,      0,   6554,  23395,     34,      0,   2121,\n",
              "               3,  26103,     14,   4644]), tensor(0)),\n",
              " (tensor([42964,     0,   621,     3, 26103,    19, 40962,    89]), tensor(0)),\n",
              " (tensor([    84, 192059]), tensor(1)),\n",
              " (tensor([33936,    89, 32605,    89, 12661,    35,  1767,    13,    20,    61,\n",
              "             20]), tensor(1)),\n",
              " (tensor([    33,   1813, 122237,     41,    405,      6,      7,   8433,   1960,\n",
              "              89,   2288,    192,  49170,      2,   3173,     10,    285,      4,\n",
              "              33,    785,     81,     32,      0,    629]), tensor(0)),\n",
              " (tensor([   41,    33,   192,   294,  4002,   188,   188,   188,   188,   188,\n",
              "            188,     2, 33838,    14, 21654,    34,  3981]), tensor(0)),\n",
              " (tensor([ 4001,  1587,    34,  2451, 19496,   974,     2,     0,  6245,   305,\n",
              "             11,   974,    11,     2,     2]), tensor(1)),\n",
              " (tensor([ 1716,    37,   922,   169, 19105,    60,    21,     7, 42967,     6,\n",
              "            124,     7,  1214,     2]), tensor(1)),\n",
              " (tensor([    0,  1470, 14582,    37,   766]), tensor(1)),\n",
              " (tensor([  886, 13633,   392,   169,     7,  2829,   359, 97576,    61,    81,\n",
              "           3050,    60,    17,     0,   254,  1314,     4,     2]), tensor(0)),\n",
              " (tensor([  409,  4574,  7313,  5817,    21,   142,     6, 54107,  4851,  4389,\n",
              "           6822,     2]), tensor(1)),\n",
              " (tensor([   71,  7931,  2146,   117,     7, 31870,  5479]), tensor(0)),\n",
              " (tensor([28811,    15,     0,    96, 18590,   254,  9872, 13987,   661,    51,\n",
              "             13,     2,    51,    13,   191,   306,     2]), tensor(0)),\n",
              " (tensor([    37, 120602,   7704,      4,    169,   7357,    188,    188]),\n",
              "  tensor(0)),\n",
              " (tensor([   53,   346,    37,    14,   978,    10,     0, 15160,    11,   455,\n",
              "              6,     4,   826,    25,   636,   570,  1269, 12594,  2291,   337,\n",
              "              2,     2,     2,     2]), tensor(0)),\n",
              " (tensor([45520,    14,  3973,    21, 15861,   100,    30,  5604,     5,   886,\n",
              "            392, 15861,   424]), tensor(1)),\n",
              " (tensor([  578,  3030,   392,  5127,   188,   188,  6571,  8597,  2654, 22861,\n",
              "          95096, 11728, 88438, 21979,     2]), tensor(1)),\n",
              " (tensor([  1544,    408,      7,   4385,    188,     41,    282,   7008,  25048,\n",
              "          281435,    644,      2, 267689]), tensor(0)),\n",
              " (tensor([ 5116,  5059, 17574, 33155,    74,    48,    93,     6,   656,     2,\n",
              "             22,   338, 17574,    69,    33,    51,   256,     5,   573,   418]),\n",
              "  tensor(1)),\n",
              " (tensor([4851,   88,   36, 1916, 4851, 5312,   91, 4851, 1605,   10, 1247]),\n",
              "  tensor(0)),\n",
              " (tensor([ 6321,    41,    33,     7, 11845,     5,   408,  1318,    14,   690,\n",
              "            117,     6,     5,    41,   346,   197,    41,   405,   100,  5065]),\n",
              "  tensor(0)),\n",
              " (tensor([  119,    81,   169, 14187,   378,   188]), tensor(1)),\n",
              " (tensor([   41,   966,   404,   599,  5564, 15418,     2,  3501,  8484,  4042,\n",
              "              2]), tensor(0)),\n",
              " (tensor([   232,   1933,     25,  23239,   8814,      6,    206,  80746,   1402,\n",
              "          178539,     44,  34855,      2,    652,    767,     25,  41919,      6,\n",
              "               7,    229,     89,  43372]), tensor(1)),\n",
              " (tensor([    6,   192,  1221,    83,   690,  3400,     5,  1626,    19,     7,\n",
              "          34822,    81,    32,     6,  4503,  3052,     3,   222,   138,     0,\n",
              "          15217,     2]), tensor(0)),\n",
              " (tensor([ 9330,     0,  4060,   408,    10,   162, 10894,     2,   197,    54,\n",
              "             81,  1129,    20,   135,     6,     2]), tensor(0)),\n",
              " (tensor([ 2125,     3,    81, 17249, 39237,   973,   362, 25495,    69,   661,\n",
              "           1403,   280,  3158,    81,   120,  5281,    61,   521,  1933,   169,\n",
              "            999,     2]), tensor(0)),\n",
              " (tensor([    36,    134,    667,      4,   3255,   1096,     46,   1544,      6,\n",
              "          349789,    296,    134,  38335,    188,    188]), tensor(0)),\n",
              " (tensor([1816,    5, 2375,   66,   26,  416,  592,  300,   47]), tensor(0)),\n",
              " (tensor([   10,  2964, 18821,   775,    10]), tensor(0)),\n",
              " (tensor([46501,  1007,   719, 12704, 13994, 13788,  3051,  1258,  4610,   884,\n",
              "          43752,  5149,  3424,     2,     2]), tensor(0)),\n",
              " (tensor([  41,  120, 3186,   17,  150,  192, 1108,    6,    0,  569,   12,   15,\n",
              "             7, 6114,  436, 2110,    4, 1927]), tensor(0)),\n",
              " (tensor([ 3168,    49,   559,    10, 10665,     2]), tensor(1)),\n",
              " (tensor([   81,   662,   117,    81,   405,  1921,     6,     7, 35067,    37,\n",
              "             14,  5772,     5, 23967,    22,     0,   215,    79]), tensor(0)),\n",
              " (tensor([  219,  2699,    41,   119,    36,  3467,     4,    34,   114,    41,\n",
              "            913,  1011,     4,     2,    41,   390, 55211,    81]), tensor(0)),\n",
              " (tensor([  254,   733,    64,     0,  1797,  2344,    32,   134,   116,    66,\n",
              "            187,     6,   158,  7396,  1736,   105,    37,   187, 35067, 73048,\n",
              "            192,  5007, 14219]), tensor(0)),\n",
              " (tensor([ 3644,    81,    86,  8722, 10678,  1856,   275,   285,   192,  2124,\n",
              "             14,    36, 16402, 38622,    41, 13072,  1028,    69,   197,  1950,\n",
              "             20,     2]), tensor(0)),\n",
              " (tensor([  53, 1527,  169,   20,  169,   20,    6, 1454]), tensor(0)),\n",
              " (tensor([  9271,    658,    283, 116582,    611,    851,    331,   9372,   6904,\n",
              "              11,      2]), tensor(1)),\n",
              " (tensor([  1384,   1933,      7,     62,     25,  95926,   4270,      2,      2,\n",
              "               2, 158715,      2,      2,      2,      2]), tensor(1)),\n",
              " (tensor([14663,  9174,     6,  1655, 11955, 22048,     0,  4090]), tensor(0)),\n",
              " (tensor([    0, 11461,  2115,     3, 13053,     5, 20937,  4065,  2947,   149,\n",
              "            134,  1349,   373,     2]), tensor(1)),\n",
              " (tensor([   38,    33,    51,  1011,     4,   891,    44,   123,     6,   460,\n",
              "              4,  2968,   136, 10000,    46,  1132]), tensor(1)),\n",
              " (tensor([   269,  66103,    326,      4,      5,  23703,   1490,    378,    393,\n",
              "            6843, 133668,  11993,      2]), tensor(0)),\n",
              " (tensor([ 3978, 33056,   436,    13, 16257,    34,   359,    79,    41,   253,\n",
              "           9011,  8278,   197, 13566,  2431,     5, 74514,  1402,    14,     6,\n",
              "              0, 20470,     2]), tensor(0)),\n",
              " (tensor([    6,   188,    53,  1786,  7546,     7, 21365, 98698, 25926,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 12659,     45, 113120,     43,    114,  12142,   2024,   2768,      2,\n",
              "               2]), tensor(0)),\n",
              " (tensor([   20, 15113,    12,    13,     0,  2349,     3, 13053,   162,   533,\n",
              "             90,    14,  2116,     7,  1376,   513,  5538,   490,   736,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([2284,    2,   41,   33,   29,   38, 1403, 1111,    4,  285,   21, 1454,\n",
              "             2]), tensor(0)),\n",
              " (tensor([ 2167,    74,  1510,  7516,     6, 12230,    11,  3092,   172,    11,\n",
              "           7692,  1468,    10,  3649,    49,     7,  2377,  9912,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 192, 1108,  733,    6,    0, 2895,    2, 5279,    2]), tensor(0)),\n",
              " (tensor([   700,    392,    261,    894,   3117, 184385,   5775,    199,   1975,\n",
              "           13041,      2,      2]), tensor(1)),\n",
              " (tensor([11083,    41,   733,    63,    43,    30,    13,  8364,    49,     0,\n",
              "           6289,    34,    63,    14,   936,   117,  2660,    20,   682, 64029]),\n",
              "  tensor(1)),\n",
              " (tensor([  111,     0,  5678,  3094,     5,  1329,  1475,   326,     6,     2,\n",
              "            359,     2, 48271,     2,    79,     2]), tensor(0)),\n",
              " (tensor([ 545, 1965, 2686,  573, 4573,   85,  384,    2]), tensor(1)),\n",
              " (tensor([  213, 34388, 15095,     3, 18452,    17,  2348,  5255, 58885,  1548,\n",
              "           1150,     3,     2]), tensor(0)),\n",
              " (tensor([   89,    89,    89,     2,    89,    89,    89,    89,    89,    89,\n",
              "          60007]), tensor(0)),\n",
              " (tensor([ 3230,    14,  6002,  3833,   531,   323, 12131,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 2796,     2,   738,     0,   550,    25, 81349,    76,    62,    15,\n",
              "            100,   353,   113, 17058, 43446,     7,  1856]), tensor(0)),\n",
              " (tensor([  8235,  23753, 237943,     53,   3823,      0,    863,      2,      2,\n",
              "             188,    188]), tensor(0)),\n",
              " (tensor([  102,   588,  1579,     6,     0,   492,   691,   523,  8718,     2,\n",
              "              7,   863,   903,    12,  8366,     7,  2924,     6, 12609,     2,\n",
              "              2]), tensor(0)),\n",
              " (tensor([ 2696,  2160,  3424,  4322,    37,   913,    17,  6662,  9200,  1627,\n",
              "           3424,    89,  3193,   635,    74,  1801,  2431, 80243,  1264, 18493,\n",
              "              2,   197,   188]), tensor(1)),\n",
              " (tensor([ 1357,  2981,     2, 17771,     2, 74109,     2]), tensor(1)),\n",
              " (tensor([113120,     43,    114,      2,      2]), tensor(1)),\n",
              " (tensor([   36,     7, 12456,  3267,    34,    41,  3710,  2660,   103,    69,\n",
              "              2,   353,  2253, 73048,     2]), tensor(0)),\n",
              " (tensor([ 3630,   336,  1311,     6,  3853,     6,   139,  8319,    89,   477,\n",
              "            846,  5427,  4026, 13013,     2]), tensor(1)),\n",
              " (tensor([ 1581,    17,  4527,  8183,  4359,  1245,    11, 13116, 24605,  1891,\n",
              "           1509]), tensor(1)),\n",
              " (tensor([   83,  6479,   757,    59,   214,    13,   607,   937,    89,     6,\n",
              "            325,   127, 46768, 15480,    89,  7149,     0,   490,  2395,     6,\n",
              "             37,    14,     7,   747]), tensor(1)),\n",
              " (tensor([ 6084,  2541,  1144,   502,   106,  1984,  5440,   976,  5423,    98,\n",
              "          28098]), tensor(0)),\n",
              " (tensor([ 9628,   583,   368, 41232,     2,  1343,  4735, 43454,  2964, 14343,\n",
              "           7011,   314, 77983,  2749,   188,   188]), tensor(1)),\n",
              " (tensor([   41,   269,    91,    40,   117,    48,   521,  1329, 12871,     6,\n",
              "              0,   299,     3,  1329,  6059,   298,    69,    88,    12, 34855,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  232,  4471,   300,  3640,  3278,  1907,  1280,    11,   549,  1465,\n",
              "             21, 10891,     2,     2]), tensor(0)),\n",
              " (tensor([ 78550,     41,   2715,      0,  11845,      0,    122,     41,    119,\n",
              "              71,   3017,    117,  32156,      5,     36,   5055,      2,      2,\n",
              "               2,      2, 268072,      0,  73048]), tensor(0)),\n",
              " (tensor([2375,  158,    2,    2,    2,    2]), tensor(0)),\n",
              " (tensor([  170,   298,  1856,   595,     4,  1329,  1475,    69,    10,    84,\n",
              "           3456,  1247,   120,   113,   886,   285,  5020,  7278,  3118, 26914,\n",
              "          26914, 26914]), tensor(1)),\n",
              " (tensor([   12,  1600,    61,    81,   169,    13,     7, 10212,  9872, 13987,\n",
              "              5,     0,  1856,   561,    81,    14,   120,  9225,  4647,  1475,\n",
              "            188,   188,   188,   188,   188,   188]), tensor(0)),\n",
              " (tensor([ 1591,    32, 44690,    17,     2,   159, 16402,  1346,    66,    17,\n",
              "           8237,    46,  3030,     5,     4,  1027,     4,     0,   220,     3,\n",
              "              0,  9623,     2]), tensor(0)),\n",
              " (tensor([ 8738,   120,    38,    53,   408,   170,   699,   905, 39774,   742,\n",
              "             66,     4,   169,   605,   500, 12193,   484,  2347,  2562]),\n",
              "  tensor(0)),\n",
              " (tensor([33222,  3366, 49922,     2,   120,   285,     7,  1334,     3, 14533,\n",
              "             77, 25361,     5,     0,   766,  1662,     2,     2]), tensor(1)),\n",
              " (tensor([   96,  5313,     6,    85,   254,   664,  2009, 16999,     5, 14489,\n",
              "            254,   321,   105,   584,    85, 11845,   102,  2796,    33,    81,\n",
              "            751,   188,   188]), tensor(0)),\n",
              " (tensor([   41,  5572,     7,   974,     2, 63594, 72587,    11]), tensor(0)),\n",
              " (tensor([  738,  1291,    14,    36,  1968,   136,    10,  1968,   330,    34,\n",
              "             10,  5438,  2103,    38,    86,  3299,    44,  2478,   106,    39,\n",
              "          20886,    44,  3084,     2]), tensor(1)),\n",
              " (tensor([  181,     3,    42,    31,     4,    88,    17,  1628, 15835,   545,\n",
              "           3986,  4428,  3670,   913]), tensor(1)),\n",
              " (tensor([ 2546, 14522,     5,  6179,  5116,   555,     6,     0, 81235,     5,\n",
              "           7727,     2]), tensor(1)),\n",
              " (tensor([27672,     2,   316,  6830,    94,    30,  1758,    73,  1273,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 2255,   203,     7,  5553,  5176, 26120, 24166,  2005,    76,    62,\n",
              "             15,  1098,    21,  6731,  1899,    49,     0, 71168, 28084,     7,\n",
              "          20949]), tensor(1)),\n",
              " (tensor([ 2213,   279, 59192,  1600,    45, 12088, 14814,    17,     2,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([    0,  4493,   561, 27702,  8555,     2]), tensor(0)),\n",
              " (tensor([149784,   5545,   1916,   2430,   3283,     11,      2,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 3856,   408,     4, 22496,   300, 34090,   435,    10,  6219,     2,\n",
              "              2,   324,  4973,  7478,  3926,  2031,   163,     6,  3881,  2396]),\n",
              "  tensor(0)),\n",
              " (tensor([23159,  7695,  1470,   633,  1875,  4037,   109,   973]), tensor(1)),\n",
              " (tensor([ 6943,    10,  3045,  4429,     6,  3052,     3, 47575,  3570,     0,\n",
              "           7243,    10, 24294,     2,     2,     2,     2,  5483]), tensor(0)),\n",
              " (tensor([   84, 35541,     6,    20,    12, 70091, 10764,  1454,     2,    84,\n",
              "          28091,  2021]), tensor(0)),\n",
              " (tensor([56403, 32907,  1007,   719, 17823,  4467, 56079, 84459,  3950,  5149,\n",
              "            298,     2,     2]), tensor(0)),\n",
              " (tensor([26844,  1540,  1710,  1052,    49, 14343,   770,     2]), tensor(1)),\n",
              " (tensor([   37, 15134, 39031,  6654,  9659, 10758,     6, 15822,  7496, 49922,\n",
              "            886,    20,   242,     5,   100,     4,   596,   420]), tensor(1)),\n",
              " (tensor([   61,    41,    33,   100,   181, 34855,   222,    13,     6,   192,\n",
              "            362,   871,  1077,    59,    20,    73,    33,    29, 18804,     2,\n",
              "              2,  5228,  7113]), tensor(0)),\n",
              " (tensor([90539,  1974,  1382,   436,   142,   658,   232,  1602,  1382,  4385,\n",
              "           2143,     7,  3420,     2,     2,     2,     2]), tensor(1)),\n",
              " (tensor([11854,  2508,  2022,     4,   407,  4564,  1921,     6,   529,   628,\n",
              "             11,   796,   930,   246,     2]), tensor(1)),\n",
              " (tensor([33222, 42967, 83720, 40459,     5,  8863,     6,     0,  3818,  1176,\n",
              "              2]), tensor(1)),\n",
              " (tensor([    5,   127,    69,   117,   285,   111,   192,  1115,    69,    32,\n",
              "            564, 49922]), tensor(0)),\n",
              " (tensor([ 11035,      6,   1857,  34268,  12122,   1585,    934,    124,   1546,\n",
              "           10306,      4,   9490,  21068,      2,      2,      2,     11,  37171,\n",
              "          140511,      2]), tensor(0)),\n",
              " (tensor([1045,   14,   36,  675,   13, 1045,    2,   47,  675,   13, 1899,    2,\n",
              "            47,  675,   13, 6428,    2,   47,  675,   13, 9936,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([912]), tensor(0)),\n",
              " (tensor([5366, 2990,   34, 1233,   74,    0,  215, 5116,  555,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([16789,    13,  9298,     7, 11409,   115,    49,   314,   265,     3,\n",
              "          22312,  1763,    21,   607,    89,   325]), tensor(1)),\n",
              " (tensor([  263,   131,   117,     7, 10192,     5,  1950,   285,     2,   125,\n",
              "           3366,  1374]), tensor(0)),\n",
              " (tensor([   169,      7,    692,  16384,    415,   5670,     22, 231630,      4,\n",
              "             234,     13,     64,    884,    818,      2,      2]), tensor(0)),\n",
              " (tensor([ 19997,    682,      5,      0,    186,      2,      2,      2, 216177]),\n",
              "  tensor(0)),\n",
              " (tensor([16058,  4647,  1627]), tensor(0)),\n",
              " (tensor([3589, 6923,  484,   12,  256,  524, 1098,   21, 2731, 9923,  124, 2179,\n",
              "          2654,  255,  210,   11,   75,    0, 6255,    2,    2,    2,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([   41,    33,  1577,    89,   192,   213,    33,  1577,     6,   252,\n",
              "            111, 20727,    35,   635,    13,  4881,   111, 11343, 14733,     2,\n",
              "            738,   187]), tensor(1)),\n",
              " (tensor([  6305,    430,   7643,   5545,   7138,     22, 276395,    598,    313,\n",
              "              11,    430,   7643,   5545,      7,      2,      2,      2,      2]),\n",
              "  tensor(1)),\n",
              " (tensor([  6827, 103367,   6004,     10,    532,   1152,      2]), tensor(0)),\n",
              " (tensor([   0,  182,  395, 2005,    2, 1649,   14,   13,    0,    2,  203,    2]),\n",
              "  tensor(0)),\n",
              " (tensor([   20,  2146,   100, 27329,     2,   156,     3,     0,    85,  3496,\n",
              "              2, 16429,     2]), tensor(0)),\n",
              " (tensor([   484,   5954,   9347,   1892,     25,      7,    764,    954,  15173,\n",
              "            4799,     61, 134688,    540,    531,      7,  12846,      2,  67125,\n",
              "               2]), tensor(1)),\n",
              " (tensor([ 8036,     6,  1031, 12038,  5059,  2618,    11,    87,    69,    35,\n",
              "            256,    61,     7,  2546, 35067,     6, 14358,     2,     2,     2,\n",
              "              2]), tensor(1)),\n",
              " (tensor([ 47180,    322,    210,      7,    569,  38186, 286964,   2893,     21,\n",
              "               7,    461,    300,  10857,     17,   1374,     35,   7580,   3814,\n",
              "              18,    119,   3810,      6,    416,  17047]), tensor(1)),\n",
              " (tensor([   0, 6008,  238,   13, 8816,  583,   15,   25, 1248,    2,    0, 5351,\n",
              "           561,   12, 1313, 9397,   94,   30,  439,   73,  130, 1999,    2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 2749,   188,   188,  2749,   188,   188,  2749,   188,   188,   188,\n",
              "           2749,   188,   188,   188,  1523,  4469,  5059,   404,     6,  1643,\n",
              "            194,   576,  3913,    11, 10851,     2]), tensor(1)),\n",
              " (tensor([   29,  1452, 14094,  3238,     4,   433,    69,   662,   117,  3353,\n",
              "           1840,     2,    57,    11,   369,     3,  1115,  5008,  4214,  1519]),\n",
              "  tensor(0)),\n",
              " (tensor([  149, 60269]), tensor(0)),\n",
              " (tensor([  361,  2583, 18256,  2349,     3, 13053,  4065,  1763,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([  41,  824,   39,  807,  138,    7, 8525,    2]), tensor(0)),\n",
              " (tensor([  88,   81,  346,    0, 1357,  394,   22,  392, 9069,  188,   83,   36,\n",
              "          1712,  392, 8166,   46,  825,  865,    2]), tensor(0)),\n",
              " (tensor([  11,  580,   10, 1357,  522,    4,   30, 3111,    6, 2867,    2,    2,\n",
              "             2,   11,    2,    2]), tensor(1)),\n",
              " (tensor([14187,  7650,     2]), tensor(0)),\n",
              " (tensor([5551,   81,    2,  188,  188,  114,   41,   33,    7,  115, 1260, 9292,\n",
              "             2,  188,  188,  188,  188]), tensor(0)),\n",
              " (tensor([ 1716,    37,   922,   169, 19105,    60,    21,     7, 42967,     6,\n",
              "            124,     7,  1214,     2]), tensor(1)),\n",
              " (tensor([    7,   662,    22,    92,  1970,     7,    62,    49, 16281,     2]),\n",
              "  tensor(0)),\n",
              " (tensor([ 568, 3360,    4, 2561,  484,    2]), tensor(1)),\n",
              " (tensor([    3,  1960,     0,    58, 33345,    54,   346,    12,    63,    14,\n",
              "              7,  2232,   943,     2]), tensor(0)),\n",
              " (tensor([  197,    14,    37, 40484,   149,  2977, 55211,    37,  1647]),\n",
              "  tensor(0)),\n",
              " (tensor([ 1391,     5,  1236,    71,   137,     4,   111,    26,  1955,     5,\n",
              "           4731,    35,     5,  1691,     0,   325,  1370,     4,   242,   137,\n",
              "              4, 15790]), tensor(0)),\n",
              " (tensor([   86,   210,  3415, 15811,   500,     4,  5843,    58, 65817,  1523,\n",
              "              2]), tensor(1)),\n",
              " (tensor([  467, 12786,  7681,  1351,   721, 10968,  5400,    11,  6600,   172,\n",
              "              2]), tensor(1)),\n",
              " (tensor([   31,   120, 15733,   103,    63,   188,   188]), tensor(0)),\n",
              " (tensor([  114,    11, 42967,    11,   681, 16841,     2,     2]), tensor(0)),\n",
              " (tensor([    2, 15729,    84,  1078,     4,  1878, 75478, 25663,     6,  3050,\n",
              "              3,  7789,  5577, 30663,     2]), tensor(1)),\n",
              " (tensor([   7,  490, 1211,   14,    7, 5510]), tensor(1)),\n",
              " (tensor([22964,  9823,  5869,     4,   607,     6,     7,  1352,     5,  1894,\n",
              "           4005,     6,   545,     6,  2454,     2,     2,     2,     2,     2]),\n",
              "  tensor(1)),\n",
              " (tensor([ 1890, 17729,   469,    55,     2]), tensor(0)),\n",
              " (tensor([    45,     22,  16958,    913,    232, 175920,  29379,   1644,    386,\n",
              "             239,    687,   3558,   3708,      2,      2]), tensor(1))]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best3, \"best3\")"
      ],
      "metadata": {
        "id": "BHFxe3cd0U5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i, data in enumerate(test_l)\n",
        "#valid = [torch.['On plus side LOOK AT THE SKY LASY NIGHT IT WAS ABLAZE', 0]]\n",
        "line = ['On plus side LOOK AT THE SKY LASY NIGHT IT WAS ABLAZE',0]\n",
        "tweet = line[0]\n",
        "valid = []\n",
        "idxs = [glove.stoi[w]        # lookup the index of word\n",
        "        for w in split_tweet(tweet)\n",
        "        if w in glove.stoi] # keep words that has an embedding\n",
        "idxs = torch.tensor(idxs) # convert list to pytorch tensor\n",
        "label = torch.tensor(line[1]).long()\n",
        "#print(label)\n",
        "valid.append((idxs, label))\n",
        "val_l = TweetBatcher(valid, batch_size=1)\n",
        "for i, data in enumerate(val_l,0):\n",
        "  tweet, label = data\n",
        "  tweet, label = tweet.to(device), label.to(device)\n",
        "  tweet = tweet.squeeze(0)\n",
        "  for w in tweet:\n",
        "    print(glove.itos[w],end=\" \")\n",
        "  print(\"\")\n",
        "  out = network3(tweet.unsqueeze(0))\n",
        "  print([round(i,3) for i in F.softmax(out[-1], dim=-1).tolist()], onehot_labels[label].tolist())\n",
        "  if i > 10:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1LvBW_70yVS",
        "outputId": "49858256-94ff-4e05-cb06-a5437d98beb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on plus side look at the sky night it was ablaze \n",
            "[0.789, 0.211] [[1.0, 0.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best2,network2=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=1, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "id": "0kV9_EnfnaRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network2.load_state_dict(torch.load(\"//content//best2\"))\n",
        "network2.eval()\n",
        "print(len(train), len(test), len(valid))\n",
        "def get_data_loader(batch_size):\n",
        "  train_loader = TweetBatcher(train, batch_size=batch_size, drop_last=False)  \n",
        "  val_loader = TweetBatcher(valid, batch_size=batch_size, drop_last=False)  \n",
        "  test_loader = TweetBatcher(test, batch_size=batch_size, drop_last=False)  \n",
        "  return train_loader, val_loader, test_loader\n",
        "train_l, val_l, test_l = get_data_loader(64)\n",
        "\n",
        "print(get_accuracy(network2, val_l, criterion=nn.CrossEntropyLoss()))\n",
        "print(get_accuracy(network2, test_l, criterion=nn.CrossEntropyLoss()))\n",
        "print(get_accuracy(network2, train_l, criterion=nn.CrossEntropyLoss()))"
      ],
      "metadata": {
        "id": "UTHz-rwQykLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQsjvJpLuj94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_l.dataset))\n",
        "print(len(val_l.dataset))\n",
        "print(len(test_l.dataset))"
      ],
      "metadata": {
        "id": "5BOSsM2-sTAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best2, \"best2\")"
      ],
      "metadata": {
        "id": "6ZU6u2-Ywdc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best4,network4=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=1, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "UypIOrsOAawi",
        "outputId": "6dc7f616-0835-4752-cf05-98119cd633d9"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6519\n",
            "1087\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-cfc28f90fac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtune_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIGRatioNet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 81.6% val set epoch 12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-132-0fdad3987c28>\u001b[0m in \u001b[0;36mtune_network\u001b[0;34m(net, device, input_size, batch_size, embedding_size, hidden_size, lstm_input_size, lstm_layers, bidirectional, epochs, learning_rate, learning_rate_decay, dropout, momentum, weight_decay, adam, sanity_check, run_test)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best15,networK15=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=100, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ok2r4K7xRiPQ",
        "outputId": "57f002f7-539f-479b-8ed3-f3263c8ccf48"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6520\n",
            "1087\n",
            "1087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t\r 45/??\t\r 46/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5867,  653],\n",
            "        [2906, 3614]])\n",
            "tensor([[989,  98],\n",
            "        [454, 633]])\n",
            "Epoch: 0, Train Accuracy: 0.77178, Train Loss: 0.47457, Validation Accuracy: 0.77093, Validation Loss: 0.44732, prediction: [0.156, 0.844], true label: [0.0, 1.0]\n",
            "0.7709291628334867 0\n",
            "best_state_dict updated\n",
            "tensor([[5873,  647],\n",
            "        [2579, 3941]])\n",
            "tensor([[971, 116],\n",
            "        [428, 659]])\n",
            "Epoch: 1, Train Accuracy: 0.78758, Train Loss: 0.45169, Validation Accuracy: 0.78197, Validation Loss: 0.41632, prediction: [0.565, 0.435], true label: [1.0, 0.0]\n",
            "0.7819687212511499 0.7709291628334867\n",
            "best_state_dict updated\n",
            "tensor([[5919,  601],\n",
            "        [2561, 3959]])\n",
            "tensor([[980, 107],\n",
            "        [434, 653]])\n",
            "Epoch: 2, Train Accuracy: 0.80000, Train Loss: 0.43182, Validation Accuracy: 0.79393, Validation Loss: 0.40595, prediction: [0.701, 0.299], true label: [1.0, 0.0]\n",
            "0.7939282428702852 0.7819687212511499\n",
            "best_state_dict updated\n",
            "tensor([[5941,  579],\n",
            "        [2298, 4222]])\n",
            "tensor([[967, 120],\n",
            "        [408, 679]])\n",
            "Epoch: 3, Train Accuracy: 0.80982, Train Loss: 0.40820, Validation Accuracy: 0.80405, Validation Loss: 0.39733, prediction: [0.861, 0.139], true label: [1.0, 0.0]\n",
            "0.8040478380864765 0.7939282428702852\n",
            "best_state_dict updated\n",
            "tensor([[5944,  576],\n",
            "        [2235, 4285]])\n",
            "tensor([[966, 121],\n",
            "        [392, 695]])\n",
            "Epoch: 4, Train Accuracy: 0.81840, Train Loss: 0.39341, Validation Accuracy: 0.79485, Validation Loss: 0.37916, prediction: [0.794, 0.206], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.8040478380864765\n",
            "tensor([[6022,  498],\n",
            "        [2152, 4368]])\n",
            "tensor([[968, 119],\n",
            "        [380, 707]])\n",
            "Epoch: 5, Train Accuracy: 0.82730, Train Loss: 0.37637, Validation Accuracy: 0.79669, Validation Loss: 0.39080, prediction: [0.521, 0.479], true label: [1.0, 0.0]\n",
            "0.796688132474701 0.8040478380864765\n",
            "tensor([[5948,  572],\n",
            "        [1885, 4635]])\n",
            "tensor([[956, 131],\n",
            "        [351, 736]])\n",
            "Epoch: 6, Train Accuracy: 0.83804, Train Loss: 0.35715, Validation Accuracy: 0.79853, Validation Loss: 0.40184, prediction: [0.56, 0.44], true label: [0.0, 1.0]\n",
            "0.7985280588776449 0.8040478380864765\n",
            "tensor([[6118,  402],\n",
            "        [1946, 4574]])\n",
            "tensor([[974, 113],\n",
            "        [382, 705]])\n",
            "Epoch: 7, Train Accuracy: 0.85353, Train Loss: 0.33975, Validation Accuracy: 0.79393, Validation Loss: 0.39496, prediction: [0.221, 0.779], true label: [1.0, 0.0]\n",
            "0.7939282428702852 0.8040478380864765\n",
            "tensor([[6015,  505],\n",
            "        [1588, 4932]])\n",
            "tensor([[959, 128],\n",
            "        [331, 756]])\n",
            "Epoch: 8, Train Accuracy: 0.86089, Train Loss: 0.31869, Validation Accuracy: 0.80037, Validation Loss: 0.39132, prediction: [0.9, 0.1], true label: [1.0, 0.0]\n",
            "0.8003679852805887 0.8040478380864765\n",
            "tensor([[6127,  393],\n",
            "        [1497, 5023]])\n",
            "tensor([[957, 130],\n",
            "        [339, 748]])\n",
            "Epoch: 9, Train Accuracy: 0.88021, Train Loss: 0.28890, Validation Accuracy: 0.80681, Validation Loss: 0.38849, prediction: [0.947, 0.053], true label: [0.0, 1.0]\n",
            "0.8068077276908924 0.8040478380864765\n",
            "best_state_dict updated\n",
            "tensor([[6066,  454],\n",
            "        [1363, 5157]])\n",
            "tensor([[933, 154],\n",
            "        [321, 766]])\n",
            "Epoch: 10, Train Accuracy: 0.87439, Train Loss: 0.27919, Validation Accuracy: 0.80221, Validation Loss: 0.43164, prediction: [0.968, 0.032], true label: [1.0, 0.0]\n",
            "0.8022079116835327 0.8068077276908924\n",
            "tensor([[6167,  353],\n",
            "        [1208, 5312]])\n",
            "tensor([[946, 141],\n",
            "        [322, 765]])\n",
            "Epoch: 11, Train Accuracy: 0.89862, Train Loss: 0.24737, Validation Accuracy: 0.80681, Validation Loss: 0.41713, prediction: [0.649, 0.351], true label: [0.0, 1.0]\n",
            "0.8068077276908924 0.8068077276908924\n",
            "tensor([[6052,  468],\n",
            "        [1373, 5147]])\n",
            "tensor([[909, 178],\n",
            "        [317, 770]])\n",
            "Epoch: 12, Train Accuracy: 0.87147, Train Loss: 0.27331, Validation Accuracy: 0.78381, Validation Loss: 0.46548, prediction: [0.657, 0.343], true label: [0.0, 1.0]\n",
            "0.7838086476540939 0.8068077276908924\n",
            "tensor([[6242,  278],\n",
            "        [ 816, 5704]])\n",
            "tensor([[939, 148],\n",
            "        [280, 807]])\n",
            "Epoch: 13, Train Accuracy: 0.92761, Train Loss: 0.18489, Validation Accuracy: 0.80589, Validation Loss: 0.43917, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8068077276908924\n",
            "tensor([[6288,  232],\n",
            "        [ 733, 5787]])\n",
            "tensor([[940, 147],\n",
            "        [276, 811]])\n",
            "Epoch: 14, Train Accuracy: 0.93666, Train Loss: 0.16444, Validation Accuracy: 0.81509, Validation Loss: 0.39092, prediction: [0.971, 0.029], true label: [1.0, 0.0]\n",
            "0.8150873965041399 0.8068077276908924\n",
            "best_state_dict updated\n",
            "tensor([[6328,  192],\n",
            "        [ 621, 5899]])\n",
            "tensor([[936, 151],\n",
            "        [276, 811]])\n",
            "Epoch: 15, Train Accuracy: 0.95077, Train Loss: 0.14054, Validation Accuracy: 0.81049, Validation Loss: 0.41790, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8104875804967802 0.8150873965041399\n",
            "tensor([[6331,  189],\n",
            "        [ 582, 5938]])\n",
            "tensor([[926, 161],\n",
            "        [272, 815]])\n",
            "Epoch: 16, Train Accuracy: 0.94923, Train Loss: 0.13964, Validation Accuracy: 0.81141, Validation Loss: 0.44643, prediction: [0.964, 0.036], true label: [1.0, 0.0]\n",
            "0.8114075436982521 0.8150873965041399\n",
            "tensor([[6282,  238],\n",
            "        [ 742, 5778]])\n",
            "tensor([[909, 178],\n",
            "        [291, 796]])\n",
            "Epoch: 17, Train Accuracy: 0.92945, Train Loss: 0.17738, Validation Accuracy: 0.79393, Validation Loss: 0.52720, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.8150873965041399\n",
            "tensor([[6387,  133],\n",
            "        [ 449, 6071]])\n",
            "tensor([[919, 168],\n",
            "        [261, 826]])\n",
            "Epoch: 18, Train Accuracy: 0.96350, Train Loss: 0.11160, Validation Accuracy: 0.81141, Validation Loss: 0.50550, prediction: [0.971, 0.029], true label: [1.0, 0.0]\n",
            "0.8114075436982521 0.8150873965041399\n",
            "tensor([[6402,  118],\n",
            "        [ 372, 6148]])\n",
            "tensor([[930, 157],\n",
            "        [258, 829]])\n",
            "Epoch: 19, Train Accuracy: 0.96718, Train Loss: 0.09935, Validation Accuracy: 0.81877, Validation Loss: 0.46467, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.8187672493100276 0.8150873965041399\n",
            "best_state_dict updated\n",
            "tensor([[6033,  487],\n",
            "        [ 971, 5549]])\n",
            "tensor([[884, 203],\n",
            "        [270, 817]])\n",
            "Epoch: 20, Train Accuracy: 0.89356, Train Loss: 0.23072, Validation Accuracy: 0.78473, Validation Loss: 0.62877, prediction: [0.987, 0.013], true label: [1.0, 0.0]\n",
            "0.7847286108555658 0.8187672493100276\n",
            "tensor([[6424,   96],\n",
            "        [ 343, 6177]])\n",
            "tensor([[909, 178],\n",
            "        [258, 829]])\n",
            "Epoch: 21, Train Accuracy: 0.97377, Train Loss: 0.07933, Validation Accuracy: 0.80681, Validation Loss: 0.51490, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8068077276908924 0.8187672493100276\n",
            "tensor([[6362,  158],\n",
            "        [ 423, 6097]])\n",
            "tensor([[922, 165],\n",
            "        [241, 846]])\n",
            "Epoch: 22, Train Accuracy: 0.95951, Train Loss: 0.10142, Validation Accuracy: 0.81969, Validation Loss: 0.55052, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.8196872125114996 0.8187672493100276\n",
            "best_state_dict updated\n",
            "tensor([[6427,   93],\n",
            "        [ 280, 6240]])\n",
            "tensor([[909, 178],\n",
            "        [245, 842]])\n",
            "Epoch: 23, Train Accuracy: 0.97638, Train Loss: 0.08282, Validation Accuracy: 0.80681, Validation Loss: 0.53047, prediction: [0.99, 0.01], true label: [1.0, 0.0]\n",
            "0.8068077276908924 0.8196872125114996\n",
            "tensor([[6409,  111],\n",
            "        [ 288, 6232]])\n",
            "tensor([[925, 162],\n",
            "        [242, 845]])\n",
            "Epoch: 24, Train Accuracy: 0.97285, Train Loss: 0.07300, Validation Accuracy: 0.81233, Validation Loss: 0.58915, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.812327506899724 0.8196872125114996\n",
            "tensor([[6451,   69],\n",
            "        [ 245, 6275]])\n",
            "tensor([[917, 170],\n",
            "        [242, 845]])\n",
            "Epoch: 25, Train Accuracy: 0.97761, Train Loss: 0.06120, Validation Accuracy: 0.80957, Validation Loss: 0.54308, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8095676172953082 0.8196872125114996\n",
            "tensor([[6455,   65],\n",
            "        [ 243, 6277]])\n",
            "tensor([[918, 169],\n",
            "        [244, 843]])\n",
            "Epoch: 26, Train Accuracy: 0.97868, Train Loss: 0.05758, Validation Accuracy: 0.80865, Validation Loss: 0.63271, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8086476540938362 0.8196872125114996\n",
            "tensor([[6453,   67],\n",
            "        [ 251, 6269]])\n",
            "tensor([[907, 180],\n",
            "        [240, 847]])\n",
            "Epoch: 27, Train Accuracy: 0.97868, Train Loss: 0.05697, Validation Accuracy: 0.80865, Validation Loss: 0.59944, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.8086476540938362 0.8196872125114996\n",
            "tensor([[6450,   70],\n",
            "        [ 236, 6284]])\n",
            "tensor([[909, 178],\n",
            "        [246, 841]])\n",
            "Epoch: 28, Train Accuracy: 0.97945, Train Loss: 0.05752, Validation Accuracy: 0.80405, Validation Loss: 0.61623, prediction: [0.962, 0.038], true label: [1.0, 0.0]\n",
            "0.8040478380864765 0.8196872125114996\n",
            "tensor([[6437,   83],\n",
            "        [ 226, 6294]])\n",
            "tensor([[918, 169],\n",
            "        [232, 855]])\n",
            "Epoch: 29, Train Accuracy: 0.97853, Train Loss: 0.05975, Validation Accuracy: 0.81509, Validation Loss: 0.57798, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8150873965041399 0.8196872125114996\n",
            "tensor([[6407,  113],\n",
            "        [ 279, 6241]])\n",
            "tensor([[919, 168],\n",
            "        [227, 860]])\n",
            "Epoch: 30, Train Accuracy: 0.97515, Train Loss: 0.07546, Validation Accuracy: 0.82061, Validation Loss: 0.58263, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8206071757129715 0.8196872125114996\n",
            "best_state_dict updated\n",
            "tensor([[6450,   70],\n",
            "        [ 218, 6302]])\n",
            "tensor([[911, 176],\n",
            "        [249, 838]])\n",
            "Epoch: 31, Train Accuracy: 0.98006, Train Loss: 0.05863, Validation Accuracy: 0.80405, Validation Loss: 0.62659, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.8040478380864765 0.8206071757129715\n",
            "tensor([[6452,   68],\n",
            "        [ 214, 6306]])\n",
            "tensor([[917, 170],\n",
            "        [236, 851]])\n",
            "Epoch: 32, Train Accuracy: 0.98006, Train Loss: 0.05208, Validation Accuracy: 0.81049, Validation Loss: 0.68554, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8104875804967802 0.8206071757129715\n",
            "tensor([[6460,   60],\n",
            "        [ 209, 6311]])\n",
            "tensor([[918, 169],\n",
            "        [244, 843]])\n",
            "Epoch: 33, Train Accuracy: 0.98098, Train Loss: 0.05081, Validation Accuracy: 0.81601, Validation Loss: 0.56343, prediction: [0.014, 0.986], true label: [0.0, 1.0]\n",
            "0.8160073597056118 0.8206071757129715\n",
            "tensor([[6451,   69],\n",
            "        [ 197, 6323]])\n",
            "tensor([[919, 168],\n",
            "        [234, 853]])\n",
            "Epoch: 34, Train Accuracy: 0.98083, Train Loss: 0.05367, Validation Accuracy: 0.82061, Validation Loss: 0.60122, prediction: [0.955, 0.045], true label: [1.0, 0.0]\n",
            "0.8206071757129715 0.8206071757129715\n",
            "tensor([[6431,   89],\n",
            "        [ 239, 6281]])\n",
            "tensor([[892, 195],\n",
            "        [244, 843]])\n",
            "Epoch: 35, Train Accuracy: 0.97730, Train Loss: 0.06286, Validation Accuracy: 0.80589, Validation Loss: 0.62411, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8206071757129715\n",
            "tensor([[6463,   57],\n",
            "        [ 211, 6309]])\n",
            "tensor([[917, 170],\n",
            "        [241, 846]])\n",
            "Epoch: 36, Train Accuracy: 0.98206, Train Loss: 0.04912, Validation Accuracy: 0.81417, Validation Loss: 0.59556, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8141674333026679 0.8206071757129715\n",
            "tensor([[6451,   69],\n",
            "        [ 197, 6323]])\n",
            "tensor([[907, 180],\n",
            "        [240, 847]])\n",
            "Epoch: 37, Train Accuracy: 0.98175, Train Loss: 0.05139, Validation Accuracy: 0.80589, Validation Loss: 0.62819, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8206071757129715\n",
            "tensor([[6427,   93],\n",
            "        [ 225, 6295]])\n",
            "tensor([[919, 168],\n",
            "        [239, 848]])\n",
            "Epoch: 38, Train Accuracy: 0.97883, Train Loss: 0.05750, Validation Accuracy: 0.81877, Validation Loss: 0.59374, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.8187672493100276 0.8206071757129715\n",
            "tensor([[6456,   64],\n",
            "        [ 202, 6318]])\n",
            "tensor([[901, 186],\n",
            "        [243, 844]])\n",
            "Epoch: 39, Train Accuracy: 0.98190, Train Loss: 0.05107, Validation Accuracy: 0.80221, Validation Loss: 0.75272, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8022079116835327 0.8206071757129715\n",
            "tensor([[6463,   57],\n",
            "        [ 201, 6319]])\n",
            "tensor([[915, 172],\n",
            "        [239, 848]])\n",
            "Epoch: 40, Train Accuracy: 0.98190, Train Loss: 0.04580, Validation Accuracy: 0.80865, Validation Loss: 0.66596, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8086476540938362 0.8206071757129715\n",
            "tensor([[6438,   82],\n",
            "        [ 212, 6308]])\n",
            "tensor([[922, 165],\n",
            "        [233, 854]])\n",
            "Epoch: 41, Train Accuracy: 0.98083, Train Loss: 0.05168, Validation Accuracy: 0.82429, Validation Loss: 0.68492, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8242870285188593 0.8206071757129715\n",
            "best_state_dict updated\n",
            "tensor([[6453,   67],\n",
            "        [ 196, 6324]])\n",
            "tensor([[901, 186],\n",
            "        [237, 850]])\n",
            "Epoch: 42, Train Accuracy: 0.98221, Train Loss: 0.04929, Validation Accuracy: 0.80773, Validation Loss: 0.66721, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8077276908923643 0.8242870285188593\n",
            "tensor([[6465,   55],\n",
            "        [ 216, 6304]])\n",
            "tensor([[908, 179],\n",
            "        [236, 851]])\n",
            "Epoch: 43, Train Accuracy: 0.98252, Train Loss: 0.05416, Validation Accuracy: 0.80865, Validation Loss: 0.62578, prediction: [0.42, 0.58], true label: [1.0, 0.0]\n",
            "0.8086476540938362 0.8242870285188593\n",
            "tensor([[6462,   58],\n",
            "        [ 206, 6314]])\n",
            "tensor([[899, 188],\n",
            "        [236, 851]])\n",
            "Epoch: 44, Train Accuracy: 0.98129, Train Loss: 0.04706, Validation Accuracy: 0.80773, Validation Loss: 0.65908, prediction: [0.889, 0.111], true label: [1.0, 0.0]\n",
            "0.8077276908923643 0.8242870285188593\n",
            "tensor([[6454,   66],\n",
            "        [ 198, 6322]])\n",
            "tensor([[901, 186],\n",
            "        [239, 848]])\n",
            "Epoch: 45, Train Accuracy: 0.98160, Train Loss: 0.04710, Validation Accuracy: 0.80589, Validation Loss: 0.65060, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8242870285188593\n",
            "tensor([[6467,   53],\n",
            "        [ 199, 6321]])\n",
            "tensor([[914, 173],\n",
            "        [236, 851]])\n",
            "Epoch: 46, Train Accuracy: 0.98083, Train Loss: 0.04576, Validation Accuracy: 0.80957, Validation Loss: 0.64058, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8095676172953082 0.8242870285188593\n",
            "tensor([[6454,   66],\n",
            "        [ 190, 6330]])\n",
            "tensor([[925, 162],\n",
            "        [235, 852]])\n",
            "Epoch: 47, Train Accuracy: 0.98252, Train Loss: 0.04501, Validation Accuracy: 0.82153, Validation Loss: 0.66298, prediction: [0.951, 0.049], true label: [0.0, 1.0]\n",
            "0.8215271389144434 0.8242870285188593\n",
            "tensor([[6449,   71],\n",
            "        [ 192, 6328]])\n",
            "tensor([[893, 194],\n",
            "        [237, 850]])\n",
            "Epoch: 48, Train Accuracy: 0.98052, Train Loss: 0.05290, Validation Accuracy: 0.80589, Validation Loss: 0.65530, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8242870285188593\n",
            "tensor([[6471,   49],\n",
            "        [ 207, 6313]])\n",
            "tensor([[899, 188],\n",
            "        [233, 854]])\n",
            "Epoch: 49, Train Accuracy: 0.98160, Train Loss: 0.04638, Validation Accuracy: 0.80773, Validation Loss: 0.65645, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8077276908923643 0.8242870285188593\n",
            "tensor([[6442,   78],\n",
            "        [ 179, 6341]])\n",
            "tensor([[918, 169],\n",
            "        [228, 859]])\n",
            "Epoch: 50, Train Accuracy: 0.98144, Train Loss: 0.04982, Validation Accuracy: 0.82337, Validation Loss: 0.62940, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8233670653173873 0.8242870285188593\n",
            "tensor([[6459,   61],\n",
            "        [ 183, 6337]])\n",
            "tensor([[921, 166],\n",
            "        [233, 854]])\n",
            "Epoch: 51, Train Accuracy: 0.98221, Train Loss: 0.04569, Validation Accuracy: 0.82061, Validation Loss: 0.63525, prediction: [0.336, 0.664], true label: [0.0, 1.0]\n",
            "0.8206071757129715 0.8242870285188593\n",
            "tensor([[6413,  107],\n",
            "        [ 284, 6236]])\n",
            "tensor([[887, 200],\n",
            "        [260, 827]])\n",
            "Epoch: 52, Train Accuracy: 0.97377, Train Loss: 0.06896, Validation Accuracy: 0.79485, Validation Loss: 0.75567, prediction: [0.598, 0.402], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.8242870285188593\n",
            "tensor([[6449,   71],\n",
            "        [ 180, 6340]])\n",
            "tensor([[921, 166],\n",
            "        [223, 864]])\n",
            "Epoch: 53, Train Accuracy: 0.98190, Train Loss: 0.04739, Validation Accuracy: 0.82521, Validation Loss: 0.62144, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8252069917203312 0.8242870285188593\n",
            "best_state_dict updated\n",
            "tensor([[6460,   60],\n",
            "        [ 202, 6318]])\n",
            "tensor([[896, 191],\n",
            "        [251, 836]])\n",
            "Epoch: 54, Train Accuracy: 0.98282, Train Loss: 0.04517, Validation Accuracy: 0.80313, Validation Loss: 0.74006, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8031278748850046 0.8252069917203312\n",
            "tensor([[6446,   74],\n",
            "        [ 185, 6335]])\n",
            "tensor([[910, 177],\n",
            "        [233, 854]])\n",
            "Epoch: 55, Train Accuracy: 0.98190, Train Loss: 0.04772, Validation Accuracy: 0.81601, Validation Loss: 0.68564, prediction: [0.984, 0.016], true label: [1.0, 0.0]\n",
            "0.8160073597056118 0.8252069917203312\n",
            "tensor([[6457,   63],\n",
            "        [ 171, 6349]])\n",
            "tensor([[915, 172],\n",
            "        [234, 853]])\n",
            "Epoch: 56, Train Accuracy: 0.98298, Train Loss: 0.04216, Validation Accuracy: 0.81325, Validation Loss: 0.67812, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8132474701011959 0.8252069917203312\n",
            "tensor([[6465,   55],\n",
            "        [ 177, 6343]])\n",
            "tensor([[905, 182],\n",
            "        [235, 852]])\n",
            "Epoch: 57, Train Accuracy: 0.98359, Train Loss: 0.04138, Validation Accuracy: 0.80957, Validation Loss: 0.66379, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.8095676172953082 0.8252069917203312\n",
            "tensor([[6447,   73],\n",
            "        [ 215, 6305]])\n",
            "tensor([[898, 189],\n",
            "        [245, 842]])\n",
            "Epoch: 58, Train Accuracy: 0.97699, Train Loss: 0.05274, Validation Accuracy: 0.80497, Validation Loss: 0.70862, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8049678012879485 0.8252069917203312\n",
            "tensor([[6427,   93],\n",
            "        [ 220, 6300]])\n",
            "tensor([[894, 193],\n",
            "        [244, 843]])\n",
            "Epoch: 59, Train Accuracy: 0.97669, Train Loss: 0.05466, Validation Accuracy: 0.80589, Validation Loss: 0.72133, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8058877644894205 0.8252069917203312\n",
            "tensor([[6418,  102],\n",
            "        [ 218, 6302]])\n",
            "tensor([[917, 170],\n",
            "        [222, 865]])\n",
            "Epoch: 60, Train Accuracy: 0.97776, Train Loss: 0.05991, Validation Accuracy: 0.82061, Validation Loss: 0.66166, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8206071757129715 0.8252069917203312\n",
            "tensor([[6476,   44],\n",
            "        [ 189, 6331]])\n",
            "tensor([[909, 178],\n",
            "        [234, 853]])\n",
            "Epoch: 61, Train Accuracy: 0.98436, Train Loss: 0.04509, Validation Accuracy: 0.80773, Validation Loss: 0.69533, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8077276908923643 0.8252069917203312\n",
            "tensor([[6441,   79],\n",
            "        [ 176, 6344]])\n",
            "tensor([[921, 166],\n",
            "        [232, 855]])\n",
            "Epoch: 62, Train Accuracy: 0.98236, Train Loss: 0.04360, Validation Accuracy: 0.82245, Validation Loss: 0.68342, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.8224471021159153 0.8252069917203312\n",
            "tensor([[6480,   40],\n",
            "        [ 191, 6329]])\n",
            "tensor([[908, 179],\n",
            "        [229, 858]])\n",
            "Epoch: 63, Train Accuracy: 0.98451, Train Loss: 0.03742, Validation Accuracy: 0.81141, Validation Loss: 0.66636, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8114075436982521 0.8252069917203312\n",
            "tensor([[6476,   44],\n",
            "        [ 178, 6342]])\n",
            "tensor([[907, 180],\n",
            "        [231, 856]])\n",
            "Epoch: 64, Train Accuracy: 0.98359, Train Loss: 0.03563, Validation Accuracy: 0.81049, Validation Loss: 0.63643, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.8104875804967802 0.8252069917203312\n",
            "tensor([[6466,   54],\n",
            "        [ 170, 6350]])\n",
            "tensor([[914, 173],\n",
            "        [235, 852]])\n",
            "Epoch: 65, Train Accuracy: 0.98374, Train Loss: 0.03754, Validation Accuracy: 0.82429, Validation Loss: 0.65902, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8242870285188593 0.8252069917203312\n",
            "tensor([[6474,   46],\n",
            "        [ 176, 6344]])\n",
            "tensor([[905, 182],\n",
            "        [227, 860]])\n",
            "Epoch: 66, Train Accuracy: 0.98451, Train Loss: 0.03843, Validation Accuracy: 0.80773, Validation Loss: 0.66187, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8077276908923643 0.8252069917203312\n",
            "tensor([[6474,   46],\n",
            "        [ 170, 6350]])\n",
            "tensor([[916, 171],\n",
            "        [231, 856]])\n",
            "Epoch: 67, Train Accuracy: 0.98466, Train Loss: 0.03672, Validation Accuracy: 0.81509, Validation Loss: 0.66631, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8150873965041399 0.8252069917203312\n",
            "tensor([[6472,   48],\n",
            "        [ 180, 6340]])\n",
            "tensor([[913, 174],\n",
            "        [226, 861]])\n",
            "Epoch: 68, Train Accuracy: 0.98374, Train Loss: 0.03644, Validation Accuracy: 0.81693, Validation Loss: 0.62162, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8169273229070837 0.8252069917203312\n",
            "tensor([[6480,   40],\n",
            "        [ 176, 6344]])\n",
            "tensor([[909, 178],\n",
            "        [233, 854]])\n",
            "Epoch: 69, Train Accuracy: 0.98482, Train Loss: 0.03410, Validation Accuracy: 0.81417, Validation Loss: 0.69969, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8141674333026679 0.8252069917203312\n",
            "tensor([[6473,   47],\n",
            "        [ 188, 6332]])\n",
            "tensor([[919, 168],\n",
            "        [230, 857]])\n",
            "Epoch: 70, Train Accuracy: 0.98344, Train Loss: 0.03790, Validation Accuracy: 0.81509, Validation Loss: 0.67274, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8150873965041399 0.8252069917203312\n",
            "tensor([[6475,   45],\n",
            "        [ 189, 6331]])\n",
            "tensor([[906, 181],\n",
            "        [235, 852]])\n",
            "Epoch: 71, Train Accuracy: 0.98298, Train Loss: 0.03972, Validation Accuracy: 0.80497, Validation Loss: 0.68331, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8049678012879485 0.8252069917203312\n",
            "tensor([[6477,   43],\n",
            "        [ 180, 6340]])\n",
            "tensor([[902, 185],\n",
            "        [237, 850]])\n",
            "Epoch: 72, Train Accuracy: 0.98451, Train Loss: 0.03848, Validation Accuracy: 0.81049, Validation Loss: 0.66093, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8104875804967802 0.8252069917203312\n",
            "tensor([[6485,   35],\n",
            "        [ 189, 6331]])\n",
            "tensor([[908, 179],\n",
            "        [230, 857]])\n",
            "Epoch: 73, Train Accuracy: 0.98466, Train Loss: 0.03745, Validation Accuracy: 0.81509, Validation Loss: 0.71936, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.8150873965041399 0.8252069917203312\n",
            "tensor([[6458,   62],\n",
            "        [ 203, 6317]])\n",
            "tensor([[901, 186],\n",
            "        [238, 849]])\n",
            "Epoch: 74, Train Accuracy: 0.98129, Train Loss: 0.04607, Validation Accuracy: 0.80497, Validation Loss: 0.71840, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8049678012879485 0.8252069917203312\n",
            "tensor([[6464,   56],\n",
            "        [ 175, 6345]])\n",
            "tensor([[907, 180],\n",
            "        [236, 851]])\n",
            "Epoch: 75, Train Accuracy: 0.98436, Train Loss: 0.03706, Validation Accuracy: 0.80681, Validation Loss: 0.69008, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8068077276908924 0.8252069917203312\n",
            "tensor([[6476,   44],\n",
            "        [ 167, 6353]])\n",
            "tensor([[910, 177],\n",
            "        [225, 862]])\n",
            "Epoch: 76, Train Accuracy: 0.98482, Train Loss: 0.03426, Validation Accuracy: 0.81233, Validation Loss: 0.67166, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.812327506899724 0.8252069917203312\n",
            "tensor([[6468,   52],\n",
            "        [ 167, 6353]])\n",
            "tensor([[908, 179],\n",
            "        [233, 854]])\n",
            "Epoch: 77, Train Accuracy: 0.98405, Train Loss: 0.03564, Validation Accuracy: 0.80957, Validation Loss: 0.77906, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8095676172953082 0.8252069917203312\n",
            "tensor([[6463,   57],\n",
            "        [ 165, 6355]])\n",
            "tensor([[903, 184],\n",
            "        [226, 861]])\n",
            "Epoch: 78, Train Accuracy: 0.98436, Train Loss: 0.04008, Validation Accuracy: 0.81141, Validation Loss: 0.75160, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8114075436982521 0.8252069917203312\n",
            "tensor([[6473,   47],\n",
            "        [ 169, 6351]])\n",
            "tensor([[907, 180],\n",
            "        [229, 858]])\n",
            "Epoch: 79, Train Accuracy: 0.98451, Train Loss: 0.03692, Validation Accuracy: 0.81325, Validation Loss: 0.66763, prediction: [0.341, 0.659], true label: [1.0, 0.0]\n",
            "0.8132474701011959 0.8252069917203312\n",
            "tensor([[6476,   44],\n",
            "        [ 173, 6347]])\n",
            "tensor([[925, 162],\n",
            "        [230, 857]])\n",
            "Epoch: 80, Train Accuracy: 0.98451, Train Loss: 0.03517, Validation Accuracy: 0.82061, Validation Loss: 0.66484, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8206071757129715 0.8252069917203312\n",
            "tensor([[6467,   53],\n",
            "        [ 169, 6351]])\n",
            "tensor([[912, 175],\n",
            "        [227, 860]])\n",
            "Epoch: 81, Train Accuracy: 0.98420, Train Loss: 0.03566, Validation Accuracy: 0.81509, Validation Loss: 0.68922, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8150873965041399 0.8252069917203312\n",
            "tensor([[6464,   56],\n",
            "        [ 185, 6335]])\n",
            "tensor([[910, 177],\n",
            "        [233, 854]])\n",
            "Epoch: 82, Train Accuracy: 0.98221, Train Loss: 0.03981, Validation Accuracy: 0.81141, Validation Loss: 0.67844, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8114075436982521 0.8252069917203312\n",
            "tensor([[6475,   45],\n",
            "        [ 169, 6351]])\n",
            "tensor([[921, 166],\n",
            "        [223, 864]])\n",
            "Epoch: 83, Train Accuracy: 0.98466, Train Loss: 0.03309, Validation Accuracy: 0.82153, Validation Loss: 0.72952, prediction: [0.015, 0.985], true label: [0.0, 1.0]\n",
            "0.8215271389144434 0.8252069917203312\n",
            "tensor([[6462,   58],\n",
            "        [ 156, 6364]])\n",
            "tensor([[917, 170],\n",
            "        [223, 864]])\n",
            "Epoch: 84, Train Accuracy: 0.98451, Train Loss: 0.03448, Validation Accuracy: 0.81693, Validation Loss: 0.65217, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8169273229070837 0.8252069917203312\n",
            "tensor([[6476,   44],\n",
            "        [ 168, 6352]])\n",
            "tensor([[921, 166],\n",
            "        [220, 867]])\n",
            "Epoch: 85, Train Accuracy: 0.98436, Train Loss: 0.03300, Validation Accuracy: 0.82613, Validation Loss: 0.68281, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8261269549218031 0.8252069917203312\n",
            "best_state_dict updated\n",
            "tensor([[6451,   69],\n",
            "        [ 185, 6335]])\n",
            "tensor([[904, 183],\n",
            "        [231, 856]])\n",
            "Epoch: 86, Train Accuracy: 0.98129, Train Loss: 0.04217, Validation Accuracy: 0.80129, Validation Loss: 0.69359, prediction: [0.984, 0.016], true label: [1.0, 0.0]\n",
            "0.8012879484820608 0.8261269549218031\n",
            "tensor([[6479,   41],\n",
            "        [ 174, 6346]])\n",
            "tensor([[912, 175],\n",
            "        [233, 854]])\n",
            "Epoch: 87, Train Accuracy: 0.98451, Train Loss: 0.03220, Validation Accuracy: 0.81325, Validation Loss: 0.68479, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8132474701011959 0.8261269549218031\n",
            "tensor([[6473,   47],\n",
            "        [ 159, 6361]])\n",
            "tensor([[918, 169],\n",
            "        [226, 861]])\n",
            "Epoch: 88, Train Accuracy: 0.98528, Train Loss: 0.03002, Validation Accuracy: 0.82337, Validation Loss: 0.65981, prediction: [0.989, 0.011], true label: [1.0, 0.0]\n",
            "0.8233670653173873 0.8261269549218031\n",
            "tensor([[6473,   47],\n",
            "        [ 182, 6338]])\n",
            "tensor([[906, 181],\n",
            "        [238, 849]])\n",
            "Epoch: 89, Train Accuracy: 0.98328, Train Loss: 0.03657, Validation Accuracy: 0.80129, Validation Loss: 0.71838, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8012879484820608 0.8261269549218031\n",
            "tensor([[6468,   52],\n",
            "        [ 173, 6347]])\n",
            "tensor([[921, 166],\n",
            "        [222, 865]])\n",
            "Epoch: 90, Train Accuracy: 0.98390, Train Loss: 0.03391, Validation Accuracy: 0.82429, Validation Loss: 0.70904, prediction: [0.666, 0.334], true label: [0.0, 1.0]\n",
            "0.8242870285188593 0.8261269549218031\n",
            "tensor([[6486,   34],\n",
            "        [ 163, 6357]])\n",
            "tensor([[916, 171],\n",
            "        [224, 863]])\n",
            "Epoch: 91, Train Accuracy: 0.98589, Train Loss: 0.02977, Validation Accuracy: 0.82337, Validation Loss: 0.68507, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8233670653173873 0.8261269549218031\n",
            "tensor([[6472,   48],\n",
            "        [ 146, 6374]])\n",
            "tensor([[911, 176],\n",
            "        [225, 862]])\n",
            "Epoch: 92, Train Accuracy: 0.98635, Train Loss: 0.02965, Validation Accuracy: 0.81417, Validation Loss: 0.79988, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8141674333026679 0.8261269549218031\n",
            "tensor([[6478,   42],\n",
            "        [ 198, 6322]])\n",
            "tensor([[906, 181],\n",
            "        [231, 856]])\n",
            "Epoch: 93, Train Accuracy: 0.98405, Train Loss: 0.03662, Validation Accuracy: 0.80957, Validation Loss: 0.71315, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.8095676172953082 0.8261269549218031\n",
            "tensor([[6480,   40],\n",
            "        [ 165, 6355]])\n",
            "tensor([[915, 172],\n",
            "        [222, 865]])\n",
            "Epoch: 94, Train Accuracy: 0.98558, Train Loss: 0.03195, Validation Accuracy: 0.82337, Validation Loss: 0.69654, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8233670653173873 0.8261269549218031\n",
            "tensor([[6465,   55],\n",
            "        [ 179, 6341]])\n",
            "tensor([[909, 178],\n",
            "        [231, 856]])\n",
            "Epoch: 95, Train Accuracy: 0.98313, Train Loss: 0.03731, Validation Accuracy: 0.80773, Validation Loss: 0.76833, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8077276908923643 0.8261269549218031\n",
            "tensor([[6478,   42],\n",
            "        [ 166, 6354]])\n",
            "tensor([[909, 178],\n",
            "        [233, 854]])\n",
            "Epoch: 96, Train Accuracy: 0.98589, Train Loss: 0.03189, Validation Accuracy: 0.81233, Validation Loss: 0.76144, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.812327506899724 0.8261269549218031\n",
            "tensor([[6473,   47],\n",
            "        [ 164, 6356]])\n",
            "tensor([[924, 163],\n",
            "        [222, 865]])\n",
            "Epoch: 97, Train Accuracy: 0.98528, Train Loss: 0.03139, Validation Accuracy: 0.82521, Validation Loss: 0.67862, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8252069917203312 0.8261269549218031\n",
            "tensor([[6478,   42],\n",
            "        [ 159, 6361]])\n",
            "tensor([[917, 170],\n",
            "        [220, 867]])\n",
            "Epoch: 98, Train Accuracy: 0.98543, Train Loss: 0.02945, Validation Accuracy: 0.82337, Validation Loss: 0.71118, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8233670653173873 0.8261269549218031\n",
            "tensor([[6478,   42],\n",
            "        [ 160, 6360]])\n",
            "tensor([[924, 163],\n",
            "        [219, 868]])\n",
            "Epoch: 99, Train Accuracy: 0.98482, Train Loss: 0.03131, Validation Accuracy: 0.83165, Validation Loss: 0.67802, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8316467341306347 0.8261269549218031\n",
            "best_state_dict updated\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xV5fnAv0/2DpmQwQhLliwDuAUnVgG3onXUVq2tta2t1tGqtdW6Wv3Z2qF11FZF6ioqigvcKBvZhJ2EQPbeeX9/vPfm3iQ3i+TmZjzfzyefe8+57zn3OQmc5zxbjDEoiqIoAxc/XwugKIqi+BZVBIqiKAMcVQSKoigDHFUEiqIoAxxVBIqiKAMcVQSKoigDHFUEyoBBRN4Vkau7e62i9HVE6wiU3oyIlLlthgHVQL1j+wZjzIs9L1XXEJEo4D7gAiAWOAS8BfzeGJPnS9mUgYlaBEqvxhgT4fwB9gPz3PY1KgERCfCdlB1HRIKAj4CJwFwgCjgOyAdmHsH5+sR1K70bVQRKn0REZotIpoj8SkRygOdEJEZE3haRXBEpdLxPdTtmhYj8wPH+GhH5XEQedazdIyJnH+HaNBH5VERKReRDEXlSRP7TiuhXAcOA840xW4wxDcaYw8aY3xljljrOZ0RktNv5nxeR37dx3VtF5Fy39QGO38F0x/axIvKliBSJyAYRmd3V37/Sv1BFoPRlhmBdK8OB67H/np9zbA8DKoG/tHH8LGA7EA88DDwjInIEa18CvgHigHuBK9v4ztOB94wxZW2saY/m1/0ysNDt87OAPGPMWhFJAd4Bfu845pfAayKS0IXvV/oZqgiUvkwDcI8xptoYU2mMyTfGvGaMqTDGlAL3A6e0cfw+Y8zTxph64F9AEjC4M2tFZBgwA7jbGFNjjPkcWNLGd8YBBzt3mS1oct1YRTRfRMIcn1+OVQ4A3wWWGmOWOqyPD4DVwHe6KIPSj1BFoPRlco0xVc4NEQkTkX+IyD4RKQE+BQaJiH8rx+c43xhjKhxvIzq5NhkocNsHcKANmfOxSqQrNLluY0wGsBWY51AG87HKAazVcLHDLVQkIkXAid0gg9KP0ECT0pdpnvL2C+AoYJYxJkdEpgLrgNbcPd3BQSBWRMLclMHQNtZ/CPxeRMKNMeWtrKnAZkg5GQJkum17SvVzuof8gC0O5QBWKf3bGHNdO9ehDGDUIlD6E5HYuECRiMQC93j7C40x+7CulntFJEhEjgPmtXHIv7E359dEZJyI+IlInIjcKSJOd8164HIR8ReRubTt3nKyCDgTuBGXNQDwH6ylcJbjfCGOgHOqx7MoAxJVBEp/4nEgFMgDVgLv9dD3XoErBfT3wCvYeocWGGOqsQHjbcAHQAk20BwPfO1Y9lOsMilynPvN9gQwxhwEvgKOd3y/c/8BYAFwJ5CLVUK3ov/3FTe0oExRuhkReQXYZozxukWiKN2BPhUoShcRkRkiMsrh5pmLfQJv9yleUXoLGixWlK4zBHgdmxqaCdxojFnnW5EUpeOoa0hRFGWAo64hRVGUAU6fcw3Fx8ebESNG+FoMRVGUPsWaNWvyjDEeW4v0OUUwYsQIVq9e7WsxFEVR+hQisq+1z9Q1pCiKMsBRRaAoijLAUUWgKIoywOlzMQJP1NbWkpmZSVVVVfuL+zghISGkpqYSGBjoa1EURekn9AtFkJmZSWRkJCNGjKD1uSJ9H2MM+fn5ZGZmkpaW5mtxFEXpJ3jVNSQic0Vku4hkiMjtHj4fJiLLRWSdiGx0677YKaqqqoiLi+vXSgBARIiLixsQlo+iKD2H1xSBYxjIk8DZwARgoYhMaLbs18BiY8w04DLgr134viM9tE8xUK5TUZSew5sWwUwgwxiz2xhTg+2XvqDZGgNEOd5HA9lelEdRFMX75O2EXct9LUWn8KYiSKHpyL5Mxz537gW+KyKZwFLgJ55OJCLXi8hqEVmdm5vrDVm7RH5+PlOnTmXq1KkMGTKElJSUxu2ampo2j129ejU333xzD0mqKIrX+eRhePV7vpaiU/g6WLwQeN4Y80fHZKd/i8gkY0yD+yJjzFPAUwDp6em9rkteXFwc69evB+Dee+8lIiKCX/7yl42f19XVERDg+Vednp5Oenp6j8ipKEoPUJIFlYX2JzTG19J0CG9aBFk0nd2a6tjnzveBxQDGmK+AEOykpj7PNddcww9/+ENmzZrFbbfdxjfffMNxxx3HtGnTOP7449m+fTsAK1as4NxzzwWsErn22muZPXs2I0eO5IknnvDlJSiKciSUHrSvBXt8K0cn8KZFsAoYIyJpWAVwGXB5szX7gdOA50VkPFYRdMn389u3NrMlu6Qrp2jBhOQo7pk3sdPHZWZm8uWXX+Lv709JSQmfffYZAQEBfPjhh9x555289tprLY7Ztm0by5cvp7S0lKOOOoobb7xRawYUpa9gDJQ4FcFuSJnuW3k6iNcUgTGmTkRuApYB/sCzxpjNInIfsNoYswT4BfC0iPwcGzi+xvSjAQkXX3wx/v7+ABQXF3P11Vezc+dORITa2lqPx5xzzjkEBwcTHBxMYmIihw4dIjVV54wrA5DaKjANEBTma0k6TlUR1FXa94VqEQBgjFmKDQK777vb7f0W4ITu/M4jeXL3FuHh4Y3vf/Ob3zBnzhzeeOMN9u7dy+zZsz0eExwc3Pje39+furo6b4upKL2TN663T9fffx/6Stp0aY7rfcFen4nRWbTXUA9RXFxMSopNmnr++ed9K4yi9AUOb4XMb2D/Sl9L0nFKHBnw/sHWNdRHUEXQQ9x2223ccccdTJs2TZ/yFaU9jIFiR27JyiOuM+15nIHi1PS2XUO1lbBtKdS1nV7eU/S5mcXp6emm+WCarVu3Mn78eB9J1PMMtOtVBiCVRfDQcAiNtX73m9dDzHBfS9U+nzwCy38PJ/0SPnsU7jzoOcbxzdOw9JcQOwrOegDGnuV195eIrDHGeMxVV4tAUZTeR4nDGjjpF4DAqqd9Kk6HKT1olVei40GtcK/ndYc2QVAEiB+8fCm8dIlPrQNVBIrSE9TXQk25r6XoOzh97UNnwoQFsOYFqC7zrUwdofQgRCVDrKM7cGvuocPbYMhk+NFX1nrY+T4c+Lrn5GyGKgKlf1B2GDLX+FqK1vnkIXj6NF9L0XcozrSvUclw7I+guhg2vOxbmTpCSTZEDoEYhyLwFDA2BnK3QcJR4B8I0690rN3Vc3I2QxWB0j/44v/ghfnQ0ND+Wl9waAvk7ei98vU2SrKs2yRiCAydAcnTYe0LvpaqfUoPQmQShMVCyCDP1cVlh2zcw+k+ih4K/kGQr4pAUbpGaQ7UlLmyNnobZTlg6qGywNeS9A1Ksq0S8HeUOo04AXK3925FWl9nLdOoZLsdm+bZIji81b4mjLOvfv4QM8Kn6aaqCJT+QUW+fe2tudvOQqOyw033NzRAVfe2ROkXFGdCtFuz4thRUF/tCiL3RsoOAca6hsC6hzzFCHK32ddEt8y/2FFqEfR15syZw7Jly5rse/zxx7nxxhs9rp89ezbOFNjvfOc7FBUVtVhz77338uijj3a/sP0V55N2byzrb2hw3CSA8maKYOMr8NhEmy6puCjJdj1ZA8SOtK+9VdGDyxqNdFoEI6HogE0UcOfwVptZFJ7g2hc3yv7b9ZHFo4qgG1i4cCGLFi1qsm/RokUsXLiw3WOXLl3KoEGDvCXawKGi0L72xo6PFfnQ4CgiLGvWU/HwFqgugazVLY8bqBhjn/yj3HpsxY2yrz4MqLaLUxFEJdnX2DTrDiza33Rd7nbrFnKvG4gbBXVVPrN4VBF0AxdddBHvvPNO4xCavXv3kp2dzcsvv0x6ejoTJ07knnvu8XjsiBEjyMvLA+D+++9n7NixnHjiiY1tqpUO4rQIeuMTY5lb/5nmFoHTZZSpiqCRqiKorWhqEUQmQ0DIkblP6mth02vef9p2dh2NdCoChxXjbqUaA7lbIXFc02NjfavofD2Ypvt593bI+bZ7zznkaDj7wVY/jo2NZebMmbz77rssWLCARYsWcckll3DnnXcSGxtLfX09p512Ghs3bmTy5Mkez7FmzRoWLVrE+vXrqaurY/r06RxzzDHdex39lbpqGyiG3ukacm9E1jxG4HyKPPBNz8nT23G2lnCPEfj5WZ/7kVh8W/4Hr30frk6EtJO6R0ZPlGaDXyCEOUaqNKaQuslcmgNVxZDQrDOA0+LJ3wUjZ3tPxlZQi6CbcHcPOd1CixcvZvr06UybNo3NmzezZcuWVo//7LPPOP/88wkLCyMqKor58+f3lOh9nwqHNRAQYjs+9ra2KU5FIP5Qnuf5s6zVR/bEuu+r/leo5iwmi2o22TZ25JE9Me/70r7mednKLjloA8V+jttq5BAICG2qCHIdGUPNLQKnxeMji7b/WQRtPLl7kwULFvDzn/+ctWvXUlFRQWxsLI8++iirVq0iJiaGa665hqqqKp/I1u9xuoWSptjqzIoCCI/zrUzuOG/28WNbuobKDtl886oiyN9pi4w6ypd/hvd/DWfcByf8tPvk9QYN9fDSpVCRZ5+YwxNg1vWQPK3l2hJnMVkzRRA3EjI+tArTrxPPsM7upXk7j0x2d7a+BX4BcNTZLT8rPejKGAIbA4htljmU61BGCc0UgZ+fVXQ+yhxSi6CbiIiIYM6cOVx77bUsXLiQkpISwsPDiY6O5tChQ7z77rttHn/yySfz5ptvUllZSWlpKW+99VYPSd4PcFoEKY5+Wr3NPVSWY2fXRqc2dQ1Vl9lA8VHfsduZqzp+zjXPWyUAkNWLK6qd5O2AjA9s0Lw817pr3rvT89qSbGs9ud9Uwd4oO5tCWlloA/LQdUVgDCy5GV6+zLqgm2cDOYvJ3IlpVkvgKWPIyZFaPN2AKoJuZOHChWzYsIGFCxcyZcoUpk2bxrhx47j88ss54YS25+9Mnz6dSy+9lClTpnD22WczY8aMHpK6H+CsIXCOBextmUOlObY4KiLR3gSdOFNK006CkOiOK4JvX4W3fgZjzoSjzoHs9d0vc3eTtda+XvgM3PAJzLkT9n/pOZ5XnOVwsfg33d8YUO2E++TAKsBY66KriqBon7U+hxwNX/8Nnj/XFSAG+949wA2QMBbyM2xlOdgagsTxnjuNxo2yTeoa6u12VQm8fn2P/Hv2qmtIROYC/4cdVflPY8yDzT5/DJjj2AwDEo0xfTaX8rzzzsO9rXdrA2hWrFjR+H7v3r2N7++66y7uuusuL0nXj3G6hlKmA9L7ModKcyBysH0KLM+1T5YibnnnSdaaOdABRVB0AN64AYafAJe8AF//Hba/Y62isFjvXkdXyF5nu23GjbHb066Aj38P3zwF8//cdG1JVku3EDRNIR15Sse+d/9X1pUz+RL4/DGoqTjy0ZfZ6+zr/D9bF86Sn8CihXDdcpusUFPa0iI49kew7kV49Vq4frltNnf0RZ7PHzsK6mug+ICtNN70qq0zCYuDuX84Mpk7iNcsAhHxB54EzgYmAAtFZIL7GmPMz40xU40xU4E/A697Sx6lH+N0DUUm2yeyXucaOmRvEBGJ9j96laN4zBk7iEyC1BmOmoLSts+V8aF1r5z7JwgMhaSpdv/BXm4VZK+zsjp9+6Ex9ua88b+uv5+TkqyWT9ZwZAHV/Svt9yZNsdtdcb1krbU9gRIn2pv5dx6x17XjvaZ/S3ciEuH8v9kg8evX2eZ5zeMDTtwzhwA2OGqTvn3Vtq/wIt50Dc0EMowxu40xNcAiYEEb6xcCfaC9oNLrqCiAwHAIDDnyFENvYYzDNTQYwhPtPmdRWaNF4Gishmnf3797hb0hxo+128kOReB8Wu0pCvbAy5e3vIl7oq7GuoBSmgWGZ15vB72vf9G1zxgbI4hOpQXOFNL8DiqCumr7+xx2rMsSydvRsWM9kb0OBk+CgCC7PflS++S+4g+uuEVUUsvjRp8Ox91kA83QMmPIibvrK3+XTXwYdpxNMNi94sjl7gDeVAQpwAG37UzHvhaIyHAgDfi4lc+vF5HVIrI6NzfX0xL62qS1I2WgXGenqHRzi7TW6MtXVBRAQ619Ugx35Jc7M4dKc2x6YUg0pDhqRtqKEzTUw55PYNQcl485NMbejJrHCb78C2x/r1svpQk7P7AuqVX/bH9t7lYb5G2eITRkknVxffO0yy9eWdiymMydzgRUs9fZ7x1+vONpW9qOExTsaX04TEMDHNzQ9Br8A+HkW+3+Nc/bfZGtyH3a3Xb+ALSsIXASOcQ+0ORnWJeQ+MH5f7dZZRsXeT6mm+gtweLLgFeNMfWePjTGPGWMSTfGpCcktIy2h4SEkJ+f3+9vksYY8vPzCQkJ8bUovYuKAntDBKsIyg/3niEmjU/9g62bAFwB49Ic+59fxMofP7btCuOcjfZGOXJ20/3J05q6hgr3wft3Wf/1t69215U0Jd9xQ/3mKahtJy3aGShOnt7ys5nX2SDszg/sduOTtcdnRptCWtBGT566atf7/V/Z16GzrBtt0LDWFcHKv8MT0+CZMzyncBbsshleKc2uwWkVbH7DbjfPdHISEAwLX4YLnoYIDxlD4Eg3HWkVwYaX7d85ZgRMPB+2vt2+27ALeDNYnAUMddtOdezzxGXAj4/0i1JTU8nMzKQ1a6E/ERISQmqqB7O5L1FZBMFRncsFb/N8BTagBk3L+occbd87g7O+oMzNd9zCNZTT1KecOhN2vNu6vLuW29eRs5vuT5pqb0TOgPG3/3Xtf/06e77JF3fXFVnydtqn1/JcG9Sc9t3W12avc1kuzRl3rr3pL78fRp/WejGZE/cU0kFDm372zdPw/m/ggn/YqWb7V1rl6rTE4se0dA0ZAx/91gaSR5xkXVj/OBnOfbzp78zpemtu1Titgv/92P6bDo5o/fcQnWrjIm0RN9IOtW+ohVN/Y/dNuQzWPGeVwdT2+5cdCd5UBKuAMSKShlUAlwGXN18kIuOAGOCrI/2iwMBA0tLSjvRwpSepKIDHJsH8J1rPnuj0OfPt0x40LesfcjRseAVWPABXvukaH9iTOIOIEYPtTVr83FxDB11BTIDhx8H6/9isoLMecN3AnOxeYQOVTsvCiXucYNSpsHGx9S1/9zVbxPXG9TYVc9IF3XddeTth3DlwaDN89VeYeoVVXhUFsOoZSP+eS/7stfYG6km5+QfC3Adh8ZXw5RPWDQJN20u44+5Hd1cENRV2Clx9DSy+Gs5+2CqCCW4V+vFjbZWxsyCtoQGW3GRjFMd8D875o/2bvPYDeP0H9gFj1g322Ky1EBgG8R4K/iZfCp8+Yj/vKrGjrBIIirC/X7AWzaDh1l3kJUXgNdeQMaYOuAlYBmwFFhtjNovIfSLi3j/hMmCR6e9+HcWStRZqy13DObqDigJbpANNZ8WW5sDSW21u9v9+7JsWv43ZJI68+LB4W1TmDCK7WwSTL7Xzaze9Bn+ZAetfcrXLqK20N7aRs1t+h1OZHFxv3Ud52+2TZ1A4XP6KtTSW/KT7Yic15bb6N34sHPdjOLzZKqnCffDsWbD89/DhvS65D2/1XEHsZMJ8GD8fVjxkzyP+VnF6orEddTP3zZrnrXVyxX9h7Fx491abnTXsONea+DE2/lDqsDp2f2yVwEm/gHMfs3+f6FS4+m1IO9ne3Gsr7drsddbH7+/h2dk/EBYuggV/afv31hGcmUMTzrN/P7AKdPKlNj7kXrfQjXg1RmCMWWqMGWuMGWWMud+x725jzBK3NfcaY273phxKL8JpYrt35OwK9XW2iZczWBwSbd1EBbvhvdtta9+Tfgn7vrA59z1NaY6VKTDUbjuLyqpLrUJ09yn7B8Jpv4Effm5vsm/eaNtIgPV311fbQHFzQmOsJZS9zloDfoH2RgL2ZnLRM/bm+voN3ZOG6PShx4+2Vl14onWvPHOGTZUdc5a9wR7eBjmbbLqrp/iAO9951P6Oti6xyrF5MZmTqBTwD26q1Gor4YvHrWtn9Glw6X9g+lU2ED/Crclc88yhtS/Yfyun/KqpteIfAKfcbv9Oa1+wv7PmgeLmJI53Bfy7QsoxNkX1mKub7p98KZgG64bzAr0lWKwMFJyKoPRQ95yvqggwrhgB2Jvi1res3/zkW+HUX9unxI9+2z39ZjpDWbOn/vAEaxG4WwrNSRwP33vX+rk/uNtm/+xeYW/w7k+47iRPg6x11poYc0bT4rLoVFt3kPkNfP6nrl+T80YaP9YGQWdeb/+u/kFw7ftw3t9s/ODj37XuW29O5GBX0VRrbiFw9ORplkK69t9WAZ1ym932D7BFX7c1cx85U27zdto4zbalMGWhvYbmjDjB/q6/eAIOfWvTXJsHir1B4ni4IwuGzmy6P360tTqO+Z5XvlYVgdKzdLdF4MxjD3W78cWm2bhBwjjbjE0E5v2ffeJ844euVMWewFlD4CQ8wcYI3GsIPOHnB+f93bp9Xvs+bHrD3hxaC0YmT7XumtKDcLSHwPDRF8HRl8CKByGzE72JqkttNbM7+RmAuNw0s26A2XfA9z+wOfLhcXDCzbDtbVj7L3v9raWDujNloQ06O33jrRE7yrrBdrxvlernj9mbtvvTP7SsII5IhOBoqwg2vGx98dOubP17TvqF/Z0uc1T7t6fMugtnnUJzjjq77WB0F1BFoPQcpTmOnu0B3WcRONtLhMW49jkDevOecP2nihwCZ95v2z3v/ezIvitzjatXfkcpPdTUIohItK2onX2GmleiuhMUZlMOgyKgeD+M9OAWcuK8SQVFeu6MCbYSNjLJ+s/boqHeWiCv3wCPjrXxCvdRmnk77ZO2090VEgWzb29aTHXsj6zL6NCm1gPFzRGBBU+230l19Gn239JLF8OjY+y/qZNvbf87ROyTdd526/IZOqv14i6whWBJU6xbMTjKFajuh6giUHoOZ9HT8OOt/7U7/NVOi8DdNTTrBrjuYxg2q+naiedZ94UzZ92JMbD7k7b7+ufttD7wv8yAr//RMavCGIdrqJlFUFvheKqmdYvASVSyVQaDJ1lXUWskTQEExs9z3aCbEzoIjv+JrbY9uLHpZ6U5Njj67wvgweHwwgLYvhTSTrFuEXflmb/T5W9vjeAIl6umvfhAZ5nxfbjjAFz9Fsy5y/6MOrVjxzozh/J32jhCW4hYqwDs77e70p17If1vHoHSe8lea9Mnx5wJez61LpKOuAzawtl51N01FBLlOXAXFA4jTrSK4Kz7Xft3fQT/uRDiRtuCH0++4I9/Z2+wQ2fCu7fZoOxRc61rouwQjJvXMle/stCmMza3CMDeiIMiIDiy/WtMmQ43ftH2mpBomzHjno7qiSmXwof32Cybcx3xAmNg0eVWQSSMt9eRdrKNq/gFwEMjbA3D+Hl2bV4GTD++fbmnX21dVVMua39tZwkKtzKmndy54+LH2OB1UKQt1GqPcfNg9Bkw7jtHJmcfQRWB0nNkr7NuG6dvuTSn64qg0TXUwc6bY8602USFe10FThtesb7j2kr71D/7Djjx567Mlaw1tn/+7Dtshsm3r8J7v7LdM0OiAbGKbdw5Tf3S7jUETpxFZTkb27cGOsuYM9pfExpjb4AbF9uBNsER1peftcYGWD09JQ8/wdXrpiTbZjvFj27/uwKCbGuF3oTTkjn6Ild6Zlv4+cF3vVSd3Yvov7aO0rswxiqC5Gm2Nz+4/ORdoaLAunuCOhhEG3OmfXW6h6rL7I1w0gX2qXv8fPv0//Jlth+8MTYnPize5syL2CfmW7bBXTlw+37ruqksbNkPxr3NtBNne4GSrLbjA97kmGtsy+TNr1v33Ee/sy6TKS3qPS2j5ti8/aL9rtYS7bmGeivDjrUtv4+90deS9CpUESg9Q0mWjQskT3M9CZd2Q+ZQpaOYrKMtJOJGWYtk5/t2e9s71mc/+VL7tHzRs3DOnyDjI3jmTOtC2fOpDUa6u3ECgly++GHH2XYOX/21adFaY0C4WYzASXdbBB1l6CzrAlr9nFVeedttiq2nYilwFbHtWu5Kv43vo4ogIhGu+6hzI0EHAKoIlJ7BmTaaMt3hJ5fuswg6O5DFGaOorbRl+4OG2ZsjWIUy4/tw5es2G+Xtn9nP09vI3xaxbYbzd9p5AU6cFkGE2w3fXRG0Vj3rbUSsVZC91qZGJk+zllBrJIyz17B7hVUEQRG+s2YUr6CKQOkZstfZwOPgibaCNiyueywC9/YSHWXMGbbieNNrsHu5za9vnhEycjb84GObNfOdP3ouOnJn4nm2BfHKJ137Sg/Z2IN73MA/0NUp1Zc30ymX2iEvVUVw+r1tW1Qi9vex5xNrPcSN9l0TP8UrqCJQOsbhrTZt8kjJXmerJp3ulMgh3WMRVB6BRTD8RNt+4P1f27L9yZd6Xhc/Gq5eAmPPbP+c/oG2pfLuFbBjGbzzC+tW8uRCcQaMfeUaAquMjv0RTL7Mc/+i5oyaYzO09n7Rd91CSquoIujvrH0Bcrd3/Tyr/mnTJo/kXO6BYicRg12uk85waHPTKV4V+Z1XBIEhduZtZaGVKWFs5+XwxDHX2A6UL10Ca/5l0yYvfr7lOmcKqa/dK6ffY1s2d4SRs+1rQ23fDRQrraKKoD/TUA9v/bRjU6Tao3Cvfd24+AiO3WNvus75umCfhtuqLs5a4/pOJ8bYIeAvL7TXZow9b2ddQ+BKtWzNGjgSwmJtv5xjfwQ3r7Ottpv3zAdXnMCXFkFniRzimqylFkG/Q+sI+jNVxdb14Rz20RWcN+VvF9tKzs5UWe7+xL6694KJGGwLypy94d0pOwzPz4PBE+AHbsHXg+shd5t9v/dz21+noa5pVXFHmXSR7aI5tZWUySPlmGvaXxPRC1xDR8KoOXbspCqCfocqgv6Ms/3Ckbhg3Gmotznk0cPs64Gv7RAVsANB9n9p+7K0xq6Pbftg9xtI5BB7E6/Ibzm677M/2aKlzFVNXUobFtmaAf8g247XOYyms64hsO0WnN0ue5oJC2yFdUcKmnoT6dfaIHtrM3eVPou6hvozlYX2tavZOSXZtlXCrBusD9xZOGWMHXjynwtd6aHN8TRwHVypk827kBYdgNXP2JtlYBh843Br1dfaEYxHnW0reLcscV3XkbiGfMnw432nhLpC/Bg7wKW1ejTvVfUAACAASURBVAOlz+JVRSAic0Vku4hkiIjH4TMicomIbBGRzSLykjflGXA42y+U5nSt9bLTLTR4op0xu/kNOyR842LXoIytb3s+NnuddVE1bwrmDJQ2jxN8+rB9PfN+67/f9Kq1bDI+tNbDlIXWrVNV5JrNeySuIUVRGvGaIhARf+BJ4GxgArBQRCY0WzMGuAM4wRgzEfiZt+QZkDhdQ6beVvUeKU5FEJtmb85VxfDNUzZFctjxthfNtnc8H7vrY0AgbXbT/ZEeLIK8DFj3IqR/3wZZZ15nXRHr/m37x4fFWRfUqDnWCtjgsEyOxDWkKEoj3rQIZgIZxpjdxpgaYBHQvI/udcCTxphCAGPMYS/KM/BwuoagawHjwr121GFUqk0jDE+0OfjiBxc8ZatSc7e6Rhi6s+tj2xEzvNlTu7Pa1j1+seIBW+R00i12e/BEq2S+fgq2v2sHrvgH2p8JC2wcAVwFWoqiHBHeVAQpgPtoo0zHPnfGAmNF5AsRWSkic70oz8DD6RqCrgWMC/fYJ3T/APtz9EV2/7zH7H5ni95tzdxDVSU24OupV3xgiO3c6XQNlefD5jdhxrWurBqwVkFJpo1RuLczdsogfhAy6MivTVEUn2cNBQBjgNlAKvCpiBxtjClyXyQi1wPXAwwbNqynZey7VBTYG2VXU0jdWzaDHTgyco6r4nbQMBgy2bqH3KdL7f3cZga1NjQkYojLNbTjXevCmnRh0zXjzrXxhJDopnUIw463LR3qq/v1wBBF6Qm8+T8oC3Cvpkl17HMnE1hijKk1xuwBdmAVQxOMMU8ZY9KNMekJCQnNP1Zao7IQBg23bp2OWgT5uyBrbdN9hXvtQHgnoTEt2y6MOxcOfNM0+LvrY5v503wQt5PIwa71W9+G6KFNb/Zg3UBXvAqX/Ltp1pGfn3UhdWS4iKIobeJNRbAKGCMiaSISBFwGLGm25k2sNYCIxGNdRbu9KNPAorLAVrFGDIaSDiqCpbfayl1j7HZVic3WcbcIPDH+XMDYJ3snu5fbiWCtNWxzWgTVZVZpjDvHczOzIZM8t4GYeR2c88eOXJWiKG3gNUVgjKkDbgKWAVuBxcaYzSJyn4g4e94uA/JFZAuwHLjVGJPvLZkGHBUF9uk9Ksm2VG4PY2xrh7IcyNth9zkzhtpTBIkT7Jpt79jv/epJO5e3rVmyTosg40Pr4hl3bgcuSlGU7sarMQJjzFJgabN9d7u9N8Atjh+lu6kscrV9dg4UaYvCPTY/H2xbiISjOq4IROyNfOXf4I/j7I095Rib898aEUPsuvUv2tTQYcd15KoURelmNMrWn3FO74pK7liMwFkd7B9sq4Gh44oAbN+e2DQ45mq44TO47uOW7SPccfba2fmBrRjWilVF8Qn6P6+/UlcDNWXWNeTnD9Ul1hcf3MZs3+x1VglMugC2L7XVyIV77TlCO5CiOXgi/GRN++ucNDZdMzBuXsePUxSlW1GLoL/iLCYLi7EWAbRvFWSts4HZ0afb6uGcjdZd1BFr4EhwFpUFRXRsOIqiKF5BFUF/xVlMFhrr6uvTVi1BQ4Nt85w83dUuevcnLWsIuhNnm4nRp9sCM0VRfIIqgv6Ks89QWGzHLIL8DOtKSp5mb9AJ4236Z9F+7ymC4Eg47W44+VbvnF9RlA6hMYL+SqNFENMxiyDbUUTm7P2fdjKsetpWJbsXk3U3J/3Ce+dWFKVDqEXQX3HGCEJjbYA4OKqpRZDxoa0EdpK9zlYBJxxlt0eeYpUAeM8iUBSlV6AWQX/F3TUE1ipwKoK6GvjvtRAQBDetthlB2etsl1A/f7tm+AmuPkWqCBSlX6MWQX+lssCOdAwMs9tRSa42E7uXQ3WxnVGw4g9QXwcHN7rcQmCVQ9JU8AuwYyYVRem3qEXQX6kstG4hZ++eyGTIcxSJbX7DdvMcP98OmEmeDnWV9tWdGT+A/V9poZei9HPUIuivVBQ0ndwVlWRHVtZU2H5A4+bBGffZXv5vOVpHu1sEANOugAV/6TmZFUXxCaoI+iuVhU0nd0Um2X7/G1+xVcYTz7eK4vR7rDUQHAWxI30nr6IoPkMVQV+lvg6++qutAPZEc0XgrCVY+TdrBYw8xW5PuwqGHmuLyHTAi6IMSNT521c5sBKW3QEFu+GcR1t+XlEAqemubWctQd52mHal7UgK9uZ/9Vs2Q0hRlAGJ/u/vq+Rn2Nc1z0FeRtPPjHF0HvVgEUDLqV4BQRoQVpQBjCqCvkp+hk0PDQiBD+9p+llthR32HuoWLA5PsCMrQ2Mh7ZSelVVRlF6NKoK+Sv4uiBsNJ/wMtr0N+750fda8mAxsodjgiXZmgD79K4rihlcVgYjMFZHtIpIhIrd7+PwaEckVkfWOnx94U55+RX4GxI2C435s/f/v/9o1Z9i986g71y23KaOKoihueE0RiIg/8CRwNjABWCgiEzwsfcUYM9Xx809vydOvqK+Dgj3WIggKg1N/Y2cNb3cMjm/sMxTT9Dj/AFcLCUVRFAfetAhmAhnGmN3GmBpgEbDAi983cCjeDw21VhEATLnM3vS3vmW3PbmGFEVRWsGbiiAFOOC2nenY15wLRWSjiLwqIkM9nUhErheR1SKyOjc31xuy9i3yd9lXpyLw87fDXXa+bwfMtOYaUhRF8YCvg8VvASOMMZOBD4B/eVpkjHnKGJNujElPSGhjGPpAwZk66lQEAGPOgoo8O1egNdeQoiiKB7ypCLIA9yf8VMe+Rowx+caYasfmP4FjvChP/yE/wzaNC4tz7Rt9mi0K27EMKgrtHOCAIN/JqChKn8GbimAVMEZE0kQkCLgMWOK+QESS3DbnA1u9KE//IT/DWgPOzqJg4wGpM2HnMkcxmbqFFEXpGF5TBMaYOuAmYBn2Br/YGLNZRO4TkfmOZTeLyGYR2QDcDFzjLXn6Ffm7IHZUy/1jz4SDG+DwFjtPQFEUpQN4NUZgjFlqjBlrjBlljLnfse9uY8wSx/s7jDETjTFTjDFzjDHbvClPdlGlN0/fM9RWQvGBpvEBJ2Pn2teDGzRjSFGUDuPrYHGP8eTyDM740yfkl1W3v7g3U7DbvsZ5sAgSJ0BUqn2vriFFUTrIgFEEZ00cQmVtPX9bscvXonQNTxlDTkSsewg0Y0hRlA4zYBTB6MQILpyeygsr93GwuJe4iPZ8Bsv/0LljGhWBB4sAbBopqGtIUZQOM2AUAcBPTx+DMYYnPspof3FP8OWf4ZMH4cCqjh+TvwsihkBwpOfP006GhHEt5w8riqK0woBSBKkxYVwxaziLVx9gb165b4VpqLeD4QG+fKLjxzlTR1sjKAx+/DWM+07X5FMUZcAwoBQBwI/mjCLI34/HPtzhW0FyNtrZwfFH2R5B+R2MXTi7jiqKonQTA0sRFGeRGBnC904YwZIN2WzMLPKdLHu/sK8XPGXHRq78a/vHVBRARX7bFoGiKEonGTiK4NNH4M/HQFUxP5w9iviIYH7z5ibqG4xv5Nn7uS0KS54Kky+FdS9CeX7bx+TttK+qCBRF6UY6pAhEJFzETjcXkbEiMl9EAr0rWjcz6lSoq4RvXyUqJJBfnzOeDZnFvLLqQPvHdjcN9bD/Sxhxgt0+/idWtlXtjGPY9KodT5k6w/syKooyYOioRfApECIiKcD7wJXA894SyiskT4fEibDu3wDMn5LMrLRYHl62jYLymp6V5dAmqCqGESfZ7YSjbFXwN0/ZoTOeqC6F9S/bwfMR2oFVUZTuo6OKQIwxFcAFwF+NMRcDE70nlhcQgelXQvY6yNmEiPC78yZRVlXHw+95tbOFxbi5oJzxgeEnuPZNvtS2kc7Z4Pn4DYugphRmXOc9GRVFGZB0WBGIyHHAFcA7jn19b+bh5Euta8VhFYwdHMm1J6axaNUBNmUVe+97l9wMz861fYLAxgdiRkC025wep1LY+3nL442xbqOkqZCa7j05FUUZkHRUEfwMuAN4w9FBdCSw3HtieYmwWBh3Dmx8Bepsz6GbTh1NdGggj33gpXTS+lrY9DocWAn/+7FbfODEpusiB0PcGJe14M7ezyB3G8y8rmnraUVRlG6gQ4rAGPOJMWa+MeYhR9A4zxhzs5dl8w7TrrQTvLa9DUBUSCDXnzySj7YdZv0BL6STZq6yLp0RJ8Gm1+CNH9rvH35iy7UjTrRFZg31Tfd/87TtHTTpwu6XT1GUAU9Hs4ZeEpEoEQkHNgFbRORW74rmJUbOgeihsPbfjbuuPn4EMWGBPO6NIrOMj0D84dL/wNEXw7eL7f4RJ7RcO+JEW2SWs9G1rzgLtr0D06+CwNDul09RlAFPR11DE4wxJcB5wLtAGjZzqO/h5wdTr4DdK2DDKwBEBAdwwymjWLE9lzX7Crv3+3Z9ZNM9QwfB/D9DyjEQPxYGDWu51lOcYNXTgIH0a7tXLkVRFAcdVQSBjrqB84AlxphawEeVWN3AcT+2T99vXA8rHgJjuOq44cSFB3WvVVCeD9nr7TxhsE/017wD1y7zvD4qyRaZOeMENeWw+jkYd64NLiuKoniBjiqCfwB7gXDgUxEZDpS0d5CIzBWR7SKSISK3t7HuQhExItIzKTEhUfDd12HyZbDiAXjzR4RJHT88ZRSf7czjgy2Huud7di8HDIw6zbUvMLTtFtEjToR9X9o4wfqXoKrIKi5FURQv0dFg8RPGmBRjzHeMZR8wp61jRMQfeBI4G5gALBSRCR7WRQI/Bb7utPRdISAIzv87zL4DNrwET5/KVaMrmJQSxc9fWU/G4bLWj93zKZRkt/8dGR/ZIG/y1I7LNeJEqC624yZX/s26kobO6vjxiqIonaSjweJoEfmTiKx2/PwRax20xUwgwxiz2xhTAywCFnhY9zvgIaCqM4J3CyIw+3a4/L9QdojgZ0/jP5M3ERIgXP/Caoora5uuNwY+vh/+Nc/2LfrkYVdtQHOMgV0f2+C0XydKLpxxgg/vgYJd1hrQlFFFUbxIR11DzwKlwCWOnxLguXaOSQHcG/lkOvY1IiLTgaHGmHdoAxG53qmEcnNzOyhyJxh7Jtz4JQw/nkHLb+e/M3eyv6CCny5a52pK11AP79wCnz4MUy6HMWfA8vvhLzPgy7+4Zgk7ObQZynJc8YGOEp0CMWnW6ogeCuM96U5FUZTuo6OKYJQx5h7H0/1uY8xvgZFd+WJHPcKfgF+0t9YY85QxJt0Yk56Q4KU+O5GD4YrXYMRJpK35A4+cGceK7bn8dXkG1NXAaz+A1c/CCT+D8/4Kl7xgA7/hCfD+XfDENHhyFrx3B2xZAptft+cd1UlFAK5is5nXg39A912joiiKBzqqCCpFpLECSkROANob/JsFDHXbTnXscxIJTAJWiMhe4FhgSY8FjD3h52dTPE0952c+zPzJSfz1oy0Uv7DQ3tjPuA/O+K3LVTPiRLh+Ofx0A8x9CCIGW2Wx+Er47I+2yV1UUuflOPpiGxuYflX3Xp+iKIoHxJj2s0BFZArwAhDt2FUIXG2M2djGMQHADuA0rAJYBVxujNncyvoVwC+NMavbkiU9Pd2sXt3mkq7z9T/g3duoPONhNnz4Esea9dSc9TBBx93Q/rF1NXBwPexfafsCDT/eu7IqiqJ0ABFZY4zx+KDdIb+DMWYDMEVEohzbJSLyM6BVRWCMqRORm4Bl2AZ1zzr6FN0HrDbGLOnshfQYM66DzW8S+sFtzEL4Ve11BOQcz/0dOTYgCIbOtD+Koih9gA5ZBB4PFNlvjPFQHutdesQiADtDePHVcMLN/CHzaP7x6W6eu2YGc8Ylev+7FUVRupm2LIKujKrs3zmNcaPgxs9h8iXccuZYxiRG8Os3N1FR08rgGEVRlD5KVxRB320x0UmCA/x54IKjySqq5P8+3OlrcRRFUbqVNhWBiJSKSImHn1IguYdk7BXMGBHLwplD+efne9iS3W53DUVRlD5Dm4rAGBNpjIny8BNpjBlwCe6/mjuOQaGB3PnGt65CM0VRlD5OV1xDA45BYUH85twJrD9QxL+/2utrcRRFUboFVQSdZMHUZGYflcCD721jd24bjekURVH6CKoIOomI8NCFkwkJ9OeWxRuoq2/wtUiKoihdQhXBETA4KoTfnzeJ9QeK+Psnu3wtjqIoSpdQRXCEnDs5mflTknn8w51syir2tTiKoihHjCqCLnDfgonEhgdx15ubaNAsIkVR+iiqCLrAoLAgfjV3HBsOFLFkQwcmlimKovRCVBF0kfOnpTA5NZoH392m7ScURemTqCLoIn5+wm/OnUBOSRVPfbq7/QMURVF6GaoIuoEZI2I55+gk/vHJbg4WtzevR1EUpXehiqCbuP3scdQbo03pFEXpc6gi6CaGxoZxwbQU3lyfRXFlra/FURRF6TBeVQQiMldEtotIhojc7uHzH4rItyKyXkQ+F5EJ3pTH21w+axhVtQ38b31W+4sVRVF6CV5TBCLiDzwJnA1MABZ6uNG/ZIw52hgzFXgY+JO35OkJJqcOYlJKFC99vZ8jnfymKIrS03jTIpgJZBhjdhtjaoBFwAL3BcYY98b+4fSDYTeXzxzOtpxS1u4v8rUoiqIoHcKbiiAFOOC2nenY1wQR+bGI7MJaBDd7UZ4eYf7UZMKD/Hnp6/2+FkVRFKVD+DxYbIx50hgzCvgV8GtPa0TkehFZLSKrc3Nze1bAThIRHMCCaSm8vTGb4goNGiuK0vvxpiLIAoa6bac69rXGIuA8Tx8YY54yxqQbY9ITEhK6UUTvcPnMYVTXNfDq2kxfi6IoitIu3lQEq4AxIpImIkHAZcAS9wUiMsZt8xygXyThT0qJJn14DA+9u43/rj7Q/gGKoig+xGuKwBhTB9wELAO2AouNMZtF5D4Rme9YdpOIbBaR9cAtwNXekqenefqqdNJHxHDrqxv57VubdYCNoii9FulraY7p6elm9erVvhajQ9TVN/DA0m08+8Uezp+WwmOXTvW1SIqiDFBEZI0xJt3TZz4PFvdnAvz9uHveBL5/Yhr/W5/FoZKqJp/nllazdn+hj6RTFEWxqCLoAb577HAaDLy+tmms/NZXN3DVM99o8ZmiKD5FFUEPkBYfTvrwGF5dc6Dxpr/1YAkrtudSVl1Hbmm1jyVUFGUgo4qgh7jomFR25Zaz7oCtOHafXbCvoMJXYimKoqgi6CnOmZxESKAfr67JJLOwgiUbsjltXCIA+/JVESiK4jsCfC3AQCEyJJCzJyXxlmO2sQB3z5vA8u2H2a8WgaIoPkQtgh7k4mNSKa2q46Wv9zN/ajLD48JJig5lf365r0VTFGUAo4qgBzl2ZBwpg0IBuP7kkQAMjwvTGIGiKD5FXUM9iJ+fcPvZ48g4XMa4IVEADIsN44Mth3wsmaIoAxlVBD3MvCnJTbaHxYWRX15DWXUdEcH651AUpedR15CPGR4bDsB+zRxSFMVHqCLwMcNiwwDYX+CdgPGnO3JbtLZQFEVxRxWBjxkW51QE3W8R1DcYfvCv1Tz7+Z5uP7eiKP0HVQQ+Jjo0kEFhgV4pKiusqKGmvoHcMm1hoShK66gi6AUMiw3zikWQ51AAheU13X5uRVH6D6oIegHeUgTOZnYFOjtZUZQ2UEXQCxgeF0ZWYWW3TzFTi0BRlI7gVUUgInNFZLuIZIjI7R4+v0VEtojIRhH5SESGe1Oe3sqw2DDqGgzZRd2b3dNoEagiUBSlDbymCETEH3gSOBuYACwUkQnNlq0D0o0xk4FXgYe9JU9vZpizlqCb3UN5ZVYBlFXXUV1X363nVhSl/+BNi2AmkGGM2W2MqQEWAQvcFxhjlhtjnHe/lUCqF+XptThTSPd1cy1BntvAmyKNEyiK0greVAQpwAG37UzHvtb4PvCupw9E5HoRWS0iq3Nzc7tRxN7BkKgQgvz9ur262D1tNL9M3UOKonimVwSLReS7QDrwiKfPjTFPGWPSjTHpCQkJPStcD+DvJ6TGhnZ7LUFuaTWRIbZ/UWGFKgJFUTzjTUWQBQx120517GuCiJwO3AXMN8YM2Monb6SQ5pXVcNTgSEADxoqitI43FcEqYIyIpIlIEHAZsMR9gYhMA/6BVQKHvShLr2e4QxHUN5huOV99g6GgvJqxQ6wiUItAUZTW8JoiMMbUATcBy4CtwGJjzGYRuU9E5juWPQJEAP8VkfUisqSV0/V7jhsVT1l1HYtW7e+W8xWU19BgYHRCBKAxAkVRWserDfCNMUuBpc323e32/nRvfn9f4qyJg5mZFsujy7ZzztFJDAoLanN9cUUtt7++kV+fO6Fx6pk7zmKypOgQokMD1SJQFKVVekWwWAER4d55EymurOWxD3a0u/7tb7N5d1MOH231PN3MWUwWHxlMXHiQxggURWkVVQS9iAnJUVwxazj/+Xo/23JK2ly7bLNVAFsPel7ntAjiI4KJCQ9Si0BRlFZRRdDLuOWMsUSGBHDvks0Y4zlwXFxZy5cZeQBsPVjqcY3TIkiIDCYmLEhjBIqitIoqgl5GTHgQvzhjLCt3F/DJDs/Fc8u3HaauwTB16CC255R6zDTKK6smJNCP8CB/4tQiUBSlDVQR9EIunTGMlEGhPPbhTo9WwbLNOSRGBrNw5lAqa+vZl9+yNUVeWQ3xEcGIiHUNlde2amEoijKwUUXQCwkK8OOmU0ez4UARK5pZBVW19azYnsuZEwczISkagG05Ld1DuaXVJEQGAxAbHkhNfQPlNdp4TlGUlqgi6KVcOD2VlEGhPP7BjiZP8p/uyKWytp6zJg5hzOAI/MRzwDivrJr4CKsIYhypqAUaJ1AUxQOqCHopQQF+/OTU0WzILGbFdpdVsGzzIaJCAjh2ZBwhgf6MTIjwGDB2VwRxEQ5FoHECRVE8oIqgF3PB9FRSY0J59P3tfJGRx6asYj7adojTxw8m0N/+6cYnRbWwCOrqG8gvr2l0DTktAp1UpiiKJ1QR9GKCAvy45YyxbM4u4Yp/fs25f/6coopazpo0pHHN+KRIsooqKa50zRsoqKjBGEhwWAKx4Q6LQBWBoige8GqLCaXrXDA9lenDYsgpqaKoooa6BsMZ4wc3fj5+SBQA23NKmZkWC7hVFUc4g8WqCBRFaR1VBH2AEfHhjIgP9/jZ+CSrCLYeLGlUBM4RlU7XUERwAIH+ojECRVE8oq6hPs7gqGAGhQU2aUmR18wiEBFiwoI0RqAoikdUEfRxRITxQ6LY4pY55BxRGe+wCMC6h/JVESiK4gFVBP2A8UlRbM8paWw1kVdaTWigP+FB/o1rYsPVIlAUxTOqCPoB45IiqaptaGw1kVdWTXxkECLSuCYmPEhjBIqieEQVQT9ggiNg/PE2O+0z162YzEmsxggURWkFryoCEZkrIttFJENEbvfw+ckislZE6kTkIm/K0p8ZnxTFCaPjeGDpVt7akE1eaQ0JzRVBeBBFlbXdNhNZUZT+g9cUgYj4A08CZwMTgIUiMqHZsv3ANcBL3pJjIODvJzx9VTrpI2L52Svr2ZNX3iRQDFYRGANFDvfQoZIqSqpqPZ1OUZQBhjctgplAhjFmtzGmBlgELHBfYIzZa4zZCDR4UY4BQVhQAM9eM4OpQwdRU9/QwjUU4ygqK6yooby6jnP//DkX/e1Laur0V68oAx1vKoIU4IDbdqZjX6cRketFZLWIrM7N9TysRbGFY89/bwaXzRjKmRMGN/ks1tmBtLyWpz/bTW5pNTsOlfHXFRm+EFVRlF5EnwgWG2OeMsakG2PSExISfC1OryYyJJAHL5zMpJToJvudbSa2HyrlqU93c/akIcyfksyTyzPYccjzuEtFUQYG3lQEWcBQt+1Uxz7FBzgVweMf7KC6roFbzzqKe+ZNICI4gF+9tlGDyIoygPGmIlgFjBGRNBEJAi4Dlnjx+5Q2iAkPBCC/vIaFM4cyMiGCuIhg7pk3kXX7i3jm890+llBRFF/hNUVgjKkDbgKWAVuBxcaYzSJyn4jMBxCRGSKSCVwM/ENENntLnoFOcIA/EcEBhAX5c/NpYxr3L5iazBkTBvPA0m08smwbDWoZKMqAw6vdR40xS4Glzfbd7fZ+FdZlpPQA86YkMSE5msTIkMZ9IsKTl0/nniWbeHL5LrbnlPLYpVOJDAns0ncVltfw7Bd7uPr4ES0ymBRF6V2I+zzcvkB6erpZvXq1r8Xodxhj+PfKffz2rS2MSYzgPz+YdcQ38IYGw7X/WsWK7bmcPDaB56+ZgZ+ftH+goiheQ0TWGGPSPX3WJ7KGFO8jIlx13Aieu2YGe/PLWfjUysYBN53lrysyWLE9l1PGJvDpjlz+9dXebpW1L/L0p7u54p8rqa3Xug2l96GKQGnCyWMTePaaGWQWVnLZU19xuKSqU8d/mZHHnz7YwYKpyTz/vRmcPj6RP7y7rcm8hI6wZl9BYxO9vs7hkir++MF2vsjI5+Vv9vtaHEVpgSoCpQXHj4rn+e/N4GBxFXP/7zN+9epG3t+cQ0lVLc1dicYY8suq+SIjj39+tpubF61jZEIED5x/NCLCQxdOJiokkJtfXkd5dV27311X38CD727jwr99xYV/+4oDBRXeuswe468rdlFbb5iQFMXjH+70SmuPbTkl/O7tLazdX9jt51b6PxojUFplY2YRT326m0+251LquIn7CYQHBRAc6EdFTT2VtfW4/xMaHhfGP69KZ8zgyMZ9n+zI5ZrnviExMphbzhjLhdNTCfBv+QxyuKSKm15exzd7CrhgWgofbj1EYlQIr/3weKLDXMFrYwwfbT3M/320k8KKGn48ZzQXH+P5nK1hjCG/vMbrgezsokpmP7KCC6an8N1jh3Punz/nxtmj+NXccV06b0ODIauokk1Zxfzn6318kZEPQExYIEtuOpGhsWHdIb7Sj2grRqCKQGmXmroGVu0tYGNmMeXVdZRV11FT30BYoD9hwQFEhQQwbkgU45MiiWvlxrp6bwEPLN3K2v1FjEmM4MQx8SRFhxAfEcyu3DJW7SlkfWYRWOX9HgAADqRJREFU/iI8cMEkzp+Wysrd+Vz5zNdMHxbDM9fMYF9+OZuzSnjx631syCxmWGwYseFBrD9QxMiEcH5xxlHMnTQEf7fA9Lr9hXy+M4/RiRFMSokmKjSQN9Zm8uLX+9l5uIzTxiVy97wJDI/zPBPaE3vyynlk2TYGhQVx86ljGBLtysJypt86g+N3vP4tr63JZPmts0kZFMotr6zn7W8PsvyXdruz7Mkr57ZXN7Apq4TK2noAhkSFcNXxwzl2ZBxXP/sNqTFhvHbjcYQF6UhyxYUqAqVXYIzhvU05PLkig9255VTU2BuZv58wKTmKGSNiuWzmUEYnuqyJN9dl8bNX1iNCo+WRMiiUm08bzQXTUwnwE97fcohHlm0n43AZQ2NDueb4NMYNieTvn+zis515TWRwnmfK0EHMSovlxZX7qK03XHtiGkcNicAYuyY2PJjk6BCSBoUSHuSPiFDfYHjuiz08smw7Qf5+VNXV4+8nXHtCGmnx4azYkctnO3Lx9xPOPjqJ40bG8fNX1nPFrGH8dsEkALKKKjn10RWcODqeH586mnFDIgkN9GdffgUbMos4VFLFvCnJJEW3VBLbckr47j+/ocEYzpuawujECEYnRjBt2CACHdbQiu2H+d7zqzjn6CT+vHBak+FEvYmq2nqCA/x6rXz9EVUESq/DGENpdR25pdUMiQohPLj1p9e3N2azObuECUlRTEiOYkRceJOnfoD6BsMHW3J45vM9rNpr/eRx4UFcf/JILkkfyv6CCr7NKuZgcSVzJyZxdKrtxXSopIoH393GG+ta734S5O9HVGgAfiIcLq3m9PGJ3H/+0dTUNfDo+9v53/psABIig5k9NoHqugY+2HKISsfN7rPb5pAY5bIa/vLxTh59fwdglU5EUECj6w0g0F84b2oK155oFUxIoD8bDhRx9XPfEBzgx4s/mNVEWTbnbyt28dB72zg6JZq0+HCGxoZy0pgEjh0Z1+oxPcmSDdnc9ca3TEiK4omF0xjs9rvxJdV19QQH+Le/sI+iikAZUGzMLGJXbhlzJyYRGtSx/9iHSqqoqKlHgAZjyCur4WBxJQeLqyiqqKWkqpayqjpOG5/I/CnJTZ5kMw6XUV1Xz4SkqMb9FTV1fLztMFEhgZw8tmWjxAMFFWw9WMKWgyXklVUzMTmaKamDCAvy57kv9vDK6gNU1dpU0+AAP+obDEmDQnjx+8cyLK5t/78xhieXZ/BFRj6ZRRVkF1VR32A4YXQct5xxFMcMj2n12Nr6BgorasBYxdbRJ/bqunr251ewK7eczMIKokIDGRIVwuCoEBIigxkUGkhFbT33LtnMq2symZAUxZ68csKD/Xn80mmcOCa+1XOXVNWydONBCipqOHZkHJNTotuMBzU0GNYdKGRbTinnTk4mOrT94sjFqw5w95JNzJ04hAcvnExIYP9TCKoIFKWPUVBew/ubc8gvr6HEMVnu+yeleXQZtUdVbT0vfr2fv63IIK+shnFDIhmVGMHI+HBEhF2Hy8g4XEZWUSVlbpZJSKAfI+LCSR4USnCAH4H+foQHBzA+KZKJyVEkRobwyY5clm3OYeXufGrrW7+X+AkEBfhRU9fATXNGc/NpY9iTV86PXlxLRm4ZcycOYWZaLDNGxBIRHEB2cSVZhZV8ujOP9zfnUO02NyMyOIBpw2MYGR/OyIRwEiODqaptoKKmnn355by98SBZRZWADZ7//IyxLJw5jEB/+/2FFTXEhAURFOBHZU09v/nfJl5dk8m4IZFsyyllytBBPH3lMU2sOIDiilqe/WIPFTV1TBsWw/RhMU3iQ81paDC8tjaTLQdLOHdyEtOHxSAiZBdV8vyXe1m3v5D5U1O4aHpqhx9YuoIqAkVRKK+u4z8r97Fydz578so5UFiJMYahsWGMTohgaGwYMWFBjQ0K9+VXsC+/nIPFVdTWN1BbbyisqKGoomn6a1p8OKePT2RicjQjE8IZGhNGaVUdh0qryCmuIr+smvzyGoora5k3JZkZI2Ibj62oqePh97bz/uYcsotb1qwMCgtk/pRkLpyeytDYML7alc/nGblsOFDM3nxXnMlJgJ9w0ph45k9NZlhsGH98fwdf7spnSFQIBsPh0urGONBgR6uVQ6VV/GTOaH56+lg+3HqIn7+ynqiQQG6cPYrxSVGkxYfz5ros/rI8g5Kq2kaFAjAyIZx5k5OZNyWZ0YkRjXKs2VfIb9/azMbMYvz9bHxpdGIEYxIj+GDLIRqMYURcOLvzyokJC+SSGUNJGRRKSKA/kcEBDI+zSi4k0J+6+gYyCyvZlVvG2MGRR5wRpopAUZQW1NQ10GBMp9wgxhhySqrYlFVCdlElx42KY0xiRLcEfbOKKlm9t4CaugZSBoWSNCiU1JjQxkC4J1lyS6vJLasmNNCfsKAAokMDmzxdO1ONF68+QHRoIMmDQomPCCKvrIbMwkoKK2q46rjhzD4qsfGYLdkl/OjFNezNb1rDcsrYBG4/exyjEiLYcrCENfsK+XDLof9v795jpDrLOI5/f4VKt5ByaXFTWXSpoJVae5EYpMYY2j9KNcXEmlKbWBuSJo0XNEbFmJjU+E+NsYo2TehFsWnaRqxKGlJtodEmthRQ5FJq2QIWmmXZbYEtVJYFHv84L2QcdmCX7mHKeX+fZDLnvGey8z77bObZc5nn8MK2N4goWr2POEecI+jq7aP1glEsnHMp132kleUbOnls9Q62dh/gpo+38ZVZ7bSNb2H19j3c/9xWntncRf1HsVRcEdazv+/43tZdN17GbbPaT+v360JgZjYEEUFXbx+bO3t5pestLp80lllTBz6P0dV7kOUbOunYvZ+jERw9CpMntHD7NVNOehFErYP9RzjQd5i3Dx2h92A/23oOsKVrPzvefJv3XnAeH5w4mksmjuFDrWNOuyGkC4GZWebcdM7MzBpyITAzy1yphUDS9ZL+LalD0sIBto+S9HjavkpSe5nzMTOzE5VWCCSNAO4F5gDTgVskTa972XxgT0RMBe4B7i5rPmZmNrAy9wg+AXRExNaIOAQ8Bsyte81cYElaXgpcKzcfMTM7o8osBJOAHTXrO9PYgK9JN7vfB5zQEEXSHZLWSFrT3d1d0nTNzPJ0VpwsjojFETEjImZMnHhi3xYzMzt9ZRaC14HJNettaWzA10gaCYwF3ihxTmZmVqfMO1esBqZJmkLxgT8P+FLda5YBtwHPAzcBK+MU33Bbu3Ztj6T/nOacLgJ6Tvmq6skx7hxjhjzjzjFmGHrcH2i0obRCEBGHJX0N+DMwAngoIjZJ+hGwJiKWAQ8CD0vqAN6kKBan+rmnfWxI0ppG36yrshzjzjFmyDPuHGOG4Y271HvZRcRyYHnd2A9rlg8CXyxzDmZmdnJnxcliMzMrT26FYHGzJ9AkOcadY8yQZ9w5xgzDGPdZ133UzMyGV257BGZmVseFwMwsc9kUglN1Qq0CSZMlPSvpJUmbJC1I4xMkPS1pS3oe3+y5DjdJIyT9U9KTaX1K6mjbkTrcvqfZcxxuksZJWirpZUmbJX0yk1x/K/19b5T0qKTzqpZvSQ9J2i1pY83YgLlVYVGKfb2kq4f6flkUgkF2Qq2Cw8C3I2I6MBP4aopzIbAiIqYBK9J61SwANtes3w3ckzrb7qHodFs1vwCeiohLgSso4q90riVNAr4BzIiIj1J8R2ke1cv3b4Dr68Ya5XYOMC097gDuG+qbZVEIGFwn1LNeRHRGxD/S8lsUHwyT+P8ur0uAzzdnhuWQ1AZ8FnggrQuYTdHRFqoZ81jg0xRfyiQiDkXEXiqe62Qk0JLa0pwPdFKxfEfE3yi+ZFurUW7nAr+NwgvAOEkXD+X9cikEg+mEWinpJj9XAauA1ojoTJt2Aa1NmlZZfg58Fzia1i8E9qaOtlDNfE8BuoFfp0NiD0gaTcVzHRGvAz8FXqMoAPuAtVQ/39A4t+/48y2XQpAVSWOA3wPfjIje2m2pl1NlrhmW9Dlgd0SsbfZczrCRwNXAfRFxFXCAusNAVcs1QDouPpeiEL4PGM2Jh1Aqb7hzm0shGEwn1EqQdC5FEXgkIp5Iw13HdhXT8+5mza8E1wA3StpOcchvNsWx83Hp0AFUM987gZ0RsSqtL6UoDFXONcB1wLaI6I6IfuAJir+BqucbGuf2HX++5VIIjndCTVcTzKPofFop6dj4g8DmiPhZzaZjXV5Jz38603MrS0R8PyLaIqKdIq8rI+JW4FmKjrZQsZgBImIXsEPSh9PQtcBLVDjXyWvATEnnp7/3Y3FXOt9Jo9wuA76crh6aCeyrOYQ0OBGRxQO4AXgFeBX4QbPnU1KMn6LYXVwPrEuPGyiOma8AtgDPABOaPdeS4v8M8GRavgR4EegAfgeMavb8Soj3SmBNyvcfgfE55Bq4C3gZ2Ag8DIyqWr6BRynOgfRT7P3Nb5RbQBRXRb4KbKC4ompI7+cWE2Zmmcvl0JCZmTXgQmBmljkXAjOzzLkQmJllzoXAzCxzLgRmdSQdkbSu5jFsjdsktdd2lDR7Nyj15vVmZ6n/RsSVzZ6E2ZniPQKzQZK0XdJPJG2Q9KKkqWm8XdLK1At+haT3p/FWSX+Q9K/0mJV+1AhJ96ee+n+R1NK0oMxwITAbSEvdoaGba7bti4jLgV9RdD0F+CWwJCI+BjwCLErji4C/RsQVFH2ANqXxacC9EXEZsBf4QsnxmJ2Uv1lsVkfS/ogYM8D4dmB2RGxNzf12RcSFknqAiyOiP413RsRFkrqBtojoq/kZ7cDTUdxcBEnfA86NiB+XH5nZwLxHYDY00WB5KPpqlo/gc3XWZC4EZkNzc83z82n57xSdTwFuBZ5LyyuAO+H4PZXHnqlJmg2F/xMxO1GLpHU1609FxLFLSMdLWk/xX/0taezrFHcK+w7FXcNuT+MLgMWS5lP8538nRUdJs3cVnyMwG6R0jmBGRPQ0ey5mw8mHhszMMuc9AjOzzHmPwMwscy4EZmaZcyEwM8ucC4GZWeZcCMzMMvc/qQe+y2RD9yYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xUVd7/3yeT3kglQBIINXQIBBALxd5RbOBaWF1d/a3us0Vd1y26lmebz67bLWtbG7q6i6jYwAKKAqFKJ0AgBUJ6bzNzfn+cuckkmQmTkCGF7/v1yitz79x758ydmfM533aO0lojCIIgCG0J6OkGCIIgCL0TEQhBEATBIyIQgiAIgkdEIARBEASPiEAIgiAIHhGBEARBEDwiAiGc8iil3ldK3dzdxwpCX0dJHYTQF1FKVbtthgMNgMO1/V2t9Ssnv1UnhlIqGngYWAjEAYXAO8CjWuvinmybcGoiFoTQJ9FaR1p/wGHgMrd9zeKglArsuVb6jlIqGFgFTAAuBKKB2UAJMLML1+sT71vo3YhACP0KpdQ8pVSeUuonSqmjwPNKqVil1LtKqSKlVJnrcYrbOZ8ppb7jerxEKfWFUupx17EHlVIXdfHY4Uqp1UqpKqXUSqXU35RSL3tp+k3AUOBKrfVOrbVTa31Ma/2I1nqF63paKTXK7fovKKUe7eB971JKXep2fKDrHkxzbZ+mlFqrlCpXSm1VSs070fsv9C9EIIT+yCCMi2YYcDvme/68a3soUAf8tYPzZwF7gATgd8CzSinVhWNfBdYD8cBDwI0dvOa5wAda6+oOjjkebd/3a8Bit+cvAIq11puUUsnAe8CjrnPuAd5SSiWewOsL/QwRCKE/4gQe1Fo3aK3rtNYlWuu3tNa1Wusq4DFgbgfnH9JaP6O1dgAvAoOBpM4cq5QaCswAfqm1btRafwEs7+A144EjnXub7Wj1vjECdblSKtz1/PUY0QC4AVihtV7hslY+BrKAi0+wDUI/QgRC6I8Uaa3rrQ2lVLhS6iml1CGlVCWwGohRStm8nH/UeqC1rnU9jOzksUOAUrd9ALkdtLkEIy4nQqv3rbXOBnYBl7lE4nKMaICxMq5xuZfKlVLlwJnd0AahHyGBLKE/0jY178dAOjBLa31UKTUV2Ax4cxt1B0eAOKVUuJtIpHZw/ErgUaVUhNa6xssxtZiMLYtBQJ7btqeURMvNFADsdIkGGLF6SWt923Heh3AKIxaEcCoQhYk7lCul4oAH/f2CWutDGJfNQ0qpYKXUbOCyDk55CdNpv6WUGquUClBKxSulHlBKWW6fLcD1SimbUupCOnaTWSwFzgfupMV6AHgZY1lc4LpeqCvQneLxKsIpiQiEcCrwBBAGFANfAx+cpNf9Fi2pqo8Cr2PqNdqhtW7ABKp3Ax8DlZgAdwKwznXY/2BEptx17WXHa4DW+gjwFXC66/Wt/bnAAuABoAgjTvcifYLghhTKCcJJQin1OrBba+13C0YQugMZLQiCn1BKzVBKjXS5iy7EjNiPO+oXhN6CBKkFwX8MAv6DSWHNA+7UWm/u2SYJgu+Ii0kQBEHwiLiYBEEQBI/0GxdTQkKCTktL6+lmCIIg9Ck2btxYrLX2OMVKvxGItLQ0srKyeroZgiAIfQql1CFvz4mLSRAEQfCICIQgCILgEREIQRAEwSMiEIIgCIJHRCAEQRAEj4hACIIgCB4RgRAEQRA80m/qIARBEHojx6rqOVhUw6HSWipqm1g4LZn4yBCfzrU7nCilsAX4c20r74hACILQrdQ3OQi2BRDQjZ2a3eGkrslBVGhQt12zq2itOVBcw8acMuxOzVXTkwkJbL967ZGKOv53xW7e2VrQav9Tq/fz64WTOW98EnaHk/e+OcK7245w0cRBLJzWsl7TV/tLuOvVTdQ02klPimLc4GgiQwKpaXRQ22hnQFgQ4wZHM25wNGOSIgkP7v7uvN9M1peZmamlkloQOmZDTikf7TjK7XNGkhhlRrFOp+aVdYdY8c1RpqTGMGd0AtPTYlEoahvtlNY0siW3nI2HytiWV0FFXRO1jXYampyMGxLNnNEJnDYinr2F1by//Qhf7S9hcEwo35o1jGszU4mLCG7Vhm/yKnhmzQG2F1RQ1+igpsHO+CHRPHVDJgPCWwRgzb4inllzkEMlNeSX1WF3akYkRDBtWCxjB0VRWW+nuLqBkuoGal3XqWtyYvVpSiliwoJIjAphYFQIV2QkMzF5QPP1dxRUcO+/t5FfXkdEsI2wYBsRIYGEB9sIDw5kXnoiN542DKWM0GmtefLzAzyz5gClNY3N10mLD+fByycwP30gWmuOVNTz9pYC/vLJPuxOzXfOHM6sEfEMiwunusHOvW9uY9eRSs4fn8SOgkryy+uICgmkqsHOlRnJPHLFRP67OZ9fLd9BWkIEc8cksutIJbuPVtHQ5CDc1caS6kaqG+wAjB0UxQc/mNOl74RSaqPWOtPjcyIQgtD7aLQ72XmkktTYsFbuiKr6Jj7fW8TW3HJ2Hali99EqrswYws8uGX/ca9odTs7/42oOFNcQFRLID84bw+kj4/n5su1sPFRGWnw4ea6O2BNRIYFMSY0hITKY8JBAbEqxObeM7fmVzcekxYdzzrgktudXsO5gKcG2AKamxjA0PpzU2HC+PlDCVwdKiAoJ5MzRCUSFBhJkC+DfWXmkD4ri5e/MYkBYEMs253PPv7eSFB3K1KExDIsLJzzYxpbcCjYdLqO0phGlIC48mPjIYCJDAgkPDiQ0yIZluDg1lNc2UlzdwJGKepocTq6fNZQfn5fOsi35/HrFbmIjgrhgwiAjVI12ahsd1DY6KKluYH9RDd8+I41fXDIepeA3H+zmqc8PMC89kQsnDCIzLZb88np+9c4ODhTVMHZQFEcq6qmoawLg3HFJ/PLS8QyND291HxvtTv60ai9Pfn6A6UNjuX3OCOamJ/L3T/fzp1V7GRAWRFltE2ePHcifFk31ajU5nZq8sjp2HqkENBdOHHzc74AnRCCEfsnRinpeWXeI8OBAEiKDGRYfwYy02OYRH0CTw8k7WwuodP1oAwIU04bGMmFINEoptNZsyCnjjaxc9hdVU1zdQHFVIyMSI7gyI5kFU5NJjAqhyeGktKaRsGAb0W4/2HUHSvjTqn0UVzfwo/PGcMGEQc2v73BqCsrrCAkKICI4ELtDszm3jE2Hysgrr+PByyYwIKzlWlpr3tyYxwfbj/LVgRJqGx0ATEyOZvaIePYX1fDFvmIaHU6CAwNIT4pCo9l1pIpPfjyXYfERHd6v/2zK40dvbOWBi8fyRXYJq/cWARATHsQvLhnPwmnJ1DQ6WHeghK15FQTbFOHBgUSFBjIpZQCjB0Z59IUXVzeQlVNKWkIE6UlRze9/b2EVS9fnsj2/gpySGo5VNZAUHcKtZw5n0cyhre7jJ7sL+e5LGxk3OJoLJgzi9x/u4bQRcTxzU2a7DlJrTVltE9GhgQTafMuzqahr4o8f7+VfX+UQaAug0e7knLED+f01U9pZOGA630ff28VzXx7kiqlDGBAWxItfHeKG04by8OUTW7nPGu1OnvvyIJ/uPsaIxEjGDY5iamoMk1NiOmyTw6nb3c91B0r4+bLtnDMuiXsvSD8psQcRCKHPoLUm+1g1q/cVk1dW22zujx8czfyxA5uPa3I4uebJr9iSW97q/G/NGsqvLp9AoC2AukYHd726iVW7j7V7nZTYMOalJ7LhYBl7CquICg1kSooZHcdGBDe7U2wBiujQQMpqjcAoBWMGRjFtWCyHSmpYu7+ExKgQYsKC2HesmrNGJ7BoxlDW7Cvi452FlLi5IiwClBnd/uzicdw2Z0Tz/tV7i7jpufUMjQtn7phEZo2II6e4htX7itl0qIyk6FAunDiICycOIiM1hkBbAIWV9cz53adcOnkI/3ftFK/31e5wcs4fPiciOJB37z4TpeCjnYVsOFjKHfNGkuBj0PREqGt0EBwY4LXTW7mzkDtf2UiTQ3PBhCT+tCiD0KD2vv0TYdeRSp5YuZfTRsSz5PS0VoOJtmit+ftn+/n9h3sA+M6Zw/nZJeM6PKcvIgIhnHQsX2xcRHCHP/LnvjjIqt2FrnPgYHENRyrqAYgItlFvd+JwuTweXjCBm2anAfDHj/fyp1X7+MviDM4eO5Di6gZeXXeYp1YfYH56Io9dOYnvv7aZjYfLePjyCVw6eQgA9XYHa/YW8/72I3yZXcKYQZHceNowLpsypF2QL/tYFcs2F1Ba28jAqBASIkMoq2kk61AZmw6XERJo4855I/nWrKEEBihe+voQf/hoL1UNdiKCbZw9LonZI+JxaE1tgx0NTE4ewJTUGG56bj1ltY2s+tHc5g7ntn9lselQGWt/ena7oGej3UmQTXnsnB55dyfPf3mQlT+ay4jESI/3+Y2sXO57cxvP3JTJeeOTjvPp9Rxf7Ctma145d8wd2WOZO215Z2sB5bWN3OAWj+hPiEAIfiP7WDVr9hVR12TcIXaHZkdBBRsPlVNc3UBIYACzRsQzZ3QCV2a0Tu+zRsyjBkYS43K1JEWHctboBM4cnUBKbDhaa+qbnNz92iZW7jrG49dMYXhCBNc8uZYrpibzh+umtmrPK+sO8Ytl2wlQigCleGLRVC6e5Nk363BqAhRd+tE7XaLVNlOnpLqBvYXVZAyN6VAY/52Vy71vbuP1209j1oh48svrOOu3n3DH3JHcd+HYTrWlqKqBOb/7lAsmJPHEoox2zzc5nMx//DNiw4NZftcZ/bKTE7pORwIhaa5Cp6lvcvCPz/bz3jdHyD5W3e75YfHhzBmdwJTUGA6V1LJmXxGPvreLl78+xNLbZzNoQCgVtU3c9+Y2Rg2M5N27z/TamSqlCAu28dfrp3Hrixu4782txEWEMCQmjF8tmNDu+G/NGsaQAWH84eO93H/RWM4YleD1fZzICNVbCmd8ZAizfXDXXDp5CA+/u5PX1h9m1oh4lq4/jAYWzxza6bYkRoVw0+nDeHr1Ae46exSjBkY1P3ewuIYX1+aQV1bHIwsmijgInUIEQvBKfZODTYfLmD0ivlXH8rsP9vDclwc5fWQ8N80exrnjkpoDfUrhMSc8K6eUJc9vYPEzX/Pabafxuw92U1TdwNM3TffJzxwaZOOZmzK58dn1bD5cxuvfne01u2P+2IGt4hW9kbBgG1dmJLN0Qy4PVNXz2vpczk4fSGpc+PFP9sB354zk5a8Occ2TXzE0LpyEyBDyyurYU1gFwCWTBjMv3eOiYYLgFXExCV55bf1hfvqfb7hr/ijuuSAdMLnpNz67nptnD+NXCyZ26nobD5Vx07PrCA8JpKiqge+fM5ofnTemU9eob3KQV1bHqIGefe19iZ0FlVz85zXMHB7H+oOlPL9kxgkJ22d7jrF8awHF1Y0UVTUwICyQ88cP4oKJg0iOCevGlgv9CXExCV1iy2GTIfTXT7OJCAlk0YxU7vn3VkYNjOSnF4/r9PWmD4vlxVtmcvNz65mYHM3dZ4/q9DVCg2z9QhwAxg+JZkpqDOsPlpIaF8acMSc2wp+XPpB56b3bchL6FiIQAsu3FvDSVzm8fvvsVr71b/IrOHNUAvGRwfz2g928tSmP0ppGnr15RpfTDzPT4lj143lEhNgI8jGHvT9z/cxUtuaWc/3MYb0ma0cQLEQgBLbmlrMhp4zsomrGJJkAZ32Tg72FVdw+ZwQ/PG8MtY0OPt5ZyP0XjW01XUFXGDQgtDua3S+4IiOZ2kYH12am9nRTBKEdIhBCc4rqhpzSZoHYW1iF3amZmDyAIFsAf70+g405ZZw2Ir4nm9rvCAm08e0zhvd0MwTBI2LjC9S5pnTIyilr3vdNfgUAk1zWQkigjdNHJXTrDJ2CIPRuRCAEahvNjJAbckqb923Pr2BAWBApsZL9IginKiIQQvOkcHlldRypqAOMBTEpeYAUVgnCKYwIxCmC1pqHlu/gp//5pt1z9U2O5llFs3LKaLA72HO06oSD0YIg9G1EIE4RfvP+bl5Ym8OX2cXtnqttdDA1NYbwYBtZOaXsPVpNk0M3xx8EQTg1kSymU4CnV+/nqdUHCA+2NbuT3KlrdBAVGsi0obFsyCkjfVA0YNYhEATh1EUsiH7O21vy+d8Vu7lk0mCum5HaHJB2p67JQXiwjcy0WHYdrWTt/mKiQwMZ2sV5gQRB6B+IQPRzXlybQ3pSFH+4bgpRIYHUNjqap6q2qG10EBZkY0ZaHFrDB9uPMlEC1IJwyiMC0c8prGxg/JBoQgJthIcYj2K9vbWbqa7RQVhwIFNTY7AFKOxOiT8IgiAC0a/RWlNU1cDAaLM+QUSwmT+ppqFFIOwOJ40OJ+HBNiJCApk4xIo/iEAIwqmOCEQ/pry2iUaHk4FRZu6jMNeSmu5xCGuajTDX5HuZaXEAYkEIgiBZTP2ZY1UNAAyMam1BuGcyWdNshLmeu3l2GgmRIQyLlwC1IJzqiED0Y45V1QMtAmHFIDxZEOEugRgaH86d80aezGYKgtBLERdTP+ZYpcuCiDYupnAPMQjLmgjr4voOgiD0X0Qg+jFtXUzhHlxMtW1cTIIgCBYiEP2Ywsp6IkMCiXC5liI8BKnrm11M4m0UBKE1fhUIpdSFSqk9SqlspdT9Hp4fppRapZTappT6TCmV4vacQym1xfW33J/t7K8UVTU0Ww/g5mLyZEGIi0kQhDb4bdiolLIBfwPOA/KADUqp5VrrnW6HPQ78S2v9olLqbODXwI2u5+q01lP91b5TgWNV9SS6C4TLkqhzsyAsa0JcTIIgtMWfFsRMIFtrfUBr3QgsBRa0OWY88Inr8acenhe8oLXm+69t5qf/2cb+omqPxxyramgOUEOLleAepLbSXMNFIARBaIM/BSIZyHXbznPtc2crsND1+EogSillLXocqpTKUkp9rZS6wo/t7JPkltaxfGsBr63P5Zz/+5zvvJhFbmlt8/Naawor60lysyBsAYrQoIAOC+UEQRAsejpIfQ8wVym1GZgL5APW8HaY1joTuB54QinVLjlfKXW7S0SyioqKTlqjewPrXcuDvvqdWXz/7FF8mV3M4x/taX6+qsFOfZOzeZoNi4jgQMliEgTBJ/yZupIPpLptp7j2NaO1LsBlQSilIoGrtNblrufyXf8PKKU+AzKA/W3Ofxp4GiAzM7P1FKX9nA0HSxkQFsRpI+I5fVQC2wsq2XO0qvn55hqIqNBW54WH2NpVUgcoCAns6bGCIAi9DX/2ChuA0Uqp4UqpYGAR0CobSSmVoJSy2vBT4DnX/lilVIh1DHAG4B7cPuXZcKiUGWmxBASYKblHJ0Wyv6iaJocTaF9FbREeFEhNQ2sXU1iQTab2FgShHX4TCK21HbgL+BDYBbyhtd6hlHpYKXW567B5wB6l1F4gCXjMtX8ckKWU2ooJXv+mTfbTKU1xdQMHimqaJ9YDGDMwiiaH5lBJDWBSXIF2LqbwEFtz3AFca0FIDYQgCB7wa8+gtV4BrGiz75duj98E3vRw3lpgkj/b1pfJcsUfZrgJRPqgKAD2FlYzamAUhZUuCyK6tYspIriNBdFolwwmQRA8Io7nPsj6g2WEBgW0mpJ7ZGIkStEchzhW2UBoUABRIa3HAGFt1qW2lhsVBEFoiwhEHyTrUClTU2MIdgsshwXbGBoXzr5jLoGoamBgVGi72EJEG4GobXQQKimugiB4QASij1HTYGdHQSUz3dxLFmOSothbaIrmjlXVtwtQg6mmblUH0SgWhCAInhGB6GNsOlyGw6lbBagtxiRFklNcQ4Pd4aqi9iAQQeJiEgTBN0Qg+hgbDpYSoGDasNh2z41JisLu1BwsruFYZUO7GgiwLAgHTqcpG6kTF5MgCF4QgehjrM8pZcKQAUSGtE9AG5NkMpm25pZT3WD3bEG4rAUr1bVWXEyCIHhBBKIPUd/kYEtueav0VndGJEZgC1B8kV0CtK+ihvbrUhsXk9RBCILQHhGIPsTKXYXUNzk5e+xAj8+HBNpIiw9nbXYx0L6KGloWBrIC1eJiEgTBGyIQfYi3NuYxeEAos0fGez1mTFIUJTWNQPsqami9LrXd4aTR4RQXkyAIHhGB6CMcq6pn9b5irshIxhbgfd6k0a44BECSlyA1QF2TvTkOIQIhCIInRCD6CMu3FOBwaq6altLhcekugQi2BRATHtTu+Qg3C8JaLEhcTIIgeEIEoo/w5sY8pqTGMGpgZIfHjUkyzydGhXicoTWsOUhtbw5UiwUhCIInRCD6ADsKKth9tIqrp7VdkK89aQkRBNlUq7Wo3YloDlI7RCAEQegQyW/sA/xnUz5BNsWlk4cc99ggm5nEb0SiZ0sjPMTlYmp0NMcgxMUkCIInRCB6OXaHk7e35HPO2CRiI4J9OueFW2YSFODZOGxOc22wN8cgpA5CEARPSM/Qy8krq6O4utFr7YMnokPbB6ctwoJaCuWsWghxMQmC4AmJQfRyqupNJ+4pI6kr2AIUYUE2ahvt4mISBKFDRCB6OZX1TQBEh3WPQICxGGoaHW4uJhEIQRDaIwLRy6lyCURUaPd5A8NDbNRJFpMgCMdBBKKXU+lyMXUUV+gs1rrUlospTARCEAQPiED0cqr8IBBhwTbqmoyLKUCZqmtBEIS2SM/Qy6msMy6myG50MVkWhFkLItBjxbUgCIIIRC+nqt5ORLCtwwn6Okt4sFl2tK7JIe4lQRC8IgLRy6mqb+rWDCZwE4hGe3NdhCAIQltEIHo5VfX2bs1gAmtdarssNyoIQoeIQPRyKuubiOrGADWYKb9rGsTFJAhCx4hA9HL8YUGEBQdS12TqIMTFJAiCN0QgejlV9U3dmuIKLYsGlVQ3iItJEASviED0cir9EYNoFohGwmQmV0EQvCAC0YvRWlPlhxiENb13VYOdsCD5CgiC4BnpHXoxDXYnTQ5NdFj3jvIjQlrcSrIWhCAI3hCB6MVUNk/U170WhLtbSbKYBEHwhghEL6ayzpqHqZstCDdRkCwmQRC8IQLRi/HHVN/Q2q0kWUyCIHhDBKIX44+ZXKG1KIiLSRAEb4hA9GL8FYMIDxEXkyAIx0cEohdjWRDd7WKKEBeTIAg+4FeBUEpdqJTao5TKVkrd7+H5YUqpVUqpbUqpz5RSKW7P3ayU2uf6u9mf7eytVPlhPWpobTVIoZwgCN7wm0AopWzA34CLgPHAYqXU+DaHPQ78S2s9GXgY+LXr3DjgQWAWMBN4UCkV66+29laq6u0EqNZZR91BQIBqFgmxIARB8IY/LYiZQLbW+oDWuhFYCixoc8x44BPX40/dnr8A+FhrXaq1LgM+Bi70Y1t7JZV1TUSG+GfFN6tYTmIQgiB447gCoZS6TCnVFSFJBnLdtvNc+9zZCix0Pb4SiFJKxft4Lkqp25VSWUqprKKioi40sXdjZnLtXveShZW9JFlMgiB4w5eO/zpgn1Lqd0qpsd38+vcAc5VSm4G5QD7g8PVkrfXTWutMrXVmYmJiNzft5HKgqJrZv15Fbmlt877Kenu3xx8srEC1uJgEQfDGcQVCa30DkAHsB15QSn3lGrlHHefUfCDVbTvFtc/92gVa64Va6wzgZ6595b6c29/IOlTGkYp6tuVVNO8ziwX5J4hsCYO4mARB8IZPriOtdSXwJiaOMBjjDtqklLq7g9M2AKOVUsOVUsHAImC5+wFKqQQ399VPgedcjz8EzldKxbqC0+e79vVbDpcYyyGvrMWCqKq3d/s0GxZWNbW4mARB8MZxex+l1OXAt4FRwL+AmVrrY0qpcGAn8BdP52mt7UqpuzAduw14Tmu9Qyn1MJCltV4OzAN+rZTSwGrge65zS5VSj2BEBuBhrXXpCbzPXk9OSQ0AeWV1zfvMYkHHM9S6RniwDVuAItgmpTBC76SpqYm8vDzq6+t7uin9gtDQUFJSUggK8t1t7cvw9Crgj1rr1e47tda1SqlbOzpRa70CWNFm3y/dHr+JsUw8nfscLRZFv+ewK/aQX+4uEN2/WJBFREggYUE2v2RICUJ3kJeXR1RUFGlpafI9PUG01pSUlJCXl8fw4cN9Ps+X4eNDwHprQykVppRKc73oqs41U/BGTrFlQRih8NdiQRbD4sMZGhful2sLQndQX19PfHy8iEM3oJQiPj6+09aYLwLxb8Dptu1w7RO6ifLaRirr7QTbAsgvq0NrTU2jA6em2xcLsrj77NEs+94Zfrm2IHQXIg7dR1fupS8CEegqdAPA9Ti4068keOWQK0A9bVgMNY0Oymub3Kb69o8FYQtQBAdK/EEQvFFSUsLUqVOZOnUqgwYNIjk5uXm7sbGxw3OzsrL4/ve/f5Ja6j98GZ4WKaUudwWVUUotAIr926xTCytAfcbIBL4+UEpeWR0hrrWi/RWDEAShY+Lj49myZQsADz30EJGRkdxzzz3Nz9vtdgIDPf8+MzMzyczMPCnt9Ce+DCHvAB5QSh1WSuUCPwG+699mnVpYKa6zR8YDkF9eS2Wdfy0IQRA6z5IlS7jjjjuYNWsW9913H+vXr2f27NlkZGRw+umns2fPHgA+++wzLr30UsCIyy233MK8efMYMWIEf/7zn3vyLXSK4w5Ptdb7gdOUUpGu7Wq/t+oUI6eklqToEEYPNCmteWV1hASa+gR/1UEIQl/iV+/sYGdBZbdec/yQaB68bEKnz8vLy2Pt2rXYbDYqKytZs2YNgYGBrFy5kgceeIC33nqr3Tm7d+/m008/paqqivT0dO68885OpZv2FD71PkqpS4AJQKgV6NBaP+zHdp1SHC6tYVhcBNFhgUSGBJJXVkdiVAggFoQg9DauueYabDYzgKuoqODmm29m3759KKVoamryeM4ll1xCSEgIISEhDBw4kMLCQlJSUjwe25vwpVDuSSAcmA/8E7gat7RX4cQ5VFLL3DGJKKVIiQ0jr6yOkQMjAbEgBAHo0kjfX0RERDQ//sUvfsH8+fP573//S05ODvPmzfN4TkhISPNjm82G3W73dzO7BV9iEKdrrW8CyrTWvwJmA2P826xTh9pGO8eqGhgWb2oSkmPCyCur9dtiQYIgdB8VFRUkJ5uJpl944YWebYwf8EUgrMqKWqXUEKAJMx+T0A1YFdRD482oJCU2jPzyOqrq7ZnVa+YAACAASURBVATZFCGSiioIvZb77ruPn/70p2RkZPQZq6Az+OK/eEcpFQP8HtgEaOAZv7bqFCKn2AhEmsuCSIkNp6reTn5ZHVGhQVIoJAi9gIceesjj/tmzZ7N3797m7UcffRSAefPmNbub2p67fft2fzTRL3QoEK6ZVle5puB+Syn1LhCqta7o6DzBO1prGuxOQl3TbB8uNTUQw+KMBZEcGwbAriOVUgMhCEKP0qH/QmvtxKwrbW03iDicGO9uO8K0Rz7mQJHJFj5UUktMeBADwk2sIcUlEAeKa4iWDCZBEHoQXxzcq5RSVynxdXQLG3JKqW108Nh7uwAjEMPcJs1LjjEC4XBqsSAEQehRfBGI72Im52tQSlUqpaqUUt1bsXIKsedoFQEKVu0+xuq9RRwqrWkOUAPERQQ3r/ImAiEIQk/iy5KjUVrrAK11sNY62rUdfTIa19/QWrOnsIorMpIZFh/Or97ZQUF5fXOAGmiuhQDExSQIQo/iS6HcHE/72y4gJByfoqoGymubmJQ8gAsnDOL2lzYCtFuXITk2jH3HqqWKWhCEHsUXF9O9bn+/AN7BLCIkdJI9hVUApA+K4rzxSZwxykzON8zNxQQtgWpxMQlCzzF//nw+/PDDVvueeOIJ7rzzTo/Hz5s3j6ysLAAuvvhiysvL2x3z0EMP8fjjj3f4usuWLWPnzp3N27/85S9ZuXJlZ5vfLfjiYrrM7e88YCJQ5v+m9T/2HHUJRFIUSikevWISV09PYXLKgFbHJccYi0IEQhB6jsWLF7N06dJW+5YuXcrixYuPe+6KFSuIiYnp0uu2FYiHH36Yc889t0vXOlG6UqabB4zr7oacCuw5WkVCZDDxkWZeluEJETx+zZTmmgiL5hiETLMhCD3G1VdfzXvvvde8OFBOTg4FBQW89tprZGZmMmHCBB588EGP56alpVFcbJbNeeyxxxgzZgxnnnlm83TgAM888wwzZsxgypQpXHXVVdTW1rJ27VqWL1/Ovffey9SpU9m/fz9LlizhzTffBGDVqlVkZGQwadIkbrnlFhoaGppf78EHH2TatGlMmjSJ3bt3d8s98CUG8RdM9TQYQZmKqagWOsmewirSB0Ud97g0l8spPkIW7hMEAN6/H45+073XHDQJLvqN16fj4uKYOXMm77//PgsWLGDp0qVce+21PPDAA8TFxeFwODjnnHPYtm0bkydP9niNjRs3snTpUrZs2YLdbmfatGlMnz4dgIULF3LbbbcB8POf/5xnn32Wu+++m8svv5xLL72Uq6++utW16uvrWbJkCatWrWLMmDHcdNNN/OMf/+AHP/gBAAkJCWzatIm///3vPP744/zzn/884VvkiwWRBWx0/X0F/ERrfcMJv/IphtOp2VtYxZik4wvExORoXvj2DOaOSTwJLRMEwRvubibLvfTGG28wbdo0MjIy2LFjRyt3UFvWrFnDlVdeSXh4ONHR0Vx++eXNz23fvp2zzjqLSZMm8corr7Bjx44O27Jnzx6GDx/OmDFmrtSbb76Z1atbcoUWLlwIwPTp08nJyenqW26FL07uN4F6rbUDQCllU0qFa61ru6UFpwi5ZbXUNzkZ64MFoZRiXvrAk9AqQegjdDDS9ycLFizghz/8IZs2baK2tpa4uDgef/xxNmzYQGxsLEuWLKG+vv74F/LAkiVLWLZsGVOmTOGFF17gs88+O6G2WlOKd+d04j5VUgNhbtthQM+E1Pswu10Bal8sCEEQegeRkZHMnz+fW265hcWLF1NZWUlERAQDBgygsLCQ999/v8Pz58yZw7Jly6irq6Oqqop33nmn+bmqqioGDx5MU1MTr7zySvP+qKgoqqqq2l0rPT2dnJwcsrOzAXjppZeYO3duN71Tz/giEKHuy4y6Hod3cLzggb0ugRgtAiEIfYrFixezdetWFi9ezJQpU8jIyGDs2LFcf/31nHHGGR2eO23aNK677jqmTJnCRRddxIwZM5qfe+SRR5g1axZnnHEGY8eObd6/aNEifv/735ORkcH+/fub94eGhvL8889zzTXXMGnSJAICArjjjju6/w27obTWHR+g1JfA3VrrTa7t6cBftdaz/dqyTpKZmamtHOTeyF2vbmJrXjlr7ju7p5siCH2CXbt2MW6cJEx2J57uqVJqo9Y609PxvsQgfgD8WylVAChgEHDdiTb0VGPP0SrSxXoQBKEPcVyB0FpvUEqNBdJdu/ZorT2vzC14pMHu4GBxDeeNT+rppgiCIPjMcWMQSqnvARFa6+1a6+1ApFLq//m/af2HA0U12J3apxoIQRCE3oIvQerbXCvKAaC1LgNu81+T+h973eZgEgTBd44XIxV8pyv30heBsLkvFqSUsgFS4tsJPt9bRFiQjREJkT3dFEHoM4SGhlJSUiIi0Q1orSkpKSE0NLRT5/kSpP4AeF0p9ZRr+7tAx8m/QjNHK+p5Z2sB35o1jODArkx9JQinJikpKeTl5VFUVNTTTekXhIaGkpKS0qlzfBGInwC3A1bC7TZMJpPgA8+vPYjDqbn1zOE93RRB6FMEBQUxfLj8bnoSX6b7dgLrgBxgJnA2sMu/zeofVNU38erXh7lo0mBS46S2UBCEvoVXC0IpNQZY7PorBl4H0FrPPzlN6/u8viGXqgY7t581oqebIgiC0Gk6cjHtBtYAl2qtswGUUj88Ka3qBzQ5nDz3xUFmDY9jSmrXFg4RBEHoSTpyMS0EjgCfKqWeUUqdg6mkFnxgxTdHKKio5/Y5Yj0IgtA38SoQWutlWutFwFjgU8yUGwOVUv9QSp3vy8WVUhcqpfYopbKVUvd7eH6oUupTpdRmpdQ2pdTFrv1pSqk6pdQW19+TXXt7PcdHOwsZPCCU+TJttyAIfRRfptqoAV4FXlVKxQLXYDKbPuroPFe9xN+A8zDLlG5QSi3XWruvrvFz4A2t9T+UUuOBFUCa67n9WuupnXw/vYYth8uZNiyWgAAxugRB6Jt0KjFfa12mtX5aa32OD4fPBLK11ge01o3AUmBB20sC0a7HA4CCzrSnt3Kssp788joyJPYgCEIfxp+VW8lArtt2nmufOw8BNyil8jDWw91uzw13uZ4+V0qd5ekFlFK3K6WylFJZvamYZnOumZkkY6gIhCAIfZeeLu1dDLygtU4BLgZeUkoFYILjQ7XWGcCPMO6t6LYnu6yZTK11ZmJi71m/eUtuOUE2xYQhA3q6KYIgCF3GnwKRD6S6bae49rlzK/AGgNb6KyAUSNBaN2itS1z7NwL7gTF+bGu3svlwGeMGRxMaZOvppgiCIHQZfwrEBmC0Umq4UioYWAQsb3PMYeAcAKXUOIxAFCmlEl1BbpRSI4DRwAE/trXbcDg13+RVMFXiD4Ig9HF8mYupS2it7Uqpu4APARvwnNZ6h1LqYSBLa70c+DHwjKsATwNLtNZaKTUHeFgp1QQ4gTu01qX+amt3su9YFTWNDok/CILQ5/GbQABorVdggs/u+37p9ngn0G7Vb631W8Bb/mybv9h82ASop6bG9nBLBEEQToyeDlL3O7YcLicmPIi0eJmcTxCEvo0IRDezObeMqakxuK2xJAiC0CcRgehGquqb2HesWgLUgiD0C0QgupFteRVoDRlDJf4gCELfRwSiG9niqqCemiIWhCAIfR8RiG7k6wMljEyMYEB4UE83RRAE4YQRgegmKuqa+Gp/CeeOS+rppgiCIHQLIhDdxGd7jmF3as6fIAIhCEL/QASim/hoZyEJkSFSICcIQr9BBKIbaLA7+Gz3Mc4bPxCbLBAkCEI/QQSiG1i7v4SaRgfnjx/U000RBOFUY+MLsP4Z0LrbLy0C0Q18tKOQiGAbs0fG93RTBEE4lXDY4bPfwp73wQ+zN4hAnCBOp2blrkLmpQ+U9R8EQTi57PsQqgog8xa/XF4E4gTZkldOUVWDZC8JgnDyyXoeogbDmAv9cnkRiBPkox2FBAYo5qUP7OmmCIJwKlF2CLJXwrSbwOaflRtEIE4Ap1PzztYCTh+VwIAwqZ4WhH5D3kYo2NLTreiYTS+auMO0m/z2EiIQJ8DXB0rIL6/jqmnJPd0UoT/gdMAnj0F1UU+35NTG6YDXb4AV9/Z0S1qz+WWTseRoMn+bXoLRF8CAFL+9pAjECfDmxjyiQgO5YIKkt/Y5nA747x1weF1Pt6SFwu2w+newvRctplh9DF673vw/VchZYwK/pQe6dn7hTnhpIax6BA6tNZ35idJUD+/+CN75H/j7bPjoF1BzzG/BaQsRiC5SVd/Eiu1HuGzKEMle6osU7YGtr5m/k0HeRvjbaZC9yvsxlQXmf0n2yWmT1mBv7PiY3e/Cnvdg30cnp029ga2vm/+1xdBQ5f24TS/Bi5e1rz/YswL2r4Iv/gjPXwR/nAAVed6v01AFT54JBz73fkzuOnA0wOy7jFtp3T9gQCqMOsf399UFRCC6yIpvjlDf5OTq6f4z7wQ/kr/R/D/SDX7mhmqoyO/4mF1vQ9EueOVq+PofnouaKl3XKNl34m3yhY0vwB/GdtwJ5nxp/vd2f3xXKT9sPj+LxhrY+TZEuJJOynK8n7vuKTi4GmpLW+8vPWAyi+47AFc9C9WFsOVV79c5/DUc/QZ2veP9mIOfg7LB3J/AnV/BFU/CwmcgwL+DUxGILvLvrDxGJkaQIavHdZ68jVB60PfjKwsg54vubUN+lvl/dDvYG07sWh/9DJ6Z33Ela95GSJoI6RfDB/fDO98Hp7P1MZbIFHezBVGe2yKI7uz7GGpLYP+nns/T2rhIAAo2d2+b/I3WsOtd0+F7w94IT8+Dl68yBWcAu9+Dpho443/Mtrfvacl+KPzG9biNoJdkQ/woCIuBSVdD2lmwdan378chlwhb30lPHFwNydMgNNpkLE1dDMNmez++mxCB6AIHi2vIOlTG1dNT+9/a0xV5sO5pv5TtAyY174VL4MMHfDu+qc78gF9aaPyw3UXeRrAFg7MJju3s+nW0NlWs1YWm0/CE02E62GGnw7UvGTfBpn9B3vrWx1kupsq8jju2zvLhA/DSlS2doNXuXFf8Zc/7ns8ryzG++LBYM8LtDl/6ySJ7Jbz+rY6/Zwc+MwKZ+7WJ/YDpyAekwtTrzbY3C2LHf1seF7cViP0QN6Jle/J1ULof8rwIgCXCR7d7/o7XV0L+Jhg+1/t78RMiEF3gzY25BChY2Neyl755E75+suNjvvobvH+v8dH7gw/uB3ud+cL7woc/Mx24o8F3d1BNCSz7f1BX5vn5xho4tgPGX2G2T2R0XLjdiAN4HwEW7Taj0uTpEBDQElhsGwStdHNTeRObzqK1cWHUV8DRrS37Sw8YH3tQhKnGdTran2t1XJm3mvt/bFf3tOlksPbP5v/GF713zDuXQUg0TLoGVv/eJAcc+BQmXwvhcRAaA2VeLIidb8OQaRAQ1NqCqCs39zV+ZMu+8QsgMBS2LW1/ncZa81uIH20GK0e3tT/m0FrQDhghAtHrcTg1b23M56zRiSRFh/Z0c3ynsQZW3ANr/9LxcQdXt/7fnex53wTwEtKh+ihUHun4+F3vQNazMPVbZvvw1769zs5lsOUV40LxRMEW0E6YuNB0AifiX7eCzrYQ7x2RtT850/wfkAIoY025U1kACWPM4+6KQ5QdNNku0DoIalkPp99lRtF5G9qfe2gthMXBlMVmuyOBbusu60kKtpjv75z7IGoQvPej9gJobzQB+PSL4dInIHY4vHmr+V5MXmSOiU3zbEGUHjAd+cSrjKXg7hIsdQl7nJtAhEbD2EuMALVNCsjbYITh9LvNtidX4MHPjcCkzOzMXegWRCA6yeq9RRytrGfRjNSebkrn2PyKGVFXF3p3H1UXmRExmC9ld9JYC+/fB4lj4dI/mH0djdzLc+Htu2BIhvkBx42E3PXej3fHaru361sj/ZQZ5vonYkFkrzSxhdSZ3i2I/CwjRNaoMjAEopNbdz5aG4FIO8tst7Ugaktbu4h8xbpnIdGtP9PcdRAyAE77f2YUvGdF+3MPfWncYvEjzbGe7lNjLax+HH6bZqy27nQDdpW1f4bgKCN+FzwGR7ZC1nOtjzm42lhVE66AkEi4+jkICDRWQaJLpOOGe45B7Fhm/o+/HBJGtxbzEpdVGD+q9TmTF5nfX9tssENrQQWYdkQN8TzIOPA5pM6CoJM/IBWB6CRLNxwmPiKYc3pqadGj282PsjM4HfDVX12Pm9pnXVjkuKyGpIkmF9yT26GrfPEHkzFy8ePmR6gCvI9ItYbld4PTbrJAAoPNDyR33fFjI04nHFxjHnvr+POyIGYYRCQYgTi2s2sdW0OVsWpGnWPcR958yHkbzfPu8arYYVDuZkHUlRnXW/wo4wN392s31cFfpsFzF0DV0c61MXedEYcpi01brYB87npInWECqWlntI9DVBYY62PY6abdQ6a0v59bX4e/TIdPHjGd6pZX4MVLocrlcmusNX5+a9sbFflwbHfn3pc3yg6ZDjxzCYQOgAkLYcQ8U5Pg3o6d/zUiMmK+2R4yFW75EK5+tuWY2DSoyG0vzDvfNp9nzFDzeZUebDmmdD+gzLnujDwbIhLbu5kOfQmDJpm2pkxvP8ioLjLu0OFzunI3ThgRiE5wrKqeVbuOcdX0FIIDe+DWlR6Ap86CN27qnEm/a7npjCZeZbarvXQyB1ebzuT0u83o6shWz8d1lqY6E9uYeBUMPwuCwyFxnPcOfMd/jS/4nAdbRt2pM41v191vX1Nigr3uolG4HepKTZrika2eRS5/E6S43D1DMowQFe7o/Ps6uMYI7kiXQDibTDDXnYZqk95qvZ5FzLDWLiYr/jAg2XQ67qPSw18bAcnfCE/P9z1+A0YIUjJh5Hyw15vtunITT0idZY5JvxiK97Z2lVjxh2Gnm/9DMsw9slwkuevhv7dD9GD49vvwnZVw7b/MMc/Mhxcvh98Og38tMMVd3qivNEkLL17WPQOSr/9hBG3WHWZbKTMosdeZ301jrQm2734P0i9qPSpPmd46uBw73Hw3Kt1qGEoPmoGNFb9KcMUOLLEvyTYC33a0bwuEiVfD3g9bBmj2RuNiGnaG2U7ONFZlTXHLedagbcS8E7gpXUcEohP8Z1M+dqfm2sweci9te8P4SLM/NoUyvqA1fPln88XPvNXsq/Li+z/wufmyWqOq7opDHFwNTbUtsQRoce20tQgaqkzmyaDJMOPWlv1WZ5brVvn8+W+NpeHuOrEen3aHec22GSZVR80PPtlNIAAKOtHpWuxfZYK8Q09rEYC2I8AjrnhHchuBiB1mPgfL4rAymKJdAlGc3XJvDq427o9bPjB5789fZFI4j0d9hemwU2e5LIEAc628LEC33FNrJtC9blbEoS/NCHvQZLM9JAMcjS0ZX1/+ybjNblreIiLjF5hReEi0qbyeeTuMu8zcp/oKz21ccU9LnMRK9+wq+RvNgGHi1a2nn0gYDQufNt+dN79t0nrryoxbpyPihpv/7q7AnW+b/+MXmP+WK8kqbizZD/FuIuPOtBuN4FiZVQWbjWhb96/5O+QWh7AGbYOndtxWPyEC4SNaa97YkMuMtFhGDYzsiQaYFLy0syD9Evj4Qd+Cq4fWms5v9vfMaA88m/zlh80PdcRciEoyI3z3jvfYbpNu6i0Q2xF7VpjOJu3Mln1DpkJNUevMHYDPfmM6zkv+0LoIKHGs8YNbAtFYa+4HmCmPLQ6uNhkh6ZeY7bZWitX+FLeAcXhC5wvmtDZB8OFzXDGFIZ59yM0B6mmt98emAdq4MKDlPkQPMR1aY1VLdtTBz43ADD0NbvvUuADf/HbHlbfNr+0SgtABxrV38HNzD1WAsXrAiNXACbDng5ZzD601r2d9Bs1Cutl0grvfgxnfMf57dwZPhu99bf4ueAxO/74RFvdrW2x5Dba9bmoOgsJbOl9PHFwDr1zrOburLAfevAWeOdtYp3PuaX/MhCvhksdh7wfw1ncgONK4fTrCchO5xyH2fmhEM3aY2Y4fbf4X7zPfidL97eMPFkkTTOB862vGPWcJ4lCXQAyeaj4X6ztjb4TsT8ygzU+ztR4PEQgf2ZBTxoHimp6zHvI2mA58yiJY8Ffjz3zzFvMj+8934Q8TPGcorX8KwuNhyvUQ6ZozypOLybIWrFzr4XPg0FfmS+p0msKu7JXw/MUtUxH4gtNpOodR55iO1MK9w7Eo3GlcBNNuNv5xdwICzD4r6LrjP9BQYTq/3e8a0XM0mY5txFzTyQZFtBeI/CwzGrdGxkoZsepsJlPpAeNWcJ/qwJMPOT/LdDQRCa33x7g6GMvNVJFvKmUjk1o6mOJ9ZuRdsLklxTEyEW540wTtl36rYzdg7vrWQjB8jhmd7l9lRMa9c0+/CA6vhdcWm+9R0e6Wka3V3rBY05av/gq2IGMhHI/kTGMV7VzWen9xNrz3Y9P5nfMgjD4Pdi737GZqrIW3/59Jx33m7JbCvtpS+OAB+Esm7F4Bc+6FuzeZz94TM74Dc+8335sxF0JQWMdtj042AXzLgqivMOI6+ryWYyLizX0p2WfaU1/ROoOpLXPuNYLw3o/MdzhxnLkGmM8jcVyLBfHJI1Bx2K+ztR4PEQgfWbrhMJEhgVwyeXDPNGDrUpPqNu5yk6N91TNGMJbdYVxOTTVmVNeWw1/DqPPMyCo43IzCPVkQBz43ojNwnNkeMdf4bfM2mOBj7jo4/1ETC/jv7WayMG91Bu4c2WwEKf2i1vuTJpiO2r0D/+B+kxJ47kOer5U6y/jO68pNVkpCOiz4mzHbt7xsfPON1UbkAmxmNOvJgkia2NpHPCTDXLczwf/slea/u0B48iHnbWzvXoKWEWh5jvlfWWBSMgNsLR1cyT4z1YV2tg5ShsXCjf8xAeaXr/JeM5G7zlgGodFme8Rcc6/yN7a4lyxOv9vUZxTugI9+bvZZGVXgEtIMY4FsedUMVKJ8SNQICDDumOxVJt4AZtCw7A6TfGBNFzF+gXEzHf6q/TWsBIcr/mEsrJevgre/B3+ealytU66D72+Cs3/e8l69Me9+WPhPOO9hH9puM4Foqxbi4GpTjzDq3NbHxY82gme5meI7EAhboHF3BQSaeJW7CINrkLHRfL/W/tl8JmMvPn5b/YQIhA/UNtp5/5ujXDZlMOHBPWDq2RtMDvXYS1t+AGlnwrc/gNs/h3uyjd/16Detg9dVhcZNMXhyy76opPYWhNbmyz98TkumzbAzzOhz5zL4+JeQehqc9j248b/mS7v2z/C7EfDPc02GyNq/mr91T7cWjj3vm+uMPr/1awaFGTGyOvADn5nOZ+5PjAB6InUmoE1tRP5G046E0aYj2/iCCWyjWlxZQzJcFcCuDBOrorltwHhIhvnhF243HfXW1027vc1RVHXUjKLjR7cOalojdWsEWFlgKpHbvh4Ya84W0jI6rcw3I1aA6BQIDDMd/8HPzeOUNhZV9BC44T/mPS29vr24OR1GDFPdcudTZ5nXBOM+cicsBi75P/jBNvj+ZnPttlbc4KmmvfZ6Uw3uK+MXmEK7vS430+Z/mYHHhb8xQXkw01YHhrakkFoUZ5t4x+TrTHXzrR/BmAvM1Neps+COL8wgIXqIb21RCiZf0/K6xyNueMtnlL3SxAPafhYJo404eKqB8ERMqvECgEkecCc5E+rL4Y0lxpq44H99a6ef6BnHVh/jk93HqGtycNkUH7+E3c2+j8yXZsqi1vuHuo0CB0+GDS6rwhrBWFWZg6e0HBeZ1N6CKN5rRMO9lD8sxnQI6582ro9L/s+MBgmAS/9oXFbZH8P+T8wIT7sJ0+534MZlZgS25wMYOttzpz94qrF6tDYiE50M07/t/T4kZxqx+fx3ptOccp3Zn3mL8cl//XdzH6zXGpIB9r9D8R5jsez9wFgYbUdtlrvrtUWmaMwiIMh0QpOvgak3mNFfXbkZwdaUwJJ32l9HBRiBGHNBi0XnyYIICHCNTl0upsoC00brufiRxsVUkWs6c3f3nEXiGLjqn/DyQhP4vOyJlueO7TRxDHchCAozgpGzprVwtCVuRGvha3ufxlwIienez29LykwTn9mxzGR8rXzIDEAmX9dyTEikcd3sWg4X/dZ8d7Q2QezAMDjvEddxUXDdK8b10jaV1B/EpkHuBtOW7FVmEGVrszhY/ChjZRdsMb8VyzrsiHGXwQ93tAwKLKzBhLPJ1GYczw3mZ8SC8IF3tx4hMSqEWcPjT/xiR78xBWBtR6elB+Hf3/Zco7B1qUnbHDG//XMWlk/d3SdtPR40qWVf1KD2WUzN8Yc2udaW33vWHTBoYuvnUmfA/AdMeuMDBXB/rvm79AlzvS+fMG6Bwm+8r5c7JMOkpK5/2vjq597XcTFQSKRxD9nrTRV0WKzZP/ZS4x6rr2j9HtzjHE6nWYwnbiSMW9D6ulGDYcxF5j6d9zB8dw3c/I4ptKorM2ma/5htfORLrzfTkCx6ucVicG9f4jgjRC9fZTq3xLGtLTh3rFoIq0jOvbOIH2nuybGdHU+xMOocEwje+HzrIK8VzG8rBNOXmPs1oAuxtLQzTaB73v2dOy8gwBSVZa8007g0VJnU07bzmI2/wli8uetMdtdnvzFW4dk/b+3OCgg4OeIAJtW1wRV7qMht716CFpfgvg/NZ9pWQLwxIKX9PUgcayziy/4ESeNPrO3dgFgQx6GqvolP9hzj+plDsQWc4MR8WptFP/LWm4DqwqfMfnujGQEXbDbZFuMvbzmnvtJkTsy8reNMhoHjXH7NbabzBPM4Ns1ksFhEDWqppra+nEe2mkweK63PYuoNxp1yvA4hKKxlpDN9iRGITx6Dor1mX7oXH6rVgX/0C/NDdE+D9UbqLPO+3BdKCQyGjBvM/PvD57XsjxtpsqcKNhv3xbEdpvCu7X1UCq73ME/O8DkmgLr7PVj5ILxxo9l/1bPeM2BSpptUy9ABJmYz4zbPo38wgd+8DcY6bKpp7SaJjI1BegAAEFtJREFUH93S4R9vkrazf2Fmu11+t/kO5G+Cb94w1mJMm9HspKvNX1cIj4Pbvcz8ejzGXwHrnjSu0tPv9tz5jbnQfE6fPGoGFxW5ZqTtnu58srGEaMM/zX9P6y9YmUxlOSbedyIE2GCJDynMJwkRiOOwclchjXYnV6YHm/mMgiO6frF9HxlxSJ5uKipHzjduo08ebvHFl7YJOB7bZczN43USgSFm9HrEbbKvI9taLAuLyEFmBF5fYdxIYPyn1hxA7iSMgiuPM7lfW5Qyro78LPMe40eb63giaYJx4zgajDXiy8jrtDvNiK3t6P3075vURffRdkCAca/lbTCZLwMnmMrazr6fcZcal9GWV00MaMKV3o8//X+MME27yXssxSI2zXwO1iR47n5xa1QaOqC1i9ATgcGmAvjJOcbCUTbjJz/jf9qPUHuK1FnGUkOZTCJPhESaEfrud833dsFfe6xArBlr0LRjmUmKiBnq+RgVYNysHQWo+yAiEMfhna1HSI4OZvIHV5sR7zUvdO1CTqfxs8cOhyUrjN/4vR8bc3vtX0wR267l7TNSrIpab6l77gyebERIa2ioNPGIjDaj8igr1bWwRSCK93VvpkToALjqOXj+QtO5eiMwxNzTxpqWKu/jET/S848wPM5z/vuQqS3TjCx61RVH6QK2IJh+8/GPSxgFZ/7At2tavmqrarmVi8n1eaed5duiMHEj4Oa3W+Zzsj7b3kJAACx+zVgIbWsn3LnodybNedS5Xf+suhPLAnM2eV+9LTDEFU/K8V4D0Ufx6yeglLpQKbVHKZWtlGo3bFBKDVVKfaqU2qyU2qaUutjtuZ+6ztujlLrAn+30RnltI2v2FXHbiBJUWY6pXvU2j9Hx2LnM+OPn/dT42a1UtxX3uLIVXP7xtlNAF+8zo+y2rgJPDJpsis+qjpp5gQAGtRl9Rrp8udacPnVlrumJu/mLnToDvrfeFAZ1xHUvw83L/bcyluXGSp7u3dXVU1ifqZXa6e5iShxjUpLHdiCwbUmeblwyvU0cLIZktKRRe2NAMow5v3eIAxgxs1aX62h5T0vQPQX3+zB++xSUUjbgb8BFwHhgsVKqrePx58AbWusMYBHwd9e5413bE4ALgb+7rndS+XDHUZocmksCXQVHziZT3NJZHHb49H9NAMry/w5IgSufMmarla0QP7L9esQl2caE9aWS0gqGHt3mlsHUxsXkbkFAi8US74OF0lniR5rai46ISmpfRNadpJ1pfrTnP9p73C0Wln/7sKuy2SpkBJOtc8/e9plrwsknNs1YPtacSZ6wLHxxMfnMTCBba30AQCm1FFgAuC/fpQGrsmUA4JqQhgXAUq11A3BQKZXtup6HKhr/8e62IwyLDSXh8Icmj7/skMmRn/Gdzl1o2+vGVXTtS61HyukXmj+L+JEmXa6hynQQYCwIXzvvJFem0ZGtJisqYmCLIFhY21YmU3EnXFh9kahBJq+/NxIWY9xx9RUmDbTtIKAHpncWPDDtRrN2SUcppxOuNN6FrmSH9WL8acclA7lu23mufe48BNyglMoDVgB3d+JclFK3K6WylFJZRUVF3dVuwGQvfbW/hFuHl6Iq80wWxpRFJsjsrXLV3tA+fdXeYNL1Bk815n9HWAU2lpvJ6TCPvQV52xIabUbLR7YaC8JTemVIlJmCwqqFKNlnXF0nK21QaI3lZvK10Es4+Uy7Ceb9pONjUmearER/uUp7iJ529C0GXtBapwAXAy8ppXxuk9b6aa11ptY6MzExsVsb9vWBUuxOzbn6KxMDSL/ILE2IMrOquuN0wKaX4E9T4K8zTRGVxaZ/maKec35xfBeHZZ5aAlR+yLi1OuP+GTzFpDkW7W6fwWThXk1dvM+Ig6+520L3EisCIfRe/CkQ+YC7vZXi2ufOrcAbAFrrr4BQIMHHc/3KF/uKCAsKYHD+hybnPSzGBNCGzzHpm1q3zOj55Jmw/C7jzqgtNhOLae1abev3ZnKukR0EuCysAJclENb8/J1x/wyabKZ3cNq9p0dGDnKzILL7XeZFn8Ky3NpW1ApCL8CfArEBGK2UGq6UCsYEnZe3OeYwcA6AUmocRiCKXMctUkqFKKWGA6MBH9eb7B7WZBezaEiRcS+5zxs/ZZFJZ8t6ziyG8srVZkGca14wUzGf/6ippF33pJn6orrQN+sBTI1F1JCWWggrxbVTFsRkz4/dsSwIp8M1f70IRI9huZh8nRtIEE4ifgtSa63tSqm7gA8BG/Cc1nqHUuphIEtrvRz4MfCMUuqHmID1Eq21BnYopd7ABLTtwPe01t24/mXHFJTXcaCohifGbGhxL1mMu8zUL7z3I7Og+4W/MTUMgcHm+Zm3m6Ksj39pglojz2k/909HxI90syD2mekkIjoxxYeV1hoSDTFpno+JGmwsn4pcU6TWXwPUfYFmC0JcTELvw6+FclrrFZjgs/u+X7o93gl4zB3TWj8GPObP9nnji33FgGZs2aemktOa8wdMkPf8R00dwezvtc85V8rMLvnkGSZT6Oyfd+7F40fCLtckcF1x/0QmGgGIG+E9lzwyyUxaZ62B4I8UV8E3hs4205N0NM+WIPQQUkntgTXZxcyILCa4Khfm/LD9AcebGyYi3kyXXLjj/7d39zFyVWUcx7+/trSUFmlLzQot0CJFLFVerKaIMQ1gLC+CUSISDIRgTIhRNL6hiTEm+ofGKIKEBAGtCUENIhL/ICAQBRSQ0vdWpC2VpVnabtotUAql28c/zhl7Xe7QXTrTu9z7+ySbnXtmsnNOzmaeOS/3OW88SWx/pr07ZRTdtT2NIPZ36lWZC29Ix0G209rq2jrRyiOI6kyYnBKzmY1CDhBD7N0bPLqun+9OfwY2U569cTh65r61bIytnUx9y9M6wXC3uBYVT7wq07qbeuOj6W7dSZ3dAWZm9VD1NtdRZ03fi2zbuZsz9i5NCeyGk9u9k1pTSv++L1934dt9awSxZXUKSKPtDmMzGxUcIIZ4ZF0/E9hNz7Ylw9ua2mlTZ6W0C63Tt7ox/TO5kFvf00tm1oYDxBCPPNPPp6ZtRIOvvvXppQMxbkLK07RtfQoU3Uj+NXHqvqMnvUBtZm04QBS8tmeQJzZu46LJa1Nyrllvkpyrm1rTTFOObX/YzIGQ9p3Q9VbWOMysERwgCtb2vcTuPXs5edeTKXNjVefBtnIydfPbfStzqEcQZtaGA0TB8t4BZrCVw19a/+a537uttZOpm+sDrRFEzfLXm1nneJtrwfLeAc6ftAYGqWb9oaU1xdTN3PLHnQmvvbz/8xrMrLE8gihY1jvAxyesSTndy85oPlhmzk931nZzF9WCq+Hyu7v3983sbc8jiGzHK6/zXP8O5k16Ck66uNp7AyZO9Ye3mVXOI4hsxaYBPjjmaSYM7oQTKzkC28xsVHGAyJY9N8DHxiwhxh2aEvSZmTWcA0S2vHc7iw5Zio5fmM5lMDNrOAcIICJ4sXcVR8dmOHFR1dUxMxsVHCCATQO7mP/qY+nCAcLMDHCAAGB57w7OGbuEV6afAu84qurqmJmNCg4QwLpn13Oq1jP+5POrroqZ2ajh+yCA8Rv+whgFY957XtVVMTMbNRo/gtgzuJc5Aw8zML4HeuZVXR0zs1Gj8QFiy/YBztRKts042yermZkVNH6K6egJu2HeJ5j9gUurroqZ2ajS+ADB4e+Ci2/FYwczs//X+CkmMzMr5wBhZmalHCDMzKyUA4SZmZVygDAzs1IOEGZmVsoBwszMSjlAmJlZKUVE1XXoCElbgf8cwJ+YDvR3qDpvF01sMzSz3U1sMzSz3SNt83ER8c6yJ2oTIA6UpCcjYn7V9TiYmthmaGa7m9hmaGa7O9lmTzGZmVkpBwgzMyvlALHPzVVXoAJNbDM0s91NbDM0s90da7PXIMzMrJRHEGZmVsoBwszMSjU+QEhaJOlpSeskXVt1fbpF0jGSHpK0RtJqSdfk8mmS7pf0TP49teq6dpqksZKWSvpzvp4t6fHc57+TNL7qOnaapCmS7pT0L0lrJZ1R976W9NX8v71K0h2SDq1jX0u6TdIWSasKZaV9q+T63P4Vkk4fyXs1OkBIGgvcCJwLzAUulTS32lp1zR7gaxExF1gAfDG39VrggYiYAzyQr+vmGmBt4fpHwM8i4gRgO3BVJbXqrp8D90bEScAppPbXtq8lzQC+DMyPiHnAWOCz1LOvfw0sGlLWrm/PBebkny8AN43kjRodIIAPAesiYkNE7AZ+C1xUcZ26IiL6IuKp/Pgl0gfGDFJ7F+eXLQY+WU0Nu0PSTOB84JZ8LeAs4M78kjq2+Qjgo8CtABGxOyIGqHlfk45QnihpHHAY0EcN+zoi/gZsG1Lcrm8vAn4TyWPAFElHDfe9mh4gZgC9hevnc1mtSZoFnAY8DvRERF9+6gWgp6Jqdct1wDeBvfn6SGAgIvbk6zr2+WxgK/CrPLV2i6RJ1LivI2IT8BPgOVJg2AEsof593dKubw/oM67pAaJxJE0G/gB8JSJeLD4Xac9zbfY9S7oA2BIRS6quy0E2DjgduCkiTgN2MmQ6qYZ9PZX0bXk2cDQwiTdOwzRCJ/u26QFiE3BM4XpmLqslSYeQgsPtEXFXLt7cGnLm31uqql8XnAlcKGkjafrwLNLc/JQ8DQH17PPngecj4vF8fScpYNS5r88Bno2IrRHxOnAXqf/r3tct7fr2gD7jmh4g/gnMyTsdxpMWte6puE5dkefebwXWRsRPC0/dA1yRH18B/Olg161bIuLbETEzImaR+vbBiLgMeAi4OL+sVm0GiIgXgF5J78lFZwNrqHFfk6aWFkg6LP+vt9pc674uaNe39wCX591MC4Adhamo/Wr8ndSSziPNU48FbouIH1Zcpa6Q9BHgYWAl++bjv0Nah/g9cCwpXfpnImLoAtjbnqSFwNcj4gJJx5NGFNOApcDnIuK1KuvXaZJOJS3Mjwc2AFeSvhDWtq8lfR+4hLRjbynwedJ8e636WtIdwEJSWu/NwPeAuynp2xwsf0GabnsFuDIinhz2ezU9QJiZWbmmTzGZmVkbDhBmZlbKAcLMzEo5QJiZWSkHCDMzK+UAYTYCkgYlLSv8dCzhnaRZxQydZlUbt/+XmFnBrog4tepKmB0MHkGYdYCkjZJ+LGmlpCcknZDLZ0l6MOfif0DSsbm8R9IfJS3PPx/Of2qspF/mcw3ukzSxskZZ4zlAmI3MxCFTTJcUntsREe8j3bl6XS67AVgcEe8Hbgeuz+XXA3+NiFNIeZJW5/I5wI0RcTIwAHy6y+0xa8t3UpuNgKSXI2JySflG4KyI2JCTIr4QEUdK6geOiojXc3lfREyXtBWYWUz7kNOw358PfUHSt4BDIuIH3W+Z2Rt5BGHWOdHm8UgU8wQN4nVCq5ADhFnnXFL4/Y/8+O+kTLIAl5ESJkI6FvJq+N+Z2UccrEqaDZe/nZiNzERJywrX90ZEa6vrVEkrSKOAS3PZl0gnu32DdMrblbn8GuBmSVeRRgpXk05CMxs1vAZh1gF5DWJ+RPRXXRezTvEUk5mZlfIIwszMSnkEYWZmpRwgzMyslAOEmZmVcoAwM7NSDhBmZlbqv3WAZmpmOkefAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best5,networK5=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=100, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOqi-qNpSDtc",
        "outputId": "da6d287f-5756-4d79-f9c3-ab84835abba5"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6520\n",
            "1086\n",
            "1087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t\r 45/??\t\r 46/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6491,   29],\n",
            "        [6155,  365]])\n",
            "tensor([[1079,    7],\n",
            "        [1029,   57]])\n",
            "Epoch: 0, Train Accuracy: 0.71871, Train Loss: 0.56303, Validation Accuracy: 0.69705, Validation Loss: 0.60076, prediction: [0.538, 0.462], true label: [0.0, 1.0]\n",
            "0.6970534069981584 0\n",
            "best_state_dict updated\n",
            "tensor([[5921,  599],\n",
            "        [3207, 3313]])\n",
            "tensor([[987,  99],\n",
            "        [538, 548]])\n",
            "Epoch: 1, Train Accuracy: 0.77592, Train Loss: 0.47425, Validation Accuracy: 0.75875, Validation Loss: 0.50379, prediction: [0.352, 0.648], true label: [0.0, 1.0]\n",
            "0.7587476979742173 0.6970534069981584\n",
            "best_state_dict updated\n",
            "tensor([[5642,  878],\n",
            "        [2512, 4008]])\n",
            "tensor([[932, 154],\n",
            "        [448, 638]])\n",
            "Epoch: 2, Train Accuracy: 0.75828, Train Loss: 0.49115, Validation Accuracy: 0.73757, Validation Loss: 0.56086, prediction: [0.648, 0.352], true label: [1.0, 0.0]\n",
            "0.7375690607734806 0.7587476979742173\n",
            "tensor([[6079,  441],\n",
            "        [3408, 3112]])\n",
            "tensor([[1013,   73],\n",
            "        [ 579,  507]])\n",
            "Epoch: 3, Train Accuracy: 0.79448, Train Loss: 0.44175, Validation Accuracy: 0.77993, Validation Loss: 0.49335, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.7799263351749539 0.7587476979742173\n",
            "best_state_dict updated\n",
            "tensor([[6116,  404],\n",
            "        [3437, 3083]])\n",
            "tensor([[1013,   73],\n",
            "        [ 585,  501]])\n",
            "Epoch: 4, Train Accuracy: 0.79985, Train Loss: 0.43548, Validation Accuracy: 0.78269, Validation Loss: 0.48751, prediction: [0.524, 0.476], true label: [1.0, 0.0]\n",
            "0.7826887661141805 0.7799263351749539\n",
            "best_state_dict updated\n",
            "tensor([[5998,  522],\n",
            "        [2730, 3790]])\n",
            "tensor([[993,  93],\n",
            "        [463, 623]])\n",
            "Epoch: 5, Train Accuracy: 0.80767, Train Loss: 0.40541, Validation Accuracy: 0.79006, Validation Loss: 0.47690, prediction: [0.146, 0.854], true label: [0.0, 1.0]\n",
            "0.7900552486187845 0.7826887661141805\n",
            "best_state_dict updated\n",
            "tensor([[6211,  309],\n",
            "        [3370, 3150]])\n",
            "tensor([[1026,   60],\n",
            "        [ 583,  503]])\n",
            "Epoch: 6, Train Accuracy: 0.80215, Train Loss: 0.41856, Validation Accuracy: 0.77440, Validation Loss: 0.46511, prediction: [0.75, 0.25], true label: [1.0, 0.0]\n",
            "0.7744014732965009 0.7900552486187845\n",
            "tensor([[5915,  605],\n",
            "        [2176, 4344]])\n",
            "tensor([[962, 124],\n",
            "        [397, 689]])\n",
            "Epoch: 7, Train Accuracy: 0.82055, Train Loss: 0.38654, Validation Accuracy: 0.79466, Validation Loss: 0.46273, prediction: [0.062, 0.938], true label: [0.0, 1.0]\n",
            "0.7946593001841621 0.7900552486187845\n",
            "best_state_dict updated\n",
            "tensor([[5911,  609],\n",
            "        [2144, 4376]])\n",
            "tensor([[956, 130],\n",
            "        [387, 699]])\n",
            "Epoch: 8, Train Accuracy: 0.82209, Train Loss: 0.38881, Validation Accuracy: 0.79374, Validation Loss: 0.47584, prediction: [0.029, 0.971], true label: [0.0, 1.0]\n",
            "0.7937384898710865 0.7946593001841621\n",
            "tensor([[6042,  478],\n",
            "        [2394, 4126]])\n",
            "tensor([[991,  95],\n",
            "        [415, 671]])\n",
            "Epoch: 9, Train Accuracy: 0.83129, Train Loss: 0.36766, Validation Accuracy: 0.80571, Validation Loss: 0.43516, prediction: [0.712, 0.288], true label: [0.0, 1.0]\n",
            "0.8057090239410681 0.7946593001841621\n",
            "best_state_dict updated\n",
            "tensor([[6076,  444],\n",
            "        [2468, 4052]])\n",
            "tensor([[995,  91],\n",
            "        [438, 648]])\n",
            "Epoch: 10, Train Accuracy: 0.83267, Train Loss: 0.36709, Validation Accuracy: 0.79650, Validation Loss: 0.47090, prediction: [0.772, 0.228], true label: [1.0, 0.0]\n",
            "0.7965009208103131 0.8057090239410681\n",
            "tensor([[6010,  510],\n",
            "        [2107, 4413]])\n",
            "tensor([[971, 115],\n",
            "        [395, 691]])\n",
            "Epoch: 11, Train Accuracy: 0.83957, Train Loss: 0.35705, Validation Accuracy: 0.79742, Validation Loss: 0.42992, prediction: [0.029, 0.971], true label: [0.0, 1.0]\n",
            "0.7974217311233885 0.8057090239410681\n",
            "tensor([[6026,  494],\n",
            "        [1941, 4579]])\n",
            "tensor([[968, 118],\n",
            "        [376, 710]])\n",
            "Epoch: 12, Train Accuracy: 0.84985, Train Loss: 0.33324, Validation Accuracy: 0.80939, Validation Loss: 0.45508, prediction: [0.803, 0.197], true label: [1.0, 0.0]\n",
            "0.8093922651933702 0.8057090239410681\n",
            "best_state_dict updated\n",
            "tensor([[6036,  484],\n",
            "        [2256, 4264]])\n",
            "tensor([[967, 119],\n",
            "        [436, 650]])\n",
            "Epoch: 13, Train Accuracy: 0.81917, Train Loss: 0.37911, Validation Accuracy: 0.77901, Validation Loss: 0.47663, prediction: [0.507, 0.493], true label: [0.0, 1.0]\n",
            "0.7790055248618785 0.8093922651933702\n",
            "tensor([[5959,  561],\n",
            "        [1679, 4841]])\n",
            "tensor([[955, 131],\n",
            "        [334, 752]])\n",
            "Epoch: 14, Train Accuracy: 0.85153, Train Loss: 0.33798, Validation Accuracy: 0.80939, Validation Loss: 0.43565, prediction: [0.819, 0.181], true label: [0.0, 1.0]\n",
            "0.8093922651933702 0.8093922651933702\n",
            "tensor([[6128,  392],\n",
            "        [2087, 4433]])\n",
            "tensor([[986, 100],\n",
            "        [401, 685]])\n",
            "Epoch: 15, Train Accuracy: 0.85506, Train Loss: 0.33330, Validation Accuracy: 0.80387, Validation Loss: 0.45490, prediction: [0.797, 0.203], true label: [1.0, 0.0]\n",
            "0.8038674033149171 0.8093922651933702\n",
            "tensor([[6102,  418],\n",
            "        [1845, 4675]])\n",
            "tensor([[975, 111],\n",
            "        [371, 715]])\n",
            "Epoch: 16, Train Accuracy: 0.86963, Train Loss: 0.30296, Validation Accuracy: 0.80755, Validation Loss: 0.41303, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.8075506445672191 0.8093922651933702\n",
            "tensor([[6068,  452],\n",
            "        [1635, 4885]])\n",
            "tensor([[964, 122],\n",
            "        [343, 743]])\n",
            "Epoch: 17, Train Accuracy: 0.87117, Train Loss: 0.30487, Validation Accuracy: 0.81400, Validation Loss: 0.47951, prediction: [0.276, 0.724], true label: [0.0, 1.0]\n",
            "0.8139963167587477 0.8093922651933702\n",
            "best_state_dict updated\n",
            "tensor([[6036,  484],\n",
            "        [1415, 5105]])\n",
            "tensor([[957, 129],\n",
            "        [314, 772]])\n",
            "Epoch: 18, Train Accuracy: 0.87592, Train Loss: 0.31914, Validation Accuracy: 0.81215, Validation Loss: 0.46335, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8121546961325967 0.8139963167587477\n",
            "tensor([[6136,  384],\n",
            "        [1528, 4992]])\n",
            "tensor([[969, 117],\n",
            "        [346, 740]])\n",
            "Epoch: 19, Train Accuracy: 0.88528, Train Loss: 0.27301, Validation Accuracy: 0.82228, Validation Loss: 0.42690, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.8222836095764272 0.8139963167587477\n",
            "best_state_dict updated\n",
            "tensor([[6196,  324],\n",
            "        [1677, 4843]])\n",
            "tensor([[976, 110],\n",
            "        [354, 732]])\n",
            "Epoch: 20, Train Accuracy: 0.88727, Train Loss: 0.28077, Validation Accuracy: 0.81492, Validation Loss: 0.44404, prediction: [0.285, 0.715], true label: [1.0, 0.0]\n",
            "0.8149171270718232 0.8222836095764272\n",
            "tensor([[6120,  400],\n",
            "        [1415, 5105]])\n",
            "tensor([[952, 134],\n",
            "        [311, 775]])\n",
            "Epoch: 21, Train Accuracy: 0.88374, Train Loss: 0.27000, Validation Accuracy: 0.81123, Validation Loss: 0.50193, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8112338858195212 0.8222836095764272\n",
            "tensor([[6113,  407],\n",
            "        [1257, 5263]])\n",
            "tensor([[949, 137],\n",
            "        [291, 795]])\n",
            "Epoch: 22, Train Accuracy: 0.89172, Train Loss: 0.26122, Validation Accuracy: 0.82320, Validation Loss: 0.42399, prediction: [0.827, 0.173], true label: [0.0, 1.0]\n",
            "0.8232044198895028 0.8222836095764272\n",
            "best_state_dict updated\n",
            "tensor([[6084,  436],\n",
            "        [1284, 5236]])\n",
            "tensor([[945, 141],\n",
            "        [303, 783]])\n",
            "Epoch: 23, Train Accuracy: 0.88374, Train Loss: 0.26290, Validation Accuracy: 0.81492, Validation Loss: 0.43072, prediction: [0.915, 0.085], true label: [1.0, 0.0]\n",
            "0.8149171270718232 0.8232044198895028\n",
            "tensor([[6206,  314],\n",
            "        [1385, 5135]])\n",
            "tensor([[953, 133],\n",
            "        [311, 775]])\n",
            "Epoch: 24, Train Accuracy: 0.89755, Train Loss: 0.25529, Validation Accuracy: 0.81123, Validation Loss: 0.51021, prediction: [0.846, 0.154], true label: [1.0, 0.0]\n",
            "0.8112338858195212 0.8232044198895028\n",
            "tensor([[6215,  305],\n",
            "        [1308, 5212]])\n",
            "tensor([[960, 126],\n",
            "        [321, 765]])\n",
            "Epoch: 25, Train Accuracy: 0.90567, Train Loss: 0.23555, Validation Accuracy: 0.82505, Validation Loss: 0.42116, prediction: [0.881, 0.119], true label: [1.0, 0.0]\n",
            "0.8250460405156538 0.8232044198895028\n",
            "best_state_dict updated\n",
            "tensor([[6210,  310],\n",
            "        [1286, 5234]])\n",
            "tensor([[953, 133],\n",
            "        [308, 778]])\n",
            "Epoch: 26, Train Accuracy: 0.90460, Train Loss: 0.23851, Validation Accuracy: 0.81492, Validation Loss: 0.49691, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8149171270718232 0.8250460405156538\n",
            "tensor([[6219,  301],\n",
            "        [1146, 5374]])\n",
            "tensor([[951, 135],\n",
            "        [286, 800]])\n",
            "Epoch: 27, Train Accuracy: 0.90966, Train Loss: 0.22098, Validation Accuracy: 0.81952, Validation Loss: 0.48661, prediction: [0.007, 0.993], true label: [0.0, 1.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[6216,  304],\n",
            "        [1069, 5451]])\n",
            "tensor([[954, 132],\n",
            "        [279, 807]])\n",
            "Epoch: 28, Train Accuracy: 0.91334, Train Loss: 0.22464, Validation Accuracy: 0.82228, Validation Loss: 0.51202, prediction: [0.918, 0.082], true label: [1.0, 0.0]\n",
            "0.8222836095764272 0.8250460405156538\n",
            "tensor([[6234,  286],\n",
            "        [1112, 5408]])\n",
            "tensor([[955, 131],\n",
            "        [292, 794]])\n",
            "Epoch: 29, Train Accuracy: 0.91334, Train Loss: 0.21626, Validation Accuracy: 0.82413, Validation Loss: 0.46315, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8241252302025782 0.8250460405156538\n",
            "tensor([[6231,  289],\n",
            "        [1055, 5465]])\n",
            "tensor([[950, 136],\n",
            "        [286, 800]])\n",
            "Epoch: 30, Train Accuracy: 0.91534, Train Loss: 0.20474, Validation Accuracy: 0.82505, Validation Loss: 0.47059, prediction: [0.915, 0.085], true label: [1.0, 0.0]\n",
            "0.8250460405156538 0.8250460405156538\n",
            "tensor([[6244,  276],\n",
            "        [1096, 5424]])\n",
            "tensor([[950, 136],\n",
            "        [289, 797]])\n",
            "Epoch: 31, Train Accuracy: 0.91534, Train Loss: 0.20934, Validation Accuracy: 0.81768, Validation Loss: 0.45531, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8176795580110497 0.8250460405156538\n",
            "tensor([[6218,  302],\n",
            "        [ 968, 5552]])\n",
            "tensor([[948, 138],\n",
            "        [280, 806]])\n",
            "Epoch: 32, Train Accuracy: 0.91610, Train Loss: 0.20077, Validation Accuracy: 0.82228, Validation Loss: 0.44803, prediction: [0.886, 0.114], true label: [1.0, 0.0]\n",
            "0.8222836095764272 0.8250460405156538\n",
            "tensor([[6223,  297],\n",
            "        [ 954, 5566]])\n",
            "tensor([[944, 142],\n",
            "        [273, 813]])\n",
            "Epoch: 33, Train Accuracy: 0.91641, Train Loss: 0.20200, Validation Accuracy: 0.82413, Validation Loss: 0.47476, prediction: [0.944, 0.056], true label: [1.0, 0.0]\n",
            "0.8241252302025782 0.8250460405156538\n",
            "tensor([[6267,  253],\n",
            "        [ 991, 5529]])\n",
            "tensor([[950, 136],\n",
            "        [282, 804]])\n",
            "Epoch: 34, Train Accuracy: 0.92239, Train Loss: 0.19103, Validation Accuracy: 0.82044, Validation Loss: 0.47318, prediction: [0.966, 0.034], true label: [0.0, 1.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6204,  316],\n",
            "        [ 857, 5663]])\n",
            "tensor([[939, 147],\n",
            "        [259, 827]])\n",
            "Epoch: 35, Train Accuracy: 0.91856, Train Loss: 0.19357, Validation Accuracy: 0.82413, Validation Loss: 0.43815, prediction: [0.906, 0.094], true label: [1.0, 0.0]\n",
            "0.8241252302025782 0.8250460405156538\n",
            "tensor([[6267,  253],\n",
            "        [ 969, 5551]])\n",
            "tensor([[942, 144],\n",
            "        [284, 802]])\n",
            "Epoch: 36, Train Accuracy: 0.92546, Train Loss: 0.18707, Validation Accuracy: 0.81768, Validation Loss: 0.46673, prediction: [0.033, 0.967], true label: [0.0, 1.0]\n",
            "0.8176795580110497 0.8250460405156538\n",
            "tensor([[6260,  260],\n",
            "        [ 851, 5669]])\n",
            "tensor([[943, 143],\n",
            "        [266, 820]])\n",
            "Epoch: 37, Train Accuracy: 0.92638, Train Loss: 0.18374, Validation Accuracy: 0.81492, Validation Loss: 0.50204, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8149171270718232 0.8250460405156538\n",
            "tensor([[6273,  247],\n",
            "        [ 881, 5639]])\n",
            "tensor([[941, 145],\n",
            "        [279, 807]])\n",
            "Epoch: 38, Train Accuracy: 0.93037, Train Loss: 0.17954, Validation Accuracy: 0.81400, Validation Loss: 0.61741, prediction: [0.97, 0.03], true label: [1.0, 0.0]\n",
            "0.8139963167587477 0.8250460405156538\n",
            "tensor([[6291,  229],\n",
            "        [ 922, 5598]])\n",
            "tensor([[949, 137],\n",
            "        [287, 799]])\n",
            "Epoch: 39, Train Accuracy: 0.93160, Train Loss: 0.18246, Validation Accuracy: 0.81676, Validation Loss: 0.49678, prediction: [0.858, 0.142], true label: [1.0, 0.0]\n",
            "0.8167587476979742 0.8250460405156538\n",
            "tensor([[6262,  258],\n",
            "        [ 877, 5643]])\n",
            "tensor([[944, 142],\n",
            "        [275, 811]])\n",
            "Epoch: 40, Train Accuracy: 0.92439, Train Loss: 0.17938, Validation Accuracy: 0.81676, Validation Loss: 0.50821, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.8167587476979742 0.8250460405156538\n",
            "tensor([[6290,  230],\n",
            "        [ 917, 5603]])\n",
            "tensor([[941, 145],\n",
            "        [287, 799]])\n",
            "Epoch: 41, Train Accuracy: 0.93298, Train Loss: 0.18145, Validation Accuracy: 0.81492, Validation Loss: 0.49019, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8149171270718232 0.8250460405156538\n",
            "tensor([[6274,  246],\n",
            "        [ 766, 5754]])\n",
            "tensor([[936, 150],\n",
            "        [269, 817]])\n",
            "Epoch: 42, Train Accuracy: 0.93328, Train Loss: 0.18030, Validation Accuracy: 0.81676, Validation Loss: 0.54639, prediction: [0.975, 0.025], true label: [1.0, 0.0]\n",
            "0.8167587476979742 0.8250460405156538\n",
            "tensor([[6293,  227],\n",
            "        [ 799, 5721]])\n",
            "tensor([[942, 144],\n",
            "        [279, 807]])\n",
            "Epoch: 43, Train Accuracy: 0.93788, Train Loss: 0.16720, Validation Accuracy: 0.81492, Validation Loss: 0.50591, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.8149171270718232 0.8250460405156538\n",
            "tensor([[6296,  224],\n",
            "        [ 783, 5737]])\n",
            "tensor([[936, 150],\n",
            "        [276, 810]])\n",
            "Epoch: 44, Train Accuracy: 0.93957, Train Loss: 0.17026, Validation Accuracy: 0.81400, Validation Loss: 0.52076, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8139963167587477 0.8250460405156538\n",
            "tensor([[6215,  305],\n",
            "        [ 747, 5773]])\n",
            "tensor([[932, 154],\n",
            "        [252, 834]])\n",
            "Epoch: 45, Train Accuracy: 0.92255, Train Loss: 0.17934, Validation Accuracy: 0.82044, Validation Loss: 0.49317, prediction: [0.045, 0.955], true label: [0.0, 1.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6275,  245],\n",
            "        [ 708, 5812]])\n",
            "tensor([[934, 152],\n",
            "        [257, 829]])\n",
            "Epoch: 46, Train Accuracy: 0.93727, Train Loss: 0.16508, Validation Accuracy: 0.82413, Validation Loss: 0.48626, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.8241252302025782 0.8250460405156538\n",
            "tensor([[6296,  224],\n",
            "        [ 694, 5826]])\n",
            "tensor([[931, 155],\n",
            "        [256, 830]])\n",
            "Epoch: 47, Train Accuracy: 0.94356, Train Loss: 0.15387, Validation Accuracy: 0.81768, Validation Loss: 0.48815, prediction: [0.913, 0.087], true label: [1.0, 0.0]\n",
            "0.8176795580110497 0.8250460405156538\n",
            "tensor([[6287,  233],\n",
            "        [ 710, 5810]])\n",
            "tensor([[931, 155],\n",
            "        [258, 828]])\n",
            "Epoch: 48, Train Accuracy: 0.93804, Train Loss: 0.15774, Validation Accuracy: 0.82136, Validation Loss: 0.53242, prediction: [0.29, 0.71], true label: [0.0, 1.0]\n",
            "0.8213627992633518 0.8250460405156538\n",
            "tensor([[6289,  231],\n",
            "        [ 634, 5886]])\n",
            "tensor([[928, 158],\n",
            "        [248, 838]])\n",
            "Epoch: 49, Train Accuracy: 0.94448, Train Loss: 0.14581, Validation Accuracy: 0.81860, Validation Loss: 0.50321, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.8186003683241252 0.8250460405156538\n",
            "tensor([[6314,  206],\n",
            "        [ 706, 5814]])\n",
            "tensor([[938, 148],\n",
            "        [270, 816]])\n",
            "Epoch: 50, Train Accuracy: 0.94356, Train Loss: 0.15560, Validation Accuracy: 0.82136, Validation Loss: 0.50382, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8213627992633518 0.8250460405156538\n",
            "tensor([[6302,  218],\n",
            "        [ 641, 5879]])\n",
            "tensor([[929, 157],\n",
            "        [256, 830]])\n",
            "Epoch: 51, Train Accuracy: 0.94463, Train Loss: 0.14431, Validation Accuracy: 0.82320, Validation Loss: 0.50552, prediction: [0.88, 0.12], true label: [1.0, 0.0]\n",
            "0.8232044198895028 0.8250460405156538\n",
            "tensor([[6338,  182],\n",
            "        [ 626, 5894]])\n",
            "tensor([[932, 154],\n",
            "        [268, 818]])\n",
            "Epoch: 52, Train Accuracy: 0.94954, Train Loss: 0.13794, Validation Accuracy: 0.81400, Validation Loss: 0.60311, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.8139963167587477 0.8250460405156538\n",
            "tensor([[6346,  174],\n",
            "        [ 692, 5828]])\n",
            "tensor([[923, 163],\n",
            "        [275, 811]])\n",
            "Epoch: 53, Train Accuracy: 0.95015, Train Loss: 0.13624, Validation Accuracy: 0.81215, Validation Loss: 0.54145, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8121546961325967 0.8250460405156538\n",
            "tensor([[6312,  208],\n",
            "        [ 574, 5946]])\n",
            "tensor([[931, 155],\n",
            "        [247, 839]])\n",
            "Epoch: 54, Train Accuracy: 0.94755, Train Loss: 0.14978, Validation Accuracy: 0.82044, Validation Loss: 0.56951, prediction: [0.972, 0.028], true label: [1.0, 0.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6364,  156],\n",
            "        [ 631, 5889]])\n",
            "tensor([[927, 159],\n",
            "        [275, 811]])\n",
            "Epoch: 55, Train Accuracy: 0.95261, Train Loss: 0.12451, Validation Accuracy: 0.80939, Validation Loss: 0.54954, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8093922651933702 0.8250460405156538\n",
            "tensor([[6332,  188],\n",
            "        [ 605, 5915]])\n",
            "tensor([[934, 152],\n",
            "        [263, 823]])\n",
            "Epoch: 56, Train Accuracy: 0.94831, Train Loss: 0.13559, Validation Accuracy: 0.82044, Validation Loss: 0.52211, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6229,  291],\n",
            "        [ 649, 5871]])\n",
            "tensor([[930, 156],\n",
            "        [249, 837]])\n",
            "Epoch: 57, Train Accuracy: 0.93113, Train Loss: 0.16757, Validation Accuracy: 0.81584, Validation Loss: 0.54670, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.8158379373848987 0.8250460405156538\n",
            "tensor([[6357,  163],\n",
            "        [ 564, 5956]])\n",
            "tensor([[920, 166],\n",
            "        [268, 818]])\n",
            "Epoch: 58, Train Accuracy: 0.95552, Train Loss: 0.12761, Validation Accuracy: 0.81400, Validation Loss: 0.58602, prediction: [0.846, 0.154], true label: [1.0, 0.0]\n",
            "0.8139963167587477 0.8250460405156538\n",
            "tensor([[6319,  201],\n",
            "        [ 496, 6024]])\n",
            "tensor([[924, 162],\n",
            "        [239, 847]])\n",
            "Epoch: 59, Train Accuracy: 0.95123, Train Loss: 0.12598, Validation Accuracy: 0.81768, Validation Loss: 0.53322, prediction: [0.929, 0.071], true label: [1.0, 0.0]\n",
            "0.8176795580110497 0.8250460405156538\n",
            "tensor([[6351,  169],\n",
            "        [ 489, 6031]])\n",
            "tensor([[916, 170],\n",
            "        [250, 836]])\n",
            "Epoch: 60, Train Accuracy: 0.95736, Train Loss: 0.15311, Validation Accuracy: 0.81860, Validation Loss: 0.56068, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.8186003683241252 0.8250460405156538\n",
            "tensor([[6378,  142],\n",
            "        [ 517, 6003]])\n",
            "tensor([[922, 164],\n",
            "        [264, 822]])\n",
            "Epoch: 61, Train Accuracy: 0.95936, Train Loss: 0.11323, Validation Accuracy: 0.81676, Validation Loss: 0.55574, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8167587476979742 0.8250460405156538\n",
            "tensor([[6363,  157],\n",
            "        [ 470, 6050]])\n",
            "tensor([[921, 165],\n",
            "        [251, 835]])\n",
            "Epoch: 62, Train Accuracy: 0.95752, Train Loss: 0.11208, Validation Accuracy: 0.81676, Validation Loss: 0.59810, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8167587476979742 0.8250460405156538\n",
            "tensor([[6304,  216],\n",
            "        [ 503, 6017]])\n",
            "tensor([[920, 166],\n",
            "        [245, 841]])\n",
            "Epoch: 63, Train Accuracy: 0.94939, Train Loss: 0.14513, Validation Accuracy: 0.81400, Validation Loss: 0.61376, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.8139963167587477 0.8250460405156538\n",
            "tensor([[6387,  133],\n",
            "        [ 570, 5950]])\n",
            "tensor([[918, 168],\n",
            "        [284, 802]])\n",
            "Epoch: 64, Train Accuracy: 0.96074, Train Loss: 0.12456, Validation Accuracy: 0.79466, Validation Loss: 0.63053, prediction: [0.967, 0.033], true label: [1.0, 0.0]\n",
            "0.7946593001841621 0.8250460405156538\n",
            "tensor([[6386,  134],\n",
            "        [ 491, 6029]])\n",
            "tensor([[920, 166],\n",
            "        [270, 816]])\n",
            "Epoch: 65, Train Accuracy: 0.96150, Train Loss: 0.10886, Validation Accuracy: 0.80295, Validation Loss: 0.59912, prediction: [0.848, 0.152], true label: [1.0, 0.0]\n",
            "0.8029465930018416 0.8250460405156538\n",
            "tensor([[6375,  145],\n",
            "        [ 458, 6062]])\n",
            "tensor([[922, 164],\n",
            "        [245, 841]])\n",
            "Epoch: 66, Train Accuracy: 0.96089, Train Loss: 0.10503, Validation Accuracy: 0.82228, Validation Loss: 0.56477, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.8222836095764272 0.8250460405156538\n",
            "tensor([[6271,  249],\n",
            "        [ 552, 5968]])\n",
            "tensor([[919, 167],\n",
            "        [233, 853]])\n",
            "Epoch: 67, Train Accuracy: 0.94172, Train Loss: 0.13825, Validation Accuracy: 0.81952, Validation Loss: 0.60745, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[5985,  535],\n",
            "        [ 835, 5685]])\n",
            "tensor([[888, 198],\n",
            "        [249, 837]])\n",
            "Epoch: 68, Train Accuracy: 0.89325, Train Loss: 0.27066, Validation Accuracy: 0.79190, Validation Loss: 0.75498, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.7918968692449355 0.8250460405156538\n",
            "tensor([[6390,  130],\n",
            "        [ 479, 6041]])\n",
            "tensor([[923, 163],\n",
            "        [264, 822]])\n",
            "Epoch: 69, Train Accuracy: 0.96396, Train Loss: 0.10976, Validation Accuracy: 0.81031, Validation Loss: 0.61934, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8103130755064457 0.8250460405156538\n",
            "tensor([[6412,  108],\n",
            "        [ 554, 5966]])\n",
            "tensor([[924, 162],\n",
            "        [289, 797]])\n",
            "Epoch: 70, Train Accuracy: 0.96365, Train Loss: 0.10506, Validation Accuracy: 0.80018, Validation Loss: 0.62468, prediction: [0.986, 0.014], true label: [0.0, 1.0]\n",
            "0.8001841620626151 0.8250460405156538\n",
            "tensor([[6390,  130],\n",
            "        [ 416, 6104]])\n",
            "tensor([[920, 166],\n",
            "        [257, 829]])\n",
            "Epoch: 71, Train Accuracy: 0.96564, Train Loss: 0.09501, Validation Accuracy: 0.81215, Validation Loss: 0.63066, prediction: [0.955, 0.045], true label: [1.0, 0.0]\n",
            "0.8121546961325967 0.8250460405156538\n",
            "tensor([[6404,  116],\n",
            "        [ 442, 6078]])\n",
            "tensor([[915, 171],\n",
            "        [268, 818]])\n",
            "Epoch: 72, Train Accuracy: 0.96672, Train Loss: 0.09608, Validation Accuracy: 0.80939, Validation Loss: 0.68852, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8093922651933702 0.8250460405156538\n",
            "tensor([[6407,  113],\n",
            "        [ 418, 6102]])\n",
            "tensor([[923, 163],\n",
            "        [260, 826]])\n",
            "Epoch: 73, Train Accuracy: 0.96810, Train Loss: 0.08813, Validation Accuracy: 0.80663, Validation Loss: 0.58974, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.8066298342541437 0.8250460405156538\n",
            "tensor([[6410,  110],\n",
            "        [ 440, 6080]])\n",
            "tensor([[925, 161],\n",
            "        [268, 818]])\n",
            "Epoch: 74, Train Accuracy: 0.96764, Train Loss: 0.09024, Validation Accuracy: 0.80847, Validation Loss: 0.61079, prediction: [0.934, 0.066], true label: [1.0, 0.0]\n",
            "0.8084714548802947 0.8250460405156538\n",
            "tensor([[6412,  108],\n",
            "        [ 386, 6134]])\n",
            "tensor([[922, 164],\n",
            "        [261, 825]])\n",
            "Epoch: 75, Train Accuracy: 0.96887, Train Loss: 0.09243, Validation Accuracy: 0.81031, Validation Loss: 0.72377, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.8103130755064457 0.8250460405156538\n",
            "tensor([[6403,  117],\n",
            "        [ 440, 6080]])\n",
            "tensor([[920, 166],\n",
            "        [278, 808]])\n",
            "Epoch: 76, Train Accuracy: 0.96672, Train Loss: 0.09538, Validation Accuracy: 0.79926, Validation Loss: 0.64333, prediction: [0.572, 0.428], true label: [0.0, 1.0]\n",
            "0.7992633517495396 0.8250460405156538\n",
            "tensor([[6401,  119],\n",
            "        [ 355, 6165]])\n",
            "tensor([[921, 165],\n",
            "        [250, 836]])\n",
            "Epoch: 77, Train Accuracy: 0.96840, Train Loss: 0.08333, Validation Accuracy: 0.81952, Validation Loss: 0.67297, prediction: [0.983, 0.017], true label: [1.0, 0.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[6424,   96],\n",
            "        [ 383, 6137]])\n",
            "tensor([[923, 163],\n",
            "        [259, 827]])\n",
            "Epoch: 78, Train Accuracy: 0.97040, Train Loss: 0.08897, Validation Accuracy: 0.80847, Validation Loss: 0.65807, prediction: [0.933, 0.067], true label: [1.0, 0.0]\n",
            "0.8084714548802947 0.8250460405156538\n",
            "tensor([[6413,  107],\n",
            "        [ 566, 5954]])\n",
            "tensor([[914, 172],\n",
            "        [298, 788]])\n",
            "Epoch: 79, Train Accuracy: 0.96288, Train Loss: 0.11044, Validation Accuracy: 0.79282, Validation Loss: 0.69322, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7928176795580111 0.8250460405156538\n",
            "tensor([[6397,  123],\n",
            "        [ 330, 6190]])\n",
            "tensor([[923, 163],\n",
            "        [237, 849]])\n",
            "Epoch: 80, Train Accuracy: 0.96840, Train Loss: 0.08147, Validation Accuracy: 0.81860, Validation Loss: 0.66747, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8186003683241252 0.8250460405156538\n",
            "tensor([[6414,  106],\n",
            "        [ 342, 6178]])\n",
            "tensor([[922, 164],\n",
            "        [247, 839]])\n",
            "Epoch: 81, Train Accuracy: 0.97132, Train Loss: 0.08032, Validation Accuracy: 0.81952, Validation Loss: 0.59993, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[6411,  109],\n",
            "        [ 423, 6097]])\n",
            "tensor([[918, 168],\n",
            "        [281, 805]])\n",
            "Epoch: 82, Train Accuracy: 0.96840, Train Loss: 0.08724, Validation Accuracy: 0.79466, Validation Loss: 0.65836, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7946593001841621 0.8250460405156538\n",
            "tensor([[6418,  102],\n",
            "        [ 355, 6165]])\n",
            "tensor([[925, 161],\n",
            "        [246, 840]])\n",
            "Epoch: 83, Train Accuracy: 0.96994, Train Loss: 0.08195, Validation Accuracy: 0.82044, Validation Loss: 0.68911, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6418,  102],\n",
            "        [ 356, 6164]])\n",
            "tensor([[926, 160],\n",
            "        [246, 840]])\n",
            "Epoch: 84, Train Accuracy: 0.96948, Train Loss: 0.08151, Validation Accuracy: 0.82320, Validation Loss: 0.62189, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.8232044198895028 0.8250460405156538\n",
            "tensor([[6418,  102],\n",
            "        [ 321, 6199]])\n",
            "tensor([[928, 158],\n",
            "        [232, 854]])\n",
            "Epoch: 85, Train Accuracy: 0.97117, Train Loss: 0.07877, Validation Accuracy: 0.82228, Validation Loss: 0.60387, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8222836095764272 0.8250460405156538\n",
            "tensor([[6435,   85],\n",
            "        [ 371, 6149]])\n",
            "tensor([[911, 175],\n",
            "        [275, 811]])\n",
            "Epoch: 86, Train Accuracy: 0.97362, Train Loss: 0.07658, Validation Accuracy: 0.79926, Validation Loss: 0.75541, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.7992633517495396 0.8250460405156538\n",
            "tensor([[6433,   87],\n",
            "        [ 322, 6198]])\n",
            "tensor([[917, 169],\n",
            "        [253, 833]])\n",
            "Epoch: 87, Train Accuracy: 0.97347, Train Loss: 0.07004, Validation Accuracy: 0.81952, Validation Loss: 0.64006, prediction: [0.885, 0.115], true label: [1.0, 0.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[6368,  152],\n",
            "        [ 375, 6145]])\n",
            "tensor([[927, 159],\n",
            "        [224, 862]])\n",
            "Epoch: 88, Train Accuracy: 0.96350, Train Loss: 0.09046, Validation Accuracy: 0.82505, Validation Loss: 0.64792, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.8250460405156538 0.8250460405156538\n",
            "tensor([[6447,   73],\n",
            "        [ 378, 6142]])\n",
            "tensor([[922, 164],\n",
            "        [272, 814]])\n",
            "Epoch: 89, Train Accuracy: 0.97377, Train Loss: 0.07330, Validation Accuracy: 0.81123, Validation Loss: 0.68794, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8112338858195212 0.8250460405156538\n",
            "tensor([[6441,   79],\n",
            "        [ 326, 6194]])\n",
            "tensor([[916, 170],\n",
            "        [264, 822]])\n",
            "Epoch: 90, Train Accuracy: 0.97623, Train Loss: 0.06827, Validation Accuracy: 0.80847, Validation Loss: 0.66602, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.8084714548802947 0.8250460405156538\n",
            "tensor([[6443,   77],\n",
            "        [ 305, 6215]])\n",
            "tensor([[934, 152],\n",
            "        [250, 836]])\n",
            "Epoch: 91, Train Accuracy: 0.97454, Train Loss: 0.07008, Validation Accuracy: 0.82505, Validation Loss: 0.62395, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.8250460405156538 0.8250460405156538\n",
            "tensor([[6446,   74],\n",
            "        [ 351, 6169]])\n",
            "tensor([[917, 169],\n",
            "        [267, 819]])\n",
            "Epoch: 92, Train Accuracy: 0.97592, Train Loss: 0.07427, Validation Accuracy: 0.80295, Validation Loss: 0.70135, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.8029465930018416 0.8250460405156538\n",
            "tensor([[6428,   92],\n",
            "        [ 297, 6223]])\n",
            "tensor([[929, 157],\n",
            "        [242, 844]])\n",
            "Epoch: 93, Train Accuracy: 0.97454, Train Loss: 0.06858, Validation Accuracy: 0.82228, Validation Loss: 0.74875, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8222836095764272 0.8250460405156538\n",
            "tensor([[6450,   70],\n",
            "        [ 287, 6233]])\n",
            "tensor([[925, 161],\n",
            "        [248, 838]])\n",
            "Epoch: 94, Train Accuracy: 0.97638, Train Loss: 0.06511, Validation Accuracy: 0.82044, Validation Loss: 0.62856, prediction: [0.03, 0.97], true label: [0.0, 1.0]\n",
            "0.8204419889502762 0.8250460405156538\n",
            "tensor([[6445,   75],\n",
            "        [ 283, 6237]])\n",
            "tensor([[930, 156],\n",
            "        [245, 841]])\n",
            "Epoch: 95, Train Accuracy: 0.97669, Train Loss: 0.07302, Validation Accuracy: 0.81952, Validation Loss: 0.62609, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8195211786372008 0.8250460405156538\n",
            "tensor([[6428,   92],\n",
            "        [ 320, 6200]])\n",
            "tensor([[921, 165],\n",
            "        [244, 842]])\n",
            "Epoch: 96, Train Accuracy: 0.97423, Train Loss: 0.07146, Validation Accuracy: 0.82136, Validation Loss: 0.72078, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.8213627992633518 0.8250460405156538\n",
            "tensor([[6429,   91],\n",
            "        [ 278, 6242]])\n",
            "tensor([[927, 159],\n",
            "        [228, 858]])\n",
            "Epoch: 97, Train Accuracy: 0.97561, Train Loss: 0.06476, Validation Accuracy: 0.82781, Validation Loss: 0.68850, prediction: [0.395, 0.605], true label: [0.0, 1.0]\n",
            "0.8278084714548803 0.8250460405156538\n",
            "best_state_dict updated\n",
            "tensor([[6447,   73],\n",
            "        [ 321, 6199]])\n",
            "tensor([[912, 174],\n",
            "        [273, 813]])\n",
            "Epoch: 98, Train Accuracy: 0.97592, Train Loss: 0.06519, Validation Accuracy: 0.79926, Validation Loss: 0.72178, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.7992633517495396 0.8278084714548803\n",
            "tensor([[6456,   64],\n",
            "        [ 282, 6238]])\n",
            "tensor([[916, 170],\n",
            "        [258, 828]])\n",
            "Epoch: 99, Train Accuracy: 0.97853, Train Loss: 0.06550, Validation Accuracy: 0.81031, Validation Loss: 0.74851, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8103130755064457 0.8278084714548803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NG89yTpDWXWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best8,network8=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0005, epochs=40, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fCsqKVqDUU_S",
        "outputId": "66a89a43-5a07-4f9d-e588-08eacea5f270"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6520\n",
            "1087\n",
            "1087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5938,  582],\n",
            "        [2717, 3803]])\n",
            "tensor([[990,  97],\n",
            "        [451, 636]])\n",
            "Epoch: 0, Train Accuracy: 0.79479, Train Loss: 0.43693, Validation Accuracy: 0.78933, Validation Loss: 0.43559, prediction: [0.114, 0.886], true label: [0.0, 1.0]\n",
            "0.7893284268629255 0\n",
            "best_state_dict updated\n",
            "tensor([[5993,  527],\n",
            "        [2416, 4104]])\n",
            "tensor([[978, 109],\n",
            "        [418, 669]])\n",
            "Epoch: 1, Train Accuracy: 0.81334, Train Loss: 0.41620, Validation Accuracy: 0.79209, Validation Loss: 0.39708, prediction: [0.52, 0.48], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.7893284268629255\n",
            "best_state_dict updated\n",
            "tensor([[6038,  482],\n",
            "        [2238, 4282]])\n",
            "tensor([[973, 114],\n",
            "        [407, 680]])\n",
            "Epoch: 2, Train Accuracy: 0.83405, Train Loss: 0.37897, Validation Accuracy: 0.80313, Validation Loss: 0.39684, prediction: [0.574, 0.426], true label: [1.0, 0.0]\n",
            "0.8031278748850046 0.7920883164673413\n",
            "best_state_dict updated\n",
            "tensor([[6006,  514],\n",
            "        [1492, 5028]])\n",
            "tensor([[945, 142],\n",
            "        [330, 757]])\n",
            "Epoch: 3, Train Accuracy: 0.87009, Train Loss: 0.31617, Validation Accuracy: 0.80497, Validation Loss: 0.39234, prediction: [0.898, 0.102], true label: [1.0, 0.0]\n",
            "0.8049678012879485 0.8031278748850046\n",
            "best_state_dict updated\n",
            "tensor([[6211,  309],\n",
            "        [1300, 5220]])\n",
            "tensor([[956, 131],\n",
            "        [347, 740]])\n",
            "Epoch: 4, Train Accuracy: 0.90000, Train Loss: 0.24791, Validation Accuracy: 0.79761, Validation Loss: 0.39874, prediction: [0.87, 0.13], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.8049678012879485\n",
            "tensor([[6245,  275],\n",
            "        [ 733, 5787]])\n",
            "tensor([[934, 153],\n",
            "        [276, 811]])\n",
            "Epoch: 5, Train Accuracy: 0.93160, Train Loss: 0.18272, Validation Accuracy: 0.81049, Validation Loss: 0.39269, prediction: [0.598, 0.402], true label: [1.0, 0.0]\n",
            "0.8104875804967802 0.8049678012879485\n",
            "best_state_dict updated\n",
            "tensor([[6311,  209],\n",
            "        [ 557, 5963]])\n",
            "tensor([[929, 158],\n",
            "        [277, 810]])\n",
            "Epoch: 6, Train Accuracy: 0.94816, Train Loss: 0.14266, Validation Accuracy: 0.80129, Validation Loss: 0.45776, prediction: [0.053, 0.947], true label: [0.0, 1.0]\n",
            "0.8012879484820608 0.8104875804967802\n",
            "tensor([[6356,  164],\n",
            "        [ 450, 6070]])\n",
            "tensor([[923, 164],\n",
            "        [273, 814]])\n",
            "Epoch: 7, Train Accuracy: 0.95920, Train Loss: 0.11452, Validation Accuracy: 0.80405, Validation Loss: 0.55364, prediction: [0.938, 0.062], true label: [1.0, 0.0]\n",
            "0.8040478380864765 0.8104875804967802\n",
            "tensor([[6405,  115],\n",
            "        [ 314, 6206]])\n",
            "tensor([[928, 159],\n",
            "        [233, 854]])\n",
            "Epoch: 8, Train Accuracy: 0.97025, Train Loss: 0.08693, Validation Accuracy: 0.81969, Validation Loss: 0.48948, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.8196872125114996 0.8104875804967802\n",
            "best_state_dict updated\n",
            "tensor([[6427,   93],\n",
            "        [ 244, 6276]])\n",
            "tensor([[925, 162],\n",
            "        [245, 842]])\n",
            "Epoch: 9, Train Accuracy: 0.97561, Train Loss: 0.06758, Validation Accuracy: 0.81509, Validation Loss: 0.55251, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8150873965041399 0.8196872125114996\n",
            "tensor([[6396,  124],\n",
            "        [ 333, 6187]])\n",
            "tensor([[933, 154],\n",
            "        [223, 864]])\n",
            "Epoch: 10, Train Accuracy: 0.97009, Train Loss: 0.07774, Validation Accuracy: 0.83441, Validation Loss: 0.59115, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8344066237350506 0.8196872125114996\n",
            "best_state_dict updated\n",
            "tensor([[6458,   62],\n",
            "        [ 197, 6323]])\n",
            "tensor([[929, 158],\n",
            "        [223, 864]])\n",
            "Epoch: 11, Train Accuracy: 0.98052, Train Loss: 0.04663, Validation Accuracy: 0.82981, Validation Loss: 0.57268, prediction: [0.144, 0.856], true label: [0.0, 1.0]\n",
            "0.8298068077276909 0.8344066237350506\n",
            "tensor([[6456,   64],\n",
            "        [ 196, 6324]])\n",
            "tensor([[931, 156],\n",
            "        [217, 870]])\n",
            "Epoch: 12, Train Accuracy: 0.98206, Train Loss: 0.04374, Validation Accuracy: 0.83533, Validation Loss: 0.64241, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8353265869365225 0.8344066237350506\n",
            "best_state_dict updated\n",
            "tensor([[6435,   85],\n",
            "        [ 200, 6320]])\n",
            "tensor([[923, 164],\n",
            "        [212, 875]])\n",
            "Epoch: 13, Train Accuracy: 0.98067, Train Loss: 0.04951, Validation Accuracy: 0.82429, Validation Loss: 0.68836, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8242870285188593 0.8353265869365225\n",
            "tensor([[6458,   62],\n",
            "        [ 186, 6334]])\n",
            "tensor([[925, 162],\n",
            "        [222, 865]])\n",
            "Epoch: 14, Train Accuracy: 0.98405, Train Loss: 0.04737, Validation Accuracy: 0.82889, Validation Loss: 0.56659, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.828886844526219 0.8353265869365225\n",
            "tensor([[6480,   40],\n",
            "        [ 190, 6330]])\n",
            "tensor([[906, 181],\n",
            "        [255, 832]])\n",
            "Epoch: 15, Train Accuracy: 0.98374, Train Loss: 0.03759, Validation Accuracy: 0.80129, Validation Loss: 0.70800, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8012879484820608 0.8353265869365225\n",
            "tensor([[6467,   53],\n",
            "        [ 195, 6325]])\n",
            "tensor([[923, 164],\n",
            "        [233, 854]])\n",
            "Epoch: 16, Train Accuracy: 0.98252, Train Loss: 0.03816, Validation Accuracy: 0.82061, Validation Loss: 0.65832, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.8206071757129715 0.8353265869365225\n",
            "tensor([[6449,   71],\n",
            "        [ 265, 6255]])\n",
            "tensor([[905, 182],\n",
            "        [271, 816]])\n",
            "Epoch: 17, Train Accuracy: 0.97791, Train Loss: 0.05887, Validation Accuracy: 0.79669, Validation Loss: 0.70526, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.8353265869365225\n",
            "tensor([[6482,   38],\n",
            "        [ 186, 6334]])\n",
            "tensor([[911, 176],\n",
            "        [250, 837]])\n",
            "Epoch: 18, Train Accuracy: 0.98558, Train Loss: 0.03274, Validation Accuracy: 0.80773, Validation Loss: 0.82795, prediction: [0.963, 0.037], true label: [1.0, 0.0]\n",
            "0.8077276908923643 0.8353265869365225\n",
            "tensor([[6461,   59],\n",
            "        [ 163, 6357]])\n",
            "tensor([[925, 162],\n",
            "        [216, 871]])\n",
            "Epoch: 19, Train Accuracy: 0.98252, Train Loss: 0.03613, Validation Accuracy: 0.82153, Validation Loss: 0.68511, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8215271389144434 0.8353265869365225\n",
            "tensor([[6491,   29],\n",
            "        [ 180, 6340]])\n",
            "tensor([[922, 165],\n",
            "        [231, 856]])\n",
            "Epoch: 20, Train Accuracy: 0.98512, Train Loss: 0.02628, Validation Accuracy: 0.82337, Validation Loss: 0.76346, prediction: [0.837, 0.163], true label: [1.0, 0.0]\n",
            "0.8233670653173873 0.8353265869365225\n",
            "tensor([[6495,   25],\n",
            "        [ 190, 6330]])\n",
            "tensor([[908, 179],\n",
            "        [237, 850]])\n",
            "Epoch: 21, Train Accuracy: 0.98543, Train Loss: 0.02700, Validation Accuracy: 0.80957, Validation Loss: 0.79637, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8095676172953082 0.8353265869365225\n",
            "tensor([[6492,   28],\n",
            "        [ 189, 6331]])\n",
            "tensor([[903, 184],\n",
            "        [244, 843]])\n",
            "Epoch: 22, Train Accuracy: 0.98574, Train Loss: 0.02553, Validation Accuracy: 0.79945, Validation Loss: 0.95859, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.7994480220791168 0.8353265869365225\n",
            "tensor([[6487,   33],\n",
            "        [ 165, 6355]])\n",
            "tensor([[915, 172],\n",
            "        [230, 857]])\n",
            "Epoch: 23, Train Accuracy: 0.98620, Train Loss: 0.02609, Validation Accuracy: 0.81601, Validation Loss: 0.77923, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8160073597056118 0.8353265869365225\n",
            "tensor([[6486,   34],\n",
            "        [ 176, 6344]])\n",
            "tensor([[913, 174],\n",
            "        [227, 860]])\n",
            "Epoch: 24, Train Accuracy: 0.98512, Train Loss: 0.02653, Validation Accuracy: 0.81601, Validation Loss: 0.96198, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8160073597056118 0.8353265869365225\n",
            "tensor([[6493,   27],\n",
            "        [ 182, 6338]])\n",
            "tensor([[911, 176],\n",
            "        [229, 858]])\n",
            "Epoch: 25, Train Accuracy: 0.98620, Train Loss: 0.02568, Validation Accuracy: 0.81693, Validation Loss: 0.85780, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8169273229070837 0.8353265869365225\n",
            "tensor([[6490,   30],\n",
            "        [ 170, 6350]])\n",
            "tensor([[913, 174],\n",
            "        [226, 861]])\n",
            "Epoch: 26, Train Accuracy: 0.98620, Train Loss: 0.02415, Validation Accuracy: 0.81601, Validation Loss: 0.96222, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8160073597056118 0.8353265869365225\n",
            "tensor([[6495,   25],\n",
            "        [ 171, 6349]])\n",
            "tensor([[903, 184],\n",
            "        [228, 859]])\n",
            "Epoch: 27, Train Accuracy: 0.98604, Train Loss: 0.02521, Validation Accuracy: 0.81233, Validation Loss: 0.92182, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.812327506899724 0.8353265869365225\n",
            "tensor([[6495,   25],\n",
            "        [ 172, 6348]])\n",
            "tensor([[900, 187],\n",
            "        [234, 853]])\n",
            "Epoch: 28, Train Accuracy: 0.98620, Train Loss: 0.02212, Validation Accuracy: 0.80221, Validation Loss: 0.99525, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8022079116835327 0.8353265869365225\n",
            "tensor([[6486,   34],\n",
            "        [ 163, 6357]])\n",
            "tensor([[915, 172],\n",
            "        [222, 865]])\n",
            "Epoch: 29, Train Accuracy: 0.98635, Train Loss: 0.02485, Validation Accuracy: 0.81601, Validation Loss: 0.95522, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8160073597056118 0.8353265869365225\n",
            "tensor([[6494,   26],\n",
            "        [ 172, 6348]])\n",
            "tensor([[910, 177],\n",
            "        [228, 859]])\n",
            "Epoch: 30, Train Accuracy: 0.98666, Train Loss: 0.02400, Validation Accuracy: 0.81693, Validation Loss: 0.87746, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8169273229070837 0.8353265869365225\n",
            "tensor([[6493,   27],\n",
            "        [ 177, 6343]])\n",
            "tensor([[904, 183],\n",
            "        [231, 856]])\n",
            "Epoch: 31, Train Accuracy: 0.98650, Train Loss: 0.02510, Validation Accuracy: 0.80865, Validation Loss: 0.96238, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8086476540938362 0.8353265869365225\n",
            "tensor([[6501,   19],\n",
            "        [ 190, 6330]])\n",
            "tensor([[909, 178],\n",
            "        [229, 858]])\n",
            "Epoch: 32, Train Accuracy: 0.98666, Train Loss: 0.02252, Validation Accuracy: 0.81417, Validation Loss: 1.00613, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8141674333026679 0.8353265869365225\n",
            "tensor([[6494,   26],\n",
            "        [ 177, 6343]])\n",
            "tensor([[920, 167],\n",
            "        [215, 872]])\n",
            "Epoch: 33, Train Accuracy: 0.98635, Train Loss: 0.02329, Validation Accuracy: 0.82153, Validation Loss: 0.83409, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8215271389144434 0.8353265869365225\n",
            "tensor([[6493,   27],\n",
            "        [ 171, 6349]])\n",
            "tensor([[908, 179],\n",
            "        [229, 858]])\n",
            "Epoch: 34, Train Accuracy: 0.98696, Train Loss: 0.02505, Validation Accuracy: 0.81509, Validation Loss: 0.96663, prediction: [0.864, 0.136], true label: [1.0, 0.0]\n",
            "0.8150873965041399 0.8353265869365225\n",
            "tensor([[6501,   19],\n",
            "        [ 181, 6339]])\n",
            "tensor([[902, 185],\n",
            "        [234, 853]])\n",
            "Epoch: 35, Train Accuracy: 0.98712, Train Loss: 0.02593, Validation Accuracy: 0.80773, Validation Loss: 0.91075, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8077276908923643 0.8353265869365225\n",
            "tensor([[6498,   22],\n",
            "        [ 173, 6347]])\n",
            "tensor([[909, 178],\n",
            "        [233, 854]])\n",
            "Epoch: 36, Train Accuracy: 0.98666, Train Loss: 0.02227, Validation Accuracy: 0.80681, Validation Loss: 0.93275, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8068077276908924 0.8353265869365225\n",
            "tensor([[6497,   23],\n",
            "        [ 173, 6347]])\n",
            "tensor([[913, 174],\n",
            "        [223, 864]])\n",
            "Epoch: 37, Train Accuracy: 0.98712, Train Loss: 0.02355, Validation Accuracy: 0.81969, Validation Loss: 0.95078, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8196872125114996 0.8353265869365225\n",
            "tensor([[6493,   27],\n",
            "        [ 166, 6354]])\n",
            "tensor([[904, 183],\n",
            "        [235, 852]])\n",
            "Epoch: 38, Train Accuracy: 0.98650, Train Loss: 0.02321, Validation Accuracy: 0.80497, Validation Loss: 0.94838, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8049678012879485 0.8353265869365225\n",
            "tensor([[6501,   19],\n",
            "        [ 178, 6342]])\n",
            "tensor([[912, 175],\n",
            "        [228, 859]])\n",
            "Epoch: 39, Train Accuracy: 0.98666, Train Loss: 0.02490, Validation Accuracy: 0.81693, Validation Loss: 1.07356, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8169273229070837 0.8353265869365225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfSUlEQVR4nO3dfZRddX3v8fcn85DMycMcMhmBkGQmmnAxWEGN+AhFRQlcS/ReqEF7L3XhQr1wtddWBXuLljatrN4rrV5sFy0gpdwGino71igiWKFWgYA8Q2QEAglPIU+EJGQyM9/7x/5NOAzzkMzsM3vmnM9rraycsx9+57v3yuQz+/fb57cVEZiZmY3XtKILMDOz2uBAMTOzXDhQzMwsFw4UMzPLhQPFzMxy4UAxM7NcOFDMDpCk4yWtL7oOs8nKgWJTgqTHJZ1UZA0RcWtE/IdqtC3pXyW9JOlFSc9L+o6kww9w3xMlbRzn58+R9JeSnkg1/Dq9nzeedq2+OFDMEkkNBZdwXkTMApYAs4D/NREfKqkZuAk4GlgBzAHeAWwBjhtDe425FmhThgPFpjRJ0ySdn36j3iLpOklzK9b/k6RnJO2QdIukoyvWfUvSX0taK2kX8J50JfQHku5N+1wraUba/hVXAiNtm9Z/QdLTkp6S9AlJIWnJaMcUEduB/wccW9HWxyU9JGmnpEclfTItnwn8AJifrixelDR/tPMyyH8FFgEfjogHI6I/Ip6LiD+JiLXpc15Rezp3f1p5XiR9UdIzwJWp1g9WbN8oabOkN6f3b5f075K2S7pH0omjnReb/BwoNtX9d+BDwG8C84FtwKUV638ALAVeA9wFXDNo/48Cq4HZwL+lZb9N9pv6YuCNwO+O8PlDbitpBfA54CSyK44TD/SAJLUB/wnorlj8HPBBsquHjwOXSHpzROwCTgGeiohZ6c9TjH5eKp0E/DAiXjzQGodwGDAX6ADOAf4ROLNi/cnA8xFxl6QjgO8Df5r2+QPg25Lax/H5Ngk4UGyq+xTwhxGxMSL2Al8BTh/odomIKyJiZ8W6YyS1Vuz/zxHxs/Rb+Utp2dcj4qmI2Ap8j4orhSEMt+1vA1dGxAMRsTt99mi+LmkH8DwwjywUSMfx/Yj4dWR+CvwIOH6EtkY8L4O0AU8fQH0j6Qe+HBF7I2IP8H+B0ySV0vqPkoUMwO8AayNibTrvNwLrgFPHWYMVzIFiU10H8N3UdbIdeAjoAw6V1CDpq6nb5wXg8bRP5UDzk0O0+UzF691k4xnDGW7b+YPaHupzBvtMRLSSXekcAiwYWCHpFEm/kLQ1HeepvPI4Bhv2vAyx7RbggG4AGMHmikAmIrrTZ/5WCpXTyEJmoLYzBmpL9b07hxqsYA4Um+qeBE6JiHLFnxkRsYnst+KVZF06rUBn2kcV+1druu2nqQgEYOGB7hgR95F1B12qzHTg22SD9IdGRBlYy8vHMdQxjHReBvsxcHIajxnObqBU8f6wwWUPsc9At9dK4MEUMgO1XT2otpkR8dURPt+mAAeKTSVNkmZU/GkE/gZYLakDQFK7pJVp+9nAXrLfwEvAn01grdcBH5f0+vQb+h8d5P5XkV1NnAY0A9OBzUCvpFOAD1Rs+yzQNqgrb6TzMtjVZP/Jf1vSUWlAv03SlyQNdEPdDXw0XfWtIBubGc2aVOenefnqBOAfyK5cTk7tzUgD+wuGbMWmDAeKTSVrgT0Vf74C/BXQBfxI0k7gF8Db0vZ/D2wANgEPpnUTIiJ+AHwd+AnZ4PrAZ+89wP17yI7tjyJiJ/AZspDaRnbl1VWx7cNkVwOPpi6k+Yx8XgZ/1l6yq7iHgRuBF4DbybrUbkubfRb4LWA78DGyu9BGO4angZ8D7wSurVj+JNlVy5fIQvJJ4PP4/6MpT37Alln1SXo9cD8wPSJ6i67HrBr8G4FZlUj6sKTpkg4BLga+5zCxWuZAMaueT5J9f+TXZHdYfbrYcsyqy11eZmaWC1+hmJlZLup6Erd58+ZFZ2dn0WWYmU0pd9555/MR8aqpcuo6UDo7O1m3bl3RZZiZTSmSNgy13F1eZmaWCweKmZnlwoFiZma5cKCYmVkuHChmZpaLqgaKpBWS1kvqlnT+EOunp8emdku6TVJnxboL0vL1kk4erc30SNLHJN2d/oz0UCQzM8tZ1W4bltRA9sjR9wMbgTskdUXEgxWbnQ1si4glklaRzXf0EUnLgFXA0WQPKvqxpCPTPiO1+fmIuL5ax2RmZsOr5vdQjgO6I+JRAElrSA/aqdhmJS8/GvV64P9IUlq+Jk2r/Zik7tQeB9Bm1X33lxt5bPOuifzIXH3wmPkceejsosswsxpTzUA5glc+9nQjr34ew/5tIqI3PU+7LS3/xaB9j0ivR2pztaQLgZuA81MgvYKkc4BzABYtWnSQh5T53j1P85P1z41p36JFwMZte/jaR9wjaGb5qqVvyl9A9nzvZuAy4IvARYM3iojL0nqWL18+ppkxr/jdt469yoJ98Bu3sm13T9FlmFkNquag/CZe+RztBWnZkNukx7m2kj2udbh9h20zIp6OzF7gSl7uIrMK5ZZmduzZV3QZZlaDqhkodwBLJS2W1Ew2yN41aJsu4Kz0+nTg5sjm0+8CVqW7wBYDS8keSTpsm5IOT38L+BDZ0/FskNZSE9sdKGZWBVXr8kpjIucBNwANwBUR8YCki4B1EdEFXA5cnQbdt5IFBGm768gG23uBcyOiD2CoNtNHXiOpHRBwN/Cpah3bVNba0sSO3Q4UM8tfVcdQImItsHbQsgsrXr8EnDHMvquB1QfSZlr+3vHWWw/KLdkVSkSQXcyZmeXD35SvM+VSE339wa6evqJLMbMa40CpM60tTQBs951eZpYzB0qdaW1pBmC7x1HMLGcOlDpTLmVXKC/4Ti8zy5kDpc4MBIpvHTazvDlQ6szLYygOFDPLlwOlzpTTGIq/LW9meXOg1JkZTdNobpzG9j2+y8vM8uVAqTOS/G15M6sKB0odKrc0ucvLzHLnQKlD5VKTB+XNLHcOlDrU2uIZh80sfw6UOtTa0uwvNppZ7hwodSjr8vJdXmaWLwdKHWptaWJXTx/7+vqLLsXMaogDpQ4NTL/iO73MLE8OlDrk6VfMrBocKHWoXBqYfsXjKGaWHwdKHRq4QnGXl5nlyYFSh8ru8jKzKnCg1KH9z0RxoJhZjhwodWj2DD9ky8zy50CpQw3TxJwZjf62vJnlyoFSp8qlZn9b3sxy5UCpU54g0szy5kCpU+WSn4liZvlyoNQpP7XRzPLmQKlT7vIys7w5UOrUQJdXRBRdipnVCAdKnSq3NNPXH7y4t7foUsysRjhQ6lSrvy1vZjlzoNQpTxBpZnlzoNSpsgPFzHLmQKlTA89EcZeXmeXFgVKn3OVlZnlzoNSp/VPY+6mNZpaTqgaKpBWS1kvqlnT+EOunS7o2rb9NUmfFugvS8vWSTj6INr8u6cVqHVOtmNHUwPTGaf62vJnlpmqBIqkBuBQ4BVgGnClp2aDNzga2RcQS4BLg4rTvMmAVcDSwAvimpIbR2pS0HDikWsdUa1pbPJ+XmeWnmlcoxwHdEfFoRPQAa4CVg7ZZCVyVXl8PvE+S0vI1EbE3Ih4DulN7w7aZwuYvgC9U8ZhqSrnU5EF5M8tNNQPlCODJivcb07Iht4mIXmAH0DbCviO1eR7QFRFPj1SUpHMkrZO0bvPmzQd1QLWm3NLsMRQzy01NDMpLmg+cAXxjtG0j4rKIWB4Ry9vb26tf3CQ2p8VXKGaWn2oGyiZgYcX7BWnZkNtIagRagS0j7Dvc8jcBS4BuSY8DJUndeR1IrSqXmvwYYDPLTTUD5Q5gqaTFkprJBtm7Bm3TBZyVXp8O3BzZ9LddwKp0F9hiYClw+3BtRsT3I+KwiOiMiE5gdxrotxGUPYW9meWosVoNR0SvpPOAG4AG4IqIeEDSRcC6iOgCLgeuTlcTW8kCgrTddcCDQC9wbkT0AQzVZrWOodaVS03s7umjp7ef5saa6P00swJVLVAAImItsHbQsgsrXr9ENvYx1L6rgdUH0uYQ28waS731pvLb8u2zpxdcjZlNdf61tI61pvm8dvhOLzPLgQOljg3MOOw7vcwsDw6UOuYJIs0sTw6UOlb2UxvNLEcOlDpWbknPRPEVipnlwIFSx2bPaERyl5eZ5cOBUsemTRNzZjSxY7fv8jKz8XOg1Llyyd+WN7N8OFDqnJ+JYmZ5caDUuVbPOGxmOXGg1LlyqdlXKGaWCwdKnSu7y8vMcuJAqXNZl1cP/f1RdClmNsU5UOpcudREf8CLPb1Fl2JmU5wDpc7tn8/LA/NmNk4OlDrnCSLNLC8OlDpXTs9E8a3DZjZeDpQ6t3/GYT9ky8zGyYFS59zlZWZ5caDUuVY/tdHMcuJAqXMzmhqY0TTNVyhmNm4OFMsmiPQVipmNkwPFKLc0e1DezMbNgWK0ljzjsJmNnwPF/EwUM8uFA8U847CZ5cKBYtljgN3lZWbj5EAxyqVm9uzrY29vX9GlmNkU5kAx5vjb8maWAweKUfYU9maWAweK7Z8g0lcoZjYeDhTzfF5mlgsHilFuSc9E8RWKmY2DA8VodZeXmeXAgWLMnt6IBDt2ez4vMxs7B4oxbZpobWlyl5eZjUtVA0XSCknrJXVLOn+I9dMlXZvW3yaps2LdBWn5ekknj9ampMsl3SPpXknXS5pVzWOrNZ5+xczGq2qBIqkBuBQ4BVgGnClp2aDNzga2RcQS4BLg4rTvMmAVcDSwAvimpIZR2vwfEXFMRLwReAI4r1rHVotaWzz9ipmNTzWvUI4DuiPi0YjoAdYAKwdtsxK4Kr2+HnifJKXlayJib0Q8BnSn9oZtMyJeAEj7twBRxWOrOa2lZnd5mdm4VDNQjgCerHi/MS0bcpuI6AV2AG0j7Dtim5KuBJ4BjgK+kcdB1ItyS5MH5c1sXGpqUD4iPg7MBx4CPjLUNpLOkbRO0rrNmzdPaH2TWbnkMRQzG59qBsomYGHF+wVp2ZDbSGoEWoEtI+w7apsR0UfWFfafhyoqIi6LiOURsby9vf0gD6l2DTxkq7/fPYVmNjbVDJQ7gKWSFktqJhtk7xq0TRdwVnp9OnBzRERavirdBbYYWArcPlybyiyB/WMopwEPV/HYak5rSxP9ATv39hZdiplNUY3VajgieiWdB9wANABXRMQDki4C1kVEF3A5cLWkbmArWUCQtrsOeBDoBc5NVx4M0+Y04CpJcwAB9wCfrtax1aJyKZt+5YU9+/bP7WVmdjCqFigAEbEWWDto2YUVr18Czhhm39XA6gNssx94Vw4l163KCSIXzi24GDObkkbt8krf/5hX8b45DWw/VN3SbCINTGG/fY/v9DKzsRkxUCStIuuKulfSTyV9AHiU7IuFH5uA+myClP3URjMbp9G6vP4n8JaI6Jb0ZuDnwOkR8b3ql2YTyc9EMbPxGq3LqyciugEi4i7gEYdJbfJz5c1svEa7QnmNpM9VvC9Xvo+Ir1WnLJtoM5oaaGlqcKCY2ZiNFih/C8we5r2/AVdjsgkiPShvZmMzYqBExB8Pt07S7+VfjhWpXPKMw2Y2duP5pvznRt/EppJWPxPFzMZhPIGi3KqwScETRJrZeIwnUDyGUmP8kC0zG48Rx1Ak7WTo4Bh4iJXVkHKp2VcoZjZmow3Kzx5pvdWW1pYm9uzr46V9fcxoaii6HDObYmrqAVs2PgPfln/BVylmNgYOFNvv5QkiHShmdvAcKLZfuSV7JorHUcxsLBwotp8niDSz8ajqA7Zsahno8rrmtg3c9uiWgqupLS3NDXz6xNdRavaPnNUu/+u2/V4zZzqva5/JHY9t5Y7HthZdTs3oD9izr4+j57ey4g2HFV2OWdU4UGy/6Y0N3PT7JxZdRs3ZsXsfx1z0I57YuqvoUsyqymMoZlXWWmqiXGri8S27iy7FrKocKGYToGNuiSccKFbjHChmE6CjbSaPb3GXl9U2B4rZBOhoK/HU9j309PYXXYpZ1ThQzCZAR9tM+gM2bd9TdClmVeNAMZsAHW0lAHd7WU1zoJhNgI65WaB4YN5qmQPFbAK0z55OS1MDGxwoVsMcKGYTQBIdbSU2uMvLapgDxWyCLJpbYsNWX6FY7XKgmE2QznkzeWLrbvr7h3qqttnU50AxmyCL5pbo6e3nmRdeKroUs6pwoJhNkM62mQAemLea5UAxmyAD30XxwLzVKgeK2QQ5vHUGjdPkgXmrWQ4UswnS2DCNhZ512GqYA8VsAi2aW/L0K1azHChmE6ijLbtCifCtw1Z7qhooklZIWi+pW9L5Q6yfLunatP42SZ0V6y5Iy9dLOnm0NiVdk5bfL+kKSU3VPDazsehom8nOvb1s3dVTdClmuataoEhqAC4FTgGWAWdKWjZos7OBbRGxBLgEuDjtuwxYBRwNrAC+KalhlDavAY4CfgNoAT5RrWMzG6uBSSI9MG+1qJpXKMcB3RHxaET0AGuAlYO2WQlclV5fD7xPktLyNRGxNyIeA7pTe8O2GRFrIwFuBxZU8djMxqRznmcdttpVzUA5Aniy4v3GtGzIbSKiF9gBtI2w76htpq6u/wL8cKiiJJ0jaZ2kdZs3bz7IQzIbnwWHlJD8XBSrTbU4KP9N4JaIuHWolRFxWUQsj4jl7e3tE1ya1bsZTQ0cNmeGr1CsJjVWse1NwMKK9wvSsqG22SipEWgFtoyy77BtSvoy0A58Mof6zaqio82zDlttquYVyh3AUkmLJTWTDbJ3DdqmCzgrvT4duDmNgXQBq9JdYIuBpWTjIsO2KekTwMnAmRHRX8XjMhuXjrkzPf2K1aSqXaFERK+k84AbgAbgioh4QNJFwLqI6AIuB66W1A1sJQsI0nbXAQ8CvcC5EdEHMFSb6SP/BtgA/Dwb1+c7EXFRtY7PbKwWtZV4/sUeXtzby6zp1ewkMJtYVf3XHBFrgbWDll1Y8fol4Ixh9l0NrD6QNtNy/2TalPDyrMO7OHp+a8HVmOWnFgflzSa1gVmHPTBvtcaBYjbBFrX5y41WmxwoZhNszowm5s5s9sC81RwHilkBFs0t+cmNVnMcKGYF6GxzoFjtcaCYFWBR20ye2rGHvb19RZdilhsHilkBOuaWiICN2/YUXYpZbhwoZgUYmHXYA/NWSxwoZgVYNHfgy40eR7Ha4UAxK8C8Wc3MbG5woFhNcaCYFUASi9o8SaTVFgeKWUE65noae6stDhSzgnTMK7Fx6x76+qPoUsxy4UAxK0jH3Jn09PXz9A7fOmy1wYFiVhDPOmy1xoFiVpCBQHncgWI1woFiVpDDW1toahAbtvpOL6sNDhSzgjRMEwsPKbnLy2qGA8WsQB1tJXd5Wc1woJgVqKNtJk9s2UWEbx22qc+BYlagjrYSu3r62LKrp+hSzMbNgWJWoIE7vTwFi9UCB4pZgTzrsNUSB4pZgRbObUHyd1GsNjhQzAo0vbGB+a0tPOEuL6sBDhSzgi3yrMNWIxqLLsCs3nXOK/HD+59hW0F3ejU1TmPWdP9XYOPnf0VmBVs8bybbdu/jTX9yYyGfL8H1n3oHb+mYW8jnW+1woJgV7CNvXUSpuZHevv4J/+wA/nztw9zwwLMOFBs3B4pZwVpbmvidt3cU9vk3Pvgst/xqM1869fWF1WC1wYPyZnXuhCPbefiZnTz7wktFl2JTnAPFrM6dsLQdgFt+tbngSmyqc6CY1bmjDpvNvFnTufWR54suxaY4B4pZnZs2TZywdB7/1v08/f2e9djGzoFiZpxwZDtbd/Vw/1M7ii7FpjAHipnx7qXzANztZeNS1UCRtELSekndks4fYv10Sdem9bdJ6qxYd0Favl7SyaO1Kem8tCwkzavmcZnVmnmzpnP0/Dn81APzNg5VCxRJDcClwCnAMuBMScsGbXY2sC0ilgCXABenfZcBq4CjgRXANyU1jNLmz4CTgA3VOiazWnbCke3ctWEbO1/aV3QpNkVV8wrlOKA7Ih6NiB5gDbBy0DYrgavS6+uB90lSWr4mIvZGxGNAd2pv2DYj4pcR8XgVj8espp2wtJ3e/uDnv95SdCk2RVUzUI4Anqx4vzEtG3KbiOgFdgBtI+x7IG2OSNI5ktZJWrd5sy/vzQa8peMQSs0NHkexMau7QfmIuCwilkfE8vb29qLLMZs0mhun8Y7XtnHLI/5Fy8ammoGyCVhY8X5BWjbkNpIagVZgywj7HkibZjZGJxzZzoYtu/2MexuTagbKHcBSSYslNZMNsncN2qYLOCu9Ph24OSIiLV+V7gJbDCwFbj/ANs1sjE440tOw2NhVLVDSmMh5wA3AQ8B1EfGApIsknZY2uxxok9QNfA44P+37AHAd8CDwQ+DciOgbrk0ASZ+RtJHsquVeSX9XrWMzq1WdbSUWzm3hFo+j2BgouyCoT8uXL49169YVXYbZpPKl795H191P8csL309TQ90Ns9oBkHRnRCwfvNz/WszsFU5Y2s6Le3u5a8O2okuxKcaBYmav8M4lbTRMk+/2soPmQDGzV5gzo4k3Lyr7+yh20BwoZvYqxy9t575NO9i6q6foUmwKcaCY2auccGQ7EXCru73sIDhQzOxVfuOIVsqlJm75lbu97MA5UMzsVRqmiXctmcetj2ymnr9aYAfHgWJmQ/rNpe08t3Mv65/dWXQpNkU4UMxsSMcfmT2nztOw2IFyoJjZkA5vbeHIQ2d5HMUOWGPRBZjZ5HX80na+9e+P8/6v/bToUixnl5/1Vha1lXJt04FiZsP62NsWsXnnXnr7+4suxXLW3Jh/B5UDxcyG9dr2WXz9zDcVXYZNER5DMTOzXDhQzMwsFw4UMzPLhQPFzMxy4UAxM7NcOFDMzCwXDhQzM8uFA8XMzHKhep6aWtJmYMMYd58HTNZJjlzb2Li2sXFtYzOVa+uIiPbBC+s6UMZD0rqIWF50HUNxbWPj2sbGtY1NLdbmLi8zM8uFA8XMzHLhQBm7y4ouYASubWxc29i4trGpudo8hmJmZrnwFYqZmeXCgWJmZrlwoIyBpBWS1kvqlnR+0fVUkvS4pPsk3S1pXcG1XCHpOUn3VyybK+lGSY+kvw+ZRLV9RdKmdO7ulnRqQbUtlPQTSQ9KekDSZ9Pyws/dCLUVfu4kzZB0u6R7Um1/nJYvlnRb+nm9VlLzJKrtW5Ieqzhvx050bamOBkm/lPQv6f2YzpkD5SBJagAuBU4BlgFnSlpWbFWv8p6IOHYS3OP+LWDFoGXnAzdFxFLgpvS+CN/i1bUBXJLO3bERsXaCaxrQC/x+RCwD3g6cm/6NTYZzN1xtUPy52wu8NyKOAY4FVkh6O3Bxqm0JsA04exLVBvD5ivN2dwG1AXwWeKji/ZjOmQPl4B0HdEfEoxHRA6wBVhZc06QUEbcAWwctXglclV5fBXxoQotKhqltUoiIpyPirvR6J9kP+hFMgnM3Qm2Fi8yL6W1T+hPAe4Hr0/KizttwtRVO0gLgPwJ/l96LMZ4zB8rBOwJ4suL9RibJD1QSwI8k3SnpnKKLGcKhEfF0ev0McGiRxQzhPEn3pi6xQrrjKknqBN4E3MYkO3eDaoNJcO5S183dwHPAjcCvge0R0Zs2KezndXBtETFw3lan83aJpOkFlPaXwBeA/vS+jTGeMwdK7Xl3RLyZrEvuXEknFF3QcCK7Z31S/JaW/DXwOrIuiaeB/11kMZJmAd8Gfi8iXqhcV/S5G6K2SXHuIqIvIo4FFpD1JhxVRB1DGVybpDcAF5DV+FZgLvDFiaxJ0geB5yLizjzac6AcvE3Awor3C9KySSEiNqW/nwO+S/ZDNZk8K+lwgPT3cwXXs19EPJt+6PuBv6XAcyepiew/7Gsi4jtp8aQ4d0PVNpnOXapnO/AT4B1AWVJjWlX4z2tFbStSF2JExF7gSib+vL0LOE3S42Td9+8F/ooxnjMHysG7A1ia7oJoBlYBXQXXBICkmZJmD7wGPgDcP/JeE64LOCu9Pgv45wJreYWB/6yTD1PQuUt92JcDD0XE1ypWFX7uhqttMpw7Se2Syul1C/B+sjGenwCnp82KOm9D1fZwxS8IIhunmNDzFhEXRMSCiOgk+7/s5oj4GGM9ZxHhPwf5BzgV+BVZ/+wfFl1PRV2vBe5Jfx4oujbgH8m6P/aR9cOeTdY/exPwCPBjYO4kqu1q4D7gXrL/vA8vqLZ3k3Vn3Qvcnf6cOhnO3Qi1FX7ugDcCv0w13A9cmJa/Frgd6Ab+CZg+iWq7OZ23+4F/AGYV8W8u1XIi8C/jOWeeesXMzHLhLi8zM8uFA8XMzHLhQDEzs1w4UMzMLBcOFDMzy4UDxazKJPWlmWTvkXSXpHeOsn1Z0n87gHb/VVLRE4Ca7edAMau+PZHNJHsM2VQbfz7K9mVg1EAxm2wcKGYTaw7ZdOBImiXppnTVcp+kgVmrvwq8Ll3V/EXa9otpm3skfbWivTPSczZ+Jen4iT0Us1dqHH0TMxunljTL7AzgcLL5kgBeAj4cES9Imgf8QlIX2XNO3hDZRIJIOoVs6vq3RcRuSXMr2m6MiOPSA62+DJw0Qcdk9ioOFLPq21MRDu8A/j7NNCvgz9KM0P1kU4QPNSX9ScCVEbEbICIqn+MyMHHknUBndco3OzAOFLMJFBE/T1cj7WRzYLUDb4mIfWnG1xkH2eTe9Hcf/nm2gnkMxWwCSToKaAC2AK1kz6LYJ+k9QEfabCcwu2K3G4GPSyqlNiq7vMwmDf9GY1Z9A2MokHVznRURfZKuAb4n6T5gHfAwQERskfQzSfcDP4iIz0s6FlgnqQdYC3ypgOMwG5FnGzYzs1y4y8vMzHLhQDEzs1w4UMzMLBcOFDMzy4UDxczMcuFAMTOzXDhQzMwsF/8fwV76bdTGdl8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best6,network6=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=100, device=device, lstm_layers=3, bidirectional=True, learning_rate_decay=0.5, weight_decay=1e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g9ucIPQFSS_q",
        "outputId": "0e721c2b-672a-4943-92f7-ad1aae7a3ac6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4866,  836],\n",
            "        [2115, 3587]])\n",
            "tensor([[829, 121],\n",
            "        [351, 599]])\n",
            "Epoch: 0, Train Accuracy: 0.75798, Train Loss: 0.52029, Validation Accuracy: 0.76526, Validation Loss: 0.49261, prediction: [0.834, 0.166], true label: [1.0, 0.0]\n",
            "0.7652631578947369 0\n",
            "best_state_dict updated\n",
            "tensor([[5071,  631],\n",
            "        [2012, 3690]])\n",
            "tensor([[846, 104],\n",
            "        [346, 604]])\n",
            "Epoch: 1, Train Accuracy: 0.79814, Train Loss: 0.44432, Validation Accuracy: 0.79474, Validation Loss: 0.44604, prediction: [0.23, 0.77], true label: [0.0, 1.0]\n",
            "0.7947368421052632 0.7652631578947369\n",
            "best_state_dict updated\n",
            "tensor([[5165,  537],\n",
            "        [2124, 3578]])\n",
            "tensor([[858,  92],\n",
            "        [354, 596]])\n",
            "Epoch: 2, Train Accuracy: 0.81042, Train Loss: 0.43128, Validation Accuracy: 0.79263, Validation Loss: 0.43937, prediction: [0.883, 0.117], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.7947368421052632\n",
            "tensor([[5121,  581],\n",
            "        [1827, 3875]])\n",
            "tensor([[848, 102],\n",
            "        [314, 636]])\n",
            "Epoch: 3, Train Accuracy: 0.81919, Train Loss: 0.41280, Validation Accuracy: 0.80000, Validation Loss: 0.44089, prediction: [0.864, 0.136], true label: [1.0, 0.0]\n",
            "0.8 0.7947368421052632\n",
            "best_state_dict updated\n",
            "tensor([[5073,  629],\n",
            "        [1610, 4092]])\n",
            "tensor([[840, 110],\n",
            "        [278, 672]])\n",
            "Epoch: 4, Train Accuracy: 0.82234, Train Loss: 0.40694, Validation Accuracy: 0.81474, Validation Loss: 0.45170, prediction: [0.029, 0.971], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.8\n",
            "best_state_dict updated\n",
            "tensor([[5213,  489],\n",
            "        [1873, 3829]])\n",
            "tensor([[854,  96],\n",
            "        [332, 618]])\n",
            "Epoch: 5, Train Accuracy: 0.83304, Train Loss: 0.38839, Validation Accuracy: 0.80842, Validation Loss: 0.43476, prediction: [0.656, 0.344], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8147368421052632\n",
            "tensor([[5229,  473],\n",
            "        [1711, 3991]])\n",
            "tensor([[852,  98],\n",
            "        [320, 630]])\n",
            "Epoch: 6, Train Accuracy: 0.84128, Train Loss: 0.36963, Validation Accuracy: 0.80105, Validation Loss: 0.44456, prediction: [0.241, 0.759], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8147368421052632\n",
            "tensor([[5190,  512],\n",
            "        [1631, 4071]])\n",
            "tensor([[844, 106],\n",
            "        [291, 659]])\n",
            "Epoch: 7, Train Accuracy: 0.83620, Train Loss: 0.37357, Validation Accuracy: 0.82632, Validation Loss: 0.41116, prediction: [0.487, 0.513], true label: [0.0, 1.0]\n",
            "0.8263157894736842 0.8147368421052632\n",
            "best_state_dict updated\n",
            "tensor([[5241,  461],\n",
            "        [1540, 4162]])\n",
            "tensor([[833, 117],\n",
            "        [308, 642]])\n",
            "Epoch: 8, Train Accuracy: 0.84988, Train Loss: 0.34894, Validation Accuracy: 0.78842, Validation Loss: 0.47545, prediction: [0.223, 0.777], true label: [0.0, 1.0]\n",
            "0.7884210526315789 0.8263157894736842\n",
            "tensor([[5310,  392],\n",
            "        [1388, 4314]])\n",
            "tensor([[838, 112],\n",
            "        [297, 653]])\n",
            "Epoch: 9, Train Accuracy: 0.87040, Train Loss: 0.31997, Validation Accuracy: 0.81053, Validation Loss: 0.44034, prediction: [0.018, 0.982], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8263157894736842\n",
            "tensor([[5286,  416],\n",
            "        [1203, 4499]])\n",
            "tensor([[822, 128],\n",
            "        [284, 666]])\n",
            "Epoch: 10, Train Accuracy: 0.87443, Train Loss: 0.30336, Validation Accuracy: 0.79895, Validation Loss: 0.55347, prediction: [0.078, 0.922], true label: [0.0, 1.0]\n",
            "0.7989473684210526 0.8263157894736842\n",
            "tensor([[5317,  385],\n",
            "        [1149, 4553]])\n",
            "tensor([[817, 133],\n",
            "        [275, 675]])\n",
            "Epoch: 11, Train Accuracy: 0.88425, Train Loss: 0.29247, Validation Accuracy: 0.80105, Validation Loss: 0.50800, prediction: [0.906, 0.094], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8263157894736842\n",
            "tensor([[5112,  590],\n",
            "        [1295, 4407]])\n",
            "tensor([[821, 129],\n",
            "        [242, 708]])\n",
            "Epoch: 12, Train Accuracy: 0.84146, Train Loss: 0.35053, Validation Accuracy: 0.80632, Validation Loss: 0.43550, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.8263157894736842\n",
            "tensor([[5376,  326],\n",
            "        [ 916, 4786]])\n",
            "tensor([[822, 128],\n",
            "        [270, 680]])\n",
            "Epoch: 13, Train Accuracy: 0.91056, Train Loss: 0.24858, Validation Accuracy: 0.81158, Validation Loss: 0.50596, prediction: [0.781, 0.219], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8263157894736842\n",
            "tensor([[5384,  318],\n",
            "        [ 794, 4908]])\n",
            "tensor([[812, 138],\n",
            "        [254, 696]])\n",
            "Epoch: 14, Train Accuracy: 0.91617, Train Loss: 0.23571, Validation Accuracy: 0.80421, Validation Loss: 0.49646, prediction: [0.95, 0.05], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8263157894736842\n",
            "tensor([[5423,  279],\n",
            "        [ 733, 4969]])\n",
            "tensor([[810, 140],\n",
            "        [263, 687]])\n",
            "Epoch: 15, Train Accuracy: 0.92511, Train Loss: 0.21951, Validation Accuracy: 0.79263, Validation Loss: 0.55611, prediction: [0.702, 0.298], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.8263157894736842\n",
            "tensor([[5406,  296],\n",
            "        [ 614, 5088]])\n",
            "tensor([[801, 149],\n",
            "        [238, 712]])\n",
            "Epoch: 16, Train Accuracy: 0.92950, Train Loss: 0.20168, Validation Accuracy: 0.79789, Validation Loss: 0.60833, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7978947368421052 0.8263157894736842\n",
            "tensor([[5404,  298],\n",
            "        [ 617, 5085]])\n",
            "tensor([[792, 158],\n",
            "        [228, 722]])\n",
            "Epoch: 17, Train Accuracy: 0.92582, Train Loss: 0.20708, Validation Accuracy: 0.80737, Validation Loss: 0.62489, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8263157894736842\n",
            "tensor([[5436,  266],\n",
            "        [ 479, 5223]])\n",
            "tensor([[794, 156],\n",
            "        [232, 718]])\n",
            "Epoch: 18, Train Accuracy: 0.94283, Train Loss: 0.17853, Validation Accuracy: 0.79474, Validation Loss: 0.57447, prediction: [0.939, 0.061], true label: [1.0, 0.0]\n",
            "0.7947368421052632 0.8263157894736842\n",
            "tensor([[5439,  263],\n",
            "        [ 437, 5265]])\n",
            "tensor([[790, 160],\n",
            "        [228, 722]])\n",
            "Epoch: 19, Train Accuracy: 0.94248, Train Loss: 0.17390, Validation Accuracy: 0.78842, Validation Loss: 0.68080, prediction: [0.965, 0.035], true label: [1.0, 0.0]\n",
            "0.7884210526315789 0.8263157894736842\n",
            "tensor([[5487,  215],\n",
            "        [ 376, 5326]])\n",
            "tensor([[782, 168],\n",
            "        [242, 708]])\n",
            "Epoch: 20, Train Accuracy: 0.95317, Train Loss: 0.15787, Validation Accuracy: 0.77158, Validation Loss: 0.65041, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8263157894736842\n",
            "tensor([[5482,  220],\n",
            "        [ 365, 5337]])\n",
            "tensor([[780, 170],\n",
            "        [238, 712]])\n",
            "Epoch: 21, Train Accuracy: 0.95195, Train Loss: 0.14541, Validation Accuracy: 0.78526, Validation Loss: 0.63787, prediction: [0.976, 0.024], true label: [1.0, 0.0]\n",
            "0.7852631578947369 0.8263157894736842\n",
            "tensor([[5483,  219],\n",
            "        [ 358, 5344]])\n",
            "tensor([[780, 170],\n",
            "        [241, 709]])\n",
            "Epoch: 22, Train Accuracy: 0.95353, Train Loss: 0.14566, Validation Accuracy: 0.78737, Validation Loss: 0.67970, prediction: [0.935, 0.065], true label: [1.0, 0.0]\n",
            "0.7873684210526316 0.8263157894736842\n",
            "tensor([[5488,  214],\n",
            "        [ 347, 5355]])\n",
            "tensor([[779, 171],\n",
            "        [238, 712]])\n",
            "Epoch: 23, Train Accuracy: 0.95388, Train Loss: 0.14089, Validation Accuracy: 0.78211, Validation Loss: 0.70718, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7821052631578947 0.8263157894736842\n",
            "tensor([[5534,  168],\n",
            "        [ 446, 5256]])\n",
            "tensor([[753, 197],\n",
            "        [277, 673]])\n",
            "Epoch: 24, Train Accuracy: 0.95370, Train Loss: 0.14260, Validation Accuracy: 0.75263, Validation Loss: 0.88945, prediction: [0.755, 0.245], true label: [1.0, 0.0]\n",
            "0.7526315789473684 0.8263157894736842\n",
            "tensor([[5532,  170],\n",
            "        [ 297, 5405]])\n",
            "tensor([[768, 182],\n",
            "        [246, 704]])\n",
            "Epoch: 25, Train Accuracy: 0.96229, Train Loss: 0.12656, Validation Accuracy: 0.77158, Validation Loss: 0.74566, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8263157894736842\n",
            "tensor([[5540,  162],\n",
            "        [ 291, 5411]])\n",
            "tensor([[762, 188],\n",
            "        [257, 693]])\n",
            "Epoch: 26, Train Accuracy: 0.96440, Train Loss: 0.12217, Validation Accuracy: 0.76842, Validation Loss: 0.85504, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8263157894736842\n",
            "tensor([[5539,  163],\n",
            "        [ 275, 5427]])\n",
            "tensor([[766, 184],\n",
            "        [253, 697]])\n",
            "Epoch: 27, Train Accuracy: 0.96457, Train Loss: 0.11826, Validation Accuracy: 0.76632, Validation Loss: 0.81238, prediction: [0.97, 0.03], true label: [1.0, 0.0]\n",
            "0.7663157894736842 0.8263157894736842\n",
            "tensor([[5547,  155],\n",
            "        [ 262, 5440]])\n",
            "tensor([[764, 186],\n",
            "        [251, 699]])\n",
            "Epoch: 28, Train Accuracy: 0.96563, Train Loss: 0.11379, Validation Accuracy: 0.76842, Validation Loss: 0.84784, prediction: [0.983, 0.017], true label: [1.0, 0.0]\n",
            "0.7684210526315789 0.8263157894736842\n",
            "tensor([[5540,  162],\n",
            "        [ 258, 5444]])\n",
            "tensor([[765, 185],\n",
            "        [248, 702]])\n",
            "Epoch: 29, Train Accuracy: 0.96510, Train Loss: 0.11027, Validation Accuracy: 0.76947, Validation Loss: 0.82372, prediction: [0.969, 0.031], true label: [1.0, 0.0]\n",
            "0.7694736842105263 0.8263157894736842\n",
            "tensor([[5523,  179],\n",
            "        [ 291, 5411]])\n",
            "tensor([[768, 182],\n",
            "        [231, 719]])\n",
            "Epoch: 30, Train Accuracy: 0.96107, Train Loss: 0.12515, Validation Accuracy: 0.78421, Validation Loss: 0.72550, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7842105263157895 0.8263157894736842\n",
            "tensor([[5555,  147],\n",
            "        [ 256, 5446]])\n",
            "tensor([[763, 187],\n",
            "        [256, 694]])\n",
            "Epoch: 31, Train Accuracy: 0.96650, Train Loss: 0.11629, Validation Accuracy: 0.76842, Validation Loss: 0.79848, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8263157894736842\n",
            "tensor([[5548,  154],\n",
            "        [ 227, 5475]])\n",
            "tensor([[759, 191],\n",
            "        [250, 700]])\n",
            "Epoch: 32, Train Accuracy: 0.96703, Train Loss: 0.10951, Validation Accuracy: 0.76842, Validation Loss: 0.84964, prediction: [0.985, 0.015], true label: [1.0, 0.0]\n",
            "0.7684210526315789 0.8263157894736842\n",
            "tensor([[5551,  151],\n",
            "        [ 241, 5461]])\n",
            "tensor([[759, 191],\n",
            "        [249, 701]])\n",
            "Epoch: 33, Train Accuracy: 0.96668, Train Loss: 0.10729, Validation Accuracy: 0.77053, Validation Loss: 0.82046, prediction: [0.986, 0.014], true label: [1.0, 0.0]\n",
            "0.7705263157894737 0.8263157894736842\n",
            "tensor([[5544,  158],\n",
            "        [ 264, 5438]])\n",
            "tensor([[761, 189],\n",
            "        [242, 708]])\n",
            "Epoch: 34, Train Accuracy: 0.96492, Train Loss: 0.11167, Validation Accuracy: 0.77368, Validation Loss: 0.81621, prediction: [0.962, 0.038], true label: [1.0, 0.0]\n",
            "0.7736842105263158 0.8263157894736842\n",
            "tensor([[5534,  168],\n",
            "        [ 275, 5427]])\n",
            "tensor([[760, 190],\n",
            "        [227, 723]])\n",
            "Epoch: 35, Train Accuracy: 0.96370, Train Loss: 0.11389, Validation Accuracy: 0.78526, Validation Loss: 0.82771, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7852631578947369 0.8263157894736842\n",
            "tensor([[5565,  137],\n",
            "        [ 236, 5466]])\n",
            "tensor([[751, 199],\n",
            "        [267, 683]])\n",
            "Epoch: 36, Train Accuracy: 0.96931, Train Loss: 0.10301, Validation Accuracy: 0.76316, Validation Loss: 0.88085, prediction: [0.971, 0.029], true label: [1.0, 0.0]\n",
            "0.7631578947368421 0.8263157894736842\n",
            "tensor([[5557,  145],\n",
            "        [ 234, 5468]])\n",
            "tensor([[753, 197],\n",
            "        [249, 701]])\n",
            "Epoch: 37, Train Accuracy: 0.96843, Train Loss: 0.10886, Validation Accuracy: 0.76737, Validation Loss: 1.08918, prediction: [0.986, 0.014], true label: [1.0, 0.0]\n",
            "0.7673684210526316 0.8263157894736842\n",
            "tensor([[5559,  143],\n",
            "        [ 239, 5463]])\n",
            "tensor([[759, 191],\n",
            "        [236, 714]])\n",
            "Epoch: 38, Train Accuracy: 0.96913, Train Loss: 0.10438, Validation Accuracy: 0.77789, Validation Loss: 0.96677, prediction: [0.977, 0.023], true label: [0.0, 1.0]\n",
            "0.7778947368421053 0.8263157894736842\n",
            "tensor([[5558,  144],\n",
            "        [ 237, 5465]])\n",
            "tensor([[760, 190],\n",
            "        [236, 714]])\n",
            "Epoch: 39, Train Accuracy: 0.96913, Train Loss: 0.10684, Validation Accuracy: 0.77895, Validation Loss: 0.89756, prediction: [0.97, 0.03], true label: [1.0, 0.0]\n",
            "0.7789473684210526 0.8263157894736842\n",
            "tensor([[5545,  157],\n",
            "        [ 264, 5438]])\n",
            "tensor([[763, 187],\n",
            "        [227, 723]])\n",
            "Epoch: 40, Train Accuracy: 0.96650, Train Loss: 0.11156, Validation Accuracy: 0.77895, Validation Loss: 0.80855, prediction: [0.981, 0.019], true label: [1.0, 0.0]\n",
            "0.7789473684210526 0.8263157894736842\n",
            "tensor([[5500,  202],\n",
            "        [ 345, 5357]])\n",
            "tensor([[768, 182],\n",
            "        [216, 734]])\n",
            "Epoch: 41, Train Accuracy: 0.95440, Train Loss: 0.12856, Validation Accuracy: 0.79579, Validation Loss: 0.79185, prediction: [0.022, 0.978], true label: [0.0, 1.0]\n",
            "0.7957894736842105 0.8263157894736842\n",
            "tensor([[5574,  128],\n",
            "        [ 249, 5453]])\n",
            "tensor([[738, 212],\n",
            "        [274, 676]])\n",
            "Epoch: 42, Train Accuracy: 0.97089, Train Loss: 0.10397, Validation Accuracy: 0.74526, Validation Loss: 1.26873, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7452631578947368 0.8263157894736842\n",
            "tensor([[5567,  135],\n",
            "        [ 218, 5484]])\n",
            "tensor([[751, 199],\n",
            "        [249, 701]])\n",
            "Epoch: 43, Train Accuracy: 0.97071, Train Loss: 0.09586, Validation Accuracy: 0.76421, Validation Loss: 0.89479, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7642105263157895 0.8263157894736842\n",
            "tensor([[5572,  130],\n",
            "        [ 224, 5478]])\n",
            "tensor([[756, 194],\n",
            "        [240, 710]])\n",
            "Epoch: 44, Train Accuracy: 0.97071, Train Loss: 0.09572, Validation Accuracy: 0.77474, Validation Loss: 0.91372, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7747368421052632 0.8263157894736842\n",
            "tensor([[5581,  121],\n",
            "        [ 218, 5484]])\n",
            "tensor([[753, 197],\n",
            "        [258, 692]])\n",
            "Epoch: 45, Train Accuracy: 0.97036, Train Loss: 0.09484, Validation Accuracy: 0.75263, Validation Loss: 0.90001, prediction: [0.957, 0.043], true label: [1.0, 0.0]\n",
            "0.7526315789473684 0.8263157894736842\n",
            "tensor([[5583,  119],\n",
            "        [ 217, 5485]])\n",
            "tensor([[752, 198],\n",
            "        [252, 698]])\n",
            "Epoch: 46, Train Accuracy: 0.97229, Train Loss: 0.10762, Validation Accuracy: 0.76526, Validation Loss: 0.89439, prediction: [0.989, 0.011], true label: [1.0, 0.0]\n",
            "0.7652631578947369 0.8263157894736842\n",
            "tensor([[5537,  165],\n",
            "        [ 256, 5446]])\n",
            "tensor([[762, 188],\n",
            "        [225, 725]])\n",
            "Epoch: 47, Train Accuracy: 0.96633, Train Loss: 0.10892, Validation Accuracy: 0.78316, Validation Loss: 0.75790, prediction: [0.964, 0.036], true label: [1.0, 0.0]\n",
            "0.783157894736842 0.8263157894736842\n",
            "tensor([[5585,  117],\n",
            "        [ 228, 5474]])\n",
            "tensor([[738, 212],\n",
            "        [268, 682]])\n",
            "Epoch: 48, Train Accuracy: 0.97282, Train Loss: 0.10444, Validation Accuracy: 0.75684, Validation Loss: 0.97721, prediction: [0.981, 0.019], true label: [1.0, 0.0]\n",
            "0.7568421052631579 0.8263157894736842\n",
            "tensor([[5567,  135],\n",
            "        [ 227, 5475]])\n",
            "tensor([[763, 187],\n",
            "        [235, 715]])\n",
            "Epoch: 49, Train Accuracy: 0.97054, Train Loss: 0.09955, Validation Accuracy: 0.78211, Validation Loss: 0.78053, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7821052631578947 0.8263157894736842\n",
            "tensor([[5581,  121],\n",
            "        [ 200, 5502]])\n",
            "tensor([[748, 202],\n",
            "        [254, 696]])\n",
            "Epoch: 50, Train Accuracy: 0.97247, Train Loss: 0.09780, Validation Accuracy: 0.76526, Validation Loss: 0.92310, prediction: [0.97, 0.03], true label: [1.0, 0.0]\n",
            "0.7652631578947369 0.8263157894736842\n",
            "tensor([[5588,  114],\n",
            "        [ 213, 5489]])\n",
            "tensor([[741, 209],\n",
            "        [273, 677]])\n",
            "Epoch: 51, Train Accuracy: 0.97247, Train Loss: 0.09117, Validation Accuracy: 0.75684, Validation Loss: 1.07065, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7568421052631579 0.8263157894736842\n",
            "tensor([[5575,  127],\n",
            "        [ 196, 5506]])\n",
            "tensor([[754, 196],\n",
            "        [238, 712]])\n",
            "Epoch: 52, Train Accuracy: 0.97317, Train Loss: 0.08970, Validation Accuracy: 0.77263, Validation Loss: 0.92163, prediction: [0.978, 0.022], true label: [1.0, 0.0]\n",
            "0.7726315789473684 0.8263157894736842\n",
            "tensor([[5592,  110],\n",
            "        [ 201, 5501]])\n",
            "tensor([[752, 198],\n",
            "        [260, 690]])\n",
            "Epoch: 53, Train Accuracy: 0.97422, Train Loss: 0.08485, Validation Accuracy: 0.76211, Validation Loss: 0.91558, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.7621052631578947 0.8263157894736842\n",
            "tensor([[5585,  117],\n",
            "        [ 191, 5511]])\n",
            "tensor([[746, 204],\n",
            "        [245, 705]])\n",
            "Epoch: 54, Train Accuracy: 0.97404, Train Loss: 0.08759, Validation Accuracy: 0.76632, Validation Loss: 0.92314, prediction: [0.983, 0.017], true label: [1.0, 0.0]\n",
            "0.7663157894736842 0.8263157894736842\n",
            "tensor([[5592,  110],\n",
            "        [ 199, 5503]])\n",
            "tensor([[740, 210],\n",
            "        [268, 682]])\n",
            "Epoch: 55, Train Accuracy: 0.97422, Train Loss: 0.08532, Validation Accuracy: 0.75158, Validation Loss: 0.99661, prediction: [0.987, 0.013], true label: [1.0, 0.0]\n",
            "0.751578947368421 0.8263157894736842\n",
            "tensor([[5586,  116],\n",
            "        [ 187, 5515]])\n",
            "tensor([[750, 200],\n",
            "        [259, 691]])\n",
            "Epoch: 56, Train Accuracy: 0.97422, Train Loss: 0.08222, Validation Accuracy: 0.76000, Validation Loss: 0.94499, prediction: [0.98, 0.02], true label: [1.0, 0.0]\n",
            "0.76 0.8263157894736842\n",
            "tensor([[5591,  111],\n",
            "        [ 198, 5504]])\n",
            "tensor([[746, 204],\n",
            "        [254, 696]])\n",
            "Epoch: 57, Train Accuracy: 0.97457, Train Loss: 0.08460, Validation Accuracy: 0.76000, Validation Loss: 0.91956, prediction: [0.972, 0.028], true label: [1.0, 0.0]\n",
            "0.76 0.8263157894736842\n",
            "tensor([[5591,  111],\n",
            "        [ 197, 5505]])\n",
            "tensor([[742, 208],\n",
            "        [255, 695]])\n",
            "Epoch: 58, Train Accuracy: 0.97369, Train Loss: 0.08104, Validation Accuracy: 0.75684, Validation Loss: 1.03747, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7568421052631579 0.8263157894736842\n",
            "tensor([[5590,  112],\n",
            "        [ 205, 5497]])\n",
            "tensor([[743, 207],\n",
            "        [258, 692]])\n",
            "Epoch: 59, Train Accuracy: 0.97422, Train Loss: 0.08286, Validation Accuracy: 0.75684, Validation Loss: 1.25344, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7568421052631579 0.8263157894736842\n",
            "tensor([[5590,  112],\n",
            "        [ 189, 5513]])\n",
            "tensor([[751, 199],\n",
            "        [249, 701]])\n",
            "Epoch: 60, Train Accuracy: 0.97457, Train Loss: 0.08815, Validation Accuracy: 0.76737, Validation Loss: 0.88119, prediction: [0.964, 0.036], true label: [1.0, 0.0]\n",
            "0.7673684210526316 0.8263157894736842\n",
            "tensor([[5593,  109],\n",
            "        [ 199, 5503]])\n",
            "tensor([[755, 195],\n",
            "        [247, 703]])\n",
            "Epoch: 61, Train Accuracy: 0.97510, Train Loss: 0.09221, Validation Accuracy: 0.77053, Validation Loss: 0.90020, prediction: [0.981, 0.019], true label: [1.0, 0.0]\n",
            "0.7705263157894737 0.8263157894736842\n",
            "tensor([[5596,  106],\n",
            "        [ 216, 5486]])\n",
            "tensor([[744, 206],\n",
            "        [268, 682]])\n",
            "Epoch: 62, Train Accuracy: 0.97299, Train Loss: 0.08498, Validation Accuracy: 0.75158, Validation Loss: 0.95616, prediction: [0.97, 0.03], true label: [1.0, 0.0]\n",
            "0.751578947368421 0.8263157894736842\n",
            "tensor([[5599,  103],\n",
            "        [ 213, 5489]])\n",
            "tensor([[736, 214],\n",
            "        [272, 678]])\n",
            "Epoch: 63, Train Accuracy: 0.97562, Train Loss: 0.08177, Validation Accuracy: 0.74632, Validation Loss: 1.15209, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7463157894736843 0.8263157894736842\n",
            "tensor([[5612,   90],\n",
            "        [ 210, 5492]])\n",
            "tensor([[745, 205],\n",
            "        [270, 680]])\n",
            "Epoch: 64, Train Accuracy: 0.97597, Train Loss: 0.07721, Validation Accuracy: 0.75474, Validation Loss: 1.06475, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7547368421052632 0.8263157894736842\n",
            "tensor([[5587,  115],\n",
            "        [ 180, 5522]])\n",
            "tensor([[748, 202],\n",
            "        [251, 699]])\n",
            "Epoch: 65, Train Accuracy: 0.97439, Train Loss: 0.08118, Validation Accuracy: 0.76105, Validation Loss: 1.00246, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.7610526315789473 0.8263157894736842\n",
            "tensor([[5611,   91],\n",
            "        [ 212, 5490]])\n",
            "tensor([[741, 209],\n",
            "        [271, 679]])\n",
            "Epoch: 66, Train Accuracy: 0.97545, Train Loss: 0.07868, Validation Accuracy: 0.74842, Validation Loss: 1.08314, prediction: [0.946, 0.054], true label: [1.0, 0.0]\n",
            "0.748421052631579 0.8263157894736842\n",
            "tensor([[5609,   93],\n",
            "        [ 201, 5501]])\n",
            "tensor([[744, 206],\n",
            "        [258, 692]])\n",
            "Epoch: 67, Train Accuracy: 0.97527, Train Loss: 0.07454, Validation Accuracy: 0.75474, Validation Loss: 0.96430, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7547368421052632 0.8263157894736842\n",
            "tensor([[5599,  103],\n",
            "        [ 186, 5516]])\n",
            "tensor([[746, 204],\n",
            "        [259, 691]])\n",
            "Epoch: 68, Train Accuracy: 0.97562, Train Loss: 0.07731, Validation Accuracy: 0.75789, Validation Loss: 0.98521, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7578947368421053 0.8263157894736842\n",
            "tensor([[5607,   95],\n",
            "        [ 192, 5510]])\n",
            "tensor([[744, 206],\n",
            "        [258, 692]])\n",
            "Epoch: 69, Train Accuracy: 0.97545, Train Loss: 0.07588, Validation Accuracy: 0.75895, Validation Loss: 0.97096, prediction: [0.984, 0.016], true label: [1.0, 0.0]\n",
            "0.7589473684210526 0.8263157894736842\n",
            "tensor([[5605,   97],\n",
            "        [ 236, 5466]])\n",
            "tensor([[728, 222],\n",
            "        [276, 674]])\n",
            "Epoch: 70, Train Accuracy: 0.97317, Train Loss: 0.08057, Validation Accuracy: 0.74316, Validation Loss: 1.12614, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7431578947368421 0.8263157894736842\n",
            "tensor([[5610,   92],\n",
            "        [ 217, 5485]])\n",
            "tensor([[748, 202],\n",
            "        [268, 682]])\n",
            "Epoch: 71, Train Accuracy: 0.97457, Train Loss: 0.07654, Validation Accuracy: 0.75579, Validation Loss: 0.97479, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7557894736842106 0.8263157894736842\n",
            "tensor([[5592,  110],\n",
            "        [ 178, 5524]])\n",
            "tensor([[763, 187],\n",
            "        [246, 704]])\n",
            "Epoch: 72, Train Accuracy: 0.97510, Train Loss: 0.07890, Validation Accuracy: 0.76737, Validation Loss: 0.85086, prediction: [0.965, 0.035], true label: [1.0, 0.0]\n",
            "0.7673684210526316 0.8263157894736842\n",
            "tensor([[5612,   90],\n",
            "        [ 193, 5509]])\n",
            "tensor([[752, 198],\n",
            "        [254, 696]])\n",
            "Epoch: 73, Train Accuracy: 0.97685, Train Loss: 0.07356, Validation Accuracy: 0.76947, Validation Loss: 0.90138, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7694736842105263 0.8263157894736842\n",
            "tensor([[5609,   93],\n",
            "        [ 181, 5521]])\n",
            "tensor([[751, 199],\n",
            "        [254, 696]])\n",
            "Epoch: 74, Train Accuracy: 0.97755, Train Loss: 0.07202, Validation Accuracy: 0.76421, Validation Loss: 1.05118, prediction: [0.979, 0.021], true label: [1.0, 0.0]\n",
            "0.7642105263157895 0.8263157894736842\n",
            "tensor([[5608,   94],\n",
            "        [ 199, 5503]])\n",
            "tensor([[731, 219],\n",
            "        [273, 677]])\n",
            "Epoch: 75, Train Accuracy: 0.97580, Train Loss: 0.07653, Validation Accuracy: 0.73895, Validation Loss: 1.08938, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7389473684210527 0.8263157894736842\n",
            "tensor([[5607,   95],\n",
            "        [ 221, 5481]])\n",
            "tensor([[729, 221],\n",
            "        [276, 674]])\n",
            "Epoch: 76, Train Accuracy: 0.97580, Train Loss: 0.07867, Validation Accuracy: 0.73895, Validation Loss: 1.13921, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.7389473684210527 0.8263157894736842\n",
            "tensor([[5580,  122],\n",
            "        [ 222, 5480]])\n",
            "tensor([[764, 186],\n",
            "        [229, 721]])\n",
            "Epoch: 77, Train Accuracy: 0.97387, Train Loss: 0.08410, Validation Accuracy: 0.78947, Validation Loss: 0.82444, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7894736842105263 0.8263157894736842\n",
            "tensor([[5600,  102],\n",
            "        [ 215, 5487]])\n",
            "tensor([[735, 215],\n",
            "        [280, 670]])\n",
            "Epoch: 78, Train Accuracy: 0.97475, Train Loss: 0.08573, Validation Accuracy: 0.74211, Validation Loss: 1.16823, prediction: [0.015, 0.985], true label: [0.0, 1.0]\n",
            "0.7421052631578947 0.8263157894736842\n",
            "tensor([[5618,   84],\n",
            "        [ 188, 5514]])\n",
            "tensor([[750, 200],\n",
            "        [259, 691]])\n",
            "Epoch: 79, Train Accuracy: 0.97773, Train Loss: 0.06849, Validation Accuracy: 0.76421, Validation Loss: 0.94704, prediction: [0.626, 0.374], true label: [1.0, 0.0]\n",
            "0.7642105263157895 0.8263157894736842\n",
            "tensor([[5610,   92],\n",
            "        [ 185, 5517]])\n",
            "tensor([[761, 189],\n",
            "        [248, 702]])\n",
            "Epoch: 80, Train Accuracy: 0.97650, Train Loss: 0.07940, Validation Accuracy: 0.77158, Validation Loss: 0.91407, prediction: [0.987, 0.013], true label: [1.0, 0.0]\n",
            "0.771578947368421 0.8263157894736842\n",
            "tensor([[5592,  110],\n",
            "        [ 195, 5507]])\n",
            "tensor([[763, 187],\n",
            "        [240, 710]])\n",
            "Epoch: 81, Train Accuracy: 0.97527, Train Loss: 0.08427, Validation Accuracy: 0.78316, Validation Loss: 0.85489, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.783157894736842 0.8263157894736842\n",
            "tensor([[5612,   90],\n",
            "        [ 197, 5505]])\n",
            "tensor([[732, 218],\n",
            "        [268, 682]])\n",
            "Epoch: 82, Train Accuracy: 0.97580, Train Loss: 0.07483, Validation Accuracy: 0.74842, Validation Loss: 1.28326, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.748421052631579 0.8263157894736842\n",
            "tensor([[5597,  105],\n",
            "        [ 174, 5528]])\n",
            "tensor([[754, 196],\n",
            "        [248, 702]])\n",
            "Epoch: 83, Train Accuracy: 0.97667, Train Loss: 0.07212, Validation Accuracy: 0.77263, Validation Loss: 0.97884, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.7726315789473684 0.8263157894736842\n",
            "tensor([[5617,   85],\n",
            "        [ 174, 5528]])\n",
            "tensor([[744, 206],\n",
            "        [255, 695]])\n",
            "Epoch: 84, Train Accuracy: 0.97738, Train Loss: 0.06731, Validation Accuracy: 0.75895, Validation Loss: 1.05524, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7589473684210526 0.8263157894736842\n",
            "tensor([[5619,   83],\n",
            "        [ 190, 5512]])\n",
            "tensor([[738, 212],\n",
            "        [271, 679]])\n",
            "Epoch: 85, Train Accuracy: 0.97703, Train Loss: 0.06752, Validation Accuracy: 0.75158, Validation Loss: 1.02983, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.751578947368421 0.8263157894736842\n",
            "tensor([[5593,  109],\n",
            "        [ 186, 5516]])\n",
            "tensor([[729, 221],\n",
            "        [273, 677]])\n",
            "Epoch: 86, Train Accuracy: 0.97475, Train Loss: 0.07900, Validation Accuracy: 0.73895, Validation Loss: 1.11809, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7389473684210527 0.8263157894736842\n",
            "tensor([[5588,  114],\n",
            "        [ 210, 5492]])\n",
            "tensor([[726, 224],\n",
            "        [284, 666]])\n",
            "Epoch: 87, Train Accuracy: 0.97422, Train Loss: 0.08522, Validation Accuracy: 0.73474, Validation Loss: 1.51712, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.7347368421052631 0.8263157894736842\n",
            "tensor([[5623,   79],\n",
            "        [ 178, 5524]])\n",
            "tensor([[748, 202],\n",
            "        [268, 682]])\n",
            "Epoch: 88, Train Accuracy: 0.97843, Train Loss: 0.07140, Validation Accuracy: 0.75895, Validation Loss: 1.10409, prediction: [0.988, 0.012], true label: [1.0, 0.0]\n",
            "0.7589473684210526 0.8263157894736842\n",
            "tensor([[5624,   78],\n",
            "        [ 184, 5518]])\n",
            "tensor([[750, 200],\n",
            "        [261, 689]])\n",
            "Epoch: 89, Train Accuracy: 0.97843, Train Loss: 0.07305, Validation Accuracy: 0.75789, Validation Loss: 1.04318, prediction: [0.992, 0.008], true label: [0.0, 1.0]\n",
            "0.7578947368421053 0.8263157894736842\n",
            "tensor([[5623,   79],\n",
            "        [ 181, 5521]])\n",
            "tensor([[744, 206],\n",
            "        [259, 691]])\n",
            "Epoch: 90, Train Accuracy: 0.97843, Train Loss: 0.07038, Validation Accuracy: 0.75895, Validation Loss: 1.07853, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7589473684210526 0.8263157894736842\n",
            "tensor([[5625,   77],\n",
            "        [ 181, 5521]])\n",
            "tensor([[746, 204],\n",
            "        [257, 693]])\n",
            "Epoch: 91, Train Accuracy: 0.97825, Train Loss: 0.06466, Validation Accuracy: 0.76105, Validation Loss: 1.12439, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.7610526315789473 0.8263157894736842\n",
            "tensor([[5617,   85],\n",
            "        [ 172, 5530]])\n",
            "tensor([[759, 191],\n",
            "        [253, 697]])\n",
            "Epoch: 92, Train Accuracy: 0.97790, Train Loss: 0.06806, Validation Accuracy: 0.76737, Validation Loss: 0.94781, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7673684210526316 0.8263157894736842\n",
            "tensor([[5632,   70],\n",
            "        [ 197, 5505]])\n",
            "tensor([[735, 215],\n",
            "        [268, 682]])\n",
            "Epoch: 93, Train Accuracy: 0.97825, Train Loss: 0.07078, Validation Accuracy: 0.74526, Validation Loss: 1.30519, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.7452631578947368 0.8263157894736842\n",
            "tensor([[5586,  116],\n",
            "        [ 198, 5504]])\n",
            "tensor([[766, 184],\n",
            "        [231, 719]])\n",
            "Epoch: 94, Train Accuracy: 0.97510, Train Loss: 0.07998, Validation Accuracy: 0.78526, Validation Loss: 0.88763, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.7852631578947369 0.8263157894736842\n",
            "tensor([[5620,   82],\n",
            "        [ 200, 5502]])\n",
            "tensor([[743, 207],\n",
            "        [280, 670]])\n",
            "Epoch: 95, Train Accuracy: 0.97650, Train Loss: 0.07027, Validation Accuracy: 0.74421, Validation Loss: 1.19396, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.7442105263157894 0.8263157894736842\n",
            "tensor([[5601,  101],\n",
            "        [ 163, 5539]])\n",
            "tensor([[758, 192],\n",
            "        [248, 702]])\n",
            "Epoch: 96, Train Accuracy: 0.97773, Train Loss: 0.06889, Validation Accuracy: 0.77053, Validation Loss: 1.01682, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7705263157894737 0.8263157894736842\n",
            "tensor([[5621,   81],\n",
            "        [ 166, 5536]])\n",
            "tensor([[752, 198],\n",
            "        [255, 695]])\n",
            "Epoch: 97, Train Accuracy: 0.97878, Train Loss: 0.06131, Validation Accuracy: 0.76526, Validation Loss: 1.00546, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7652631578947369 0.8263157894736842\n",
            "tensor([[5636,   66],\n",
            "        [ 186, 5516]])\n",
            "tensor([[747, 203],\n",
            "        [262, 688]])\n",
            "Epoch: 98, Train Accuracy: 0.97966, Train Loss: 0.05993, Validation Accuracy: 0.75895, Validation Loss: 1.14623, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.7589473684210526 0.8263157894736842\n",
            "tensor([[5600,  102],\n",
            "        [ 208, 5494]])\n",
            "tensor([[762, 188],\n",
            "        [234, 716]])\n",
            "Epoch: 99, Train Accuracy: 0.97580, Train Loss: 0.08528, Validation Accuracy: 0.78000, Validation Loss: 1.00850, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.78 0.8263157894736842\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best7,network7=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.0001, epochs=100, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.7, weight_decay=2e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qHeDANkFSama",
        "outputId": "977a849d-f21e-4dea-92c8-7140d1d0745c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t\r 45/??\t\r 46/??\t\r 47/??\t\r 48/??\t\r 49/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5085,  617],\n",
            "        [2349, 3353]])\n",
            "tensor([[855,  95],\n",
            "        [396, 554]])\n",
            "Epoch: 0, Train Accuracy: 0.78130, Train Loss: 0.48822, Validation Accuracy: 0.78000, Validation Loss: 0.49032, prediction: [0.868, 0.132], true label: [1.0, 0.0]\n",
            "0.78 0\n",
            "best_state_dict updated\n",
            "tensor([[5004,  698],\n",
            "        [1800, 3902]])\n",
            "tensor([[836, 114],\n",
            "        [296, 654]])\n",
            "Epoch: 1, Train Accuracy: 0.79674, Train Loss: 0.43506, Validation Accuracy: 0.80842, Validation Loss: 0.44425, prediction: [0.298, 0.702], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.78\n",
            "best_state_dict updated\n",
            "tensor([[5098,  604],\n",
            "        [1848, 3854]])\n",
            "tensor([[846, 104],\n",
            "        [315, 635]])\n",
            "Epoch: 2, Train Accuracy: 0.81392, Train Loss: 0.42475, Validation Accuracy: 0.80105, Validation Loss: 0.43938, prediction: [0.923, 0.077], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8084210526315789\n",
            "tensor([[5076,  626],\n",
            "        [1656, 4046]])\n",
            "tensor([[844, 106],\n",
            "        [282, 668]])\n",
            "Epoch: 3, Train Accuracy: 0.81585, Train Loss: 0.40815, Validation Accuracy: 0.81368, Validation Loss: 0.43830, prediction: [0.866, 0.134], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8084210526315789\n",
            "best_state_dict updated\n",
            "tensor([[5062,  640],\n",
            "        [1501, 4201]])\n",
            "tensor([[840, 110],\n",
            "        [263, 687]])\n",
            "Epoch: 4, Train Accuracy: 0.82340, Train Loss: 0.39427, Validation Accuracy: 0.81368, Validation Loss: 0.44252, prediction: [0.039, 0.961], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8136842105263158\n",
            "tensor([[5168,  534],\n",
            "        [1587, 4115]])\n",
            "tensor([[850, 100],\n",
            "        [298, 652]])\n",
            "Epoch: 5, Train Accuracy: 0.83427, Train Loss: 0.37718, Validation Accuracy: 0.81368, Validation Loss: 0.43615, prediction: [0.658, 0.342], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8136842105263158\n",
            "tensor([[5202,  500],\n",
            "        [1519, 4183]])\n",
            "tensor([[847, 103],\n",
            "        [284, 666]])\n",
            "Epoch: 6, Train Accuracy: 0.84567, Train Loss: 0.35525, Validation Accuracy: 0.81053, Validation Loss: 0.43825, prediction: [0.165, 0.835], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8136842105263158\n",
            "tensor([[5198,  504],\n",
            "        [1435, 4267]])\n",
            "tensor([[843, 107],\n",
            "        [265, 685]])\n",
            "Epoch: 7, Train Accuracy: 0.84567, Train Loss: 0.35704, Validation Accuracy: 0.82316, Validation Loss: 0.41341, prediction: [0.487, 0.513], true label: [0.0, 1.0]\n",
            "0.8231578947368421 0.8136842105263158\n",
            "best_state_dict updated\n",
            "tensor([[5269,  433],\n",
            "        [1374, 4328]])\n",
            "tensor([[825, 125],\n",
            "        [296, 654]])\n",
            "Epoch: 8, Train Accuracy: 0.86478, Train Loss: 0.32137, Validation Accuracy: 0.79579, Validation Loss: 0.47930, prediction: [0.298, 0.702], true label: [0.0, 1.0]\n",
            "0.7957894736842105 0.8231578947368421\n",
            "tensor([[5345,  357],\n",
            "        [1192, 4510]])\n",
            "tensor([[835, 115],\n",
            "        [275, 675]])\n",
            "Epoch: 9, Train Accuracy: 0.88583, Train Loss: 0.29053, Validation Accuracy: 0.81158, Validation Loss: 0.46082, prediction: [0.025, 0.975], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5351,  351],\n",
            "        [1031, 4671]])\n",
            "tensor([[822, 128],\n",
            "        [268, 682]])\n",
            "Epoch: 10, Train Accuracy: 0.89688, Train Loss: 0.26075, Validation Accuracy: 0.80105, Validation Loss: 0.53728, prediction: [0.108, 0.892], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8231578947368421\n",
            "tensor([[5378,  324],\n",
            "        [ 923, 4779]])\n",
            "tensor([[822, 128],\n",
            "        [252, 698]])\n",
            "Epoch: 11, Train Accuracy: 0.90915, Train Loss: 0.24341, Validation Accuracy: 0.81053, Validation Loss: 0.51905, prediction: [0.912, 0.088], true label: [1.0, 0.0]\n",
            "0.8105263157894737 0.8231578947368421\n",
            "tensor([[5393,  309],\n",
            "        [ 751, 4951]])\n",
            "tensor([[825, 125],\n",
            "        [234, 716]])\n",
            "Epoch: 12, Train Accuracy: 0.91740, Train Loss: 0.21694, Validation Accuracy: 0.81684, Validation Loss: 0.49674, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8231578947368421\n",
            "tensor([[5196,  506],\n",
            "        [1399, 4303]])\n",
            "tensor([[739, 211],\n",
            "        [351, 599]])\n",
            "Epoch: 13, Train Accuracy: 0.84953, Train Loss: 0.33120, Validation Accuracy: 0.71053, Validation Loss: 0.84768, prediction: [0.214, 0.786], true label: [0.0, 1.0]\n",
            "0.7105263157894737 0.8231578947368421\n",
            "tensor([[5450,  252],\n",
            "        [ 834, 4868]])\n",
            "tensor([[798, 152],\n",
            "        [279, 671]])\n",
            "Epoch: 14, Train Accuracy: 0.92266, Train Loss: 0.20773, Validation Accuracy: 0.78316, Validation Loss: 0.57116, prediction: [0.923, 0.077], true label: [1.0, 0.0]\n",
            "0.783157894736842 0.8231578947368421\n",
            "tensor([[5505,  197],\n",
            "        [ 492, 5210]])\n",
            "tensor([[796, 154],\n",
            "        [241, 709]])\n",
            "Epoch: 15, Train Accuracy: 0.94669, Train Loss: 0.16068, Validation Accuracy: 0.79789, Validation Loss: 0.66193, prediction: [0.893, 0.107], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8231578947368421\n",
            "tensor([[5509,  193],\n",
            "        [ 406, 5296]])\n",
            "tensor([[784, 166],\n",
            "        [247, 703]])\n",
            "Epoch: 16, Train Accuracy: 0.95353, Train Loss: 0.14084, Validation Accuracy: 0.78316, Validation Loss: 0.71013, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.783157894736842 0.8231578947368421\n",
            "tensor([[5500,  202],\n",
            "        [ 459, 5243]])\n",
            "tensor([[801, 149],\n",
            "        [233, 717]])\n",
            "Epoch: 17, Train Accuracy: 0.94809, Train Loss: 0.15203, Validation Accuracy: 0.80842, Validation Loss: 0.56829, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.8231578947368421\n",
            "tensor([[5545,  157],\n",
            "        [ 320, 5382]])\n",
            "tensor([[789, 161],\n",
            "        [243, 707]])\n",
            "Epoch: 18, Train Accuracy: 0.96229, Train Loss: 0.12163, Validation Accuracy: 0.78947, Validation Loss: 0.61460, prediction: [0.949, 0.051], true label: [1.0, 0.0]\n",
            "0.7894736842105263 0.8231578947368421\n",
            "tensor([[5536,  166],\n",
            "        [ 333, 5369]])\n",
            "tensor([[780, 170],\n",
            "        [232, 718]])\n",
            "Epoch: 19, Train Accuracy: 0.96001, Train Loss: 0.11960, Validation Accuracy: 0.79368, Validation Loss: 0.85027, prediction: [0.983, 0.017], true label: [1.0, 0.0]\n",
            "0.7936842105263158 0.8231578947368421\n",
            "tensor([[5584,  118],\n",
            "        [ 363, 5339]])\n",
            "tensor([[757, 193],\n",
            "        [276, 674]])\n",
            "Epoch: 20, Train Accuracy: 0.96861, Train Loss: 0.10999, Validation Accuracy: 0.76316, Validation Loss: 0.84340, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.7631578947368421 0.8231578947368421\n",
            "tensor([[5584,  118],\n",
            "        [ 273, 5429]])\n",
            "tensor([[773, 177],\n",
            "        [251, 699]])\n",
            "Epoch: 21, Train Accuracy: 0.96861, Train Loss: 0.09357, Validation Accuracy: 0.77263, Validation Loss: 0.82622, prediction: [0.989, 0.011], true label: [1.0, 0.0]\n",
            "0.7726315789473684 0.8231578947368421\n",
            "tensor([[5571,  131],\n",
            "        [ 294, 5408]])\n",
            "tensor([[784, 166],\n",
            "        [227, 723]])\n",
            "Epoch: 22, Train Accuracy: 0.96580, Train Loss: 0.09654, Validation Accuracy: 0.79895, Validation Loss: 0.80039, prediction: [0.948, 0.052], true label: [1.0, 0.0]\n",
            "0.7989473684210526 0.8231578947368421\n",
            "tensor([[5592,  110],\n",
            "        [ 249, 5453]])\n",
            "tensor([[772, 178],\n",
            "        [254, 696]])\n",
            "Epoch: 23, Train Accuracy: 0.97404, Train Loss: 0.08719, Validation Accuracy: 0.77053, Validation Loss: 0.86676, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7705263157894737 0.8231578947368421\n",
            "tensor([[5621,   81],\n",
            "        [ 208, 5494]])\n",
            "tensor([[761, 189],\n",
            "        [251, 699]])\n",
            "Epoch: 24, Train Accuracy: 0.97790, Train Loss: 0.07172, Validation Accuracy: 0.77053, Validation Loss: 0.93134, prediction: [0.948, 0.052], true label: [1.0, 0.0]\n",
            "0.7705263157894737 0.8231578947368421\n",
            "tensor([[5611,   91],\n",
            "        [ 317, 5385]])\n",
            "tensor([[748, 202],\n",
            "        [287, 663]])\n",
            "Epoch: 25, Train Accuracy: 0.97054, Train Loss: 0.08660, Validation Accuracy: 0.75474, Validation Loss: 1.10554, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7547368421052632 0.8231578947368421\n",
            "tensor([[5627,   75],\n",
            "        [ 199, 5503]])\n",
            "tensor([[763, 187],\n",
            "        [266, 684]])\n",
            "Epoch: 26, Train Accuracy: 0.97843, Train Loss: 0.06808, Validation Accuracy: 0.77158, Validation Loss: 1.12415, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8231578947368421\n",
            "tensor([[5616,   86],\n",
            "        [ 185, 5517]])\n",
            "tensor([[774, 176],\n",
            "        [240, 710]])\n",
            "Epoch: 27, Train Accuracy: 0.97860, Train Loss: 0.06857, Validation Accuracy: 0.78526, Validation Loss: 0.93406, prediction: [0.988, 0.012], true label: [1.0, 0.0]\n",
            "0.7852631578947369 0.8231578947368421\n",
            "tensor([[5631,   71],\n",
            "        [ 171, 5531]])\n",
            "tensor([[767, 183],\n",
            "        [250, 700]])\n",
            "Epoch: 28, Train Accuracy: 0.98088, Train Loss: 0.05928, Validation Accuracy: 0.77474, Validation Loss: 1.02157, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.7747368421052632 0.8231578947368421\n",
            "tensor([[5557,  145],\n",
            "        [ 349, 5353]])\n",
            "tensor([[783, 167],\n",
            "        [214, 736]])\n",
            "Epoch: 29, Train Accuracy: 0.95756, Train Loss: 0.10061, Validation Accuracy: 0.79474, Validation Loss: 0.77393, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.7947368421052632 0.8231578947368421\n",
            "tensor([[5640,   62],\n",
            "        [ 192, 5510]])\n",
            "tensor([[761, 189],\n",
            "        [261, 689]])\n",
            "Epoch: 30, Train Accuracy: 0.98071, Train Loss: 0.05818, Validation Accuracy: 0.76842, Validation Loss: 1.06061, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5622,   80],\n",
            "        [ 154, 5548]])\n",
            "tensor([[769, 181],\n",
            "        [239, 711]])\n",
            "Epoch: 31, Train Accuracy: 0.97966, Train Loss: 0.05647, Validation Accuracy: 0.77789, Validation Loss: 0.97077, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7778947368421053 0.8231578947368421\n",
            "tensor([[5633,   69],\n",
            "        [ 151, 5551]])\n",
            "tensor([[769, 181],\n",
            "        [233, 717]])\n",
            "Epoch: 32, Train Accuracy: 0.98141, Train Loss: 0.05453, Validation Accuracy: 0.78211, Validation Loss: 1.04062, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.7821052631578947 0.8231578947368421\n",
            "tensor([[5644,   58],\n",
            "        [ 171, 5531]])\n",
            "tensor([[760, 190],\n",
            "        [246, 704]])\n",
            "Epoch: 33, Train Accuracy: 0.98141, Train Loss: 0.05229, Validation Accuracy: 0.77263, Validation Loss: 1.06829, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7726315789473684 0.8231578947368421\n",
            "tensor([[5623,   79],\n",
            "        [ 157, 5545]])\n",
            "tensor([[778, 172],\n",
            "        [238, 712]])\n",
            "Epoch: 34, Train Accuracy: 0.97966, Train Loss: 0.06006, Validation Accuracy: 0.77789, Validation Loss: 0.95418, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.7778947368421053 0.8231578947368421\n",
            "tensor([[5625,   77],\n",
            "        [ 137, 5565]])\n",
            "tensor([[765, 185],\n",
            "        [240, 710]])\n",
            "Epoch: 35, Train Accuracy: 0.98176, Train Loss: 0.05242, Validation Accuracy: 0.77789, Validation Loss: 0.97680, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7778947368421053 0.8231578947368421\n",
            "tensor([[5639,   63],\n",
            "        [ 154, 5548]])\n",
            "tensor([[761, 189],\n",
            "        [247, 703]])\n",
            "Epoch: 36, Train Accuracy: 0.98281, Train Loss: 0.05171, Validation Accuracy: 0.78421, Validation Loss: 1.01419, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.7842105263157895 0.8231578947368421\n",
            "tensor([[5646,   56],\n",
            "        [ 171, 5531]])\n",
            "tensor([[767, 183],\n",
            "        [247, 703]])\n",
            "Epoch: 37, Train Accuracy: 0.98176, Train Loss: 0.05416, Validation Accuracy: 0.78316, Validation Loss: 1.25275, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.783157894736842 0.8231578947368421\n",
            "tensor([[5626,   76],\n",
            "        [ 168, 5534]])\n",
            "tensor([[754, 196],\n",
            "        [260, 690]])\n",
            "Epoch: 38, Train Accuracy: 0.98141, Train Loss: 0.05576, Validation Accuracy: 0.76421, Validation Loss: 1.19505, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.7642105263157895 0.8231578947368421\n",
            "tensor([[5636,   66],\n",
            "        [ 137, 5565]])\n",
            "tensor([[772, 178],\n",
            "        [239, 711]])\n",
            "Epoch: 39, Train Accuracy: 0.98246, Train Loss: 0.04795, Validation Accuracy: 0.78421, Validation Loss: 0.96924, prediction: [0.98, 0.02], true label: [1.0, 0.0]\n",
            "0.7842105263157895 0.8231578947368421\n",
            "tensor([[5649,   53],\n",
            "        [ 159, 5543]])\n",
            "tensor([[768, 182],\n",
            "        [236, 714]])\n",
            "Epoch: 40, Train Accuracy: 0.98334, Train Loss: 0.04474, Validation Accuracy: 0.78105, Validation Loss: 1.07752, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.7810526315789473 0.8231578947368421\n",
            "tensor([[5632,   70],\n",
            "        [ 145, 5557]])\n",
            "tensor([[771, 179],\n",
            "        [231, 719]])\n",
            "Epoch: 41, Train Accuracy: 0.98246, Train Loss: 0.04955, Validation Accuracy: 0.78632, Validation Loss: 1.06415, prediction: [0.13, 0.87], true label: [0.0, 1.0]\n",
            "0.7863157894736842 0.8231578947368421\n",
            "tensor([[5646,   56],\n",
            "        [ 155, 5547]])\n",
            "tensor([[760, 190],\n",
            "        [247, 703]])\n",
            "Epoch: 42, Train Accuracy: 0.98246, Train Loss: 0.05119, Validation Accuracy: 0.77263, Validation Loss: 1.29157, prediction: [0.044, 0.956], true label: [0.0, 1.0]\n",
            "0.7726315789473684 0.8231578947368421\n",
            "tensor([[5640,   62],\n",
            "        [ 142, 5560]])\n",
            "tensor([[778, 172],\n",
            "        [239, 711]])\n",
            "Epoch: 43, Train Accuracy: 0.98264, Train Loss: 0.04613, Validation Accuracy: 0.78947, Validation Loss: 0.99149, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.7894736842105263 0.8231578947368421\n",
            "tensor([[5656,   46],\n",
            "        [ 173, 5529]])\n",
            "tensor([[767, 183],\n",
            "        [249, 701]])\n",
            "Epoch: 44, Train Accuracy: 0.98159, Train Loss: 0.04427, Validation Accuracy: 0.77789, Validation Loss: 1.10736, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7778947368421053 0.8231578947368421\n",
            "tensor([[5648,   54],\n",
            "        [ 169, 5533]])\n",
            "tensor([[763, 187],\n",
            "        [257, 693]])\n",
            "Epoch: 45, Train Accuracy: 0.98106, Train Loss: 0.04532, Validation Accuracy: 0.77053, Validation Loss: 1.04051, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.7705263157894737 0.8231578947368421\n",
            "tensor([[5564,  138],\n",
            "        [ 392, 5310]])\n",
            "tensor([[778, 172],\n",
            "        [212, 738]])\n",
            "Epoch: 46, Train Accuracy: 0.95633, Train Loss: 0.10440, Validation Accuracy: 0.79684, Validation Loss: 0.79325, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.8231578947368421\n",
            "tensor([[5617,   85],\n",
            "        [ 154, 5548]])\n",
            "tensor([[775, 175],\n",
            "        [219, 731]])\n",
            "Epoch: 47, Train Accuracy: 0.98018, Train Loss: 0.05646, Validation Accuracy: 0.79053, Validation Loss: 0.81029, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7905263157894736 0.8231578947368421\n",
            "tensor([[5644,   58],\n",
            "        [ 141, 5561]])\n",
            "tensor([[774, 176],\n",
            "        [238, 712]])\n",
            "Epoch: 48, Train Accuracy: 0.98404, Train Loss: 0.04292, Validation Accuracy: 0.78211, Validation Loss: 1.06088, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7821052631578947 0.8231578947368421\n",
            "tensor([[5649,   53],\n",
            "        [ 155, 5547]])\n",
            "tensor([[757, 193],\n",
            "        [253, 697]])\n",
            "Epoch: 49, Train Accuracy: 0.98299, Train Loss: 0.04662, Validation Accuracy: 0.76842, Validation Loss: 1.09496, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5643,   59],\n",
            "        [ 140, 5562]])\n",
            "tensor([[778, 172],\n",
            "        [234, 716]])\n",
            "Epoch: 50, Train Accuracy: 0.98369, Train Loss: 0.04363, Validation Accuracy: 0.79053, Validation Loss: 1.00497, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7905263157894736 0.8231578947368421\n",
            "tensor([[5643,   59],\n",
            "        [ 138, 5564]])\n",
            "tensor([[758, 192],\n",
            "        [252, 698]])\n",
            "Epoch: 51, Train Accuracy: 0.98387, Train Loss: 0.04023, Validation Accuracy: 0.77158, Validation Loss: 1.17026, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8231578947368421\n",
            "tensor([[5649,   53],\n",
            "        [ 157, 5545]])\n",
            "tensor([[776, 174],\n",
            "        [237, 713]])\n",
            "Epoch: 52, Train Accuracy: 0.98351, Train Loss: 0.04323, Validation Accuracy: 0.78842, Validation Loss: 0.96315, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7884210526315789 0.8231578947368421\n",
            "tensor([[5653,   49],\n",
            "        [ 179, 5523]])\n",
            "tensor([[745, 205],\n",
            "        [259, 691]])\n",
            "Epoch: 53, Train Accuracy: 0.98299, Train Loss: 0.04245, Validation Accuracy: 0.76316, Validation Loss: 1.24614, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7631578947368421 0.8231578947368421\n",
            "tensor([[5644,   58],\n",
            "        [ 135, 5567]])\n",
            "tensor([[780, 170],\n",
            "        [230, 720]])\n",
            "Epoch: 54, Train Accuracy: 0.98422, Train Loss: 0.04082, Validation Accuracy: 0.79053, Validation Loss: 1.00927, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7905263157894736 0.8231578947368421\n",
            "tensor([[5637,   65],\n",
            "        [ 154, 5548]])\n",
            "tensor([[778, 172],\n",
            "        [222, 728]])\n",
            "Epoch: 55, Train Accuracy: 0.98176, Train Loss: 0.04737, Validation Accuracy: 0.80316, Validation Loss: 0.79111, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8231578947368421\n",
            "tensor([[5647,   55],\n",
            "        [ 163, 5539]])\n",
            "tensor([[784, 166],\n",
            "        [231, 719]])\n",
            "Epoch: 56, Train Accuracy: 0.98316, Train Loss: 0.04262, Validation Accuracy: 0.79263, Validation Loss: 0.84240, prediction: [0.981, 0.019], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.8231578947368421\n",
            "tensor([[5651,   51],\n",
            "        [ 149, 5553]])\n",
            "tensor([[781, 169],\n",
            "        [236, 714]])\n",
            "Epoch: 57, Train Accuracy: 0.98422, Train Loss: 0.04050, Validation Accuracy: 0.79158, Validation Loss: 0.76767, prediction: [0.991, 0.009], true label: [1.0, 0.0]\n",
            "0.791578947368421 0.8231578947368421\n",
            "tensor([[5658,   44],\n",
            "        [ 166, 5536]])\n",
            "tensor([[760, 190],\n",
            "        [244, 706]])\n",
            "Epoch: 58, Train Accuracy: 0.98316, Train Loss: 0.03563, Validation Accuracy: 0.77158, Validation Loss: 1.12066, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8231578947368421\n",
            "tensor([[5641,   61],\n",
            "        [ 163, 5539]])\n",
            "tensor([[766, 184],\n",
            "        [247, 703]])\n",
            "Epoch: 59, Train Accuracy: 0.98141, Train Loss: 0.04076, Validation Accuracy: 0.77684, Validation Loss: 1.24487, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7768421052631579 0.8231578947368421\n",
            "tensor([[5607,   95],\n",
            "        [ 257, 5445]])\n",
            "tensor([[776, 174],\n",
            "        [220, 730]])\n",
            "Epoch: 60, Train Accuracy: 0.97369, Train Loss: 0.06668, Validation Accuracy: 0.79263, Validation Loss: 0.76046, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.8231578947368421\n",
            "tensor([[5661,   41],\n",
            "        [ 167, 5535]])\n",
            "tensor([[755, 195],\n",
            "        [256, 694]])\n",
            "Epoch: 61, Train Accuracy: 0.98404, Train Loss: 0.03694, Validation Accuracy: 0.76842, Validation Loss: 1.22366, prediction: [0.994, 0.006], true label: [1.0, 0.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5655,   47],\n",
            "        [ 160, 5542]])\n",
            "tensor([[757, 193],\n",
            "        [255, 695]])\n",
            "Epoch: 62, Train Accuracy: 0.98246, Train Loss: 0.03677, Validation Accuracy: 0.75895, Validation Loss: 1.25802, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.7589473684210526 0.8231578947368421\n",
            "tensor([[5660,   42],\n",
            "        [ 139, 5563]])\n",
            "tensor([[760, 190],\n",
            "        [252, 698]])\n",
            "Epoch: 63, Train Accuracy: 0.98544, Train Loss: 0.03195, Validation Accuracy: 0.76842, Validation Loss: 1.21681, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5665,   37],\n",
            "        [ 161, 5541]])\n",
            "tensor([[750, 200],\n",
            "        [256, 694]])\n",
            "Epoch: 64, Train Accuracy: 0.98404, Train Loss: 0.03304, Validation Accuracy: 0.75474, Validation Loss: 1.25531, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7547368421052632 0.8231578947368421\n",
            "tensor([[5659,   43],\n",
            "        [ 168, 5534]])\n",
            "tensor([[753, 197],\n",
            "        [257, 693]])\n",
            "Epoch: 65, Train Accuracy: 0.98404, Train Loss: 0.03769, Validation Accuracy: 0.76947, Validation Loss: 1.22521, prediction: [0.946, 0.054], true label: [1.0, 0.0]\n",
            "0.7694736842105263 0.8231578947368421\n",
            "tensor([[5656,   46],\n",
            "        [ 148, 5554]])\n",
            "tensor([[755, 195],\n",
            "        [256, 694]])\n",
            "Epoch: 66, Train Accuracy: 0.98457, Train Loss: 0.03353, Validation Accuracy: 0.76947, Validation Loss: 1.20382, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.7694736842105263 0.8231578947368421\n",
            "tensor([[5666,   36],\n",
            "        [ 156, 5546]])\n",
            "tensor([[767, 183],\n",
            "        [251, 699]])\n",
            "Epoch: 67, Train Accuracy: 0.98527, Train Loss: 0.03110, Validation Accuracy: 0.77158, Validation Loss: 1.08955, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.8231578947368421\n",
            "tensor([[5649,   53],\n",
            "        [ 146, 5556]])\n",
            "tensor([[755, 195],\n",
            "        [247, 703]])\n",
            "Epoch: 68, Train Accuracy: 0.98369, Train Loss: 0.03321, Validation Accuracy: 0.77053, Validation Loss: 1.12536, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7705263157894737 0.8231578947368421\n",
            "tensor([[5666,   36],\n",
            "        [ 161, 5541]])\n",
            "tensor([[751, 199],\n",
            "        [250, 700]])\n",
            "Epoch: 69, Train Accuracy: 0.98527, Train Loss: 0.03216, Validation Accuracy: 0.76842, Validation Loss: 1.25838, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5654,   48],\n",
            "        [ 177, 5525]])\n",
            "tensor([[727, 223],\n",
            "        [270, 680]])\n",
            "Epoch: 70, Train Accuracy: 0.98211, Train Loss: 0.03967, Validation Accuracy: 0.74421, Validation Loss: 1.37834, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7442105263157894 0.8231578947368421\n",
            "tensor([[5654,   48],\n",
            "        [ 172, 5530]])\n",
            "tensor([[751, 199],\n",
            "        [263, 687]])\n",
            "Epoch: 71, Train Accuracy: 0.98351, Train Loss: 0.03784, Validation Accuracy: 0.75368, Validation Loss: 1.23219, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7536842105263157 0.8231578947368421\n",
            "tensor([[5664,   38],\n",
            "        [ 147, 5555]])\n",
            "tensor([[762, 188],\n",
            "        [243, 707]])\n",
            "Epoch: 72, Train Accuracy: 0.98492, Train Loss: 0.03185, Validation Accuracy: 0.78000, Validation Loss: 1.19514, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.78 0.8231578947368421\n",
            "tensor([[5663,   39],\n",
            "        [ 147, 5555]])\n",
            "tensor([[776, 174],\n",
            "        [226, 724]])\n",
            "Epoch: 73, Train Accuracy: 0.98527, Train Loss: 0.03309, Validation Accuracy: 0.79684, Validation Loss: 1.06327, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7968421052631579 0.8231578947368421\n",
            "tensor([[5641,   61],\n",
            "        [ 172, 5530]])\n",
            "tensor([[780, 170],\n",
            "        [206, 744]])\n",
            "Epoch: 74, Train Accuracy: 0.98123, Train Loss: 0.04663, Validation Accuracy: 0.80526, Validation Loss: 1.05797, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8231578947368421\n",
            "tensor([[5669,   33],\n",
            "        [ 155, 5547]])\n",
            "tensor([[767, 183],\n",
            "        [245, 705]])\n",
            "Epoch: 75, Train Accuracy: 0.98597, Train Loss: 0.03004, Validation Accuracy: 0.77474, Validation Loss: 1.19662, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7747368421052632 0.8231578947368421\n",
            "tensor([[5659,   43],\n",
            "        [ 139, 5563]])\n",
            "tensor([[769, 181],\n",
            "        [235, 715]])\n",
            "Epoch: 76, Train Accuracy: 0.98597, Train Loss: 0.03043, Validation Accuracy: 0.78632, Validation Loss: 1.21763, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.7863157894736842 0.8231578947368421\n",
            "tensor([[5640,   62],\n",
            "        [ 135, 5567]])\n",
            "tensor([[777, 173],\n",
            "        [209, 741]])\n",
            "Epoch: 77, Train Accuracy: 0.98387, Train Loss: 0.03877, Validation Accuracy: 0.79368, Validation Loss: 1.01018, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7936842105263158 0.8231578947368421\n",
            "tensor([[5658,   44],\n",
            "        [ 133, 5569]])\n",
            "tensor([[750, 200],\n",
            "        [244, 706]])\n",
            "Epoch: 78, Train Accuracy: 0.98509, Train Loss: 0.03101, Validation Accuracy: 0.76842, Validation Loss: 1.27609, prediction: [0.013, 0.987], true label: [0.0, 1.0]\n",
            "0.7684210526315789 0.8231578947368421\n",
            "tensor([[5668,   34],\n",
            "        [ 149, 5553]])\n",
            "tensor([[774, 176],\n",
            "        [237, 713]])\n",
            "Epoch: 79, Train Accuracy: 0.98562, Train Loss: 0.02905, Validation Accuracy: 0.78737, Validation Loss: 1.12369, prediction: [0.667, 0.333], true label: [1.0, 0.0]\n",
            "0.7873684210526316 0.8231578947368421\n",
            "tensor([[5655,   47],\n",
            "        [ 131, 5571]])\n",
            "tensor([[781, 169],\n",
            "        [217, 733]])\n",
            "Epoch: 80, Train Accuracy: 0.98562, Train Loss: 0.03291, Validation Accuracy: 0.80316, Validation Loss: 1.14912, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8231578947368421\n",
            "tensor([[5657,   45],\n",
            "        [ 133, 5569]])\n",
            "tensor([[778, 172],\n",
            "        [223, 727]])\n",
            "Epoch: 81, Train Accuracy: 0.98579, Train Loss: 0.03776, Validation Accuracy: 0.79684, Validation Loss: 1.13262, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.8231578947368421\n",
            "tensor([[5651,   51],\n",
            "        [ 179, 5523]])\n",
            "tensor([[734, 216],\n",
            "        [267, 683]])\n",
            "Epoch: 82, Train Accuracy: 0.98281, Train Loss: 0.03511, Validation Accuracy: 0.74316, Validation Loss: 1.56272, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7431578947368421 0.8231578947368421\n",
            "tensor([[5652,   50],\n",
            "        [ 171, 5531]])\n",
            "tensor([[743, 207],\n",
            "        [259, 691]])\n",
            "Epoch: 83, Train Accuracy: 0.98299, Train Loss: 0.03797, Validation Accuracy: 0.75263, Validation Loss: 1.40146, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7526315789473684 0.8231578947368421\n",
            "tensor([[5658,   44],\n",
            "        [ 142, 5560]])\n",
            "tensor([[751, 199],\n",
            "        [250, 700]])\n",
            "Epoch: 84, Train Accuracy: 0.98509, Train Loss: 0.03216, Validation Accuracy: 0.76526, Validation Loss: 1.31369, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7652631578947369 0.8231578947368421\n",
            "tensor([[5656,   46],\n",
            "        [ 191, 5511]])\n",
            "tensor([[725, 225],\n",
            "        [280, 670]])\n",
            "Epoch: 85, Train Accuracy: 0.98106, Train Loss: 0.03795, Validation Accuracy: 0.73789, Validation Loss: 1.46113, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7378947368421053 0.8231578947368421\n",
            "tensor([[5649,   53],\n",
            "        [ 166, 5536]])\n",
            "tensor([[738, 212],\n",
            "        [265, 685]])\n",
            "Epoch: 86, Train Accuracy: 0.98281, Train Loss: 0.03882, Validation Accuracy: 0.75158, Validation Loss: 1.43003, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.751578947368421 0.8231578947368421\n",
            "tensor([[5667,   35],\n",
            "        [ 165, 5537]])\n",
            "tensor([[757, 193],\n",
            "        [241, 709]])\n",
            "Epoch: 87, Train Accuracy: 0.98457, Train Loss: 0.03365, Validation Accuracy: 0.77158, Validation Loss: 1.44081, prediction: [0.985, 0.015], true label: [1.0, 0.0]\n",
            "0.771578947368421 0.8231578947368421\n",
            "tensor([[5670,   32],\n",
            "        [ 154, 5548]])\n",
            "tensor([[758, 192],\n",
            "        [250, 700]])\n",
            "Epoch: 88, Train Accuracy: 0.98422, Train Loss: 0.03221, Validation Accuracy: 0.76421, Validation Loss: 1.27207, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.7642105263157895 0.8231578947368421\n",
            "tensor([[5672,   30],\n",
            "        [ 156, 5546]])\n",
            "tensor([[771, 179],\n",
            "        [240, 710]])\n",
            "Epoch: 89, Train Accuracy: 0.98544, Train Loss: 0.03058, Validation Accuracy: 0.78632, Validation Loss: 1.24303, prediction: [0.033, 0.967], true label: [0.0, 1.0]\n",
            "0.7863157894736842 0.8231578947368421\n",
            "tensor([[5664,   38],\n",
            "        [ 151, 5551]])\n",
            "tensor([[757, 193],\n",
            "        [248, 702]])\n",
            "Epoch: 90, Train Accuracy: 0.98474, Train Loss: 0.03507, Validation Accuracy: 0.76947, Validation Loss: 1.11760, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7694736842105263 0.8231578947368421\n",
            "tensor([[5673,   29],\n",
            "        [ 152, 5550]])\n",
            "tensor([[772, 178],\n",
            "        [234, 716]])\n",
            "Epoch: 91, Train Accuracy: 0.98579, Train Loss: 0.02912, Validation Accuracy: 0.78421, Validation Loss: 1.17218, prediction: [0.998, 0.002], true label: [1.0, 0.0]\n",
            "0.7842105263157895 0.8231578947368421\n",
            "tensor([[5657,   45],\n",
            "        [ 132, 5570]])\n",
            "tensor([[782, 168],\n",
            "        [228, 722]])\n",
            "Epoch: 92, Train Accuracy: 0.98579, Train Loss: 0.03069, Validation Accuracy: 0.80105, Validation Loss: 1.07602, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8231578947368421\n",
            "tensor([[5670,   32],\n",
            "        [ 154, 5548]])\n",
            "tensor([[754, 196],\n",
            "        [243, 707]])\n",
            "Epoch: 93, Train Accuracy: 0.98509, Train Loss: 0.03258, Validation Accuracy: 0.77263, Validation Loss: 1.40537, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.7726315789473684 0.8231578947368421\n",
            "tensor([[5627,   75],\n",
            "        [ 152, 5550]])\n",
            "tensor([[777, 173],\n",
            "        [208, 742]])\n",
            "Epoch: 94, Train Accuracy: 0.98071, Train Loss: 0.04750, Validation Accuracy: 0.79895, Validation Loss: 0.90761, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.7989473684210526 0.8231578947368421\n",
            "tensor([[5663,   39],\n",
            "        [ 163, 5539]])\n",
            "tensor([[744, 206],\n",
            "        [266, 684]])\n",
            "Epoch: 95, Train Accuracy: 0.98316, Train Loss: 0.03303, Validation Accuracy: 0.74316, Validation Loss: 1.52852, prediction: [0.999, 0.001], true label: [1.0, 0.0]\n",
            "0.7431578947368421 0.8231578947368421\n",
            "tensor([[5658,   44],\n",
            "        [ 130, 5572]])\n",
            "tensor([[760, 190],\n",
            "        [233, 717]])\n",
            "Epoch: 96, Train Accuracy: 0.98597, Train Loss: 0.02919, Validation Accuracy: 0.78526, Validation Loss: 1.30123, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7852631578947369 0.8231578947368421\n",
            "tensor([[5663,   39],\n",
            "        [ 135, 5567]])\n",
            "tensor([[777, 173],\n",
            "        [229, 721]])\n",
            "Epoch: 97, Train Accuracy: 0.98632, Train Loss: 0.02812, Validation Accuracy: 0.79579, Validation Loss: 1.16868, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7957894736842105 0.8231578947368421\n",
            "tensor([[5674,   28],\n",
            "        [ 155, 5547]])\n",
            "tensor([[743, 207],\n",
            "        [255, 695]])\n",
            "Epoch: 98, Train Accuracy: 0.98527, Train Loss: 0.02756, Validation Accuracy: 0.76000, Validation Loss: 1.51654, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.76 0.8231578947368421\n",
            "tensor([[5634,   68],\n",
            "        [ 142, 5560]])\n",
            "tensor([[776, 174],\n",
            "        [209, 741]])\n",
            "Epoch: 99, Train Accuracy: 0.98246, Train Loss: 0.04710, Validation Accuracy: 0.80105, Validation Loss: 1.12176, prediction: [1.0, 0.0], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8231578947368421\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3ib5dm3z8t72/GIk9jZe5Ng9kqAsgltWQ0thZaWQumgLV30baHrezt4WwodjEIpbVkFCgESRtiUFQey946TeMZ727q/P249lixLsjxkeVznceSQ9Azplu08v+faYoxBURRFGblERXoBiqIoSmRRIVAURRnhqBAoiqKMcFQIFEVRRjgqBIqiKCMcFQJFUZQRjgqBMmIQkVUick1/H6soQx3ROgJlMCMidV4vk4BmoN39+ivGmH8N/Kr6hoikAT8DPg1kAiXAc8AvjDHlkVybMjJRi0AZ1BhjUpx/wAHgYq9tHSIgIjGRW2XoiEgc8CowFzgPSANOAiqA43vxfkPieyuDGxUCZUgiIktEpEhEvi8ixcDfRGSUiDwvImUiUul+nu91zhsi8iX382tF5B0RucN97F4ROb+Xx04WkbdEpFZEVovIn0TknwGW/nlgAvApY8wWY4zLGFNqjPm5MWal+/2MiEzzev+HROQXQb73VhG5yOv4GPfPYLH79Yki8q6IVInIehFZ0tefvzK8UCFQhjJjsK6VicD12L/nv7lfTwAagT8GOf8EYDuQDfwGeEBEpBfHPgJ8CGQBtwNXB/nMs4EXjTF1QY7pDt/v/Siw3Gv/uUC5MeYjEckDXgB+4T7nFuApEcnpw+crwwwVAmUo4wJuM8Y0G2MajTEVxpinjDENxpha4JfAGUHO32+Mud8Y0w78HRgL5PbkWBGZABwH/MQY02KMeQdYEeQzs4AjPfuaXej0vbFCtExEktz7r8KKA8DngJXGmJVu6+MVoBC4oI9rUIYRKgTKUKbMGNPkvBCRJBG5V0T2i0gN8BaQISLRAc4vdp4YYxrcT1N6eOw44KjXNoCDQdZcgRWRvtDpextjdgFbgYvdYrAMKw5grYbL3W6hKhGpAk7thzUowwgNNClDGd+Ut+8AM4ETjDHFInIM8DEQyN3THxwBMkUkyUsMxgc5fjXwCxFJNsbUBzimAZsh5TAGKPJ67S/Vz3EPRQFb3OIAVpT+YYz5cjffQxnBqEWgDCdSsXGBKhHJBG4L9wcaY/ZjXS23i0iciJwEXBzklH9gL85PicgsEYkSkSwRuVVEHHfNOuAqEYkWkfMI7t5yeAw4B7gRjzUA8E+spXCu+/0S3AHnfL/vooxIVAiU4cSdQCJQDrwPvDhAn/tZPCmgvwAex9Y7dMEY04wNGG8DXgFqsIHmbOAD92HfxIpJlfu9n+luAcaYI8B7wMnuz3e2HwQuAW4FyrAi9F30/77ihRaUKUo/IyKPA9uMMWG3SBSlP9C7AkXpIyJynIhMdbt5zsPegXd7F68ogwUNFitK3xkDPI1NDS0CbjTGfBzZJSlK6KhrSFEUZYSjriFFUZQRzpBzDWVnZ5tJkyZFehmKoihDirVr15YbY/y2FhlyQjBp0iQKCwsjvQxFUZQhhYjsD7QvbK4hEXlQREpFZFOQY5aIyDoR2Swib4ZrLYqiKEpgwhkjeAjbb90vIpIB/BlYZoyZC1wexrUoiqIoAQibEBhj3gKOBjnkKuBpY8wB9/Gl4VqLoiiKEphIxghmALEi8ga2R8wfjDEP+ztQRK7H9l1nwoQJXfa3trZSVFREU1NTl33DkYSEBPLz84mNjY30UhRFGQZEUghigGOBs7D9Yd4TkfeNMTt8DzTG3AfcB1BQUNCl8KGoqIjU1FQmTZpE4LkiwwNjDBUVFRQVFTF58uRIL0dRlGFAJOsIioCXjDH17oHdbwELe/NGTU1NZGVlDXsRABARsrKyRoz1oyhK+ImkEDwLnOqer5qEHQW4tbdvNhJEwGEkfVdFUcJP2FxDIvIosATIFpEibG/4WABjzD3GmK0i8iKwATt676/GmICppoqiKCHjaod1/4KFyyFaY2ndETYhMMYsD+GY3wK/DdcaBoqKigrOOussAIqLi4mOjiYnxxbwffjhh8TFxQU8t7CwkIcffpi77rprQNaqKCOCgx/Aiq9DUhbMujDSqxn0DLnK4sFIVlYW69atA+D2228nJSWFW265pWN/W1sbMTH+f9QFBQUUFBQMyDoVZcTQWGUfK3YFP04BtOlc2Lj22mu54YYbOOGEE/je977Hhx9+yEknncSiRYs4+eST2b59OwBvvPEGF110EWBF5Itf/CJLlixhypQpaiUoSm9prrWPKgQhMewsgp8+t5kth2v69T3njEvjtovn9vi8oqIi3n33XaKjo6mpqeHtt98mJiaG1atXc+utt/LUU091OWfbtm28/vrr1NbWMnPmTG688UatF1CUntLsvgZU7I7sOoLhaoeo6EivAhiGQjCYuPzyy4mOtr/o6upqrrnmGnbu3ImI0Nra6vecCy+8kPj4eOLj4xk9ejQlJSXk5+uccUXpER1CMEgtgtKtcO/pcON7kD0t0qsZfkLQmzv3cJGcnNzx/Mc//jFLly7lP//5D/v27WPJkiV+z4mPj+94Hh0dTVtbW7iXqSjDD8c1VFcCTTWQkBbZ9fhSuQ/aW6BkU3Ah+PifMPUsSBsb1uVojGCAqK6uJi8vD4CHHnoosotRlOGOIwQARwehe6i1wT7WHgl8TGMVPHsTrH8k7MtRIRggvve97/HDH/6QRYsW6V2+ooSb5loQ9+VtMMYJWhvtY83hwMc0unt2OhlQYWTYuYYize233+53+0knncSOHZ42Sr/4xS8AWLJkSYebyPfcTZu0vk5RekVTDWRNg/KdgzNO4AhBdxYBeOIdYUSFQFGU4UdzLSSPhtamQSoEjmuoOPAxjZX2sak67MtR15CiKMOP5hqIT4WsqYNUCNxNI4O5hprcFkFT+C0CFQJFUYYfzbVuIZhmYwSmS/f6yOIdLA60NrUIFEVR+oC3EDTXQH2Z/+N2vQp1AfaFEydG0NoQ+ELvCMEAxAhUCBRFGX50uIbcOfr+3ENNNfCvy+y/tuaBXZ9jEUDggLETLFaLQFEUpYe0NdtirYQ0GyMA/ymk5TvAuODIOnjxhwO7RscigMBxgkaNEQwpli5dyksvvdRp25133smNN97o9/glS5ZQWFgIwAUXXEBVVdc84dtvv5077rij/xerKMMdp5gsPg0yJkBUrH+LoMw2fmT2xVD4AGx4wvrr97wJT1wDG/4dvjW2NkJcin0eyCJwgsVtjdDWEr61oELQLyxfvpzHHnus07bHHnuM5cu7HcnAypUrycjICNfSFGXk4fjU41NtU7fMKf6FoHw7RMfBp/8KE0+B575p+/88vAy2PGMH24SLtkbIdM8crwnkGqr0PA9znECFoB+47LLLeOGFF2hpsaq9b98+Dh8+zKOPPkpBQQFz587ltttu83vupEmTKC8vB+CXv/wlM2bM4NRTT+1oU60oSg/psAhS7aOTOeRL2Xa7LzYBLnsQEjKsW2nZ3TDrIji6J3xrbG2ExFGQmAm13biGIOxxgnCOqnwQuAgoNcbMC3LcccB7wGeMMU/2+YNX/QCKN/b5bToxZj6c/6uAuzMzMzn++ONZtWoVl1xyCY899hhXXHEFt956K5mZmbS3t3PWWWexYcMGFixY4Pc91q5dy2OPPca6detoa2tj8eLFHHvssf37PRRlJNDkZRGAjRPsWt217XPZdhh3jH2eOgZu3gBRMSACVQdg+0rrkokJPGGw17Q2QMJYSBsXuKissRKSsqGhPOxCEE6L4CHgvGAHiEg08Gvg5TCuY0Dwdg85bqEnnniCxYsXs2jRIjZv3syWLVsCnv/222/zqU99iqSkJNLS0li2bNlALV1RhhfeMQKwd/3tzVBd5DmmtdF2AM2e6dkWHWtFACBzqg0kVx3o21pc7VB1sOv21kaISYDUsYGDxU1VMGqifR5m11A4Zxa/JSKTujns68BTwHH99sFB7tzDySWXXMK3vvUtPvroIxoaGsjMzOSOO+5gzZo1jBo1imuvvZampqaIrE1RRhT+XEMAFTs9F9aKXYCBnJldTgdsXAGse6gv8wI2/htWfAO+uxMS0j3bWxshNsmusXhD1/Nam6zVkDERDq0d0hZBUEQkD/gU8JcQjr1eRApFpLCsLALFHyGQkpLC0qVL+eIXv8jy5cupqakhOTmZ9PR0SkpKWLVqVdDzTz/9dJ555hkaGxupra3lueeeG6CVK8owoyNY7LYIcufYTqQHP/Qc42QMdSsEfexcWrnfWiMNRztvb22A2ETrGqorhXafQVVOxpAjXGFOIY1ksPhO4PvGGFd3Bxpj7jPGFBhjCnJycgZgab1j+fLlrF+/nuXLl7Nw4UIWLVrErFmzuOqqqzjllFOCnrt48WKuvPJKFi5cyPnnn89xx/WfkaQoIwpfiyBxFIxbBLtf9xxTtt2KQ1aAu/3kbCskfQ0YO62kW+o6b29ttEKQOhYwdoBOp/PcQpDhCMEQDRaHQAHwmFifXDZwgYi0GWOeieCa+sQnP/lJjFffkEADaN54442O5/v27et4/qMf/Ygf/ehHYVqdooSJ1iZ4/mY4/bueAq5I0lxjawdiPNP+mHomvP1/9gKbmGFTR0dN7nyMNyI2vbPPQuBOAW2p92wzxuMaShtnt9UcgfT8rudljAdk+KaPGmMmG2MmGWMmAU8CXx3KIqAoI5ZDhbD+Udi6ItIrsTTX2qpiJ/ALVgiMC/a9bV+XbQ/sFnLInNJ3IWjwYxG0NQPGyyKgawqp4xpKzLSWzVCNEYjIo9i00JkiUiQi14nIDSJyQ7g+U1GUCHB4nX0sGyS1L07DOW/yj7OVvLtfs/74it2hCUHVga7++57gzyJw+gw5MQLoWlTmnJc4ygaZwxwjCGfWUPdltZ5jr+2Hz0O87wCGMWawtdRVRjZHHCHYFtl1OPgTguhYmHSaFYKje8HV2jl11B+ZU8HVZsWgty4vJ0bQ7GUROH2GYhMhKctWN/u2mXBiBIkZNlYxVC2CgSQhIYGKiooRcYE0xlBRUUFCQkKkl6Iolg6LYAe4us39CD9NNZ6MIW+mnmlrB3a8aF+HYhGAFY7e4tcicIQgybqvUsf4EYJKQCA+3VoEQ7WOYCDJz8+nqKiIwZpa2t8kJCSQn5/f/YGKEm6aa21Oflo+1BTZfxkTIrymGo/LxZupS+3jh/fbx+wZwd/Hu5agN7jaPXf23jECb9cQQOq4rkVljZXWGoiKsvGOmkO9W0OIDAshiI2NZfLkyZFehqKMPI5sAAwsuBze+b21CiIuBLX+LYKsaZA+HqoP2Mf4lODvkzLaxhV6KwRN1YDbS9EpWOwuLO0QgjFQssnn3Crb+wisRVC6tXdrCJFh4RpSFCVCOPGBBZ+xj4MhTuAvRgDWDTNliX3enTXgHN+XFFLv7qF+g8VJ9jFtnA0We7u2GyttoBg0RqAoyiDn8DqbAjl6FiTnDG4hABsnAMiZFdp7ZU7pfXWxdzVxS4BgMdifX2t95ziAU+8A7hhBbVjnLqsQKIrSe46sg7HuDp45syKfQtrWbFs6BBKCKUusYE0KXunfQeYUd5uItp6vpTuLIMYtBP5SSL0tgoQ0MO2d36OfUSFQFKV3NNdC+U5PK+ecmVYIIpm957SX8G7w5k1SJnx3F8y6MLT3y5xiU01riro/1hcndTQ+PXD6KPgvKvONEUBY3UMqBMrIob0V3v5dWO+sRhTFGwHT2SJorg7cX38gaPaZRdBXMt31A72JEzgWQXp+4PRR8NQolO+0jy5X1xgBhDWFVIVAGTkc/ABe/SnsejXSKxkeOPUDjkXgBGDLI+ge8m0411f6kkLacBQQSM8LHiNIybWFZU7mUEutbYfR4RpSi0BR+g8nV7uhIrLrGC4cWQcpY2z6I3gCsOGIE5Rth48e7v64/haC1DHWl1/RS4vAqQz2axG4hUAEcudCyWb3eV5VxeAlBGoRKErf6RCC8siuY7hweJ3HGgCbd5+QEZ7MocIHYcXXoaUh+HG+Yyr7ioitP9j7lrtZXA9oPGrv6uOSuxaURcd3HpuZO8/WCrjaO/cZArUIFKVfccr4fYeEDHcaq6C+n62g5joo3+GJD4C9aIYrc8jp11+xq5t1+Yyp7A9OvwVKNsLz3+5ZILyx0nYPjUvpahHE+rSIyZ1rBaJyn6fzqBMs7ogRqBAoiuXIBvj4X707dyS6hprr4P6lcP8Sj0vC4YN74eFLPBfPnlCyGRsoXth5e87M8FgEde72MeU7gh/nO52sP5j7STjj+7Dun/D+n0M/r8HbIqj39GFqbfAEih1y59rHkk1qEShKt3xwLzx7U+8agTkWQX2EXUNH98BzN/cuN92XDU8EvwN/+X/sz6rqALx7t2d7+U67b88b9ufZ05RPJ7A5Zl7n7TmzrND298+43hGCncGP6+8YgcMZP4BZF9mf2a7VoZ3TWGnTVeNTAOOpH3Cmk3mTM8tOTCve1DVGEJtgO5RqjEBR3NQeAQys/VvPz3UKdiJtEWx/0a6/r/NwWxrgP1+BNQ/437/jJfs5J38d5lxiU2eri+xF//lv2YvRKTfDlmfhv3/o2WeXbLZ33enjO293Onr2t3uovtQ+dpeR1FzbdTpZfxAVBZ+6F7Kmw+rbQzvHSQGNS7avHfdQW1NXiyA20cYiSjZ3tQjAPZNALQJFsTg56h/9w45IDBWXC+rc50Y6RuAEq31bD/eU0i02zdB3Hi7YO/Jnvwaj58KZ/wOf+Dlg7EVs/WN2UtfZt9t/cz9l02p3vxb6Z5dstu4M3xkgTuZQ0ZrefCP/tLd6Lo7dWgQ11hoIx2yS+BRbiFa6tfvAcXurXYsTIwDP78kZXO9L7lyPayg6vvMx8WlaR6AoHdQV23z1xqOwpQeTTRvK7ZCRmMTIZw05bo6+Fl4dWW8f/fn4X/4fG3T89H327njURDj5G7Dx37Dqe3Zi1+Jr7QVz2R/tBfzf18KBD7r/XGM8QuBL2jiYfLq1PnynboWCMTZzxhvn5xWfboPFvvu9ccZUhouxC+zfUemW4Mc57p2kzK4WgT/XENifZ9V+qD7Y2RqAoWsRiMiDIlIqIpsC7P+siGwQkY0i8q6ILPR3nKJ00NZs3TrzLrMm+pq/hn6uEyh2sjO6S0MMJ04GT18tAkcI/FVKH14H0z7R2Yd/6s2QlmePv+hO6+4Ae6e7/DFIyoaHl8G2lcE/t+qALXryJwQi9r3bm2HlLT2LPdSVwQPnwL8u99nudgtNONG6VaoPBn6PYA3n+oMxC+xj8cbgxzntJRJH+bcIYvwJwXz7uP9dP0KQNmRjBA8B5wXZvxc4wxgzH/g5cF8Y16IMB5wUwrSxcNx11v3gVLd2h3PRdS6MkYwTdFgEJX17n+IN9tGfa6ilrmu/nbhkuOpxe9H3DfKOmgjXvQyj58Djn4W1DwX+XKfwKXee//1ZU2HprbDteRt/CIWK3fDA2VD0oae1tYPz83IaxQVzDwWaRdBfjJoMcanuOQxB8PbzdwhBCBYB2L9zJ1DsMFQtAmPMW0BAZ6wx5l1jjNOe731AR24pwXEunKljYeFye1dVGCBQ6kuHRTCYhKAPFkF7K5S43RPNfoSgucb/4JUx82HGOf7fMzkbrn0epiy1WU2BXFeOEIyeHXh9J95kU0tXfrf7mEzRWvjr2fYiPvti+7vxttgci2DSqfYxWAppU3V4LYKoKCuixd0IQYO3ReC4hhyLoLFrsBhsT6L4dM953oyQGMF1wKpAO0XkehEpFJHCkTKOUvGDc+FMybV3TPMvhY1PBvcZe58rUZ6LVySFwPnsvsQIyndY90tMQleLwBgrDnHdTODyR1wyLPkBYKCo0P8xJZtg1KTgF9zoGBt7aCi3Kb/BePEH9g75uldsiiZ0Ht3oZAzlzLI9eYIJQbhdQ2DdQ8Wbgv/dORZBR/oo3VsETqsJ8BSTOQxViyBURGQpVgi+H+gYY8x9xpgCY0xBTk7OwC1OGVw4F06nbe/YY6y/tT6Em4OaI1ZAUnLt60gJQVuz586uLxaB45rIP66rELQ12f713Y1iDMSY+RAVA4c/8r+/dEtgt5A3YxfYi/fhjwMf43JZC2P2xdallJZnt3vHAerKIDbZilT2jMi6hsB+r9b64LUs/mIEzd4WgR8hAI8Q+AsWtzZYSzAMRFQIRGQB8FfgEmPMCCr3VHpFXbG9QCVl2dcdAz0OBz7HofawFRDn3EgJgVNolZBuha23vfuPrLfuhbELuwaLnQtOby+IsYk2VnBobdd9rY02c8dfoNgfufM8riR/VB+wF9XRc+zrdLeH2HtYe30ppLhvALOnDw6LAKB4vWdbW7PHhQXWIoiKsb8Db9eQMf4rix06hMDHIuhoM9GLKvAQiJgQiMgE4GngamNMN3XjioK9cKbkerJdOgZ6hHBnXXPECkdChnURDYQQrHsEHrqo8zbHesmdb107Tl+ZnlK8wV5kE9KtBeBdpdzivlj0xjXkkLfY3sk7bREcyrbZ2oWQhWCuHeriPa3LG2couyMEjrhXew2CqSuF5NH2efYM+zP0F3fobjpZf5EzyxateQeMV94CfznZ4y5y2kuI2KrgqBgr2G3NgAliEbgtLX8WAfT+76Ubwpk++ijwHjBTRIpE5DoRuUFEbnAf8hMgC/iziKwTkQAOSUVxU1vsaXkMPbQIjljhiIqyRT4D0WZi5yu2cMv7Ls75XCdrpzdxApfLpi+OXeB1t+n1GR1tFvoiBMdan7RvH/7uMoZ8cY4LZBU4252K5Jh4K/beQlBfZjubgmfmgb/mc+FoOOePmDg7o9lJIa0rtUV69WWeILL3YBkRd+O5Oq/B9QGEYOxCKLgOpp3debtTGxGmFNJwZg0tN8aMNcbEGmPyjTEPGGPuMcbc497/JWPMKGPMMe5/BeFaizJMqC22/e8dknNAoru3CFob7Z2UIyJJWQNjETgtJKq93BxOMdsYd854b+IEVftsnGHMgq6pieBxDfXFIhi32D76xglKNlu3xqhJob3PmG6EoHQrpE/oXASWlufHIvByDYGnhYWr3RMz6O/pZMEYs9Be9I2xLbLbW+z2ff+1j41H7Q2Hg9OB1HcWgS8xcXDR7yBzcuftYW48F/FgsaKETO2RzhZBVLR93V0Fq2MxOBZEcnb4hcAYTzDR9+4WPHfKvbEInEKysQs8d/3eKaQtfYwRgHV/xCbBIV8h2GQzr7x76QfDd/qWL6Vbu6ahpud7YgTtbfZ35VgEGROtq6V8hxWBp74EfyyAp7/iEdxwVhY7jJlvf5dV+21h4/Rz7FjLfe/Y/d4WAXhmEviOqQyVMI+rVCFQhgZtzfYuy1sIwLp7artxDTl33U5MISkz/EJQX+75T+s9+Ly+3F7IHBdHbyyCIxusz3n0nK5Vq9A/rqHoGOum8A4YG2PTJkOND4AnJbLYjxC0t9oLuj8hcJrjNVQAxmMRREXb5mzlO2zjvM1Pw4zzbOuMR66wxwyERTDWHTB+5TYrCCfeaOsc9r9rBarB3XnUId5tEbR1YxEEQi0CRcFTVewrBGljQ7AI3Psdi2AgXEPenUWrfYQgKRvikmzxUG8sguIN9o49Jt6/ELT0g2sIbJygeIMnZbGuxIpxqPEBh9z5nulb3lTsBlerJ1DskJZnfemNlZ4aAsciACuiO16Cj/4Op33HVktf97KXxTcAKebOz2DLM/Z3MWUpTDrNDo9xGsf5WgTNdd27hgIxVGMEyjCirQVWfg/uXBDWfidB8a0hcEgd1/1dtWMxdFgE2Tarwzcjpj+pcAtBVEznGEF9mXVNgRW1XrmGNngGwvhzDfWHRQAwbpHNSHIarG17wT468Y1QyZ1r74R98+6d9/VnEYAVUCclM9lHCDBw3JfhzB/bbfkF8JW34Qurglc89xcJaZ7B9ifeaC0fpwXGrldtSmwnIXBiBE6wuJeuoTBZBDFheVdl+FB9yHalLPrQvq7Yae8UBxrngukUhDmkjbUumOa6wBe+miP2P6JzV5WUZQuumqo6m+/9ydHdNpA9ZkHn4qiGcs8da2+EoKXe3iU7QdNwBYvB83s+9JENfL5ym73rHX9iz96nY/rWRsie5tleutX+jBw3mYN3LYFz4fO2CAq+YO/+F1/Tud10XBJMPLlna+sLTmbVfLdLKm2cFYetz9nX3n9bvjGCGJ9Rld0RFQ0TT/XUU/QzahEogSnZAvedYTM+znAXflcdiMxaglkEENwqcIrJHJw7cicXva0F/vEp2PNm/6wVrEUwaqLNrqkJZBGM7bkQdDQzc19kOoTAK320pc5W4oYa0A3EqEn2cw4VwnPftPUDy+721HGESs4se8H3zRwq3WKriX3n9/q1CLwugGnjrBj0dB39zfm/gS+/ZgXIYeIpnkyrLhZBXe8tAoAvvADHfan36w2CCoESmA2P2b7q178OJ91kt0VMCI50rip2SHNf4IPVEtT4ZBs5d2pOKmfJRjuUxXuUY0+or+j6+Ud32yyS9HxrVTkVxPUVPhbBkR4ORPcZY+jUEfi6hvrqFgJ7t5232I7D3P0qfOKnXdMaQyE2wVowXYTAT8YQWDdQVKwVgvpSe/c8EAHgnpKU2TWNdtJpnueJvhZBCOmjEUKFQAnM0b32Dz1nps1aSMiInBDUlXSuKnYIySI44gkkQtc2E06K5O7XPEPSQ6WlAf52Hvzj055txkDFHnu3m55vq13ry+2xrfWez08dY4OlPZmY5lSWJngLgXR2DbX0suGcP8Yttjnyk06zhU69xTdzqLXRFqv5BorB/o7TxrktgjIrDOGYOBYOnDgBdLUIWhs8v6feWARhRIVACUzl3s53gBkTImsR+MYHoHuLwOVyVyR7uYaSHNeQWwgOr7OjAU27TUfsCatvs6mMZVs92UF1JfaC71gEYOMEjgXibRGAZ4RmKPjOs/WuWnXoL4sAYOb5NjjcG5eQN7nzbF8hx+dftg0wgQO7Ti2Bd5+hoUB6vsdK8I0RgOdvTi0CZUhgDBzdZwdxOGRMgMr9kVlPbUnX+ADY/2AJ6Z0tgn3vwK8mwuqf2ipcV7RGiJwAACAASURBVKt/i8Bp93D4IzteMXe+dYOEys7V8OF9nnYATozByRjKmuLppllzyFNM5h0jgJ7VEvi6hsCdmujdYqLODk/pD/IWww3v9M4l5E1Hqwl3ppBvjyFfnFoCxyIYSjhzE7wtAkeYnZiHCoEyJGiosAFI7wvAqEnWIuhtx0xf2lrgqS/Dx//s/ljfqmJvUsd1tgi2r7KZRO/8Dv7i/k/pLSJxSe7ZxRXWVC/bZi94Cy63gdGK3XRLfQU8+1XImQ1X/tPe5e95w+5zaggyp0L6ePu8usgjPL4WQU8Cxr6uIfAUKzm0DEAHzp7iZA45VdGlW6wVNiqAwKTl2d9p7ZGhZRGAHcpz1k88VgB4XHX1Ze4mdH0M5PczKgSKf5ycb1+LoK0xtIZtbc3wz8u6tihwMAZWfB02PtG9EASqKnZIG9v5rrpoje3T/+XX3Pn24mlq5uC0mTiy3mbDjFtkZyEjtkq1O175iXXTXHq/vbubfIYVAmOskETFWhFIyrTBzk5C4LYInL5JPbIIKm0GjveFvotrKEgqbaRIG2cF8MXvw12LYcO/IWeGrWD2R3q+ddU1lA89iyB3ji1088YRhfryQWcNgAqBEgin66RvjABCixNU7oddrwS+yL/5a5uVlDrOXoy92yj7Eqiq2CF1nKd6uK3F+vzzj7N53l9YCbfs7CoETpsJR6jGLYb0PGvWb3iie6vn0FrbX8YprpqyxPqzS7dai2DUJHuRE/G4ORzXkBOjiE2wd/Y9sQgaq6xbqFP+vK9F0I/B4v5CBD6/As6+3aaTgm0NEYh0r8m1KUNMCPzhbREMskAxaEGZEojKvYDYJl8OHUKwH/K7KSpzAqOOu8Sb9Y/DG/8LC6+CqUvh6S9b94zvQHWHjmKyIBZBXYltYVC80Wbp5B9n94n4dy04bSYOf2zdEKnuQPSCK6ylcuij4N+xrqRzhsiUJZ7v62QMdazP3U0zY7x1SXm7DHpaS9BU1XWMYXxKZ9dYfwaL+5PcOfZfKHgLwUC0jAg3HUJQDslZwY+NAGoRKP45utea897FPo6/OxSLwLn7Pbq78/HNdfD8zbZK8uI/eKpXA41FBK+mcYEsgrHWjVBX6qmAdoQgEEnZ9j/l4Y+sW8hh9jLretnxYuBz21qsq8o7iyljvI0J7H7NWlOZXkKQPt4dLC63biHvu/meVhc3VnadXuXtGmpvs20h+itYHCmcIDsME4vAqfeoHpQWgQqB4p/KvZ5eKg4JaTYTIiQh8IojeFfs7njR5lOf+SPbez1zis368TcW0aHWcQ35yRoCT0ZQ7WEbH0jLs26eYCRlWYE5uscGih0SM+yFJ1iBWkcjNJ901ilLYM/rNo6S5fWzS8+zF/uaw574gENPLYLGqq7Tq5xiJfBUGA+2YHFPSUj3iNlQixH4w9sK1BiBMmRwisl88a0lqDlig8Le81rBky+dlN3ZPbTpKevTd/rViFj/fFAhCFBV7JDqVUtwcI1tQNYdyVmeYSLeFgHYC7wTl/C7nhLPcd5MWQIud6wj08c1hLFuK183R+oYW0cQagM8v66hVE9lcce84kHoGuoJIh4xH2pZQ/7w/n2MJCEQkQdFpFRE/E6kEMtdIrJLRDaIyGJ/xykRoLnO3vX6yx3PmGhjBA6b/2ODwkVrOh9XX2bbLE87ywqBy2XvZnethrmf6lyclHeszS93yu99ObrH3XYgwJ+rYxEcXmeLlvKP7/47eouKrxA4F+dAOCLh67KYfBrgdvt4xwgcf3fjUU+g2PuzXG2ht8X26xpKtgVsLlf/taAeDKTl2VRLX+EbisR6WQQxI0gIgIeAIGkBnA9Md/+7HvhLGNei9ITKffbRX463YxE4WTV7XrePvu4Nxx8+ZYkNHJdusW2M21tg3qWdj81bbH383sPAHYrWwtYVMPuirvsckrJtuubWFfZ1d/EB8AhB5pSurpaU0Z67fn8EymJKHGVFJToe0ryCnZ0Cn36EAEJLIXW5bGVuF9eQ+6LfWu/VgnqIu4bApv7mzBo67SWCERNnRQ1GlkVgjHkLCNZE5RLgYWN5H8gQkQBOYGVAqXTXEASyCNqa7B1/W7NnNF8X15BbCCafYV/vecO6hTImdvbJQ+CAcXurzeBJGePpO++PqCh7QS3fYQXB6dUfDOfOfJwfQzRljP1+gVJaHSHwl81y0k1wwlc6Wy/egU9fIXD2hSIELbW25sFf1hBYS84RguFgESz9EXxpdaRX0X84cQINFnciD/Bq1E6Re1sXROR6ESkUkcKysh42BVN6jr9iMgfvWoKDH3ja6vq6UpxJXOl5tt/85v9YMZj36a53eKlj7AXRN07w3z9A6Wa48I7u59A6cYKxC7q2NfaHc0H2dQuBO5XUeFJgfakrsRZFdGzXffMvg3N+3nlbfIrn4u0rHo5by7tVdSA6+gz5yRoCGzDumFc8DCyC6Bg7hW244AS/R5JF0J8YY+4zxhQYYwpycoZB4GiwU7nXuh98LzjQuZZg92s2iDtqUldXiuMaAuseOlRo3T9zP41fxi3qLATlu+DN38CcS2DWhd2v2Wk+F0p8AKw4XXAHLL66676Ublo/1JYErmkIhJN66xsjSMm16arVoQiB02cogGuopXb4BIuHIx0WgQqBN4eA8V6v893blEhzdG/gHjDeFsHu1+yFN3Nq5ywbl8sGP72FACBreuAxh3nH2qBww1Hbx+fJa21rhvN/E9qanXbUoWQMgbVKjv+yZyi4N042UKDMobqSnue2Oxkwvq6hqGhrEQVLV3Xw12cIOruGOoLFw8AiGG6oa8gvK4DPu7OHTgSqjTE9aLqihA3f9tPexKdYt8ihj2xriKlnurNsvC6aTVX27t+5+510qs2aWHhl4MCfEzfY8SI8dAGU74TLHghcROaLI1DjQ7QIgpHanRCUhr4uBydg7C+ukDauj64h9wWmpd422wO1CAYjzu8kFNflABO2FhMi8iiwBMgWkSLgNiAWwBhzD7ASuADYBTQAXwjXWpQe0N4KVQdh/uWBj8mYYDt8ghWCbc+7Wzy4bJDUt7laQjp846OubhFvHF/9M1+1F7bPPulOxwyRxVfbDpeOIPQFxyLwlzlkjI2H9NQiGD3HptMGEgKnPXMwGgNYBM7df0udtQqi44aXb3244LjwBqFFEDYhMMYs72a/AW4K1+crvaTqgL2bD+QaAnuxPfyxvSCNO8bWELja7B1rcpbXABavC393d9AJ6TB6rr0z/txTobt4HOJTYcoZPTsnEDHx9rv5qyVoqrIpsP6G5ATj2Gtt/YS/u8G0PDvbwJjgqZJNgWIETvuC2sHZcE6xDOIYgTadUzoTLHXUwbnrnrLE7eN2XCnFVgh8u2yGyvJHbSaO9xCZSBGoB1CgquLuiIruPLHKm7Rxtgagqdp/gN6hscre7fteSOK9soYGYwtqxaIxAmXIECx11MHpSDr1TPvom2Xj6xoKlVETB4cIgLvNRGnX7XW9FIJgdKSQdhMwbqy0loqv1dCRNeQOFmugeHDS4RoafBaBCoHSmZJNNrAbzJUz8RTrxnH6yTv+cufC6d1naKgSqM1EXYCGc32hY5xlN0LQ5KfhHFhrIybRuoaaa9QiGKwMYiFQ15Dioa0ZNj9jB5YH81XnzoGvvut57TuE3ekzFBMXvrWGG6fNhK/f3vmOqeGwCLrJHHKG0vjDGVfZXBfYBaVEFsc1NMJ6DSlDjR0v2bvOY4LG+bsSl2zdEY7/fJAO3+gRKWPsgJum6s7b60psfUN8N5XOPf0sJHTXkD+cmQQaLB68DOJgsQqB4mH9o/aiNGVpz89NGe3xnzeUD/2pUh1Wjk8KaW2Juxq4HxuhxcS5ZyB0YxEEcg2BZ1ylBosHL44LdRBabCoEiqW+HHa+bEc1RkX3/HzvojKnz9BQpqOWwCdOUFfSv/EBh7RxIVgEQbKK4lO80kc1WDwomXEefOlV/3M+IowKgWLZ+KStBTjmqt6dn5LbOWtoyLuGAlQX15WGZ3RiWl5wIXC12zGHAV1Dye5g8SCdV6zYG6ye1scMECoEimX9IzD2GBg9u3fnO+mWHX2GhrprKJAQFPe8vUQodGcROLGKYK6h+jLADI/Oo8qAokKg2PYGR9bDwh4Gib1JzbXdL2sOde4zNFSJT7PZHd6uobZmG7ANl2uoudozT8CXQH2GHOJTPKKlwWKlh6gQKDZIHBVje+n3FqeorNTdM6enxWSDDZHOAXAITw2BQ0ctQYC+i4H6DDnEpXjmJatFoPQQFYKRjqvdxgemfaJvF2/Hb1680T4OdSGArm0mwioE3dQSNDkWQRDXkL/nihICIQmBiCSLSJT7+QwRWSYifsYzKb2mtcnm8fcHq2+HZ78GW1ZAU03wY/e9DbWHbYvovuD4zUs228eh7hqCrm0mAg2t7w+6azPRMZQmiGvI33NFCYFQLYK3gAQRyQNeBq7GDqdX+ostz8AjV9jhLH3BGHj3j/DxP+CJq+E3k+GZmwILwoYnrD/caRfRW4abawi6tpnoqCoOQ7A41UcIGqvgqS95ej85MYJgriEHdQ0pPSRUIRBjTAPwaeDPxpjLgbnhW9YIxOnYGWg8Yqg0HAVXK5zzC/jCKii4zmYE3XsaFPnMBG5psFbDnGV9r3ZMHGXjDOU77ethYRGMttk6rY32tWMdhCMjKjbBDvxxXEMf3g8b/w1rH7Kvm7qxCDq5hlQIlJ4RshCIyEnAZ4EX3Nt6UXWkBMS543MEobfUuoON6eNh4slwwW/g2pU2FvDgOfDBvZ5jd6yymT4L+ugWAjuQJiXXZgwN9T5DDo6V4whAbXHgofX9gZNC2toIH9xjt219zlp5jVW2fXGggTNO+wJQ15DSY0IVgpuBHwL/McZsFpEpwOvdnSQi54nIdhHZJSI/8LN/goi8LiIfi8gGEbmgZ8sfRjg+4D4LgeO+GOvZNvEkuOEdmH4urPqe5y5zwxM2W2XiqX37TAcniDrUi8kcfNtM1JX2fGh9T3CKyj7+p23TMe8yOLobyrZZiyCQWwg6X/w1WKz0kJCEwBjzpjFmmTHm1+6gcbkx5hvBzhGRaOBPwPnAHGC5iMzxOex/gCeMMYuAzwB/7vE3GC44FkFdP1kEvn7sxAy4/CGbHfT8t2DNA7BrtU0Zjeqn5LEOIRjixWQO3m0m2tugcl94AsUOaeOg+iC8ezfkHwfn/hIQaxUE6zwKXu4g6WwdKEoIhJo19IiIpIlIMrAJ2CIi3+3mtOOBXcaYPcaYFuAx4BKfYwzgtHFMB7pptjKMaepvi8DPnWtMHFzxsL3IvPBtm3feH24hB6cadzjEB8AjBAc/gL+dD6WbPcN4wkHaOPt3ULUfTrnZ/g7HnwBbV7iFIEDqKHgu/vGp/dsQTxkRhHorOMcYUwN8ElgFTMZmDgUjDzjo9brIvc2b24HPuYfbrwS+7u+NROR6ESkUkcKysj5eKAcr/eYaOmIvGAF9yUlw1eMwZj7kH28HvvcXjttkuLiGkrNBouC9P0LZdrj0ATglqCHcN5yisuwZMNPtJZ19sa3NKN0SmmtI3UJKLwhVCGLddQOfBFYYY1qxd/N9ZTnwkDEmH7gA+IdTr+CNMeY+Y0yBMaYgJ2eYuB186QgWl/ftfWqLO8cH/JE4Cq5/E65Z0bfP8sVxmwwX11BUNOQda2MoN77Tt8rrUHDGg57yTY+7bvZF9rHxaDeuIbcAaKBY6QWhTii7F9gHrAfeEpGJQDeVShwCxnu9zndv8+Y64DwAY8x7IpIAZAN+hsUOc/rNNXQktDz3qGiI6ucBGc7nDhfXEMB1rwycq2XCiTbld8JJnm2jJsGYBVC8oRvXkFoESu8JNVh8lzEmzxhzgbHsB7qbXrIGmC4ik0UkDhsM9r0FPQCcBSAis4EEYJj6foLgcvVv1lB3FkG4cIRguFgEMLD+dhGb8uv7mbMvto/BXEMxcRAdp8VkSq8INVicLiK/c/z0IvJ/QNDUBGNMG/A14CVgKzY7aLOI/ExElrkP+w7wZRFZDzwKXGuM6Q+X09CiuQYwkJBuLYO2lt69j6vdpjqGo/I1FMYugvN+ZWceK/3HbPd/l+4yluJSVAiUXhGqa+hBbLbQFe7XVwN/w1YaB8QYsxIbBPbe9hOv51uAU0Jd7LDFiQ9kTYdDhbaff1ov7uobKmxBV6QsgqgoOPHGyHz2cGb0LOuiGjM/+HGpY8LTEE8Z9oQqBFONMZd6vf6piKwLx4JGJE58IHuGFYL6st4JQaAaAmXoM/747o/57JNaQ6D0ilCzhhpFpKP8VEROARrDs6QRiBMfyJ5uH+t7GSv3V1WsjBzS84JnFilKAEK1CG4AHhaRdPfrSuCa8CxpBOK4hrJn2MfeppCqRaAoSi8ISQiMMeuBhSKS5n5dIyI3AxvCubgRQ5OvRdDLzCHHIlA/saIoPaBHTWaMMTXuCmOAb4dhPSMTxyLImGBTAHstBEds6ma4umMqijIs6Uu3MW1o0l80VkFMgp0JkJwT2DXUXAcrvmGbn/mjtljdQoqi9Ji+CMHIy/cPF42VnmKh5OzAFsGa++Gjv9tulP6oPaKBYkVRekzQGIGI1OL/gi9AP/cnGME0eXWWTM7xLwTNdbY9MUDpNv/vU1sMYxeGZ42KogxbggqBMUbLFAcC717zyTm206UvhQ/YgrHUsVC2tev+9jY7OEUtAkVRekg/TSRR+kRjVVfXkHenjZZ6+O9dMGWpbTdQtr3zfnDXHhiNESiK0mNUCAYDvq6htiZorvXsL3zQji5c8gPbbqClzk6y8sapIQjnKEVFUYYlKgSDgcZKL9eQu7GYEydobbTWwOQzbJvinNl2u2+cINhkMkVRlCCoEESa9lZ7h+9tEYAnhXTXauv2OfVm+3r0LPvoGyfoqCrWGIGiKD1DhSDSOH2GvGME4LEI9rwJscl2ShZYwUgZ498ikKjhNQtAUZQBQYUg0jjtJbyzhsAjBHvftMNKYuI854ye5d8iSB4N0aG2j1IURbGoEEQaxyLocA05FkE51ByG8h0w5YzO5+TMtplDLpdnm1YVK4rSS1QIIo3TZ8hxDcXEQ3y6tQj2vGm3TVnS+ZzRs6C1AaoPeLZFckSloihDmrAKgYicJyLbRWSXiPwgwDFXiMgWEdksIo+Ecz2DkiYfiwA8tQR734SkLBg9t/M5/jKHQh1aryiK4kPYHMoiEg38CfgEUASsEZEV7vGUzjHTgR8CpxhjKkWkm6GswxDHIvAeKOK0majYDZNPtyMgvcmZaR9Lt8DM8+DIBlt1nDV1YNasKMqwIpwWwfHALmPMHmNMC/AYcInPMV8G/mSMqQQwxvRyNNcQxjdrCKxFcPhjqD3c1S0EVjRSx0GZ2yJ4/f/ZwfeLrg73ahVFGYaEUwjyAO/y1yL3Nm9mADNE5L8i8r6InOfvjUTkehEpFJHCsrJe9uofrDRVQVxq52yf5BxbWwC2kMwfo2dD6VYoKoQdq+Dkb+iYQkVRekWkg8UxwHRgCbAcuF9EulzNjDH3GWMKjDEFOTnDLE/eu6rYIcXtIcuYAJmT/Z83erbNKHr1ZzaOcMIN4V2noijDlnAKwSFgvNfrfPc2b4qAFcaYVmPMXmAHVhhGDt6dRx2cWoIpSwKflzPL9iTa+yac+m2ITwnXChVFGeaEUwjWANNFZLKIxAGfAVb4HPMM1hpARLKxrqI9YVzT4MN7KI2DU0sQyC0E1iIAW2V83HXhWZuiKCOCsAmBMaYN+BrwErAVeMIYs1lEfiYiy9yHvQRUiMgW4HXgu8aYinCtaVDi3XnUYcoSOOlrMPP8wOeNnm1F4Ozb7IhLRVGUXiLGt6/9IKegoMAUFhZGehn9xx0zYMa5sOzunp9rDIiOjlYUpXtEZK0xpsDfvkgHixXvoTQ9RUVAUZR+QIVgIKjcDzte6jpVrLUR2pu7uoYURVEGEBWCgWDV9+GRK+A/X7FjJx38VRUriqIMMCoE4aa5Dna/BtkzYcMTcP+ZnuH0vp1HFUVRIoAKQbjZ/Zp1/1x4B1z9H9te+v4zYe/bXTuPKoqiRAAVgnCz7QV7oZ9wMkxdCl95C9Lz4Z+XwsYn7DHqGlIUJYKoEIST9lbY8aKtB3B6CaXnwRdWQe5cWPuQ3aauIUVRIsiIEQJTW8KR534BrvaB+9D979qCsVkXdt6elAnXrIBJp0FULCRlD9yaFEVRfBgxA27fe+1ZTv74txxMm8D4Mz4/MB+67QWISYCpZ3bdF58Kn3saqg9qnyBFUSLKiLEI5p1zDdvNROLf+TW0t4XnQ1Z8Ax48z9YNGGOFYOqZEJfs//iYOB0moyhKxBkxQpCWGM+66TcxurWIqvf+3v8fUF8O6/4FB96D+86A/94JNUUw84L+/yxFUZR+ZMQIAcApF3yOda6pyFu/gbbm/n3zTU+Dqw2u/Bek5cHq20GigjeOUxRFGQSMKCHIz0zm7fE3kt5STNMHD/bvm294DHLnw+yL4LpX4LgvwXFf9rSUVhRFGaSMKCEAOP3cy3jfNRvXm3fA9lVQW+z/wMZKOPgh1IUwRrl8JxxaCwuvtK/jkuDC/4MLftN/C1cURQkTIyZryGHhhFH8MPsGFh79Hjz6GbsxJdemcMYlQXQ8HN1jB8c75M6zQ2LikqwwNFTA3E/B/Mvs/g1PWDfQvMsG/gspiqL0kREnBACfOOd8Fj+UyklJh7l6QgUnJh8hsb3ONoRra4LJp8HoOZA93fYF2vM6rLnfxgCSsiEqxmYEudpgwZWw4XErFGljI/3VFEVResyIFIIzZ+XywJfO4IF39vLF7aXERAk3LZ3G15ZOIybax1s260I47dvQ1gJR0fZfaxM8cjk8cyMUb4Sq/bD01sh8GUVRlD4S1hiBiJwnIttFZJeI/CDIcZeKiBERv9NzwsHJ07J54NrjeP07Szh/3ljuXL2TS+95jz1ldf5PiImzIgAQmwCfeRTyj4f3/gixSTDrooFauqIoSr8SNiEQkWjgT8D5wBxguYjM8XNcKvBN4INwrSUYk7KTuWv5Iu5evoh95fVceNc73PPmbprbumlFEZ8Cn33Czhc+/staHawoypAlnBbB8cAuY8weY0wL8BhwiZ/jfg78GmgK41q65eKF43jp5tM5ZVo2v1q1jXN//xavbi0h6EznhHT4/LPwiZ8N3EIVRVH6mXAKQR5w0Ot1kXtbByKyGBhvjHkh2BuJyPUiUigihWVlZf2/Ujdj0hP46zUF/P2LxxMdJVz390JueuQjqhtaw/aZiqIokSZidQQiEgX8DvhOd8caY+4zxhQYYwpycnLCvrYzZuTw4s2n891zZ/Ly5hLO/8NbfLCnIuyfqyiKEgnCKQSHgPFer/Pd2xxSgXnAGyKyDzgRWDGQAeNgxEZHcdPSaTx148nEx0bzmfvf5y9v7A7uKlIURRmChFMI1gDTRWSyiMQBnwFWODuNMdXGmGxjzCRjzCTgfWCZMaYwjGvqMQvHZ/D810/lwvlj+fWL2/jlC1txuVQMFEUZPoStjsAY0yYiXwNeAqKBB40xm0XkZ0ChMWZF8HcYPCTHx3DXZxaRnRLPX9/Zy9GGFn54/myqG1upbmxh9tg0kuJGZEmGoijDABlqro6CggJTWBgZo8EYw92v7eJ3r+zotH3WmFSe/dopxMdER2RdiqIo3SEia40xfl3vehvbA0SEb5w1nfl56eyvqGdUchwVdS387Pkt3P3qLm45d2akl6goitJjVAh6wdJZozu93nKkhr+8uZtz5uayID8jQqtSFEXpHSOuDXU4+PFFc8hJieeWf6/vviI5AOsPVnHR3W9T3ag1C4qiDCwqBP1AemIs/3vpfHaU1PH7V3b26j1e2lzMpkM1fHygsp9XpyiKEhwVgn5i6czRLD9+PPe8uZvXtpX0+Pz1RVUAbD5c099LUxRFCYoKQT9y28VzmTM2jW89vp6DRxtCPs/lMmwoqgZg8+HqcC1PURTFLyoE/UhCbDT3fO5YjDHc+K+1NLWGFi/YW1FPbVMbcdFRahEoijLgqBD0MxOykvj9lcew6VANtz27OaSWFBvcbqHz5o1hf0UDNU0aMFYUZeBQIQgDZ83O5WtLp/F44UH+9cGBbo9ff7CapLhoLjlmHABb1CpQFGUAUSEIE9/6xAyWzMzhp89tpnDf0aDHri+qYl5eekcNwqZDGidQFGXgUCEIE9FRwh8+s4j8UUnc8M+PKK72P3enpc3F5sM1HDM+g5zUeEanxqtFoCjKgKJCEEbSE2O57+pjaWxp44sPrfGbSbSjpJaWNhcL8tMBmJeXzibNHFIUZQBRIQgz03NT+dNnF3OwsoEL/vA2z60/3Gn/uoM2ULzQ7RaaOy6NXaV1NLb0rkJZURSlp6gQDABLZo5m5TdOY1puCl9/9GN++PQG2t0zDTYUVZGZHEf+qEQA5o5Lx2VgW7G6hxRFGRhUCAaI8ZlJPPGVk7jhjKk8+uFBbluxCWMM6w9WszA/HREBrEUAWmGsKMrAod1HB5DY6Ch+cP4sDIZ739xDSnwsO0trOW/emI5j8kclkp4YqxXGiqIMGCoEEeAH582irLaZe97cDcAx4z2tq0WEuePS1CJQFGXACKtrSETOE5HtIrJLRH7gZ/+3RWSLiGwQkVdFZGI41zNYEBF+fekCzpiRQ0yUdGQMOczLS2fbkVpa210RWqGiKCOJsAmBiEQDfwLOB+YAy0Vkjs9hHwMFxpgFwJPAb8K1nsFGbHQU933+WFZ+8zSyUuI77Zs7Lo2WdldH6wlFUZRwEk6L4HhglzFmjzGmBXgMuMT7AGPM68YYJ7n+fSA/jOsZdMTHRDMjN7XL9qWzRpOWEMNf3tgdgVUpijLSCKcQ5AEHvV4XubcF4jpglb8dInK9iBSKSGFZWVk/LnFwkpYQy/WnT2H11lLWH1SrQFGU8DIo0kdF5HNAAfBbf/uNMfcZYwqMMQU5OTkDu7gIce0pk8lIXlXRxQAAEr5JREFUiuX3q3dEeimKogxzwikEh4DxXq/z3ds6ISJnAz8ClhljmsO4niFFSnwMXzl9Km9sL2Ptfh1fqShK+AinEKwBpovIZBGJAz4DrPA+QEQWAfdiRaA0jGsZknz+pIlkJcdxp1oFiqKEkbAJgTGmDfga8BKwFXjCGLNZRH4mIsvch/0WSAH+LSLrRGRFgLcbkSTHx3DDGVN5e2c5/3h/f6SXoyjKMCWsBWXGmJXASp9tP/F6fnY4P384cPVJE/nv7nJ+/MwmdpfW8T8XzqbdGJ75+BCPrznIV86Yyrlzx3T/RoqiKAGQUEYpDiYKCgpMYWFhpJcxoLS7DP9v5VYeeGcviydkcKiqkZKaZpLiogF45qZT/KahKoqiOIjIWmNMgb99gyJrSAlOdJTw44vm8OtL57PpUA3TRqfwz+tO4PVblpAUF8MN/1hLrc45VhSll6hFMMRoaXMRF+PR7w/2VHDVXz/g7Nmjuedzx3Z0MVUURfEmmEWgTeeGGN4iAHDClCxuvWA2P39+Cyf+76tkp8STlRLP8ZNGcUXBeEanJURopYqiDBVUCIYBXzxlEnHRwoaiairqWyiubuKOl3dw5+qdnD07lxuXTGWhV4dTRVEUb1QIhgEiwtUnTeq0bU9ZHY+tOci/Cw/y8pZiblo6ja+fOb2LRdHflNQ0kTuMrJDfvbydheMzOGt2bqSXoihhQ4VgmDIlJ4VbL5jN186cxs+e28Ldr+3itW2lXHnceA5XNVFU2UBGUiyXHzueBV4T0vrC69tL+cLf1vDTZXO55uRJff8SEWZHSS13vbaLMWkJnDo9m/iY6EgvSVHCgmYNDXPSEmK54/KF3Hv1sRRXN/GTZzfzwDt72FBUzZNri7jkT//l/D+8zeNrDuBydU4cOHi0gRc3HSGUhIKWNhc/f34LAL97ZQdVDS1h+T4DySMfHEAEimuaeGLNwe5PUJQhiloEI4Rz547htOnZ1DS2kZMaT3SUUNPUyop1h3n0wwN8/6mNPLm2iF9duoAJmUk88M5e7ly9g6ZWF+fMyeWOKxaSlhAb8P0ffm8fe8rq+d55M/ntS9u5+7Vd/Pgi3/ETQ4fGlnae+qiIixeM41BVI39+YzdXHDderQJlWKJCMIJIioshKc7zK09LiOVzJ07ksydM4KmPDvHz57dw/h/eJj8jkT3l9Zw7N5cF+Rn8/pUdLLv7He5evpi8UYm0tbuIiY4iMzkOgPK6Zv7w6k6WzMzhq0umcaCigYff28fnTpzI5OzkCH3bvvHchsPUNrXx2RMm0NLu4uoHPuSJwiKuPnFEDNFTRhgqBAoiwmXH5nP6jGx++twWNh2q5r6rj+Ucd+uK4ydnctO/PuLiP77T6bzjJ2dyZcF43ttTQWNLO/9zobUAvn3ODFasP8yvVm3l3qv9pi0Peh754ADTRqdw/ORMABZPyOAvr+/iioL8QWkVNLa0c8u/1zM3L42vLpkW6eUoQwwtKFNCoqy2mRc2HAYgNiaKo3UtPPVREfsq7IC5606d3MkV9MfXdnLHyzs4dVo2mclxZCTFMiopjqyUODKT48hOiScnNZ7s5Hg2Ha5m1aYjvLy5hNjoKM6dO4Zz5+ZyzIQM4qKjEBHaXYaK+mZKa5opq2umprGVqoZW4mKiOHPW6H7NVNp8uJoL73qHn1w0hy+eOhmAt3aU8fkHP+SWc2Zw09Jpg6pwr7XdxQ3/WMur22wD37uWL2LZwnERXpUy2AhWUKZCoPQaYwwf7D3Ke7sr+NJpk0n1iiE0tbbz42c2saO0juqGFiobWqluDNwGIzE2mqWzcmhpc/HWznJa2lwd++JjomhzGdpd/v9WReDYCaM4a3YuU3OSmZCVREZiHFuLa9hYVM324lqO1rdQ3dhKQ0sb00ancsz4dBbkZzAuI4FRSXFkJMXR7jI0trTzy5VbeHbdYT689WzSk2I7vuu1f1vDmzvKKJg4ih9fNIeF4zOoaWplT1k9LW0u8kclkpuWQHRU70RiX3k9Gw5VMzEziVljU0OyPFwuwy1Prufpjw5x28VzWLnxCBsPVfP0jacwZ1xar9YxEOwtryc5PprRqcMn1bg7qhtaeXd3OWfOHt0rq/KFDUdYPDGDsemJvfp8FQJlUNDW7qKyoZWj9S2U1zVTVmv/jc9M4owZOSS6m+jVNbfxxvZS9pXbC2xzm4uYaCE3LYHctASyU+LJSIolPTGWyvoWXtxUzMpNxWw9UuP3cydmJZHjPic+JpqtxTXsKasPutZLF+fzf1cs7LSt3WX4d+FB7nh5B+V1zWSnxFNe13mWUkyUkDcqkYlZyUzKSiItIZbDVY0UVTZSXt9MXHQUCbHRJMZGk55ovwPAe3sqOHC0odP7TM9NJS8jgaxkaz1Nz01hYX4GE7OSqGlqY/3BKp5Zd4inPzrEtz8xg2+cNZ2y2mYuvvsdYqKFp248mfTEWETosKwC0dTaTk1TKzkp8T22dspqm3l3dzkxUVGMSo4lMzmOKdkpfmtWymqb+d0r23l8zUGS42L42Sfn8slj8vx+ZnF1E5UNLcwakxrSmtraXRTXNJGVHN/xtwT276mstpn8UYnERnvWZIyhqLKRyoYWmlpdNLe1MzY9kSnZyUT1Usz9YYxhxfrD/Pz5rZTXNTMlJ5mfXzKPU6Zlh3S+y2W44+Xt/PmN3Vx94kR+/sl5vVqHCoEyIqhqaGF/RQMHjjZQ2dDCjNxU5o5L62SpOFQ3trL5cDXldS1U1rdQ2dBCTJSQGBdDSnw0n5gzpiMY7ktdcxt/fXsPhyobmTo6hak5KcTHRHGoqpGiygb2V9h/+8rrqW9pY2x6InmjEslOiaO13dDU2k5ji73wVjW00tru4tiJozh9Rg6Lxo/iYGUDmw5Vs+VIDaU1zZTXNVNR39JhESXHRVPf0g5Ya+j606bwg/NndVws1x+s4vJ73+tkVaUmxDA/L535eemMy0ikoaWdhpY2iqub2HS4hp0ltbS5DGkJMcwck8q00SmMSUtkTHq8FdyGVirqmqlutO64pLgYXC7DmzvKWHugEt/LSEJsFAUTMzlhciYpCTHUN7dRXtfCk2uLaGpt57MnTGDz4RoK91dy4fyxbnebFdsNRdU8u+4QH+47ijGQl5HIefPGcPqMHEanxpOVHEd0lLCnvJ5dpXVsL65l46FqNh+upqnVfueMpFiykuMor2vpsEQTY6NZPDGDY8ZncOBoIx/uraCkputQxLSEGBaOt4KblhBLakJsh2hnJMVS09jKliM1bDlcQ6vLcPykUZw4JYtpo1OobWqjutFav0frWzha38LqrSW8vbOcBfnpXHX8BP7y5m72VzRw/rwxLJmZwzT331BaQmwXAaptauVbj69j9dZSlh8/np8um9frolAVAkWJAMYYXIZeu4q8aW13saOklo1FViBy0xI4ZnwG8/PT/ab1rt1fyZp9R3EZg8tlOFLdxMZD1Ww7UktLu71YikBWcjxzx6UxLy+N7JR4dpXWsaOklt1l9Ryt71oLkhgbTUu7q0OU5oxN45y5uZw1K5fYGOFofQtltc18fKCK9/dUsK24tuPcuOgoTp+Rww8vmMXUnBTaXYZ73tzN71/ZQZuP229KTjKXLMxjTHo8L20u4Z2d5R3r9remeXlpLMjPYGpOCpUNLRypbqSiroXslHjyRiWSmRzHlsM1fLD3KNuKaxidGs8Jk7M4bnImY9MSSIyLJi4mir3l9Xx8oIqPD1RSUtNEbVNbl7WB/Z1OzUlGELaX1PpZlYfU+Bi+c84Mrj5pEtFRQlNrO/e+uYd739pNg1vQHRJircjGx0QRGx1FXbMVltsunsPVJ07sU2wqYkIgIucBfwCigb8aY37lsz8eeBg4FqgArjTG7Av2nioEitJ7Wtpc1Da1khQXQ0JscHdRc1s7ZbXNVDW0Mio5jqzkOBJiozHG0NLuorXdkBIfPPGwurGVdpchOT46oF98V2kdW4/UEBstREdFkZeRyOyxnd1BtU2tbD5cw9H6FirqW2hpczElO5lpo1PIy0jskSunqbWd+Jjg393BGENjazs1jW1UNbZQ1dBKUlw0M3JTSYi13+dofQsf7q2gqLKRtIRY0tzWg5MYkZEYS0x017v4dpehqPL/t3f3IXJddRjHvw9JrWkLSZqGUJPWRBuUqH0jSqoikiq0VYyikoSCRQLF+hZF1IogKP6jiC/RUohtNZZSxVg1lFKtm6KCmrrVmOaltts2akpiNmhiG9t0kz7+cU9k3Oymu2ZnJ3vP84Fh7j0zO3N++1vmN/fcu+f8m4H9T/PEgcM89exRnhk6xuEjRxkqv9/nbVa99kKuePmcMcc3mp4UAknTgEeAtwJ7aNYwXm17Z8dzPghcbPsDklYB77K98mSvm0IQETF+vVqY5nXAgO3HbT8HfB9YMew5K4ANZXsjcKVOp+vyIiIq0M1CMB/onKBlT2kb8TllsftDwAnHQJKul9QvqX9wcLBL3Y2IqNOUmHTO9nrbS20vnTt3bq+7ExHRKt0sBE8CF3TsLyhtIz5H0nRgJs1J44iImCTdLAS/BxZLWiTpRcAqYNOw52wCrivb7wE2e6pdzxoRMcV1bdI520clfRj4Gc3lo7fZ3iHpC0C/7U3ArcDtkgaAf9AUi4iImERdnX3U9j3APcPaPtex/Szw3m72ISIiTm5KnCyOiIjumXJTTEgaBP7yf/74ecCBCezOVFFj3DXGDHXGXWPMMP64X2p7xMsup1whOBWS+kf7z7o2qzHuGmOGOuOuMWaY2LgzNBQRUbkUgoiIytVWCNb3ugM9UmPcNcYMdcZdY8wwgXFXdY4gIiJOVNsRQUREDJNCEBFRuWoKgaSrJP1Z0oCkG3vdn26QdIGk+yXtlLRD0trSfq6k+yQ9Wu5n97qv3SBpmqQ/Srq77C+StKXk/AdlzqvWkDRL0kZJD0vaJemKGnIt6ePl73u7pDslvbiNuZZ0m6T9krZ3tI2YXzXWlfi3Sbp8PO9VRSEoq6XdBFwNLAFWS1rS2151xVHgE7aXAMuAD5U4bwT6bC8G+sp+G60FdnXsfwn4mu2LgH8Ca3rSq+75BnCv7VcCl9DE3upcS5oPfBRYavvVNPOYraKduf4ucNWwttHyezWwuNyuB24ezxtVUQgY22ppU57tvbb/ULafovlgmM//rgS3AXhnb3rYPZIWAG8Dbin7ApbTrHwHLYtb0kzgTTQTN2L7OdsHqSDXNHOkzShT158F7KWFubb9K5rJODuNlt8VwPfc+B0wS9L5Y32vWgrBWFZLaxVJC4HLgC3APNt7y0P7gHk96lY3fR34FPB82Z8DHCwr30H7cr4IGAS+U4bDbpF0Ni3Pte0nga8Af6UpAIeAB2l3rjuNlt9T+oyrpRBURdI5wI+Aj9n+V+djZb2HVl0zLOntwH7bD/a6L5NoOnA5cLPty4DDDBsGammuZ9N8+10EvAQ4mxOHT6owkfmtpRCMZbW0VpB0Bk0RuMP2XaX578cPE8v9/l71r0veALxD0m6aYb/lNOPns8rwAbQv53uAPba3lP2NNIWh7bl+C/CE7UHbQ8BdNPlvc647jZbfU/qMq6UQjGW1tCmvjIvfCuyy/dWOhzpXgrsO+Olk962bbH/G9gLbC2lyu9n2tcD9NCvfQcvitr0P+JukV5SmK4GdtDzXNENCyySdVf7ej8fd2lwPM1p+NwHvK1cPLQMOdQwhvTDbVdyAa4BHgMeAz/a6P12K8Y00h4rbgK3ldg3NeHkf8CjwC+DcXve1i7+DNwN3l+2XAQ8AA8APgTN73b8JjvVSoL/k+yfA7BpyDXweeBjYDtwOnNnGXAN30pwHGaI5AlwzWn4B0VwZ+RjwEM1VVWN+r0wxERFRuVqGhiIiYhQpBBERlUshiIioXApBRETlUggiIiqXQhAxjKRjkrZ23CZs4jZJCztnk4w4HUx/4adEVOcZ25f2uhMRkyVHBBFjJGm3pC9LekjSA5IuKu0LJW0u88D3SbqwtM+T9GNJfyq315eXmibp22VO/Z9LmtGzoCJIIYgYyYxhQ0MrOx47ZPs1wLdoZjwF+CawwfbFwB3AutK+Dvil7Uto5gHaUdoXAzfZfhVwEHh3l+OJOKn8Z3HEMJKetn3OCO27geW2Hy+T++2zPUfSAeB820Olfa/t8yQNAgtsH+l4jYXAfW4WFkHSp4EzbH+x+5FFjCxHBBHj41G2x+NIx/Yxcq4ueiyFIGJ8Vnbc/7Zs/4Zm1lOAa4Ffl+0+4Ab473rKMyerkxHjkW8iESeaIWlrx/69to9fQjpb0jaab/WrS9tHaFYK+yTNqmHvL+1rgfWS1tB887+BZjbJiNNKzhFEjFE5R7DU9oFe9yViImVoKCKicjkiiIioXI4IIiIql0IQEVG5FIKIiMqlEEREVC6FICKicv8B40nds2pgmusAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "3UInDv9rkJ_T"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_load2 = TweetBatcher(test, batch_size=64, drop_last=False)\n",
        "valid_load2 = TweetBatcher(valid, batch_size=64, drop_last=False)\n",
        "train_load2 = TweetBatcher(train, batch_size=64, drop_last=False)"
      ],
      "metadata": {
        "id": "Dlb4BT5TkCfk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "networK5.load_state_dict(best5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEYsojS2l8LR",
        "outputId": "155a48cb-5198-4144-b05f-b7d0cc91c130"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = get_accuracy(networK5, valid_load2, nn.CrossEntropyLoss())\n",
        "print(q[0], q[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EqGbp6USkU-",
        "outputId": "128be3ec-8879-4679-9feb-937b0c703cbb"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r                                                     \rtensor([[841, 109],\n",
            "        [272, 678]])\n",
            "0.8231578947368421 0.4121068391121096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best7,network7=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.00001, epochs=60, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.7, weight_decay=2e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fjIqFNx0ggwA",
        "outputId": "66e7abf6-c69e-4812-bb82-d2c88ae7034f"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t\r 45/??\t\r 46/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 0, Train Accuracy: 0.56822, Train Loss: 0.68160, Validation Accuracy: 0.59684, Validation Loss: 0.67015, prediction: [0.564, 0.436], true label: [1.0, 0.0]\n",
            "0.5968421052631578 0\n",
            "best_state_dict updated\n",
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 1, Train Accuracy: 0.56822, Train Loss: 0.67613, Validation Accuracy: 0.59684, Validation Loss: 0.66096, prediction: [0.574, 0.426], true label: [0.0, 1.0]\n",
            "0.5968421052631578 0.5968421052631578\n",
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 2, Train Accuracy: 0.56822, Train Loss: 0.66592, Validation Accuracy: 0.59684, Validation Loss: 0.65350, prediction: [0.596, 0.404], true label: [1.0, 0.0]\n",
            "0.5968421052631578 0.5968421052631578\n",
            "tensor([[5683,   19],\n",
            "        [5502,  200]])\n",
            "tensor([[946,   4],\n",
            "        [911,  39]])\n",
            "Epoch: 3, Train Accuracy: 0.70817, Train Loss: 0.61716, Validation Accuracy: 0.73053, Validation Loss: 0.60726, prediction: [0.623, 0.377], true label: [1.0, 0.0]\n",
            "0.7305263157894737 0.5968421052631578\n",
            "best_state_dict updated\n",
            "tensor([[5320,  382],\n",
            "        [3116, 2586]])\n",
            "tensor([[892,  58],\n",
            "        [524, 426]])\n",
            "Epoch: 4, Train Accuracy: 0.77604, Train Loss: 0.51219, Validation Accuracy: 0.76211, Validation Loss: 0.52799, prediction: [0.232, 0.768], true label: [0.0, 1.0]\n",
            "0.7621052631578947 0.7305263157894737\n",
            "best_state_dict updated\n",
            "tensor([[5094,  608],\n",
            "        [2367, 3335]])\n",
            "tensor([[846, 104],\n",
            "        [390, 560]])\n",
            "Epoch: 5, Train Accuracy: 0.77797, Train Loss: 0.47561, Validation Accuracy: 0.76526, Validation Loss: 0.49224, prediction: [0.511, 0.489], true label: [1.0, 0.0]\n",
            "0.7652631578947369 0.7621052631578947\n",
            "best_state_dict updated\n",
            "tensor([[5007,  695],\n",
            "        [2040, 3662]])\n",
            "tensor([[838, 112],\n",
            "        [338, 612]])\n",
            "Epoch: 6, Train Accuracy: 0.78727, Train Loss: 0.46389, Validation Accuracy: 0.78842, Validation Loss: 0.46668, prediction: [0.28, 0.72], true label: [0.0, 1.0]\n",
            "0.7884210526315789 0.7652631578947369\n",
            "best_state_dict updated\n",
            "tensor([[5022,  680],\n",
            "        [2024, 3678]])\n",
            "tensor([[828, 122],\n",
            "        [327, 623]])\n",
            "Epoch: 7, Train Accuracy: 0.79270, Train Loss: 0.45421, Validation Accuracy: 0.78316, Validation Loss: 0.46493, prediction: [0.178, 0.822], true label: [0.0, 1.0]\n",
            "0.783157894736842 0.7884210526315789\n",
            "tensor([[5024,  678],\n",
            "        [1987, 3715]])\n",
            "tensor([[828, 122],\n",
            "        [320, 630]])\n",
            "Epoch: 8, Train Accuracy: 0.79621, Train Loss: 0.44366, Validation Accuracy: 0.79158, Validation Loss: 0.45295, prediction: [0.302, 0.698], true label: [0.0, 1.0]\n",
            "0.791578947368421 0.7884210526315789\n",
            "best_state_dict updated\n",
            "tensor([[5034,  668],\n",
            "        [1974, 3728]])\n",
            "tensor([[828, 122],\n",
            "        [332, 618]])\n",
            "Epoch: 9, Train Accuracy: 0.79393, Train Loss: 0.44789, Validation Accuracy: 0.78000, Validation Loss: 0.46361, prediction: [0.137, 0.863], true label: [0.0, 1.0]\n",
            "0.78 0.791578947368421\n",
            "tensor([[5020,  682],\n",
            "        [1913, 3789]])\n",
            "tensor([[830, 120],\n",
            "        [309, 641]])\n",
            "Epoch: 10, Train Accuracy: 0.79954, Train Loss: 0.44261, Validation Accuracy: 0.79263, Validation Loss: 0.47606, prediction: [0.45, 0.55], true label: [0.0, 1.0]\n",
            "0.7926315789473685 0.791578947368421\n",
            "best_state_dict updated\n",
            "tensor([[5022,  680],\n",
            "        [1900, 3802]])\n",
            "tensor([[820, 130],\n",
            "        [314, 636]])\n",
            "Epoch: 11, Train Accuracy: 0.79972, Train Loss: 0.44137, Validation Accuracy: 0.78842, Validation Loss: 0.46702, prediction: [0.538, 0.462], true label: [1.0, 0.0]\n",
            "0.7884210526315789 0.7926315789473685\n",
            "tensor([[5018,  684],\n",
            "        [1872, 3830]])\n",
            "tensor([[825, 125],\n",
            "        [302, 648]])\n",
            "Epoch: 12, Train Accuracy: 0.80182, Train Loss: 0.43757, Validation Accuracy: 0.78526, Validation Loss: 0.45098, prediction: [0.05, 0.95], true label: [0.0, 1.0]\n",
            "0.7852631578947369 0.7926315789473685\n",
            "tensor([[5002,  700],\n",
            "        [1823, 3879]])\n",
            "tensor([[832, 118],\n",
            "        [292, 658]])\n",
            "Epoch: 13, Train Accuracy: 0.80235, Train Loss: 0.43894, Validation Accuracy: 0.79579, Validation Loss: 0.44215, prediction: [0.667, 0.333], true label: [0.0, 1.0]\n",
            "0.7957894736842105 0.7926315789473685\n",
            "best_state_dict updated\n",
            "tensor([[5014,  688],\n",
            "        [1832, 3870]])\n",
            "tensor([[834, 116],\n",
            "        [292, 658]])\n",
            "Epoch: 14, Train Accuracy: 0.80340, Train Loss: 0.43602, Validation Accuracy: 0.79368, Validation Loss: 0.44059, prediction: [0.849, 0.151], true label: [1.0, 0.0]\n",
            "0.7936842105263158 0.7957894736842105\n",
            "tensor([[5042,  660],\n",
            "        [1853, 3849]])\n",
            "tensor([[829, 121],\n",
            "        [310, 640]])\n",
            "Epoch: 15, Train Accuracy: 0.80533, Train Loss: 0.43937, Validation Accuracy: 0.78947, Validation Loss: 0.45227, prediction: [0.647, 0.353], true label: [1.0, 0.0]\n",
            "0.7894736842105263 0.7957894736842105\n",
            "tensor([[5041,  661],\n",
            "        [1844, 3858]])\n",
            "tensor([[832, 118],\n",
            "        [306, 644]])\n",
            "Epoch: 16, Train Accuracy: 0.80761, Train Loss: 0.42984, Validation Accuracy: 0.79158, Validation Loss: 0.44810, prediction: [0.017, 0.983], true label: [0.0, 1.0]\n",
            "0.791578947368421 0.7957894736842105\n",
            "tensor([[5031,  671],\n",
            "        [1809, 3893]])\n",
            "tensor([[833, 117],\n",
            "        [296, 654]])\n",
            "Epoch: 17, Train Accuracy: 0.80814, Train Loss: 0.43041, Validation Accuracy: 0.79053, Validation Loss: 0.46331, prediction: [0.116, 0.884], true label: [0.0, 1.0]\n",
            "0.7905263157894736 0.7957894736842105\n",
            "tensor([[5031,  671],\n",
            "        [1789, 3913]])\n",
            "tensor([[833, 117],\n",
            "        [292, 658]])\n",
            "Epoch: 18, Train Accuracy: 0.80761, Train Loss: 0.42228, Validation Accuracy: 0.79263, Validation Loss: 0.43383, prediction: [0.842, 0.158], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.7957894736842105\n",
            "tensor([[5028,  674],\n",
            "        [1771, 3931]])\n",
            "tensor([[836, 114],\n",
            "        [290, 660]])\n",
            "Epoch: 19, Train Accuracy: 0.80989, Train Loss: 0.42060, Validation Accuracy: 0.79474, Validation Loss: 0.45218, prediction: [0.815, 0.185], true label: [1.0, 0.0]\n",
            "0.7947368421052632 0.7957894736842105\n",
            "tensor([[5018,  684],\n",
            "        [1725, 3977]])\n",
            "tensor([[835, 115],\n",
            "        [281, 669]])\n",
            "Epoch: 20, Train Accuracy: 0.80866, Train Loss: 0.43190, Validation Accuracy: 0.79684, Validation Loss: 0.42675, prediction: [0.492, 0.508], true label: [0.0, 1.0]\n",
            "0.7968421052631579 0.7957894736842105\n",
            "best_state_dict updated\n",
            "tensor([[5032,  670],\n",
            "        [1769, 3933]])\n",
            "tensor([[836, 114],\n",
            "        [286, 664]])\n",
            "Epoch: 21, Train Accuracy: 0.81217, Train Loss: 0.41706, Validation Accuracy: 0.79684, Validation Loss: 0.42936, prediction: [0.928, 0.072], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.7968421052631579\n",
            "tensor([[5031,  671],\n",
            "        [1755, 3947]])\n",
            "tensor([[838, 112],\n",
            "        [283, 667]])\n",
            "Epoch: 22, Train Accuracy: 0.81200, Train Loss: 0.41894, Validation Accuracy: 0.79579, Validation Loss: 0.44882, prediction: [0.867, 0.133], true label: [1.0, 0.0]\n",
            "0.7957894736842105 0.7968421052631579\n",
            "tensor([[5026,  676],\n",
            "        [1723, 3979]])\n",
            "tensor([[836, 114],\n",
            "        [283, 667]])\n",
            "Epoch: 23, Train Accuracy: 0.80989, Train Loss: 0.41821, Validation Accuracy: 0.80000, Validation Loss: 0.44167, prediction: [0.599, 0.401], true label: [0.0, 1.0]\n",
            "0.8 0.7968421052631579\n",
            "best_state_dict updated\n",
            "tensor([[5041,  661],\n",
            "        [1760, 3942]])\n",
            "tensor([[837, 113],\n",
            "        [291, 659]])\n",
            "Epoch: 24, Train Accuracy: 0.81305, Train Loss: 0.41469, Validation Accuracy: 0.79789, Validation Loss: 0.42424, prediction: [0.582, 0.418], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8\n",
            "tensor([[5033,  669],\n",
            "        [1728, 3974]])\n",
            "tensor([[836, 114],\n",
            "        [284, 666]])\n",
            "Epoch: 25, Train Accuracy: 0.81305, Train Loss: 0.41480, Validation Accuracy: 0.80000, Validation Loss: 0.43807, prediction: [0.102, 0.898], true label: [0.0, 1.0]\n",
            "0.8 0.8\n",
            "tensor([[5046,  656],\n",
            "        [1777, 3925]])\n",
            "tensor([[836, 114],\n",
            "        [294, 656]])\n",
            "Epoch: 26, Train Accuracy: 0.81463, Train Loss: 0.42176, Validation Accuracy: 0.79789, Validation Loss: 0.47422, prediction: [0.109, 0.891], true label: [0.0, 1.0]\n",
            "0.7978947368421052 0.8\n",
            "tensor([[5031,  671],\n",
            "        [1710, 3992]])\n",
            "tensor([[836, 114],\n",
            "        [281, 669]])\n",
            "Epoch: 27, Train Accuracy: 0.81287, Train Loss: 0.41641, Validation Accuracy: 0.80211, Validation Loss: 0.42777, prediction: [0.899, 0.101], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8\n",
            "best_state_dict updated\n",
            "tensor([[5044,  658],\n",
            "        [1738, 3964]])\n",
            "tensor([[837, 113],\n",
            "        [288, 662]])\n",
            "Epoch: 28, Train Accuracy: 0.81463, Train Loss: 0.41660, Validation Accuracy: 0.79684, Validation Loss: 0.42818, prediction: [0.532, 0.468], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.8021052631578948\n",
            "tensor([[5037,  665],\n",
            "        [1714, 3988]])\n",
            "tensor([[835, 115],\n",
            "        [282, 668]])\n",
            "Epoch: 29, Train Accuracy: 0.81708, Train Loss: 0.41475, Validation Accuracy: 0.80105, Validation Loss: 0.42769, prediction: [0.872, 0.128], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8021052631578948\n",
            "tensor([[5046,  656],\n",
            "        [1706, 3996]])\n",
            "tensor([[835, 115],\n",
            "        [289, 661]])\n",
            "Epoch: 30, Train Accuracy: 0.81550, Train Loss: 0.42350, Validation Accuracy: 0.80000, Validation Loss: 0.44129, prediction: [0.042, 0.958], true label: [0.0, 1.0]\n",
            "0.8 0.8021052631578948\n",
            "tensor([[5044,  658],\n",
            "        [1711, 3991]])\n",
            "tensor([[835, 115],\n",
            "        [283, 667]])\n",
            "Epoch: 31, Train Accuracy: 0.81708, Train Loss: 0.41865, Validation Accuracy: 0.80421, Validation Loss: 0.42404, prediction: [0.16, 0.84], true label: [0.0, 1.0]\n",
            "0.8042105263157895 0.8021052631578948\n",
            "best_state_dict updated\n",
            "tensor([[5043,  659],\n",
            "        [1696, 4006]])\n",
            "tensor([[835, 115],\n",
            "        [288, 662]])\n",
            "Epoch: 32, Train Accuracy: 0.81691, Train Loss: 0.41866, Validation Accuracy: 0.79684, Validation Loss: 0.47063, prediction: [0.899, 0.101], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.8042105263157895\n",
            "tensor([[5055,  647],\n",
            "        [1690, 4012]])\n",
            "tensor([[836, 114],\n",
            "        [284, 666]])\n",
            "Epoch: 33, Train Accuracy: 0.81708, Train Loss: 0.40212, Validation Accuracy: 0.80211, Validation Loss: 0.43583, prediction: [0.845, 0.155], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8042105263157895\n",
            "tensor([[5054,  648],\n",
            "        [1680, 4022]])\n",
            "tensor([[837, 113],\n",
            "        [284, 666]])\n",
            "Epoch: 34, Train Accuracy: 0.81813, Train Loss: 0.41395, Validation Accuracy: 0.80211, Validation Loss: 0.43633, prediction: [0.618, 0.382], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8042105263157895\n",
            "tensor([[5041,  661],\n",
            "        [1664, 4038]])\n",
            "tensor([[838, 112],\n",
            "        [277, 673]])\n",
            "Epoch: 35, Train Accuracy: 0.81796, Train Loss: 0.40254, Validation Accuracy: 0.80211, Validation Loss: 0.43180, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.8021052631578948 0.8042105263157895\n",
            "tensor([[5044,  658],\n",
            "        [1668, 4034]])\n",
            "tensor([[838, 112],\n",
            "        [277, 673]])\n",
            "Epoch: 36, Train Accuracy: 0.81796, Train Loss: 0.41029, Validation Accuracy: 0.80526, Validation Loss: 0.42161, prediction: [0.898, 0.102], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8042105263157895\n",
            "best_state_dict updated\n",
            "tensor([[5058,  644],\n",
            "        [1667, 4035]])\n",
            "tensor([[838, 112],\n",
            "        [283, 667]])\n",
            "Epoch: 37, Train Accuracy: 0.82006, Train Loss: 0.41292, Validation Accuracy: 0.80000, Validation Loss: 0.43275, prediction: [0.866, 0.134], true label: [1.0, 0.0]\n",
            "0.8 0.8052631578947368\n",
            "tensor([[5055,  647],\n",
            "        [1668, 4034]])\n",
            "tensor([[838, 112],\n",
            "        [283, 667]])\n",
            "Epoch: 38, Train Accuracy: 0.82059, Train Loss: 0.41118, Validation Accuracy: 0.80105, Validation Loss: 0.44513, prediction: [0.857, 0.143], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8052631578947368\n",
            "tensor([[5045,  657],\n",
            "        [1653, 4049]])\n",
            "tensor([[842, 108],\n",
            "        [274, 676]])\n",
            "Epoch: 39, Train Accuracy: 0.81726, Train Loss: 0.41016, Validation Accuracy: 0.81053, Validation Loss: 0.42513, prediction: [0.257, 0.743], true label: [1.0, 0.0]\n",
            "0.8105263157894737 0.8052631578947368\n",
            "best_state_dict updated\n",
            "tensor([[5046,  656],\n",
            "        [1639, 4063]])\n",
            "tensor([[840, 110],\n",
            "        [276, 674]])\n",
            "Epoch: 40, Train Accuracy: 0.81971, Train Loss: 0.40604, Validation Accuracy: 0.80842, Validation Loss: 0.46991, prediction: [0.612, 0.388], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8105263157894737\n",
            "tensor([[5046,  656],\n",
            "        [1625, 4077]])\n",
            "tensor([[840, 110],\n",
            "        [272, 678]])\n",
            "Epoch: 41, Train Accuracy: 0.81813, Train Loss: 0.40565, Validation Accuracy: 0.80947, Validation Loss: 0.43548, prediction: [0.108, 0.892], true label: [0.0, 1.0]\n",
            "0.8094736842105263 0.8105263157894737\n",
            "tensor([[5055,  647],\n",
            "        [1650, 4052]])\n",
            "tensor([[839, 111],\n",
            "        [283, 667]])\n",
            "Epoch: 42, Train Accuracy: 0.82147, Train Loss: 0.41126, Validation Accuracy: 0.80211, Validation Loss: 0.43020, prediction: [0.041, 0.959], true label: [0.0, 1.0]\n",
            "0.8021052631578948 0.8105263157894737\n",
            "tensor([[5039,  663],\n",
            "        [1599, 4103]])\n",
            "tensor([[841, 109],\n",
            "        [269, 681]])\n",
            "Epoch: 43, Train Accuracy: 0.81778, Train Loss: 0.40417, Validation Accuracy: 0.81053, Validation Loss: 0.42631, prediction: [0.094, 0.906], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8105263157894737\n",
            "tensor([[5062,  640],\n",
            "        [1653, 4049]])\n",
            "tensor([[834, 116],\n",
            "        [286, 664]])\n",
            "Epoch: 44, Train Accuracy: 0.82059, Train Loss: 0.40874, Validation Accuracy: 0.80000, Validation Loss: 0.44579, prediction: [0.315, 0.685], true label: [0.0, 1.0]\n",
            "0.8 0.8105263157894737\n",
            "tensor([[5064,  638],\n",
            "        [1646, 4056]])\n",
            "tensor([[833, 117],\n",
            "        [288, 662]])\n",
            "Epoch: 45, Train Accuracy: 0.82287, Train Loss: 0.40186, Validation Accuracy: 0.80105, Validation Loss: 0.42241, prediction: [0.84, 0.16], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8105263157894737\n",
            "tensor([[5054,  648],\n",
            "        [1615, 4087]])\n",
            "tensor([[840, 110],\n",
            "        [275, 675]])\n",
            "Epoch: 46, Train Accuracy: 0.82287, Train Loss: 0.41173, Validation Accuracy: 0.80842, Validation Loss: 0.41979, prediction: [0.925, 0.075], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8105263157894737\n",
            "tensor([[5069,  633],\n",
            "        [1652, 4050]])\n",
            "tensor([[834, 116],\n",
            "        [286, 664]])\n",
            "Epoch: 47, Train Accuracy: 0.82059, Train Loss: 0.40571, Validation Accuracy: 0.80105, Validation Loss: 0.43717, prediction: [0.743, 0.257], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8105263157894737\n",
            "tensor([[5041,  661],\n",
            "        [1580, 4122]])\n",
            "tensor([[839, 111],\n",
            "        [268, 682]])\n",
            "Epoch: 48, Train Accuracy: 0.82217, Train Loss: 0.40667, Validation Accuracy: 0.81263, Validation Loss: 0.42874, prediction: [0.614, 0.386], true label: [1.0, 0.0]\n",
            "0.8126315789473684 0.8105263157894737\n",
            "best_state_dict updated\n",
            "tensor([[5042,  660],\n",
            "        [1582, 4120]])\n",
            "tensor([[838, 112],\n",
            "        [267, 683]])\n",
            "Epoch: 49, Train Accuracy: 0.82269, Train Loss: 0.40547, Validation Accuracy: 0.81263, Validation Loss: 0.42328, prediction: [0.077, 0.923], true label: [0.0, 1.0]\n",
            "0.8126315789473684 0.8126315789473684\n",
            "tensor([[5012,  690],\n",
            "        [1568, 4134]])\n",
            "tensor([[836, 114],\n",
            "        [263, 687]])\n",
            "Epoch: 50, Train Accuracy: 0.81620, Train Loss: 0.41146, Validation Accuracy: 0.82000, Validation Loss: 0.43143, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.82 0.8126315789473684\n",
            "best_state_dict updated\n",
            "tensor([[5059,  643],\n",
            "        [1609, 4093]])\n",
            "tensor([[837, 113],\n",
            "        [275, 675]])\n",
            "Epoch: 51, Train Accuracy: 0.82568, Train Loss: 0.39958, Validation Accuracy: 0.80737, Validation Loss: 0.43048, prediction: [0.023, 0.977], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.82\n",
            "tensor([[5053,  649],\n",
            "        [1597, 4105]])\n",
            "tensor([[838, 112],\n",
            "        [266, 684]])\n",
            "Epoch: 52, Train Accuracy: 0.82550, Train Loss: 0.39817, Validation Accuracy: 0.80842, Validation Loss: 0.42229, prediction: [0.848, 0.152], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.82\n",
            "tensor([[5064,  638],\n",
            "        [1598, 4104]])\n",
            "tensor([[837, 113],\n",
            "        [274, 676]])\n",
            "Epoch: 53, Train Accuracy: 0.82620, Train Loss: 0.40100, Validation Accuracy: 0.80842, Validation Loss: 0.41877, prediction: [0.742, 0.258], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.82\n",
            "tensor([[5065,  637],\n",
            "        [1611, 4091]])\n",
            "tensor([[834, 116],\n",
            "        [280, 670]])\n",
            "Epoch: 54, Train Accuracy: 0.82480, Train Loss: 0.39909, Validation Accuracy: 0.80632, Validation Loss: 0.42927, prediction: [0.888, 0.112], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.82\n",
            "tensor([[5052,  650],\n",
            "        [1577, 4125]])\n",
            "tensor([[837, 113],\n",
            "        [265, 685]])\n",
            "Epoch: 55, Train Accuracy: 0.82585, Train Loss: 0.39660, Validation Accuracy: 0.80947, Validation Loss: 0.43183, prediction: [0.911, 0.089], true label: [1.0, 0.0]\n",
            "0.8094736842105263 0.82\n",
            "tensor([[5061,  641],\n",
            "        [1582, 4120]])\n",
            "tensor([[837, 113],\n",
            "        [264, 686]])\n",
            "Epoch: 56, Train Accuracy: 0.82638, Train Loss: 0.39874, Validation Accuracy: 0.80842, Validation Loss: 0.43800, prediction: [0.228, 0.772], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.82\n",
            "tensor([[5045,  657],\n",
            "        [1570, 4132]])\n",
            "tensor([[842, 108],\n",
            "        [267, 683]])\n",
            "Epoch: 57, Train Accuracy: 0.82532, Train Loss: 0.39434, Validation Accuracy: 0.81474, Validation Loss: 0.41993, prediction: [0.914, 0.086], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.82\n",
            "tensor([[5069,  633],\n",
            "        [1590, 4112]])\n",
            "tensor([[836, 114],\n",
            "        [273, 677]])\n",
            "Epoch: 58, Train Accuracy: 0.82638, Train Loss: 0.39209, Validation Accuracy: 0.80526, Validation Loss: 0.42898, prediction: [0.192, 0.808], true label: [0.0, 1.0]\n",
            "0.8052631578947368 0.82\n",
            "tensor([[5053,  649],\n",
            "        [1569, 4133]])\n",
            "tensor([[839, 111],\n",
            "        [265, 685]])\n",
            "Epoch: 59, Train Accuracy: 0.82725, Train Loss: 0.39515, Validation Accuracy: 0.81053, Validation Loss: 0.48836, prediction: [0.015, 0.985], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.82\n",
            "tensor([[5075,  627],\n",
            "        [1615, 4087]])\n",
            "tensor([[830, 120],\n",
            "        [281, 669]])\n",
            "Epoch: 60, Train Accuracy: 0.82568, Train Loss: 0.39827, Validation Accuracy: 0.79579, Validation Loss: 0.44391, prediction: [0.859, 0.141], true label: [1.0, 0.0]\n",
            "0.7957894736842105 0.82\n",
            "tensor([[5053,  649],\n",
            "        [1572, 4130]])\n",
            "tensor([[839, 111],\n",
            "        [265, 685]])\n",
            "Epoch: 61, Train Accuracy: 0.82743, Train Loss: 0.40388, Validation Accuracy: 0.80947, Validation Loss: 0.44014, prediction: [0.896, 0.104], true label: [1.0, 0.0]\n",
            "0.8094736842105263 0.82\n",
            "tensor([[5071,  631],\n",
            "        [1586, 4116]])\n",
            "tensor([[833, 117],\n",
            "        [271, 679]])\n",
            "Epoch: 62, Train Accuracy: 0.82743, Train Loss: 0.39177, Validation Accuracy: 0.81053, Validation Loss: 0.44611, prediction: [0.93, 0.07], true label: [1.0, 0.0]\n",
            "0.8105263157894737 0.82\n",
            "tensor([[5066,  636],\n",
            "        [1583, 4119]])\n",
            "tensor([[840, 110],\n",
            "        [265, 685]])\n",
            "Epoch: 63, Train Accuracy: 0.82760, Train Loss: 0.39314, Validation Accuracy: 0.80737, Validation Loss: 0.45613, prediction: [0.047, 0.953], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.82\n",
            "tensor([[5061,  641],\n",
            "        [1579, 4123]])\n",
            "tensor([[839, 111],\n",
            "        [266, 684]])\n",
            "Epoch: 64, Train Accuracy: 0.82831, Train Loss: 0.39582, Validation Accuracy: 0.80947, Validation Loss: 0.43067, prediction: [0.093, 0.907], true label: [0.0, 1.0]\n",
            "0.8094736842105263 0.82\n",
            "tensor([[5074,  628],\n",
            "        [1581, 4121]])\n",
            "tensor([[840, 110],\n",
            "        [266, 684]])\n",
            "Epoch: 65, Train Accuracy: 0.82831, Train Loss: 0.39227, Validation Accuracy: 0.81053, Validation Loss: 0.46686, prediction: [0.898, 0.102], true label: [1.0, 0.0]\n",
            "0.8105263157894737 0.82\n",
            "tensor([[5031,  671],\n",
            "        [1490, 4212]])\n",
            "tensor([[836, 114],\n",
            "        [257, 693]])\n",
            "Epoch: 66, Train Accuracy: 0.82059, Train Loss: 0.39701, Validation Accuracy: 0.82316, Validation Loss: 0.41860, prediction: [0.907, 0.093], true label: [1.0, 0.0]\n",
            "0.8231578947368421 0.82\n",
            "best_state_dict updated\n",
            "tensor([[5062,  640],\n",
            "        [1549, 4153]])\n",
            "tensor([[840, 110],\n",
            "        [265, 685]])\n",
            "Epoch: 67, Train Accuracy: 0.82883, Train Loss: 0.38440, Validation Accuracy: 0.81263, Validation Loss: 0.46923, prediction: [0.014, 0.986], true label: [0.0, 1.0]\n",
            "0.8126315789473684 0.8231578947368421\n",
            "tensor([[5065,  637],\n",
            "        [1546, 4156]])\n",
            "tensor([[840, 110],\n",
            "        [265, 685]])\n",
            "Epoch: 68, Train Accuracy: 0.82918, Train Loss: 0.38783, Validation Accuracy: 0.81368, Validation Loss: 0.42817, prediction: [0.286, 0.714], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8231578947368421\n",
            "tensor([[5064,  638],\n",
            "        [1534, 4168]])\n",
            "tensor([[840, 110],\n",
            "        [267, 683]])\n",
            "Epoch: 69, Train Accuracy: 0.82883, Train Loss: 0.38774, Validation Accuracy: 0.81368, Validation Loss: 0.44344, prediction: [0.936, 0.064], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8231578947368421\n",
            "tensor([[5076,  626],\n",
            "        [1561, 4141]])\n",
            "tensor([[836, 114],\n",
            "        [267, 683]])\n",
            "Epoch: 70, Train Accuracy: 0.82918, Train Loss: 0.39643, Validation Accuracy: 0.81158, Validation Loss: 0.43479, prediction: [0.06, 0.94], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5080,  622],\n",
            "        [1554, 4148]])\n",
            "tensor([[835, 115],\n",
            "        [269, 681]])\n",
            "Epoch: 71, Train Accuracy: 0.82936, Train Loss: 0.38480, Validation Accuracy: 0.81158, Validation Loss: 0.44163, prediction: [0.713, 0.287], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5080,  622],\n",
            "        [1549, 4153]])\n",
            "tensor([[832, 118],\n",
            "        [269, 681]])\n",
            "Epoch: 72, Train Accuracy: 0.82918, Train Loss: 0.39276, Validation Accuracy: 0.80842, Validation Loss: 0.44689, prediction: [0.816, 0.184], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8231578947368421\n",
            "tensor([[5081,  621],\n",
            "        [1539, 4163]])\n",
            "tensor([[834, 116],\n",
            "        [270, 680]])\n",
            "Epoch: 73, Train Accuracy: 0.83059, Train Loss: 0.39317, Validation Accuracy: 0.81158, Validation Loss: 0.44502, prediction: [0.103, 0.897], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5064,  638],\n",
            "        [1507, 4195]])\n",
            "tensor([[839, 111],\n",
            "        [263, 687]])\n",
            "Epoch: 74, Train Accuracy: 0.83006, Train Loss: 0.39085, Validation Accuracy: 0.81474, Validation Loss: 0.45461, prediction: [0.903, 0.097], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8231578947368421\n",
            "tensor([[5083,  619],\n",
            "        [1529, 4173]])\n",
            "tensor([[833, 117],\n",
            "        [269, 681]])\n",
            "Epoch: 75, Train Accuracy: 0.82936, Train Loss: 0.39708, Validation Accuracy: 0.81053, Validation Loss: 0.45160, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8231578947368421\n",
            "tensor([[5079,  623],\n",
            "        [1542, 4160]])\n",
            "tensor([[833, 117],\n",
            "        [270, 680]])\n",
            "Epoch: 76, Train Accuracy: 0.82988, Train Loss: 0.38910, Validation Accuracy: 0.80316, Validation Loss: 0.47312, prediction: [0.806, 0.194], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8231578947368421\n",
            "tensor([[5062,  640],\n",
            "        [1486, 4216]])\n",
            "tensor([[836, 114],\n",
            "        [260, 690]])\n",
            "Epoch: 77, Train Accuracy: 0.83146, Train Loss: 0.38027, Validation Accuracy: 0.81579, Validation Loss: 0.43938, prediction: [0.069, 0.931], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8231578947368421\n",
            "tensor([[5055,  647],\n",
            "        [1459, 4243]])\n",
            "tensor([[836, 114],\n",
            "        [258, 692]])\n",
            "Epoch: 78, Train Accuracy: 0.83094, Train Loss: 0.39093, Validation Accuracy: 0.81474, Validation Loss: 0.43312, prediction: [0.221, 0.779], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.8231578947368421\n",
            "tensor([[5062,  640],\n",
            "        [1478, 4224]])\n",
            "tensor([[835, 115],\n",
            "        [259, 691]])\n",
            "Epoch: 79, Train Accuracy: 0.83287, Train Loss: 0.38737, Validation Accuracy: 0.82000, Validation Loss: 0.44306, prediction: [0.692, 0.308], true label: [1.0, 0.0]\n",
            "0.82 0.8231578947368421\n",
            "tensor([[5079,  623],\n",
            "        [1486, 4216]])\n",
            "tensor([[833, 117],\n",
            "        [266, 684]])\n",
            "Epoch: 80, Train Accuracy: 0.83216, Train Loss: 0.38343, Validation Accuracy: 0.81158, Validation Loss: 0.45671, prediction: [0.469, 0.531], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5068,  634],\n",
            "        [1465, 4237]])\n",
            "tensor([[835, 115],\n",
            "        [260, 690]])\n",
            "Epoch: 81, Train Accuracy: 0.83357, Train Loss: 0.38710, Validation Accuracy: 0.81263, Validation Loss: 0.45288, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.8126315789473684 0.8231578947368421\n",
            "tensor([[5065,  637],\n",
            "        [1457, 4245]])\n",
            "tensor([[835, 115],\n",
            "        [259, 691]])\n",
            "Epoch: 82, Train Accuracy: 0.83304, Train Loss: 0.37621, Validation Accuracy: 0.82105, Validation Loss: 0.48228, prediction: [0.054, 0.946], true label: [0.0, 1.0]\n",
            "0.8210526315789474 0.8231578947368421\n",
            "tensor([[5085,  617],\n",
            "        [1491, 4211]])\n",
            "tensor([[834, 116],\n",
            "        [266, 684]])\n",
            "Epoch: 83, Train Accuracy: 0.83146, Train Loss: 0.38546, Validation Accuracy: 0.80842, Validation Loss: 0.47542, prediction: [0.618, 0.382], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8231578947368421\n",
            "tensor([[5075,  627],\n",
            "        [1451, 4251]])\n",
            "tensor([[835, 115],\n",
            "        [258, 692]])\n",
            "Epoch: 84, Train Accuracy: 0.83374, Train Loss: 0.38155, Validation Accuracy: 0.81789, Validation Loss: 0.45532, prediction: [0.024, 0.976], true label: [0.0, 1.0]\n",
            "0.8178947368421052 0.8231578947368421\n",
            "tensor([[5077,  625],\n",
            "        [1444, 4258]])\n",
            "tensor([[835, 115],\n",
            "        [258, 692]])\n",
            "Epoch: 85, Train Accuracy: 0.83409, Train Loss: 0.38016, Validation Accuracy: 0.81684, Validation Loss: 0.46078, prediction: [0.048, 0.952], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8231578947368421\n",
            "tensor([[5101,  601],\n",
            "        [1599, 4103]])\n",
            "tensor([[827, 123],\n",
            "        [287, 663]])\n",
            "Epoch: 86, Train Accuracy: 0.82462, Train Loss: 0.39382, Validation Accuracy: 0.79684, Validation Loss: 0.49574, prediction: [0.744, 0.256], true label: [0.0, 1.0]\n",
            "0.7968421052631579 0.8231578947368421\n",
            "tensor([[5080,  622],\n",
            "        [1453, 4249]])\n",
            "tensor([[835, 115],\n",
            "        [257, 693]])\n",
            "Epoch: 87, Train Accuracy: 0.83515, Train Loss: 0.38052, Validation Accuracy: 0.81158, Validation Loss: 0.48667, prediction: [0.824, 0.176], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8231578947368421\n",
            "tensor([[5087,  615],\n",
            "        [1491, 4211]])\n",
            "tensor([[834, 116],\n",
            "        [266, 684]])\n",
            "Epoch: 88, Train Accuracy: 0.83444, Train Loss: 0.39297, Validation Accuracy: 0.80737, Validation Loss: 0.47733, prediction: [0.852, 0.148], true label: [1.0, 0.0]\n",
            "0.8073684210526316 0.8231578947368421\n",
            "tensor([[5073,  629],\n",
            "        [1428, 4274]])\n",
            "tensor([[834, 116],\n",
            "        [255, 695]])\n",
            "Epoch: 89, Train Accuracy: 0.83374, Train Loss: 0.38243, Validation Accuracy: 0.81579, Validation Loss: 0.50069, prediction: [0.945, 0.055], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8231578947368421\n",
            "tensor([[5081,  621],\n",
            "        [1431, 4271]])\n",
            "tensor([[834, 116],\n",
            "        [255, 695]])\n",
            "Epoch: 90, Train Accuracy: 0.83409, Train Loss: 0.38522, Validation Accuracy: 0.81684, Validation Loss: 0.46122, prediction: [0.087, 0.913], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8231578947368421\n",
            "tensor([[5075,  627],\n",
            "        [1411, 4291]])\n",
            "tensor([[835, 115],\n",
            "        [252, 698]])\n",
            "Epoch: 91, Train Accuracy: 0.83427, Train Loss: 0.37592, Validation Accuracy: 0.81789, Validation Loss: 0.49163, prediction: [0.796, 0.204], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.8231578947368421\n",
            "tensor([[5086,  616],\n",
            "        [1442, 4260]])\n",
            "tensor([[832, 118],\n",
            "        [265, 685]])\n",
            "Epoch: 92, Train Accuracy: 0.83585, Train Loss: 0.37316, Validation Accuracy: 0.81053, Validation Loss: 0.47277, prediction: [0.027, 0.973], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8231578947368421\n",
            "tensor([[5087,  615],\n",
            "        [1483, 4219]])\n",
            "tensor([[830, 120],\n",
            "        [268, 682]])\n",
            "Epoch: 93, Train Accuracy: 0.83585, Train Loss: 0.37370, Validation Accuracy: 0.80421, Validation Loss: 0.49456, prediction: [0.852, 0.148], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8231578947368421\n",
            "tensor([[5091,  611],\n",
            "        [1435, 4267]])\n",
            "tensor([[833, 117],\n",
            "        [258, 692]])\n",
            "Epoch: 94, Train Accuracy: 0.83602, Train Loss: 0.37288, Validation Accuracy: 0.81368, Validation Loss: 0.47800, prediction: [0.029, 0.971], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8231578947368421\n",
            "tensor([[5077,  625],\n",
            "        [1411, 4291]])\n",
            "tensor([[836, 114],\n",
            "        [256, 694]])\n",
            "Epoch: 95, Train Accuracy: 0.83515, Train Loss: 0.36834, Validation Accuracy: 0.81789, Validation Loss: 0.48517, prediction: [0.897, 0.103], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.8231578947368421\n",
            "tensor([[5091,  611],\n",
            "        [1429, 4273]])\n",
            "tensor([[832, 118],\n",
            "        [257, 693]])\n",
            "Epoch: 96, Train Accuracy: 0.83602, Train Loss: 0.37346, Validation Accuracy: 0.81368, Validation Loss: 0.48811, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8231578947368421\n",
            "tensor([[5080,  622],\n",
            "        [1398, 4304]])\n",
            "tensor([[836, 114],\n",
            "        [255, 695]])\n",
            "Epoch: 97, Train Accuracy: 0.83690, Train Loss: 0.37177, Validation Accuracy: 0.81579, Validation Loss: 0.46343, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8231578947368421\n",
            "tensor([[5092,  610],\n",
            "        [1417, 4285]])\n",
            "tensor([[832, 118],\n",
            "        [256, 694]])\n",
            "Epoch: 98, Train Accuracy: 0.83672, Train Loss: 0.37361, Validation Accuracy: 0.81579, Validation Loss: 0.49974, prediction: [0.957, 0.043], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8231578947368421\n",
            "tensor([[5076,  626],\n",
            "        [1377, 4325]])\n",
            "tensor([[836, 114],\n",
            "        [251, 699]])\n",
            "Epoch: 99, Train Accuracy: 0.83672, Train Loss: 0.37219, Validation Accuracy: 0.81684, Validation Loss: 0.48842, prediction: [0.729, 0.271], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8231578947368421\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3iV5fnHP/fJ3pCQEAKEsJG9FVQEJ1oVt6JVqKvaWrWuVm3VOjqtVVt/1j2ruC0IakVBUWSEvVcIEGZIQhKyx/P74zkv5yQ5CQnJSUJyf64r1znvfs5J8n7fez5ijEFRFEVRquNq6QEoiqIorRMVCEVRFMUnKhCKoiiKT1QgFEVRFJ+oQCiKoig+UYFQFEVRfKICobR7RORzEZnW1PsqyvGOaB2EcjwiIoe9FsOBEqDCvfxzY8x/mn9UjUNEooFHgUuAWGA/MAt43BhzsCXHprRP1IJQjkuMMZHOD7ATuMBr3RFxEJHAlhtl/RGRYOBrYBAwGYgGxgFZwNhjON9x8bmV1o0KhNKmEJGJIpIhIr8RkX3AayLSUUQ+E5FMEclxv+/mdcx8EbnR/X66iHwvIk+6990uIuce4749ReQ7EckXkbki8pyIvF3L0K8DkoGLjTHrjTGVxpgDxpjHjDFz3OczItLH6/yvi8jjdXzuDSJyvtf+ge7vYKR7+SQRWSgih0RklYhMbOz3r7QtVCCUtkgi1kXTA7gZ+3f+mns5GSgC/lXH8ScCm4BOwF+BV0REjmHfd4AlQBzwCHBtHdc8E/jCGHO4jn2ORvXP/S4w1Wv7OcBBY8xyEekKzAYedx9zD/CRiMQ34vpKG0MFQmmLVAIPG2NKjDFFxpgsY8xHxphCY0w+8ARwWh3H7zDGvGSMqQDeALoAnRuyr4gkA2OAh4wxpcaY74GZdVwzDtjbsI9ZgyqfGytQF4pIuHv71VjRAPgpMMcYM8dtrXwFpALnNXIMShtCBUJpi2QaY4qdBREJF5EXRGSHiOQB3wEdRCSgluP3OW+MMYXut5EN3DcJyPZaB7CrjjFnYcWlMVT53MaYrcAG4AK3SFyIFQ2wVsblbvfSIRE5BJzSBGNQ2hAayFLaItVT8+4G+gMnGmP2ichwYAVQm9uoKdgLxIpIuJdIdK9j/7nA4yISYYwpqGWfQmzGlkMikOG17Csl0XEzuYD1btEAK1ZvGWNuOsrnUNoxakEo7YEobNzhkIjEAg/7+4LGmB1Yl80jIhIsIuOAC+o45C3sTfsjERkgIi4RiRORB0TEcfusBK4WkQARmUzdbjKHGcDZwK14rAeAt7GWxTnu84W6A93dfJ5FaZeoQCjtgaeBMOAgsAj4opmuew2eVNXHgfew9Ro1MMaUYAPVG4GvgDxsgLsTsNi92x1YkTnkPvenRxuAMWYv8CMw3n19Z/0uYArwAJCJFad70XuC4oUWyilKMyEi7wEbjTF+t2AUpSnQpwVF8RMiMkZEervdRZOxT+xHfepXlNaCBqkVxX8kAh9jU1gzgFuNMStadkiKUn/UxaQoiqL4RF1MiqIoik/ajIupU6dOJiUlpaWHoSiKclyxbNmyg8YYny1W2oxApKSkkJqa2tLDUBRFOa4QkR21bVMXk6IoiuITFQhFURTFJyoQiqIoik/aTAxCURSloZSVlZGRkUFxcfHRdz7OCQ0NpVu3bgQFBdX7GBUIRVHaLRkZGURFRZGSkkLtc0Id/xhjyMrKIiMjg549e9b7OHUxKYrSbikuLiYuLq5NiwOAiBAXF9dgS0kFQlGUdk1bFweHY/mc7V4gyioq+dOcDew+VNTSQ1EURWlVtHuB2J1TxDtLdjLt1SUcKixt6eEoitKOyMrKYvjw4QwfPpzExES6du16ZLm0tO77UWpqKrfffrtfx9fug9QpnSJ48drRTHt1CTe9mcpbN5xIaFBtUxUriqI0HXFxcaxcuRKARx55hMjISO65554j28vLywkM9H2bHj16NKNHj/br+Nq9BQEwrnccT105jKXpOfz6vZVUVGqHW0VRWobp06dzyy23cOKJJ3LfffexZMkSxo0bx4gRIxg/fjybNm0CYP78+Zx//vmAFZfrr7+eiRMn0qtXL5599tkmGUu7tyAczh+axP68Eh77bD0vLUjjltN6t/SQFEVpRv4wax3r9+Q16TkHJkXz8AWDGnxcRkYGCxcuJCAggLy8PBYsWEBgYCBz587lgQce4KOPPqpxzMaNG5k3bx75+fn079+fW2+9tUE1D75QgfDihlN6smBLJi9+l8a0cSmEBaurSVGU5ufyyy8nIMDef3Jzc5k2bRpbtmxBRCgrK/N5zE9+8hNCQkIICQkhISGB/fv3061bt0aNQwWiGrdN6sNl//6RGUt38rOT619QoijK8c2xPOn7i4iIiCPvf//73zNp0iQ++eQT0tPTmThxos9jQkJCjrwPCAigvLy80ePQGIQxsPlLKMwGYHRKLGN7xvLid2mUlle28OAURWnv5Obm0rVrVwBef/31Zr22CkR2GrxzJfzw9JFVt03qw97cYj5ZkdGCA1MURYH77ruP+++/nxEjRjSJVdAQ2syc1KNHjzbHPGHQxzfD+v/C7SsgOgljDBf+6wfyi8v4+u6JBLjaR6WlorQ3NmzYwAknnNDSw2g2fH1eEVlmjPGZL6sWBMDE+6GyAr79K2BL0n85qTfpWYXMWbO3hQenKIrSMqhAAMT2hFHTYfmbkLUNgLMHJtIxPIgfth5s2bEpiqK0ECoQDhPuhcAQmPcEAC6XkNQhjAP5JS08MEVRlJZBBcIhqjOcdCus/Qj22NL3ztGh7M9r+xOJKIqi+EIFwpvxt0NYLMy+GyorSIgKYX+eWhCKorRPVCC8CesA5/4VdqfCoudJiA4lq6CE8gqth1AUpf2hAlGdIZdBv8nwzeP0cu3HGDh4WNuAK4rS9EyaNIkvv/yyyrqnn36aW2+91ef+EydOxEnnP++88zh06FCNfR555BGefPLJJhmfCkR1ROD8f0BAEBM2PoZQyYF8jUMoitL0TJ06lRkzZlRZN2PGDKZOnXrUY+fMmUOHDh38NTTAzwIhIpNFZJOIbBWR39ayzxUisl5E1onIO17rK0Rkpftnpj/HWYPoJDj7cWIzF3NpwAKNQyiK4hcuu+wyZs+efWRyoPT0dPbs2cO7777L6NGjGTRoEA8//LDPY1NSUjh40KbhP/HEE/Tr149TTjnlSDvwpsBvzfpEJAB4DjgLyACWishMY8x6r336AvcDJxtjckQkwesURcaY4f4a31EZeR0V3zzBSXkbNJNJUdoDn/8W9q1p2nMmDoFz/1zr5tjYWMaOHcvnn3/OlClTmDFjBldccQUPPPAAsbGxVFRUcMYZZ7B69WqGDh3q8xzLli1jxowZrFy5kvLyckaOHMmoUaOaZPj+tCDGAluNMWnGmFJgBjCl2j43Ac8ZY3IAjDEH/DiehiGCq0N3EiVbayEURfEb3m4mx730/vvvM3LkSEaMGMG6detYv359rccvWLCAiy++mPDwcKKjo7nwwgubbGz+bPfdFdjltZwBnFhtn34AIvIDEAA8Yoz5wr0tVERSgXLgz8aYT6tfQERuBm4GSE5ObtrRAxLdhSTXCg6oBaEobZ86nvT9yZQpU/j1r3/N8uXLKSwsJDY2lieffJKlS5fSsWNHpk+fTnFxy9yDWjpIHQj0BSYCU4GXRMSJuvRwN5C6GnhaRGpM8WaMedEYM9oYMzo+Pr7pRxeVRGe1IBRF8SORkZFMmjSJ66+/nqlTp5KXl0dERAQxMTHs37+fzz//vM7jJ0yYwKeffkpRURH5+fnMmjWrycbmTwtiN9Dda7mbe503GcBiY0wZsF1ENmMFY6kxZjeAMSZNROYDI4BtfhxvTaK7EGEKyc3NadbLKorSvpg6dSoXX3wxM2bMYMCAAYwYMYIBAwbQvXt3Tj755DqPHTlyJFdeeSXDhg0jISGBMWPGNNm4/CkQS4G+ItITKwxXYa0Bbz7FWg6viUgnrMspTUQ6AoXGmBL3+pOBv/pxrL6JSrKvedrRVVEU/3HRRRfhPfVCbRMDzZ8//8j79PT0I+8ffPBBHnzwwSYfl98EwhhTLiK3AV9i4wuvGmPWicijQKoxZqZ729kish6oAO41xmSJyHjgBRGpxLrB/uyd/dRsRHcBIKRoP+UVlQQGtLRHTlEUpfnw65zUxpg5wJxq6x7yem+Au9w/3vssBIb4c2z1wm1BdCabg4dLSYwJbeEBKYqiNB/6SFwXbgsiUXK0mlpR2ihtZVbNo3Esn1MFoi6CI6gIjqazZGs1taK0QUJDQ8nKymrzImGMISsri9DQhnlB/OpiagtURnYhsShHq6kVpQ3SrVs3MjIyyMzMbOmh+J3Q0FC6devWoGNUII5CQIckEg/uZL3WQihKmyMoKIiePXu29DBaLepiOgqu6CS6uHK0mlpRlHaHCsTRiOpCJw6RmVfY0iNRFEVpVlQgjkZ0FwKopDR3X0uPRFEUpVlRgTga7loIV74KhKIo7QsViKPhVFMX79O5qRVFaVeoQByNI9XUOTo3taIo7QoViKMREU+lBLonDtJMJkVR2g8qEEfD5aI8PIFEydFqakVR2hUqEPUhugudUQtCUZT2hQpEPQiM6aoWhKIo7Q4ViHrgikkiUaupFUVpZ6hA1IeoLkRSRElhbkuPRFEUpdlQgagP0TbVNaRwfwsPRFEUpflQgagPUbZYLqxYBUJRlPaDCkR9cFsQESVtv2e8oiiKgwpEfXBbENFlKhCKorQfVCDqQ3A4RQGRdKg42NIjURRFaTZUIOpJQVAcMRU5LT0MRVGUZkMFop6UBkYRbgrb/OTmiqIoDn4VCBGZLCKbRGSriPy2ln2uEJH1IrJORN7xWj9NRLa4f6b5c5z1oTw4iigKKC7Tlt+KorQPAv11YhEJAJ4DzgIygKUiMtMYs95rn77A/cDJxpgcEUlwr48FHgZGAwZY5j62xXw8lcHRRJFOQWk5YcEBLTUMRVGUZsOfFsRYYKsxJs0YUwrMAKZU2+cm4Dnnxm+MOeBefw7wlTEm273tK2CyH8d6VCpDYoiWAgpLKlpyGIqiKM2GPwWiK7DLaznDvc6bfkA/EflBRBaJyOQGHIuI3CwiqSKSmpnp5xTUkGiiKaSgtNy/11EURWkltHSQOhDoC0wEpgIviUiH+h5sjHnRGDPaGDM6Pj7eT0N0ExZDiJRTVFjg3+soiqK0EvwpELuB7l7L3dzrvMkAZhpjyowx24HNWMGoz7HNSkCY1a2Sw5rqqihK+8CfArEU6CsiPUUkGLgKmFltn0+x1gMi0gnrckoDvgTOFpGOItIRONu9rsUICLcCUV6gAqEoSvvAb1lMxphyEbkNe2MPAF41xqwTkUeBVGPMTDxCsB6oAO41xmQBiMhjWJEBeNQYk+2vsdaHoAi3QBQeaslhKIqiNBt+EwgAY8wcYE61dQ95vTfAXe6f6se+Crzqz/E1hOCIjgBUFOmcEIqitA9aOkh93BAaZQWCIrUgFEVpH6hA1JOQyFgATEleC49EURSleVCBqCeusBj7WqwCoShK+0AFor4EhVNOAK5SFQhFUdoHKhD1RYTDRBBUpgKhKEr7QAWiARS4Iggqy2/pYSiKojQLKhANoNgVSXD54ZYehqIoSrOgAtEAigMiCa1QC0JRlPaBCkQDKAmMIqxSLQhFUdoHKhANoCwokvDKwpYehqIoSrOgAtEAyoOiiUQtCEVR2gcqEA2gIiSacEqgoqylh6IoiuJ3VCAaQGVwNABl2tFVUZR2gApEQwi1AlGcr3NCKIrS9lGBaAAu96xyxYdbdGoKRVGUZkEFogE4AlGm044qitIOUIFoAIHuaUfLCnTSIEVR2j4qEA3AM+2oWhCKorR9VCAaQHCknVWuUmeVUxSlHaAC0QBCI2KoNILReakVRWkHqEA0gPDQYA4TBjrtqKIo7QAViAYQERxAHuFIiVoQiqK0ffwqECIyWUQ2ichWEfmtj+3TRSRTRFa6f2702lbhtX6mP8dZX8KDA8kzEQTotKOKorQDAv11YhEJAJ4DzgIygKUiMtMYs77aru8ZY27zcYoiY8xwf43vWAgOdJFPOJGl2rBPUZS2jz8tiLHAVmNMmjGmFJgBTPHj9ZqFQlcEweU6aZCiKG0ffwpEV2CX13KGe111LhWR1SLyoYh091ofKiKpIrJIRC7ydQERudm9T2pmZmYTDr12ilyRKhCKorQLWjpIPQtIMcYMBb4C3vDa1sMYMxq4GnhaRHpXP9gY86IxZrQxZnR8fHyzDLg4MEqnHVUUpV3gT4HYDXhbBN3c645gjMkyxpS4F18GRnlt2+1+TQPmAyP8ONZ6UxIQSWhlIVRWtvRQFEVR/Io/BWIp0FdEeopIMHAVUCUbSUS6eC1eCGxwr+8oIiHu952Ak4Hqwe0WoSwoEhcGStWKUBSlbeO3LCZjTLmI3AZ8CQQArxpj1onIo0CqMWYmcLuIXAiUA9nAdPfhJwAviEglVsT+7CP7qUWoCLJzQlCcC6ExLTsYRVEUP+I3gQAwxswB5lRb95DX+/uB+30ctxAY4s+xHSsVIW5RKNZaCEVR2jYtHaQ+7jAhUfZNsVZTK4rStlGBaCghtuW3CoSiKG2degmEiESIiMv9vp+IXCgiQf4dWutEwq2LyRRry29FUdo29bUgvsMWrnUF/gdcC7zur0G1ZpxpR8sL1YJQFKVtU1+BEGNMIXAJ8H/GmMuBQf4bVuslKNxmMZUV6KxyiqK0beotECIyDrgGmO1eF+CfIbVuQkNCKTAhVBSqi0lRlLZNfQXiTmw66ifuWoZewDz/Dav1EhESSB4RVOiscoqitHHqVQdhjPkW+BbAHaw+aIy53Z8Da62EBweQZ8IJVYFQFKWNU98spndEJFpEIoC1wHoRude/Q2udRIQEkm2icRUeaOmhKIqi+JX6upgGGmPygIuAz4Ge2Eymdkd4cAA7TQIh+TtbeiiKoih+pb4CEeSue7gImGmMKQOM/4bVeokIDmSHSSC0OBNKC1p6OIqiKH6jvgLxApAORADfiUgPoF02IwoPCWCXSbALOektOhZFURR/Ui+BMMY8a4zpaow5z1h2AJP8PLZWibUgOtuF7O0tOxhFURQ/Ut8gdYyIPOVM7ykif8daE+2OsKAAj0CoBaEoShumvi6mV4F84Ar3Tx7wmr8G1ZpxuYTSoBiKAqIgRy0IRVHaLvWdD6K3MeZSr+U/iMhKfwzoeCAiJICsoCS6qYtJUZQ2TH0tiCIROcVZEJGTgSL/DKn1Ex4cSGZgkloQiqK0aeprQdwCvCkizhybOcA0/wyp9RMeHMBeEhlxaAFUlEOAXyfmUxRFaRHqm8W0yhgzDBgKDDXGjABO9+vIWjEdwoPYXpEAleWQl9HSw1EURfELDZpRzhiT566oBrjLD+M5LkiODWd1Yaxd0DiEoihtlMZMOSpNNorjjOTYcFYXuAVC4xCKorRRGiMQ7bLVBkD32HD20ZFKV7BaEIqitFnqjK6KSD6+hUCAML+M6DigR1wEBhdFEV2JUAtCUZQ2Sp0WhDEmyhgT7eMnyhhz1NQdEZksIptEZKuI/NbH9ukikikiK90/N3ptmyYiW9w/rSpjKjk2HIDs4K6Qnd6yg1EURfETfsvPFJEA4DngLCADWCoiM40x66vt+p4x5rZqx8YCDwOjsRbMMvexrWIi6I7hQUSGBLLHlUj3nJVgDEi7DckoilJaCAc3Q9Lwlh5Jk9KYGMTRGAtsNcakGWNKgRnAlHoeew7wlTEm2y0KXwGT/TTOBiMidI8NJ60iAUoPQ2FWSw9JUZSWZNFz8PKZUJLfPNdb/AIsf8vvl/GnQHQFdnktZ7jXVedSEVktIh+KSPeGHCsiNzsNBDMzM5tq3PUiOTaMdUVxdkED1YrSvtm5GCrL4FAzTST243Pw5QNQctivl/GnQNSHWUCKMWYo1kp4oyEHG2NeNMaMNsaMjo+P98sAayM5Npxl+R3sggaqFaXtUpIPhdm1bzcG9iy375tDICrKIDcDSvJg1bt+vZQ/BWI30N1ruZt73RGMMVnGmBL34svAqPoe29Ikx4aTVh6HQdSCUJS2zKw74MWJUFbse/uhnR4386FdvvepjjGwaoaNXTSU3F1gKkBc1tVUWdnwc9QTfwrEUqCviPQUkWDgKmCm9w4i0sVr8UJgg/v9l8DZItJRRDoCZ7vXtRq6x4ZTQjBl4YlqQShKW2b/Oji0A1Jf8b199zLP+0M76nfOnYvgk5/D8gY5TSzOPDQjr4OsLZD2TcPPUU/8JhDGmHLgNuyNfQPwvjFmnYg8KiIXune7XUTWicgq4HZguvvYbOAxrMgsBR51r2s1OKmuuWHdIDuthUejKIpfqKz0eAi+exKKc2vus2c5BARDx5SaLqaiHPj6sZrWx67F9nXzMTz3OuM5+U6I7GytCD/h1xiEMWaOMaafMaa3MeYJ97qHjDEz3e/vN8YMMsYMM8ZMMsZs9Dr2VWNMH/dPq5ucqGvHMERgd1AK7F/vVzNPUZQWIn8PVJTAyGlQlA0L/1lzn93LIXEoxPa27h9vNsyCBU/Ctq+rrs9Yal/Tv2945lNOOgSEQIceMPoG2PI/yNrWsHPUk5YOUh+3hAQGkBQTxiZSoDRf3UxK62LXUtg6t6VHcfzjPK0PuggGX2qzh/L3ebZXVsCeldB1JHRIrmlBZG6yr9u/86wzBnYtgY49beZT2nzf1zbGbjt8oOr6nHTo2ANcLhj9M3AF+c2KUIFoBN1jw1hW6o6l71vdsoNRFG/m/xE+r9G8QGkojvs4thdMehAqSuHbv3q2Z26CsgLoOgo6dLfB6tKCqtuhqkDkpEPBATjpFxAS49vNdGADvHEBvDkF5v2x6rac7dadBRCZYIUrJ90KShOjAtEIkmPD+SEvAVyBsG9NSw9HUTwUZELeHr/cNNoV2Wn2CT26G8T1hlHTbWDZEQ4nvTVppHX5QNVMpoObAIED6z2WgONe6jEO+pxuXUSOi9oY+PpR+Pcp9p4Sk+y5hrM9Z4e1Phwu/Cdc875fujmoQDSC5Nhwdh+upLJTf9irFoTSiijIsk+2voKqSv3J2W5dR86skRPutYIx/892efcyCImGuD4Q4/YmOG6m0kIrFn3PtsvpC+zrriUQHAkJA6HvOXB4P+xbZbeteBsW/B0GXwa/Wg6DL7ExzvJSu70ox9Y/OBYEQGCw3z6+CkQj6O7OZDrccaC6mJTWgzFQeNC+z9vTsmNpjXz5IGybV799s9Ose8khKhFOvBlWv2/dQLuX2/5LLpcVEoBct0BkbQEMDL3CupIcN9OuxdYl5QqAvmcBApv/Z4Xli/sh5VS46HmIiLPnriyzFgh4YiLeAuFHVCAagZPqui+sr30KyN/fwiNSFGxWTIX7iVMFoioFWfDjv+CD6Uf/boyxN2RvgQCbXhoSBV89bGskkkba9ZGdbbqrY0FkbravCSdAyslWIEoL7DHdx9ptEZ2g22jY/Dn895eAgSnPWcEB6DLMvu51WxhOMkysl4vJj6hANAJHILYGuP+ANA6htAYc6wEgr1U1IGh5Mt2Z9MWH4JNb6k5PLzhom3FWvxmHx8K422DLl/bpvqtbIFwuiOnmiUEc3GSrneP6QM8J1hpZP9NWQXcb6zlf33NgzworIOc8YTOUHDr2tNbH3pV22SmS6+C1jx9RgWgEsRHBRAQHsLrCbVo6fkRFaUkKvLoLqwVRFUcgTvsNbP/WdmGtDe8MpuqcdCuEuacd7jrKs9471TVzk3UFBYZYgQAbXwBrNTj0O8e+9jnT1lt4IwJdhtpUWrAWRGRnCA6v82M2FSoQjcBp+70112X/EBoaqM7cBO9cWfUfWlEai1oQtZO50QaIJ94PA86HuX+o/f+2LoEIjbZP+/3OhWivRtMx3T0CcXAzxA+w7+NPgPBONi7RqZ+1QhwSh8Clr8AlL/nOREoabt1SFWU1M5j8jApEIzmhSzRL03OoSBjS8ED1wmdh8xe20vJ4paIcvnncmuNK68D5XYR3UguiOpkbIb6/vRFf+E8bS/jhGd/75my3LiIn+Fyd4VfD1TOq3tQ79LA1DiX5trq5Uz+73uXyWBHe7iWwxw+5rKpoeNNluK3mztxoYyLNFKAGFYhGc+WY7uQWlbGeFPvEUd+y+eI8WPuxLZlf8pLHt3i8sXcVfPc321JAaR04FkSXoW3Hgtj2Td0dVetL5ib7NA/2htx7EuxY6LteJDvN1j8EhtT//I6YpH9v4xPx/T3bHIHoPqZhY+7inqVu1xL7+1SBOH44sWcs/TpH8slet/rvW1u/A9d9DGWFcOnLNt3tmyf8N0h/4mRV5O9t/LkO7YSDWxt/nvZOwUEIDIO4vm3Hglj7sQ3kZjXi76Mw22Ybet+0e4y3/ZZ8PaBlpzU8W6iDuxZiy1f2tZPXtU64EAZdAv1/0rBzxvaC4Cj3Q5hptgwmUIFoNCLCtSf14LMDCXZFfd1My9+0hTInXGADXmve96SyHU80pUDMuRc+/Fnjz1MbpYV2WshdS/13jdZAYZZNn4xOskVVxXn+uc6aD5uvEG/XEvua3YimdE7bCycuANDjZPu6Y2HN/X2luB4Nx4LY6ghEX8+2iDi4/DWIbODkZi6XtQadOgq1II4vLhrRlYLgOPIDOtYvUL1vra3AHHmd9T+efCeEdrABs+MN58krrwkEImcHHNziv864WVttm4PqnTXbGgUHITzOEzxtCvGuzqGd8NENsNK/M5oB9sn/oPvm3piupZnu6WYSvASiU3+bjVRdIIpybPfWhj6tR3WxrXcO7YSoJBvMbgq6DLPpsaBB6uONqNAgLhnZnRVlyVRu/gIWPV+zA6M3K96ysYehV9rlsA4w4R5748pYVvtxrZHsdPvaFDeh/D1QXgSH9x1932M6v3uMbX3+jsKD1oKIcQtEY+IQ2Wnw1KCa35nT0bR6e2t/kJHqNZ5GWhBBETau4OByWTfTjh+q7utULDfUgnAFeIQ5vt+xj7U6ThwiMMw26GsmVCCaiGvH9eDpsovJCoiHL34Lf+9vKyOrB7/Kiu1UgydcUDVrYcRP7ZPHxuMs2HvEgmikr7u00OOu8GLsxjIAACAASURBVNcUrs6Nsq0LREGWzWCKTrLLjfnd7FoKeRk13Z+OQDTHHMy7FoME2DkXshrxuzuwwcYfXNVuez3GW1ep9/eUc4wCAR43k3f8obE4FdUdU/zSlK82VCCaiH6dowhKOYmLyv5I6S2LYNhU23hr9/KqO67/r63iHHld1fVhHe0f6qbPGz+YH56xvWL8TXmJvekGhllzvDEZJt4WiL9u4M4NoK0LhGNBRLln9G2MQDgPAPnVrLrD7rYyuRnHfu76smuxrRVIHNp4C8I7/uDQY7x99XYzOX8jx+LvdwSiKS2ITn2t9dOMAWpQgWhSbpnYm92HivhoZwSc+xdbkJP6qmcHY+DHf9rc6JRTa56g/3nuXOdG3MBK8m1dwpKXjv0c9eXQTsB4qkIb42ZqToEozIKiQ/65RktTWmiz48LjbHpmRHzjXEy1JSE0l0BUlNt4XfcTIa6XvW5DZ2ADG1M4vK9qBpND4lCbJeTtZsreDpGJEBzR8Gv5w4JwBcDkP9qElmZEBaIJmdgvnuHdO/Cvb7ZSGhABQy6HtR/ZP06ws0PtWwPjf1XTzAXoN9m+bvri2Aex5X+2UVvmRv/PBeC4gpxMkMYIhBPkdgX5USC8bpRt1YpwaiAiOtnX6KQmsiCqNaJ0LIqCA42vTaiL/Wut4HUf63H3HMvvzslgSjih5jZXACSf5LEgDmdC2rdVM5AaQrcxVqATBx/b8bUxarqnlqKZUIFoQkSEO8/sy+5DRXywbBeMvt4GXVfNsDssfNb2UXGC09WJ7WlTXzfNOfZBOAVrJXn+yV7xxnm67DHOvjbKgnDfxLqO9K8FEef+p2+rAuFdRQ02YNoYgcg+igUB/i3Gc9Jbu59o53yGY8tkcnow+bIgwLqZMjfaTLp3LrdW5hkPN/w6AH3OgPvSrNv4OEcFook5rV88I5I78Nw3WymNH2yfJlJftZbDtm/gxJ/XXZnZb7J9knGsjoZQVmz7yjum7YENx/Yh6ktOuvWLJg61y41Jdc3b6zlX9vamt36Mgdzdtu0y+C8Q3tIUuvt6VbEg6nEDr6y0N0dvSgs9GWW+YhDBUfa9PwPVuxbbdNGYbl4WRD0EoqIcfnjW03L7wEYICrcztPnCsYJf/4kNyF/2asMrntsgKhBNjLUi+rEnt5j3U91WxMHN8NFN9gY4+vq6T9D/PJvvvPUYcvXT5tlZxE692y47ZrW/cPrChHW0gerGxiCiu9hpHUvzPTe6pqIkz343sb3tU3WbtyDi7Gt0kn3YKC2s+7iFz8I/R1YV+UNuwQiLrSkQ+fuh6wj7vinjECWHq/5udi2x7iURCIm0cYH6ZDJt/Qq++j28NMkmhmRutLE/X65dgKQREBhq03Z/8hQMOK9pPs9xjl8FQkQmi8gmEdkqIrXOoC4il4qIEZHR7uUUESkSkZXun3/7c5xNzYS+nRiZ3IH/m7eV0v5TIDTGFumMmnZ0s7PrKBtYPBY304ZZ9lqDLrY3CMes9hc56Z60u+gujXNl5O+1WTeN8TPXhXPji06y12hMNkxrpkYMwqmFqON3U1pgBaKy3LazcHDiD8njoCTXIzKVFTb2kDQCkKYViE9vgWdHwmd32af+3J3WveQQ17t+v7vV79n/gfgB8P51tjeSr/iDQ2CwLVg9548w2o/V/McZfhMIEQkAngPOBQYCU0VkoI/9ooA7gMXVNm0zxgx3/9zir3H6AxHhV2f0ZU9uMbPW58CIa23wtT4ZCC6XdTNtmeuZh9YXxsCsOz1ZUhVlVlT6nWv/2OMH1BSIdZ/YIr6mwBh7A3HS7qK6ND5I7dy8wQ8C4XazRCfZMbdlC8IVZOdJBq9aiDrcTKmveSw271YxjkA4MSbH3VSYBabStraO6tJ0xXJ7VtqHnC7DYNlr8ILT3M5LIGJ7HT0GUZxn08UHXwo/mwOjfmYb5zmu0NqYdD+M+2XjPkMbw58WxFhgqzEmzRhTCswApvjY7zHgL4AfUyGan4n94unfOYoXvttG5aTfwS8W1d42uDr9z7NPbNu+qX2f7d/af6LPfg1z7rN9WopybAEe2GBc9Uym+X+B+X9qGv/+4f02AO/kiUc1woKorHRbEInu70j8IBDusTkiVJDpvx5FLYlTA+EUUx3NgigrttZDzwnWBePdKiZ7u40zJLif6/KrxSMiE2xzuqYSiPl/si1nps2Em+ZB54E2qSNxiGefuN72M9bVA2rDLCgvhiFX2HjfBU/DzxfAmBubZpztCH8KRFfA+y8nw73uCCIyEuhujJnt4/ieIrJCRL4VER9FAyAiN4tIqoikZmZmNtnAmwIR4een9WLz/sPMT8uDTn2ObDNHu0H3OcPeKL953JrzvljykvUNn3gLLHnBzrEbFA69T7fb4wfYfyIn2yR/n3VzFed6fMu+yNoG3/6t9us6HJk83W1BRHex1zgW8SnKtk94UUn2Hzqmu/8EIqqLJxsmpw0Gqp0qaocjxXK1WBAr3rJ/IxPus0/Y1S2I2BSPFeJYiM7fVGRi1Sk2G0PGMjs3yvhfWTdp0nArEnesthaxQ30ymda8b/8uvWdt6zK06nmUetFiQWoRcQFPAXf72LwXSDbGjADuAt4RkRpdr4wxLxpjRhtjRsfHN7BDYjNwwbAkkmJC+fe39mZXWWn405wNjHnia1btqqNQKzDEptjtX2N9qdXJ3W3dSSOvtQV55z1p587te7ZnKkKnYtTJZHI6QULdDQWXvATzHoeF/6z7wznuhyMWRJKd1KQwu+7jfHHk6d59M4vt2fRZRnm7bWwnMMR/bqzWQOHBqi1cgsNt3MuXBVFeCt8/Dd1PgpRT7E00d5fnd5jjTkKISrTLjuXgCERUZysQebsb3mBx/3pba+AcN/+P7geen3v2EYGg0KrHxbkForbfXd5e+7c+9IpmbUnRVvGnQOwGunstd3Ovc4gCBgPzRSQdOAmYKSKjjTElxpgsAGPMMmAb0IR1681DUICLG07txZLt2SzcdpBfvrOcF75Lo7isgumvLWHrgcO1Hzz4UkgaCV8/VjMDZdlr9kndyYgaexP8YjGc/w/PPo5AOJlMafPtk5kE1N2SPP17+zrvCTvNYW3kbAfE4zZzbu7HEodwjolyP6nG9mrczdsYm1bsTd4ez5OwEzepTz596mt2ovnjhYKDngC1Q3Q33wKx9CXbZ+m0e+3N1PHR71vtSXvt2NO6fQJCPL+nIy6mztbaqyi1Lrv6smcFvHI2vHkhPDPUukm3zoWT77AzvNVFx6P87tZ+ZOMjQ66o/3iUWvGnQCwF+opITxEJBq4CjvynGWNyjTGdjDEpxpgUYBFwoTEmVUTi3UFuRKQX0Bc4Lh/3rhrTnZiwIK57ZQlfrNvH788fyGe/OoUAl4trX1nM7kNFvg8UgbMftwVki/7Ps768FJa9YSc69+4TE19tntvIBPuP7cQh0uZDr0k2NlGbBVGYbStXT7zVBjk/uaX2QHlOun16dMz2qGpuiIZQw4LoZd1Ox1ILArDxM/j3KVWtprw9Hn98cIR1jxzNSqmsgK8ePr6mhC2s5mICK4yHdlR1/6V/D189ZBMiep9h1zkCsXe1/T1WlHiy1KISq1oQITEQFGYFAqrGIfL32T5dvsjcDG9fajsYT3nOxj1SX4OIBPugczSCw+tOU17zvs2u8nLpKseO3wTCGFMO3AZ8CWwA3jfGrBORR0XkwqMcPgFYLSIrgQ+BW4wxx+C7aHkiQgK56dSeBAYIz18zkhtO6UlKpwjevH4sh0vKufqlRby8II21u3OprKzmv0852Qasv3/aFu8YAxtm2hTDowXcRGxaX+ZGOw9C3m7oNbGmn9mbHQsBA4Mugguesft99zff+1afGze6EY3h8vcBYp9IwcsFdIxuJiezK+1bz7q83R4LAtzpkkd55ti3xiYL7F/n33YSTUV5ia33qG5BdB8LB9bbyZhK8q1l8P519nu+5EWPKybCPYfEvtU+XIhdqgpElPt3FeNune0IRFkx/N9JMPNXNcd3aBe8dbGd5/naT20H42s/hl+vg5u+qX/fo9rSlPettf8ntXUqUBpMoD9PboyZA8yptu6hWvad6PX+I+Ajf46tOfnlpD7ccEovwoIDjqwbmBTNq9PH8JuPVvP4bBsniIsI5rGLBnPekC6eg8/8g52L94UJNkBXWW7NbOepry7i+8O6T2HbPLvca6Lta7N6hu03U31mq/TvbcFb0khrGQy9Chb83dZvxHSrum9OurViHCIdP3U9LIjZd1sXmPPEmL/HxgcCguyy4wLKTrOtNxpCzg7P53War5UW2g66UV7fa2xPm0pcF+kL7GtluRWL1l5Z66SqOkVyDqfcZfsNff2o9f27AuxnmjrDuh29SRxqLQhHII6kMSd6XI75+z1i7kyx6QSq0+ZZy2/1ezD2Zk+guKwY3rnSCtj0z6o+4cdUyV05OnG9fbv9vn/KNshUgWgytJK6GRCRKuLgMCYllm/unsii+8/gH1cOo3tsOL/4z3KemL2e8gobvDsQksz8yV9SeNbfrL8/NwPG30ZeaQV/+3IjK+sKdscPsDfGNR9Ahx72n/2In9nH9KbpCyD5RI/b6JRfu6u6q91ISw5bK8a79XBgsHVtHM2CyNkBS1+uWo+Rt9djgYDnqfVYLIgVb9nXQZfYLqBlRR7Riva6EcX2snn9pQW1nyv9exs4BdizvPb9WgsF1YrkHFwu+7u87r/WdZe5ES57zRPw9abLUMjaYi0OCfC4kKpbEI5AhMZYd6RTLLfhM+t+ikiALx/wuLXmPgwH1tkWFs7cBsdKbG/7OZzPC9Z1tfZja1l7u1qVRuFXC0KpH4kxoVw8ohs/GZLE47PX89KC7Szenk1ZhWHDXpur3zE8hd9MfpYrpiayKD2Xe/7xHXtyi/lq/X4+v2MCAS4fGRtOY7KMJTBymvti7pzyvauhz5mefZ34w+m/q3p8dDcrEKOme9Y76aHVe+VH16NYbs0H9jV7m3tS+F72mBivfIbgCHtDamgaakW5nYOjz5n2KXLdx+7ZyNw3KW8Xk3cmk3eevUNlhXW5DboYNn9pxaY2SvJt+/AO3Wvfp6moKIfZd9nPOLCap7awWqO+6vScALcutO6grqN875M41AZ5N35mrUbHqotKtC1QSvKrCgTY/XIz7Ng2zbaWZcopMOt2WP+pfapf/G+bkt33rMZ9fudziMtaope/bl1kC/5uYyLjbmv8+ZUjqAXRiggOdPHolME8feVwMvNLiAkL5DeTB/D6z8bQNyGK3368hjOeWcjVrywhNCiAX07qzeb9h5m9ppabcrxXa4FeE+1rWAdrTVSPQzjuGO95KkSgz+nWl19R5lm/+Uv72q2ayyUqqe6GfcbYiYw69LDLTr+pvD1VLQiwN/D07+Hz31h/+ex7jt5PaOtcKzajptn2zYi9yR8JglezIKD2OMS+1dYd0nOCdXNVn/jJmy8fhOfH12yJ7Q/mPgzL3/BdEV9QrVGfLyITahcHsBYEeNqoODjuuYNbrJsyylsgutuWGDt+8BRrjvgpdB4M/3sIPv2FLbY7s4nmXE8abtPA139qEziyttng9Ojra7pNlUahAtEKuWhEV368/wxm3DyOWyf2ZmL/BN77+Uk8feVwKo1h+vgUZt9+Knef1Z/+naN4eu7mIy6pKkQlWnMfoOdpnvVdhtbMZPKOP3jT50x7o3TmBTbGWgHJ42pWhkd38bTt9sW+1Xby+VPutHGUrV/bwGpRdtX4AFjf9aEdsPId6zdf+jK8fUndE/0sf8O6NvpNtkKYONjetI602fCOQfS2U7yufNc++VbHSfftcbL9TrK2+K7eNcYWeJXkwTeP1j62pmDNh/Djv2yMIWNJzYlzjmZB1IeY7jb7Daq6EJ1aCGfqUSfmBB4LYsMs+zfU5wwb5zj7cSscxblw6Ss1axoaw8l3wIDz4X+/twLkCrJFdkqTogJxnCAiXDSiK9/eO4lHLhxEWHAALpfw67P6kpZZwH9X+rgxi1j3SdIIm6HikDjMuni8bzDp31eNPzj0PM36ore5n/b3r7M+7CGX1bxeVJINlNaW4rj6ffuPPPAiKzzbv/O0mK4uEGf+AR7YA/fvgl+lWt91Riq8fj4cPlDz3Hl7rWUz4hqPW6THybYbaE66vel5Z8mERNrGbJs/h8/urFkBnv49xPWxouIEyr0b2TnsX2tdLnF9YMV/6rY0GsO+tTYzKHkcXPyCDTKn/1B1n4KD1vXSmHkIRDxWRBULorpAJHi2xXSzlsO6T6w4ON9z70kw6Xdw6Uu2bUZTIgIXPW9FbNci6wKNSjzqYUrDUIE4zjlnUCKDkqJ55ustlPmyIi55Aa54q+o69w3gT699YNt+OPGHlFNqHh/WwbqSnED1mg/sk/fAi2vue6RYbl/NbZUV9th+59ggYp8zbfvtdR9XPdZBpOoNffAlcPUMK2yvnVcz7XTZ6zagPuJaz7oe422/qM1fVnUvOZz4czjtNzawPddrchgn/uB8H0nutta+bv7O93LVu9a188VvfbcbyUm3zRUX/suKT337QFVW2uDrO1fYYPDlr1s3YGCozRjypvCgDarX1tK6vjiJDB19WRArqy6Dx5IsPOjpBeZw2r0w0FcLtiYgNBqu/I8tKj31Lv9co52jAnGcIyLcdVY/dmYXcsn/LeT0v89n4ENfcO8H7ie9mG41gqdFcYMAKN61ki0HDnvSOX3Nkw32qXDPSpsau+ZD2+8pIq7mfo4V4CtQvf1b+6Q91F3h2vNUCAi2T93gKbSriz5n2htk1hZY9Y5nfVkxpL5iXUvemTnOJDCH99cUIIeJ99vMlx+egbmPWHFw4g/O9xEea2+WvgLVW7+2vvb4ftYvvmuxreb1xhiYdYcVsf89aCel+Xt/j9uuNrbNgxdPs/ULIdFWIKMSrasmeZwnndfBVxX1seCkpnbyal4QEm17fTmprtWD1GAfHLxTn5uDhAHWulTrwS+oQLQBTh+QwIXDknC5hP6doxidEssHyzJYuPWgz/3/u7WCTBPNWNcGcj57yFZMh8fVjD849DkDMLZfTl6GnWvbF45ArHzHdo6dc5/NvV/8on1yDomBvu4bSHCEfcLPdc9GVt9/8L5n2yDr9097YgdrP7KtHqq3U4/o5JldL7oWARKBc/9mXRTf/wPevQo2untHOgID9prVXUwl+bBzkfv7AYZfA12G26C1d7B+/X9tJfu5f4F7tsA1H9r00Nl3194U8cBGW1RWnAsXvwi3/uCxZMCK9MFNti8XWBHK2mrrSRrLCVPgxm+quoWcauqKUivs3m4sJwOt54Q2Mc2m4kEFog0gIjw7dQT//eXJPP/TUbx47SiSY8N5aOY6Ssurup2MMby2cAc7gvrwk4AlnLjrVeh/Ltw4t/Zul12GW9dF6qv2KbJ/LbNtdUi2ro/lb1gxWfWuvZF/fq+NYQy+pGqg0kmzDQyt/41FxM6Yd2iHu++OsRk9CQOrBuIdnClGfbmYHFwuOP9pO5PYtnm2etyJPzh0HWmD3d7us+0LbBda53O4XHDhP23jxP9cbm/upQVWMDoPhtE3WN9937NsAHfvSlj+pu8x/fCM/V5umgfDrrRBX296T7KvafPtqzNrWlMUiblc0M1HppPzABDZuWojvKhE+92Pvbnx11ZaFSoQbZDQoAAevmAgWw8c5rUfqtYS/JiWxab9+ZQMu5b0zmdzfsnjbJ3wrCft0xeuAE8b8f7n2QCvzwtHw51r4a6N8LtMG2D+/UH71HzLDzD5T1X37+POiY/q0rDOm/3OtYLw/VM20L1/jbUefJ3DsQJqsyAcRGDMDbbKNyqppt/cSQ31jkNsnWunke1+kmddl6FwxZu2tfp7P4V5bqvrvCchwKvsaPCl0OMU+PoPNTvg5mbYtM2R1/l25QEkDLLWQto8m4L89aM2rXn41XV/zsbgWHne7iWwfx/TZtoHDaVNoQLRRjnjhM6cMSCBZ77ewt5cT0PA135IJzYimFGTpxF2zVusNb34Ym092mM4BU61uZccIuPtk7djjbhc9qk5cbAtZALeX7qLuev3ewrx6nq694XLZdtHZG6ET2+17rHaxtXnDOuW6jmhfudOPgnuWm+zb7xJHGqzuZyKamOsQPScUNPy6nOGbUS3/Tubljr0Ks+sbA4icN5fbbD6m8eqblv0vD1/XbObuVy2tiVtvo1tZG+DMx+uaWk0Jd4WhNIuUIFowzx8wSDKKw0/e20p/1m8g1W7DjF3w36uHptMaFAAnaNDGd2jI3PW+Mg6qs7gy6zvvFoQsrS8kjd/TOdAfv2a2a3bk8tvPl7NTW+l8vGK3TYF8qxjqB8YdLFNw8zbbQuk3OJTg7COcM0HNau+60KkZiZQcLi1Wla/b2/K2WnWzeXEH6oz7Co4+wmI61v75+s8yLplUl+DVTPsuqIce8MffCl07FH3OHtNsrGXrx62Qet+k+v/GY8Fx4KIUoFoL6hAtGGS48J58vJhlFZU8uAna5ny3A8EiPDTkzw3nsmDE1m/N4/0g3X0JALrHul7Vg03zjNfb+ah/67juleWkFtUVsvBFmMMf5yzgZiwIE7qGcfdH6zio4PJvv3dRyMgECY9aIO9o29o+PHHwtmP2TYUb06BNy+y67zblVRn/G22hqOuG+qkB6zV8snP4eOf29hD6WFbCHY0nDhEWYGtG/H3BDmRtbiYlDaL9mJq41w4LIkLhnZh/d48Plu9l8ToUBJjPIHic4d04fHZG/h87T7OH9qFD1J3sWLXIbrHhtOrUwQDk6IZ1ysO8XHzWZqezfPztzGuVxypO7K58Y2lvHXDiYQG+XZzzNt0gB+2ZvHwBQO5akwyN72Zyj0fruLHtCxCg+yzyvjenap2s62LoVdY11JzzRzWexLclmqruhc8aeMA3tXGx0JoNEz7zJ7v279YAepzlnXJHY3oJBsb6dDDFjn6m9piEEqbRY46P/JxwujRo01q6lHyyhWfTHnuBzbvy6eorAIR6N85in15xRwqtBbBT4Z04Y8XDyEmPOjIMfnFZZz7zAJcIsy541TmbzrAr95dwRkDOnP7GX0oKq2gpLySQUnRxEWGUF5RyeRnFlBRafjyzgkEB7ooLqvgrvdXsijNBmmLSisIDXKR+ruzfDcfbE2UFtjgcFiHpjvnjh9t9tdZj9l+Q/WhogyQqgFwf1GYbWs4Ln2l6SujlRZDRJYZY0b72qYWhMLPxqfw72+3cd6QLlw2qhtJHaw/P6eglHeX7uSp/21m5a5D/O2yofSKj6SsopJ/fLWZPYeK+OCW8USGBHL+0CSyC0p56L/rmLvB07QuKEA4Y0BnEmNC2XrgMP/+6SiCA621EBoUwP9d43EvzVy1h9vfXcHKXTmM6tHKWzbXd3KbhtBjHEyb1bBjAoKOvk9TER4Lv/ix+a6ntDgqEAoXjejKRSNqZhJ1jAjmFxP7ML53J+6YsYKrX15cZfvtp/dhVA9P/cJ141IYlBRNTkEZYcEBiMA3Gw7wyYrdZBWUMjYllnMG1e6eOK1vPAEu4ZuNB6oIxJqMXFbsyuG6cSmN/7CKotQbdTEp9eJwSTmzV++h0kBQgIuO4UFM7J9QL1dQaXklP6ZlcUJiFAnRdXf0vOKFH8krKuOLOz1pqZc9v5DUHTl8eecE+ifWnNT+4OES/vn1Fv63fj/jesdx8YiujO/dya9uquKyCsoqKokKrf8TvDHGZyxHUVoSdTEpjSYyJJArxyQffUcfBAe6OK1f/VpAnDEggT99vpE9h4pI6hDGhr15pO7IAeCNH9P548WeyX1Kyiv49/w0XvxuG8XllZzSpxNfrd/Px8t30ykymDEpsQzr3oER3TswJiUWVy2CcaiwlFveXsZPhiZx7UlHSS11c8vby1i7O4+Zt518xCVXF+8u2cmzX2/hw1vH07Ue+ytKa0DTXJVWxekDbBvpeZtsS++3F+0gJNDFOYM688ny3eQWelJpn5i9gX/M3cyEfvF89esJvHH9WJY+eCbPXzOS8b07sW5PHn/+fCNXvriIX81YQXFZzb5HxWUV3PzmMhalZfPorHWs21N1zoedWYU1ajyW7chm/qZMDh4u4ea3Un2e15tFaVn8/tO17M0t5j+LdhzT96IoLYEKhNKq6JMQSbeOYXyz4QD5xWV8umI35w9N4vYz+lJUVsH7qbsAWL4zh7cW7WD6+BSe/+koesXb9h+hQQGcO6QLz04dwXf3TWLF78/ivsn9mbNmL1e+uKjKzb6y0nDvh6tZkp7NY1MG0SE8mLveW0VJub3hz990gLOf/pbLnv+RwyWeSYWe+XorcRHB/HPqCNbtyeO3H63G21Xr/T4jp5Bf/Gc5PeLCOblPHO+n7qrRH0tRWivqYlJaFSLCGQMSeC91FzOW7KKgtIJrx/VgUFIMY1NieXNROteN78EDH6+hc1Qo95zTv87zOYH2PvGR3DFjJRf96wfOHdKF2Ihg0g8WMGvVHu6b3J9rx6XQtWMY17+eylNfbWZo1w7c+d4KuseGk36wgEdmruPJy4exYmcO323O5LfnDuCCYUnsyCrgyf9tptJAYWk5a3bnkltUxqgeHTmpZxxz1u6jrKKSl64bzc7sQqa/tpQv1u3jwmH1aG+uKC2MCoTS6pg0IIE3ftzB37/axJCuMQzrZqdNnTY+hV++s5wb30hl4758Xrh2FJEh9fsTPntQIh/cMo57P1zNjCU7KSi1VsJPT0rm1tPsHBKnD+jM1LHJvPhdGgKM6tGRl6eN4aXv0vjXvK2cPiCBD1J30TE86Eis4peT+rBxXz6zVu+hd3wk43t3Iio0kKXpOTw1dzMCvDp9DL3iI0mJiyA5Npy3F+1oMYEoKa/gUGEZnY+SLKAo4GeBEJHJwDNAAPCyMebPtex3KfAhMMYYk+pedz9wA1AB3G6M+dKfY1VaDyf1iiMsKICisgp+elLykcyfswd1pktMKAu2WRWDdwAAE7hJREFUHOTsgZ05Z1DDJokZ3DWGz++wkwAVl1VQUFJOXGRIlX1+95MTWLYjm+TYcP45dSRhwQHccWZfFmzJ5N4PVlFQWsG95/Qnwi1MIsKzV43gycuH1aggP1RYSk5hGT072ZoJl0u4+sRk/vz5Rjbvz6df55oZWf6kuKyCa15ezOZ9+Xz/29OJCWvGGgrluMRvMQgRCQCeA84FBgJTRaRG+aWIRAF3AIu91g0ErgIGAZOB/3OfT2kHhAYFMKFfJ6JDA7lwmKc+IyjAxY2n9qJjeBB/mDKo0deoLg4AESGBfHHHBF6eNoaw4IAj1336qhEYICYsiOvGVc10crnEZ3uRDuHBR8TB4fJR3QgOcPkMVheVVvDflbvZeuBwIz6ZbyorDXe/v4plO3LILynn0xW7m/waStvDnxbEWGCrMSYNQERmAFOA9dX2ewz4C3Cv17opwAxjTAmwXUS2us+nZZzthMcvGkJuUemRm7TD9SencN24HgQF+C+/wlc6bM9OEbx944kYYxpU+1CduMgQzhuSyMfLd3P6CZ05sWcsIYEuPlu9lz/N2cCeXBtEH5PSkavGJHP+sC6EBFb9Do6lnuIvX25k9pq9PHDeAGat2su7S3Zy3bgeWpeh1Ik/BaIrsMtrOQOo0lFMREYC3Y0xs0Xk3mrHLqp2bI1SXxG5GbgZIDn52HL0ldZJfFQI8VE1n/BFhKCAlrmpjUxumuk0b5rQi7kbDjDt1SWEBQXQtWMYWw8c5oQu0Txx8RA27c/nvaW7uPuDVTz5v03cdnofLh/VnUNFpby9aCfvLN7JSb1ifbq1qlNeUclz87bxwrdp/PSkZG46tRdRoUHc//Ealu88VKUSXlGq02JBahFxAU8B04/1HMaYF4EXwVZSN83IFMW/DEqKIfV3Z/JjWhbzNx5gze5cnrh4MFeNSSbAJUwakMDPJ/RiwZaDPD13Mw9+spZnv95CTkEZZZWVjO7Rkc9W7+Xg4RJevG400bVYNGt35/Kbj1azbk8eFwxL4pELBiEiXDgsiSdmb+CdxTt9CoQxhsz8khpV76np2Twyax1/vmQog7vG1Ouzzlq1h+TYcIZ1b3hTw5cXpDFz1R7evvHEWj+j4l/8KRC7ge5ey93c6xyigMHAfLeZmwjMFJEL63GsohzXhAYFMKl/ApP6J/jcLiJM6BfPqX078e3mTF5fmE5ybDg/O7knPTtF8OmK3dzzwSqufGERr00fU6WFe2FpOU/P3cIr328nNiKY568ZyeTBiUfcSREhgUwZnsSHyzJ46PyBVbr0LtuRzROzN7B85yGmjevB/eedQGhQAD9uy+KGN5ZSWFrBywvSePqqEUf9jBv35XHHjBX06xzF53ec2iB31vxNB3hizgaMgX98tZmHL2hczEk5NvwpEEuBviLSE3tzvwo4MmGuMSYX6OQsi8h84B5jTKqIFAHviMhTQBLQF1jix7EqSqtERJjYP4GJ1YTkohFdiY0I5pa3l3Ha3+Zxxeju3HRqL7ZlHuZ3n65l96EirhrTnfvPPaGKADhMHZvMfxbv5OMVGUwdm8zi7dm8u3gnX6zbR0JUCFOGJ/HGjztYvD2b6eNTeGTWOrp1DKd/5yg+X7uPPxSVHTUL6onZG6g0sHFfPqk7chiT4mnAmFdcxrL0HA4eLiG7oJROkSFH4i27sgu5Y8ZK+neOYkjXGN5YmM5lo7oxKKl+VktT86x72t4/XTK0yvrsglJ2ZBUwoolcj60RvwmEMaZcRG4DvsSmub5qjFknIo8CqcaYmXUcu05E3scGtMuBXxpj6u5noCjtjAn94pl9+6n8e/423lu6i7cX78AY6B0fwfs/H8fYnrW3TB/sri956qvN/OWLjRSXVRIRHMBdZ/XjxlN7Eh4cyEXDu3L3B6v47cdrGJAYxds3nsjeQ8XMXrOXmSt3c20d3XXnbzrAgi0HuefsfrzwXRpv/rjjiECUlldy2fML2by/arbWX7/cyE2n9uLTlbupNIYXrh1Fh7Bg5m06wO8+XctHt4z3mUBQXlFJoJ+SForLKnjpuzQOl5Zz2+l9q/TRenTWOj5bvZf5906kW8dwv1y/pdFurorSBtifV8x/Fu8kMiSAaeNTamQ++WLu+v089dVmxvaM5bT+8ZzUM65G1tiBvGI+WGatjNiIYIwxnPfs9wS44LNfnerzvOUVlZz37AJKyyv5369P4y9fbOSNheks/O3pJESH8n/zt/LXLzbxl0uHMK5XJ2Ijg1mxM4fn5m09MnnUK9NGc8YJtjX8x8szuOv9VfzpkiFMHVs1GWXhtoNMf20pN5/aizvP7NvkQjFnzV5+8Z/lANx7Tn9+OakPYGtcxv7xa0rLK7n+5J48dMHxO4GSdnNVlDZO5+hQ7jqrX4OOOXNgZ84cWPf0oQnRoUduimBdXleO7sYjs9azbk/uEbdPblEZh0vKCXQJc9bsZfN+z+RQPz2pB698v513l+zikpFdefbrLZw9sHOV7sCn9o3n1L7xLNuRQ15RGZMGeFxqF4/oyoylu/jz5xs5d3AiHcKDj2z71zdb7eu8rfyYlsUzVw1v0qf5T1fsJj4qhO4dw/hkxW5+MbE3IsKnK3ZTWl7JsO4dmLF0J7ef0afKuNoK2qxPUZQGcdGIrgQHuvggNYPKSsMr329nzBNz+f/27jw4qioL4PDv0ElMiCaQyCJJgBDWsC+CLCJuCCqiogKjpSJKgVMuMzpuVTOMU6ODOqPiuI0KgitOISqO2yDoqIAiGBWBIAEiEEIWTEhYQpPkzB/vETrwgiYkaeg+X1VX97vd6b63TqpPv/veO3fojCUMenAx97+7ttriUKmnxjK8cwteW/ET0xeuQRCmX+J90Ll/u+bVkgM4SekvY7tTWnagKiGAs5DUso07ueP8zsyc0If1O0q5cObnLMnMq/b3P+/x88B7a8nKL63VOIv3+vl0fQGX9G7DlQNSyMrfzeqcXagq877eSq/keB4a15O9/gpeXh6aVXptD8IYUyvNmkZxQffWvJWRw8aC3Xy+oZDzurVkZHprDlRWogqjA86aArhucDsmz11JXkk+947uWus1Mbq2juPK/inMXZ7NtYPb0zaxKf/6bCOnnBTBxEFtiYuOpG9Kc6a9uorJc1dy58gu3DwijVU/FXHL6xnk7ipjY8EeZl9/erX3fWl5Nm3iYzz3pN5fvQN/RSWX9kmibWJTpi9cw4JvclD3wPsDl/Wga+s4RnRpwZxl2dw0vAPRkT5+2rmHldlFXNY3qcY1SE4UliCMMbU2fkAK7363nZXZRTx4WU8mDkw56mmsI7q0pF1iU6IjfNwwLLVOn/n7kZ1Z+N12Hv4ok7tHdeX91bncdGaHqmsk2iY2Zf7UIdz95vc88tF6lmTm8+3WYpKbx3BZ3yTeynDKmHRs6ZSGz9hSxJ/eWQPAzSPSuGNkl2qrEL79bQ5pLWLpkRSHiHB+t1Ys/G47u/eXExPpqyq4OPWsNCY89yVzlmVTtMfPi0uz8VdUEh3p46Jep9VprMcLSxDGmFobkpbIjMt7MjA1oWotjqPxNRHemDKYqIgmdS6T0ioumpvOTOWJJVns3O3H10SYNLR6somJ8jFzQh96JMUx44NMRvVozYxxvfCXV/Le6lxmfbGZv13urEr4yEfrSYyN4txuLXn6042szS3h0av6kBAbRU7xPlZs/pk7zu9clfgu75fEe6tzmb9qG1f2T64quTIo1Vm5cMYHmYjAFf2SydhazD8WreeC7q0a7AyrxmAJwhhTa02aCBMG1q68TeDFfHU15aw0XluxleWbdjKuX7Lne4oIU4anMf70tsRFR1R9wY/rl8SCb7Zx58jOrMstZdnGnUwfk86koan0TmnG9HfWMPCBj+nfrnlVtd6xfQ5V+BneuQWJsVHs3ONnwsCUap/3x4u6MXvpZqad1ZGeyfF8+MMOpr6yigUZOVw1IIUT1Ymb2owxYefkkyK464IuRPqEKcM7HPW18TGR1aa9Jg9LZX95Ja98uYVHPsokqVkMvxnkJLmrB7Xj3VuGcdPwDpSUlbMkM59BqQm0TTx0RlSkrwk3DEtlaMfEI+pyDWifwNNX96enu3bJBd1b0Ts5npkfb6haofBEZNdBGGNOOCVlB+pUn2nSiytYmrUTf0UlD1/Rq8Zf9/klZURH+Y6pBtQXGwq5ZtZX/HlMOtcPrdtxl8ZwtOsgbA/CGHPCqesX941ndsBfUUlai1gu73tEgegqLeOij7lA4NCOiQzukMiTn2SxqaD+1/hoDJYgjDFhY0haIlPPSmPGuF4NfvBYRLjvwm6UHahk5GOfcf+7ayje66eiUskrKWPN9l0U7fEf9T3KKyrxmuUpLXMuTGxoNsVkjDENqKB0P48u+pE3vt5CpK8J5ZVKReWh790Wp5xE19ancPt5nejf7lD9rE0Fu5n4/JdE+powpncbxvRqQ15pGfNXbmPR2jwqVTm9fQJnd23B2V1a0qmOS9gebYrJEoQxxjSCdbklzFuxhZOjI2gdH0NibBQ5RftYn1fK0qxCivb6efaa/ozo0pJtRXu56tnl7C+vpHtSPEuzCquSSkJsFGP7tCE60scnmflk7iile5s43rvVuzbWL7EEYYwxx7HC3fu5dtYKNuSX8qeL03nhi80U7fEzb8pg0tvEUbh7Px+vzaNZ0yjO6dqSqIhD02Pbi/dRULq/TosygSUIY4w57pWUHeDGOStZkf0zsVE+Xr5xUL0tc3s0Vs3VGGOOc3HRkcy9YSCPL/6RkemtGiU5/BJLEMYYc5yIifJx7+huwe5GFTvN1RhjjCdLEMYYYzxZgjDGGOPJEoQxxhhPliCMMcZ4sgRhjDHGkyUIY4wxnixBGGOM8RQypTZEpAD46Rje4lSgsJ66c6IIxzFDeI47HMcM4Tnu2o65naq28HoiZBLEsRKRlTXVIwlV4ThmCM9xh+OYITzHXZ9jtikmY4wxnixBGGOM8WQJ4pDngt2BIAjHMUN4jjscxwzhOe56G7MdgzDGGOPJ9iCMMcZ4sgRhjDHGU9gnCBEZJSLrRSRLRO4Jdn8aioikiMgnIrJWRNaIyG1ue4KILBKRDe598Jexqmci4hORDBH5j7udKiJfuTF/Q0Sigt3H+iYizURkvohkisg6ERkc6rEWkd+5/9s/iMjrIhIdirEWkdkiki8iPwS0ecZWHE+44/9eRPrV5rPCOkGIiA94ChgNpAMTRSQ9uL1qMOXAHaqaDpwB/NYd6z3AYlXtBCx2t0PNbcC6gO2HgMdUtSNQBEwOSq8a1kzgQ1XtCvTGGX/IxlpEkoBbgQGq2gPwARMIzVjPAUYd1lZTbEcDndzbFOCZ2nxQWCcIYCCQpaqbVNUPzAPGBrlPDUJVc1X1G/dxKc4XRhLOeOe6L5sLXBqcHjYMEUkGLgJecLcFOAeY774kFMccDwwHZgGoql9ViwnxWOMsoRwjIhFAUyCXEIy1qn4G/HxYc02xHQu8pI4vgWYictqv/axwTxBJwNaA7W1uW0gTkfZAX+AroJWq5rpP7QBaBalbDeVx4C6g0t1OBIpVtdzdDsWYpwIFwIvu1NoLIhJLCMdaVXOAvwNbcBLDLmAVoR/rg2qK7TF9x4V7ggg7InIy8CZwu6qWBD6nzjnPIXPes4hcDOSr6qpg96WRRQD9gGdUtS+wh8Omk0Iw1s1xfi2nAm2AWI6chgkL9RnbcE8QOUBKwHay2xaSRCQSJzm8qqoL3Oa8g7uc7n1+sPrXAIYCl4hINs704Tk4c/PN3GkICM2YbwO2qepX7vZ8nIQRyrE+D9isqgWqegBYgBP/UI/1QTXF9pi+48I9QXwNdHLPdIjCOai1MMh9ahDu3PssYJ2qPhrw1ELgOvfxdcA7jd23hqKq96pqsqq2x4ntElW9GvgEuMJ9WUiNGUBVdwBbRaSL23QusJYQjjXO1NIZItLU/V8/OOaQjnWAmmK7ELjWPZvpDGBXwFTULwr7K6lF5EKceWofMFtVHwhylxqEiAwDPgdWc2g+/j6c4xD/BtrilEu/SlUPPwB2whOREcCdqnqxiHTA2aNIADKAa1R1fzD7V99EpA/OgfkoYBMwCecHYcjGWkTuB8bjnLGXAdyIM98eUrEWkdeBEThlvfOA6cDbeMTWTZZP4ky37QUmqerKX/1Z4Z4gjDHGeAv3KSZjjDE1sARhjDHGkyUIY4wxnixBGGOM8WQJwhhjjCdLEMbUgohUiMi3Abd6K3gnIu0DK3QaE2wRv/wSY0yAfaraJ9idMKYx2B6EMfVARLJF5GERWS0iK0Sko9veXkSWuLX4F4tIW7e9lYi8JSLfubch7lv5ROR5d12D/4pITNAGZcKeJQhjaifmsCmm8QHP7VLVnjhXrj7utv0TmKuqvYBXgSfc9ieA/6lqb5w6SWvc9k7AU6raHSgGxjXweIypkV1JbUwtiMhuVT3Zoz0bOEdVN7lFEXeoaqKIFAKnqeoBtz1XVU8VkQIgObDsg1uGfZG76AsicjcQqap/bfiRGXMk24Mwpv5oDY9rI7BOUAV2nNAEkSUIY+rP+ID75e7jZTiVZAGuximYCM6ykNOgas3s+MbqpDG/lv06MaZ2YkTk24DtD1X14KmuzUXke5y9gIlu2y04K7v9AWeVt0lu+23AcyIyGWdPYRrOSmjGHDfsGIQx9cA9BjFAVQuD3Rdj6otNMRljjPFkexDGGGM82R6EMcYYT5YgjDHGeLIEYYwxxpMlCGOMMZ4sQRhjjPH0f1ukeTlqgTKsAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best11,network11=tune_network(net=IGRatioNet,embedding_size=50, batch_size=64, learning_rate=0.00001, epochs=200, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.7, weight_decay=2e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "id": "CfGC_RF1UbEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yy3VyH-UUa9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best7,network7=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.00001, epochs=200, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.7, weight_decay=2e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9RQB77oXpBYF",
        "outputId": "84776dcb-dfea-4618-d42d-46f86b7b7f85"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 0, Train Accuracy: 0.56822, Train Loss: 0.68140, Validation Accuracy: 0.59684, Validation Loss: 0.66891, prediction: [0.567, 0.433], true label: [1.0, 0.0]\n",
            "0.5968421052631578 0\n",
            "best_state_dict updated\n",
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 1, Train Accuracy: 0.56822, Train Loss: 0.67580, Validation Accuracy: 0.59684, Validation Loss: 0.66042, prediction: [0.573, 0.427], true label: [0.0, 1.0]\n",
            "0.5968421052631578 0.5968421052631578\n",
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 2, Train Accuracy: 0.56822, Train Loss: 0.66451, Validation Accuracy: 0.59684, Validation Loss: 0.65223, prediction: [0.594, 0.406], true label: [1.0, 0.0]\n",
            "0.5968421052631578 0.5968421052631578\n",
            "tensor([[5702,    0],\n",
            "        [5702,    0]])\n",
            "tensor([[950,   0],\n",
            "        [950,   0]])\n",
            "Epoch: 3, Train Accuracy: 0.71799, Train Loss: 0.61308, Validation Accuracy: 0.74211, Validation Loss: 0.60264, prediction: [0.635, 0.365], true label: [1.0, 0.0]\n",
            "0.7421052631578947 0.5968421052631578\n",
            "best_state_dict updated\n",
            "tensor([[5543,  159],\n",
            "        [4294, 1408]])\n",
            "tensor([[919,  31],\n",
            "        [714, 236]])\n",
            "Epoch: 4, Train Accuracy: 0.77710, Train Loss: 0.51111, Validation Accuracy: 0.76737, Validation Loss: 0.52273, prediction: [0.227, 0.773], true label: [0.0, 1.0]\n",
            "0.7673684210526316 0.7421052631578947\n",
            "best_state_dict updated\n",
            "tensor([[5370,  332],\n",
            "        [3205, 2497]])\n",
            "tensor([[898,  52],\n",
            "        [532, 418]])\n",
            "Epoch: 5, Train Accuracy: 0.77447, Train Loss: 0.47892, Validation Accuracy: 0.76632, Validation Loss: 0.49203, prediction: [0.566, 0.434], true label: [1.0, 0.0]\n",
            "0.7663157894736842 0.7673684210526316\n",
            "tensor([[5246,  456],\n",
            "        [2710, 2992]])\n",
            "tensor([[881,  69],\n",
            "        [459, 491]])\n",
            "Epoch: 6, Train Accuracy: 0.78499, Train Loss: 0.46719, Validation Accuracy: 0.78526, Validation Loss: 0.46753, prediction: [0.298, 0.702], true label: [0.0, 1.0]\n",
            "0.7852631578947369 0.7673684210526316\n",
            "best_state_dict updated\n",
            "tensor([[5258,  444],\n",
            "        [2654, 3048]])\n",
            "tensor([[884,  66],\n",
            "        [441, 509]])\n",
            "Epoch: 7, Train Accuracy: 0.79218, Train Loss: 0.45727, Validation Accuracy: 0.78737, Validation Loss: 0.46572, prediction: [0.167, 0.833], true label: [0.0, 1.0]\n",
            "0.7873684210526316 0.7852631578947369\n",
            "best_state_dict updated\n",
            "tensor([[5255,  447],\n",
            "        [2607, 3095]])\n",
            "tensor([[884,  66],\n",
            "        [436, 514]])\n",
            "Epoch: 8, Train Accuracy: 0.79498, Train Loss: 0.44709, Validation Accuracy: 0.78842, Validation Loss: 0.45358, prediction: [0.298, 0.702], true label: [0.0, 1.0]\n",
            "0.7884210526315789 0.7873684210526316\n",
            "best_state_dict updated\n",
            "tensor([[5269,  433],\n",
            "        [2608, 3094]])\n",
            "tensor([[885,  65],\n",
            "        [435, 515]])\n",
            "Epoch: 9, Train Accuracy: 0.79446, Train Loss: 0.45110, Validation Accuracy: 0.77158, Validation Loss: 0.46379, prediction: [0.119, 0.881], true label: [0.0, 1.0]\n",
            "0.771578947368421 0.7884210526315789\n",
            "tensor([[5229,  473],\n",
            "        [2473, 3229]])\n",
            "tensor([[876,  74],\n",
            "        [416, 534]])\n",
            "Epoch: 10, Train Accuracy: 0.79937, Train Loss: 0.44603, Validation Accuracy: 0.79053, Validation Loss: 0.47489, prediction: [0.47, 0.53], true label: [0.0, 1.0]\n",
            "0.7905263157894736 0.7884210526315789\n",
            "best_state_dict updated\n",
            "tensor([[5242,  460],\n",
            "        [2487, 3215]])\n",
            "tensor([[882,  68],\n",
            "        [415, 535]])\n",
            "Epoch: 11, Train Accuracy: 0.80077, Train Loss: 0.44454, Validation Accuracy: 0.78632, Validation Loss: 0.46135, prediction: [0.589, 0.411], true label: [1.0, 0.0]\n",
            "0.7863157894736842 0.7905263157894736\n",
            "tensor([[5231,  471],\n",
            "        [2436, 3266]])\n",
            "tensor([[878,  72],\n",
            "        [405, 545]])\n",
            "Epoch: 12, Train Accuracy: 0.80288, Train Loss: 0.44142, Validation Accuracy: 0.78737, Validation Loss: 0.45102, prediction: [0.038, 0.962], true label: [0.0, 1.0]\n",
            "0.7873684210526316 0.7905263157894736\n",
            "tensor([[5204,  498],\n",
            "        [2355, 3347]])\n",
            "tensor([[871,  79],\n",
            "        [398, 552]])\n",
            "Epoch: 13, Train Accuracy: 0.80007, Train Loss: 0.44196, Validation Accuracy: 0.79368, Validation Loss: 0.44205, prediction: [0.613, 0.387], true label: [0.0, 1.0]\n",
            "0.7936842105263158 0.7905263157894736\n",
            "best_state_dict updated\n",
            "tensor([[5215,  487],\n",
            "        [2378, 3324]])\n",
            "tensor([[874,  76],\n",
            "        [401, 549]])\n",
            "Epoch: 14, Train Accuracy: 0.80147, Train Loss: 0.43961, Validation Accuracy: 0.79263, Validation Loss: 0.44110, prediction: [0.857, 0.143], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.7936842105263158\n",
            "tensor([[5231,  471],\n",
            "        [2384, 3318]])\n",
            "tensor([[873,  77],\n",
            "        [398, 552]])\n",
            "Epoch: 15, Train Accuracy: 0.80481, Train Loss: 0.44254, Validation Accuracy: 0.78211, Validation Loss: 0.45312, prediction: [0.667, 0.333], true label: [1.0, 0.0]\n",
            "0.7821052631578947 0.7936842105263158\n",
            "tensor([[5228,  474],\n",
            "        [2373, 3329]])\n",
            "tensor([[870,  80],\n",
            "        [397, 553]])\n",
            "Epoch: 16, Train Accuracy: 0.80603, Train Loss: 0.43268, Validation Accuracy: 0.78316, Validation Loss: 0.44606, prediction: [0.015, 0.985], true label: [0.0, 1.0]\n",
            "0.783157894736842 0.7936842105263158\n",
            "tensor([[5215,  487],\n",
            "        [2328, 3374]])\n",
            "tensor([[869,  81],\n",
            "        [387, 563]])\n",
            "Epoch: 17, Train Accuracy: 0.80656, Train Loss: 0.43371, Validation Accuracy: 0.79158, Validation Loss: 0.46729, prediction: [0.13, 0.87], true label: [0.0, 1.0]\n",
            "0.791578947368421 0.7936842105263158\n",
            "tensor([[5203,  499],\n",
            "        [2292, 3410]])\n",
            "tensor([[870,  80],\n",
            "        [384, 566]])\n",
            "Epoch: 18, Train Accuracy: 0.80463, Train Loss: 0.42672, Validation Accuracy: 0.79579, Validation Loss: 0.43399, prediction: [0.831, 0.169], true label: [1.0, 0.0]\n",
            "0.7957894736842105 0.7936842105263158\n",
            "best_state_dict updated\n",
            "tensor([[5206,  496],\n",
            "        [2269, 3433]])\n",
            "tensor([[867,  83],\n",
            "        [378, 572]])\n",
            "Epoch: 19, Train Accuracy: 0.80621, Train Loss: 0.42487, Validation Accuracy: 0.79474, Validation Loss: 0.45142, prediction: [0.812, 0.188], true label: [1.0, 0.0]\n",
            "0.7947368421052632 0.7957894736842105\n",
            "tensor([[5194,  508],\n",
            "        [2223, 3479]])\n",
            "tensor([[866,  84],\n",
            "        [375, 575]])\n",
            "Epoch: 20, Train Accuracy: 0.80498, Train Loss: 0.43572, Validation Accuracy: 0.80105, Validation Loss: 0.42841, prediction: [0.441, 0.559], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.7957894736842105\n",
            "best_state_dict updated\n",
            "tensor([[5211,  491],\n",
            "        [2271, 3431]])\n",
            "tensor([[866,  84],\n",
            "        [375, 575]])\n",
            "Epoch: 21, Train Accuracy: 0.81024, Train Loss: 0.42086, Validation Accuracy: 0.78842, Validation Loss: 0.42865, prediction: [0.923, 0.077], true label: [1.0, 0.0]\n",
            "0.7884210526315789 0.8010526315789473\n",
            "tensor([[5205,  497],\n",
            "        [2248, 3454]])\n",
            "tensor([[866,  84],\n",
            "        [372, 578]])\n",
            "Epoch: 22, Train Accuracy: 0.80901, Train Loss: 0.42302, Validation Accuracy: 0.79684, Validation Loss: 0.44579, prediction: [0.863, 0.137], true label: [1.0, 0.0]\n",
            "0.7968421052631579 0.8010526315789473\n",
            "tensor([[5207,  495],\n",
            "        [2225, 3477]])\n",
            "tensor([[866,  84],\n",
            "        [374, 576]])\n",
            "Epoch: 23, Train Accuracy: 0.80744, Train Loss: 0.42266, Validation Accuracy: 0.80000, Validation Loss: 0.43943, prediction: [0.539, 0.461], true label: [0.0, 1.0]\n",
            "0.8 0.8010526315789473\n",
            "tensor([[5213,  489],\n",
            "        [2259, 3443]])\n",
            "tensor([[866,  84],\n",
            "        [375, 575]])\n",
            "Epoch: 24, Train Accuracy: 0.81042, Train Loss: 0.41964, Validation Accuracy: 0.79368, Validation Loss: 0.42350, prediction: [0.594, 0.406], true label: [1.0, 0.0]\n",
            "0.7936842105263158 0.8010526315789473\n",
            "tensor([[5218,  484],\n",
            "        [2237, 3465]])\n",
            "tensor([[867,  83],\n",
            "        [370, 580]])\n",
            "Epoch: 25, Train Accuracy: 0.81007, Train Loss: 0.41862, Validation Accuracy: 0.80000, Validation Loss: 0.43765, prediction: [0.13, 0.87], true label: [0.0, 1.0]\n",
            "0.8 0.8010526315789473\n",
            "tensor([[5226,  476],\n",
            "        [2276, 3426]])\n",
            "tensor([[867,  83],\n",
            "        [377, 573]])\n",
            "Epoch: 26, Train Accuracy: 0.81200, Train Loss: 0.42594, Validation Accuracy: 0.79368, Validation Loss: 0.46841, prediction: [0.077, 0.923], true label: [0.0, 1.0]\n",
            "0.7936842105263158 0.8010526315789473\n",
            "tensor([[5218,  484],\n",
            "        [2229, 3473]])\n",
            "tensor([[868,  82],\n",
            "        [365, 585]])\n",
            "Epoch: 27, Train Accuracy: 0.81042, Train Loss: 0.42125, Validation Accuracy: 0.80000, Validation Loss: 0.42735, prediction: [0.891, 0.109], true label: [1.0, 0.0]\n",
            "0.8 0.8010526315789473\n",
            "tensor([[5223,  479],\n",
            "        [2241, 3461]])\n",
            "tensor([[863,  87],\n",
            "        [374, 576]])\n",
            "Epoch: 28, Train Accuracy: 0.81165, Train Loss: 0.42101, Validation Accuracy: 0.79789, Validation Loss: 0.42678, prediction: [0.438, 0.562], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8010526315789473\n",
            "tensor([[5218,  484],\n",
            "        [2216, 3486]])\n",
            "tensor([[865,  85],\n",
            "        [365, 585]])\n",
            "Epoch: 29, Train Accuracy: 0.80954, Train Loss: 0.41958, Validation Accuracy: 0.79789, Validation Loss: 0.42763, prediction: [0.821, 0.179], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8010526315789473\n",
            "tensor([[5230,  472],\n",
            "        [2244, 3458]])\n",
            "tensor([[865,  85],\n",
            "        [374, 576]])\n",
            "Epoch: 30, Train Accuracy: 0.81322, Train Loss: 0.42907, Validation Accuracy: 0.79579, Validation Loss: 0.44215, prediction: [0.043, 0.957], true label: [0.0, 1.0]\n",
            "0.7957894736842105 0.8010526315789473\n",
            "tensor([[5214,  488],\n",
            "        [2203, 3499]])\n",
            "tensor([[864,  86],\n",
            "        [365, 585]])\n",
            "Epoch: 31, Train Accuracy: 0.81182, Train Loss: 0.42355, Validation Accuracy: 0.79684, Validation Loss: 0.42347, prediction: [0.151, 0.849], true label: [0.0, 1.0]\n",
            "0.7968421052631579 0.8010526315789473\n",
            "tensor([[5227,  475],\n",
            "        [2224, 3478]])\n",
            "tensor([[864,  86],\n",
            "        [373, 577]])\n",
            "Epoch: 32, Train Accuracy: 0.81392, Train Loss: 0.42406, Validation Accuracy: 0.80000, Validation Loss: 0.46355, prediction: [0.888, 0.112], true label: [1.0, 0.0]\n",
            "0.8 0.8010526315789473\n",
            "tensor([[5223,  479],\n",
            "        [2208, 3494]])\n",
            "tensor([[864,  86],\n",
            "        [368, 582]])\n",
            "Epoch: 33, Train Accuracy: 0.81235, Train Loss: 0.40696, Validation Accuracy: 0.80526, Validation Loss: 0.43423, prediction: [0.811, 0.189], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8010526315789473\n",
            "best_state_dict updated\n",
            "tensor([[5226,  476],\n",
            "        [2210, 3492]])\n",
            "tensor([[863,  87],\n",
            "        [371, 579]])\n",
            "Epoch: 34, Train Accuracy: 0.81270, Train Loss: 0.41834, Validation Accuracy: 0.80526, Validation Loss: 0.43544, prediction: [0.482, 0.518], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8052631578947368\n",
            "tensor([[5222,  480],\n",
            "        [2204, 3498]])\n",
            "tensor([[863,  87],\n",
            "        [365, 585]])\n",
            "Epoch: 35, Train Accuracy: 0.81200, Train Loss: 0.40769, Validation Accuracy: 0.80316, Validation Loss: 0.42789, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.8031578947368421 0.8052631578947368\n",
            "tensor([[5225,  477],\n",
            "        [2206, 3496]])\n",
            "tensor([[862,  88],\n",
            "        [364, 586]])\n",
            "Epoch: 36, Train Accuracy: 0.81392, Train Loss: 0.41495, Validation Accuracy: 0.80526, Validation Loss: 0.41911, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8052631578947368\n",
            "tensor([[5235,  467],\n",
            "        [2218, 3484]])\n",
            "tensor([[866,  84],\n",
            "        [367, 583]])\n",
            "Epoch: 37, Train Accuracy: 0.81428, Train Loss: 0.41816, Validation Accuracy: 0.80316, Validation Loss: 0.42994, prediction: [0.854, 0.146], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8052631578947368\n",
            "tensor([[5237,  465],\n",
            "        [2208, 3494]])\n",
            "tensor([[864,  86],\n",
            "        [367, 583]])\n",
            "Epoch: 38, Train Accuracy: 0.81305, Train Loss: 0.41624, Validation Accuracy: 0.80632, Validation Loss: 0.43957, prediction: [0.887, 0.113], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.8052631578947368\n",
            "best_state_dict updated\n",
            "tensor([[5223,  479],\n",
            "        [2193, 3509]])\n",
            "tensor([[862,  88],\n",
            "        [364, 586]])\n",
            "Epoch: 39, Train Accuracy: 0.81392, Train Loss: 0.41498, Validation Accuracy: 0.80421, Validation Loss: 0.42563, prediction: [0.258, 0.742], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8063157894736842\n",
            "tensor([[5238,  464],\n",
            "        [2200, 3502]])\n",
            "tensor([[863,  87],\n",
            "        [366, 584]])\n",
            "Epoch: 40, Train Accuracy: 0.81305, Train Loss: 0.41128, Validation Accuracy: 0.80737, Validation Loss: 0.46369, prediction: [0.645, 0.355], true label: [1.0, 0.0]\n",
            "0.8073684210526316 0.8063157894736842\n",
            "best_state_dict updated\n",
            "tensor([[5229,  473],\n",
            "        [2179, 3523]])\n",
            "tensor([[863,  87],\n",
            "        [364, 586]])\n",
            "Epoch: 41, Train Accuracy: 0.81270, Train Loss: 0.41031, Validation Accuracy: 0.80737, Validation Loss: 0.43185, prediction: [0.091, 0.909], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8073684210526316\n",
            "tensor([[5239,  463],\n",
            "        [2197, 3505]])\n",
            "tensor([[863,  87],\n",
            "        [365, 585]])\n",
            "Epoch: 42, Train Accuracy: 0.81498, Train Loss: 0.41616, Validation Accuracy: 0.80632, Validation Loss: 0.42627, prediction: [0.117, 0.883], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.8073684210526316\n",
            "tensor([[5228,  474],\n",
            "        [2176, 3526]])\n",
            "tensor([[863,  87],\n",
            "        [363, 587]])\n",
            "Epoch: 43, Train Accuracy: 0.81410, Train Loss: 0.40816, Validation Accuracy: 0.80842, Validation Loss: 0.42537, prediction: [0.089, 0.911], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.8073684210526316\n",
            "best_state_dict updated\n",
            "tensor([[5238,  464],\n",
            "        [2194, 3508]])\n",
            "tensor([[868,  82],\n",
            "        [367, 583]])\n",
            "Epoch: 44, Train Accuracy: 0.81585, Train Loss: 0.41367, Validation Accuracy: 0.80316, Validation Loss: 0.43584, prediction: [0.235, 0.765], true label: [0.0, 1.0]\n",
            "0.8031578947368421 0.8084210526315789\n",
            "tensor([[5241,  461],\n",
            "        [2197, 3505]])\n",
            "tensor([[869,  81],\n",
            "        [368, 582]])\n",
            "Epoch: 45, Train Accuracy: 0.81691, Train Loss: 0.40670, Validation Accuracy: 0.80316, Validation Loss: 0.41605, prediction: [0.848, 0.152], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8084210526315789\n",
            "tensor([[5236,  466],\n",
            "        [2177, 3525]])\n",
            "tensor([[862,  88],\n",
            "        [367, 583]])\n",
            "Epoch: 46, Train Accuracy: 0.81603, Train Loss: 0.41615, Validation Accuracy: 0.80526, Validation Loss: 0.41500, prediction: [0.932, 0.068], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8084210526315789\n",
            "tensor([[5243,  459],\n",
            "        [2205, 3497]])\n",
            "tensor([[869,  81],\n",
            "        [373, 577]])\n",
            "Epoch: 47, Train Accuracy: 0.81778, Train Loss: 0.41088, Validation Accuracy: 0.79789, Validation Loss: 0.42876, prediction: [0.767, 0.233], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8084210526315789\n",
            "tensor([[5227,  475],\n",
            "        [2145, 3557]])\n",
            "tensor([[862,  88],\n",
            "        [358, 592]])\n",
            "Epoch: 48, Train Accuracy: 0.81638, Train Loss: 0.41154, Validation Accuracy: 0.80947, Validation Loss: 0.42486, prediction: [0.687, 0.313], true label: [1.0, 0.0]\n",
            "0.8094736842105263 0.8084210526315789\n",
            "best_state_dict updated\n",
            "tensor([[5227,  475],\n",
            "        [2142, 3560]])\n",
            "tensor([[862,  88],\n",
            "        [359, 591]])\n",
            "Epoch: 49, Train Accuracy: 0.81620, Train Loss: 0.41119, Validation Accuracy: 0.81053, Validation Loss: 0.41531, prediction: [0.091, 0.909], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8094736842105263\n",
            "best_state_dict updated\n",
            "tensor([[5199,  503],\n",
            "        [2088, 3614]])\n",
            "tensor([[861,  89],\n",
            "        [346, 604]])\n",
            "Epoch: 50, Train Accuracy: 0.81638, Train Loss: 0.41650, Validation Accuracy: 0.81368, Validation Loss: 0.42721, prediction: [0.885, 0.115], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8105263157894737\n",
            "best_state_dict updated\n",
            "tensor([[5243,  459],\n",
            "        [2165, 3537]])\n",
            "tensor([[866,  84],\n",
            "        [360, 590]])\n",
            "Epoch: 51, Train Accuracy: 0.81726, Train Loss: 0.40506, Validation Accuracy: 0.80737, Validation Loss: 0.42425, prediction: [0.026, 0.974], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8136842105263158\n",
            "tensor([[5236,  466],\n",
            "        [2144, 3558]])\n",
            "tensor([[865,  85],\n",
            "        [358, 592]])\n",
            "Epoch: 52, Train Accuracy: 0.81936, Train Loss: 0.40346, Validation Accuracy: 0.80526, Validation Loss: 0.41530, prediction: [0.873, 0.127], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8136842105263158\n",
            "tensor([[5242,  460],\n",
            "        [2151, 3551]])\n",
            "tensor([[867,  83],\n",
            "        [358, 592]])\n",
            "Epoch: 53, Train Accuracy: 0.81796, Train Loss: 0.40568, Validation Accuracy: 0.80632, Validation Loss: 0.41095, prediction: [0.753, 0.247], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5251,  451],\n",
            "        [2159, 3543]])\n",
            "tensor([[867,  83],\n",
            "        [368, 582]])\n",
            "Epoch: 54, Train Accuracy: 0.81848, Train Loss: 0.40509, Validation Accuracy: 0.80421, Validation Loss: 0.42068, prediction: [0.886, 0.114], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8136842105263158\n",
            "tensor([[5237,  465],\n",
            "        [2128, 3574]])\n",
            "tensor([[866,  84],\n",
            "        [357, 593]])\n",
            "Epoch: 55, Train Accuracy: 0.82041, Train Loss: 0.40328, Validation Accuracy: 0.80632, Validation Loss: 0.42502, prediction: [0.908, 0.092], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5237,  465],\n",
            "        [2123, 3579]])\n",
            "tensor([[867,  83],\n",
            "        [358, 592]])\n",
            "Epoch: 56, Train Accuracy: 0.82112, Train Loss: 0.40435, Validation Accuracy: 0.80632, Validation Loss: 0.42766, prediction: [0.226, 0.774], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5234,  468],\n",
            "        [2116, 3586]])\n",
            "tensor([[863,  87],\n",
            "        [352, 598]])\n",
            "Epoch: 57, Train Accuracy: 0.82217, Train Loss: 0.40012, Validation Accuracy: 0.80947, Validation Loss: 0.41216, prediction: [0.912, 0.088], true label: [1.0, 0.0]\n",
            "0.8094736842105263 0.8136842105263158\n",
            "tensor([[5245,  457],\n",
            "        [2135, 3567]])\n",
            "tensor([[868,  82],\n",
            "        [361, 589]])\n",
            "Epoch: 58, Train Accuracy: 0.82076, Train Loss: 0.39775, Validation Accuracy: 0.80526, Validation Loss: 0.41700, prediction: [0.178, 0.822], true label: [0.0, 1.0]\n",
            "0.8052631578947368 0.8136842105263158\n",
            "tensor([[5235,  467],\n",
            "        [2119, 3583]])\n",
            "tensor([[864,  86],\n",
            "        [356, 594]])\n",
            "Epoch: 59, Train Accuracy: 0.82076, Train Loss: 0.40107, Validation Accuracy: 0.80632, Validation Loss: 0.47293, prediction: [0.017, 0.983], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5247,  455],\n",
            "        [2167, 3535]])\n",
            "tensor([[865,  85],\n",
            "        [371, 579]])\n",
            "Epoch: 60, Train Accuracy: 0.82269, Train Loss: 0.40337, Validation Accuracy: 0.79789, Validation Loss: 0.42619, prediction: [0.856, 0.144], true label: [1.0, 0.0]\n",
            "0.7978947368421052 0.8136842105263158\n",
            "tensor([[5242,  460],\n",
            "        [2101, 3601]])\n",
            "tensor([[866,  84],\n",
            "        [356, 594]])\n",
            "Epoch: 61, Train Accuracy: 0.82217, Train Loss: 0.41100, Validation Accuracy: 0.80632, Validation Loss: 0.42666, prediction: [0.886, 0.114], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5248,  454],\n",
            "        [2136, 3566]])\n",
            "tensor([[867,  83],\n",
            "        [366, 584]])\n",
            "Epoch: 62, Train Accuracy: 0.82410, Train Loss: 0.39826, Validation Accuracy: 0.80632, Validation Loss: 0.43166, prediction: [0.924, 0.076], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5244,  458],\n",
            "        [2106, 3596]])\n",
            "tensor([[866,  84],\n",
            "        [358, 592]])\n",
            "Epoch: 63, Train Accuracy: 0.82234, Train Loss: 0.39894, Validation Accuracy: 0.80526, Validation Loss: 0.44757, prediction: [0.05, 0.95], true label: [0.0, 1.0]\n",
            "0.8052631578947368 0.8136842105263158\n",
            "tensor([[5245,  457],\n",
            "        [2108, 3594]])\n",
            "tensor([[866,  84],\n",
            "        [358, 592]])\n",
            "Epoch: 64, Train Accuracy: 0.82304, Train Loss: 0.40254, Validation Accuracy: 0.80737, Validation Loss: 0.41576, prediction: [0.103, 0.897], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8136842105263158\n",
            "tensor([[5245,  457],\n",
            "        [2105, 3597]])\n",
            "tensor([[866,  84],\n",
            "        [357, 593]])\n",
            "Epoch: 65, Train Accuracy: 0.82322, Train Loss: 0.39878, Validation Accuracy: 0.80632, Validation Loss: 0.45076, prediction: [0.898, 0.102], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8136842105263158\n",
            "tensor([[5209,  493],\n",
            "        [2052, 3650]])\n",
            "tensor([[861,  89],\n",
            "        [340, 610]])\n",
            "Epoch: 66, Train Accuracy: 0.81831, Train Loss: 0.40349, Validation Accuracy: 0.81684, Validation Loss: 0.40943, prediction: [0.912, 0.088], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8136842105263158\n",
            "best_state_dict updated\n",
            "tensor([[5243,  459],\n",
            "        [2108, 3594]])\n",
            "tensor([[867,  83],\n",
            "        [358, 592]])\n",
            "Epoch: 67, Train Accuracy: 0.82340, Train Loss: 0.39098, Validation Accuracy: 0.81158, Validation Loss: 0.45523, prediction: [0.018, 0.982], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8168421052631579\n",
            "tensor([[5247,  455],\n",
            "        [2098, 3604]])\n",
            "tensor([[866,  84],\n",
            "        [359, 591]])\n",
            "Epoch: 68, Train Accuracy: 0.82462, Train Loss: 0.39377, Validation Accuracy: 0.80842, Validation Loss: 0.41368, prediction: [0.323, 0.677], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.8168421052631579\n",
            "tensor([[5240,  462],\n",
            "        [2095, 3607]])\n",
            "tensor([[866,  84],\n",
            "        [359, 591]])\n",
            "Epoch: 69, Train Accuracy: 0.82392, Train Loss: 0.39436, Validation Accuracy: 0.81368, Validation Loss: 0.42397, prediction: [0.936, 0.064], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8168421052631579\n",
            "tensor([[5248,  454],\n",
            "        [2085, 3617]])\n",
            "tensor([[867,  83],\n",
            "        [358, 592]])\n",
            "Epoch: 70, Train Accuracy: 0.82497, Train Loss: 0.40354, Validation Accuracy: 0.80632, Validation Loss: 0.41232, prediction: [0.063, 0.937], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.8168421052631579\n",
            "tensor([[5250,  452],\n",
            "        [2096, 3606]])\n",
            "tensor([[868,  82],\n",
            "        [357, 593]])\n",
            "Epoch: 71, Train Accuracy: 0.82480, Train Loss: 0.39140, Validation Accuracy: 0.80842, Validation Loss: 0.41507, prediction: [0.727, 0.273], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.8168421052631579\n",
            "tensor([[5262,  440],\n",
            "        [2126, 3576]])\n",
            "tensor([[866,  84],\n",
            "        [366, 584]])\n",
            "Epoch: 72, Train Accuracy: 0.82778, Train Loss: 0.40079, Validation Accuracy: 0.80526, Validation Loss: 0.41639, prediction: [0.853, 0.147], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8168421052631579\n",
            "tensor([[5257,  445],\n",
            "        [2105, 3597]])\n",
            "tensor([[867,  83],\n",
            "        [361, 589]])\n",
            "Epoch: 73, Train Accuracy: 0.82673, Train Loss: 0.40035, Validation Accuracy: 0.80737, Validation Loss: 0.41595, prediction: [0.129, 0.871], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8168421052631579\n",
            "tensor([[5240,  462],\n",
            "        [2079, 3623]])\n",
            "tensor([[867,  83],\n",
            "        [356, 594]])\n",
            "Epoch: 74, Train Accuracy: 0.82427, Train Loss: 0.39800, Validation Accuracy: 0.81158, Validation Loss: 0.43006, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8168421052631579\n",
            "tensor([[5267,  435],\n",
            "        [2101, 3601]])\n",
            "tensor([[866,  84],\n",
            "        [363, 587]])\n",
            "Epoch: 75, Train Accuracy: 0.82778, Train Loss: 0.40403, Validation Accuracy: 0.80737, Validation Loss: 0.41908, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8073684210526316 0.8168421052631579\n",
            "tensor([[5269,  433],\n",
            "        [2132, 3570]])\n",
            "tensor([[867,  83],\n",
            "        [366, 584]])\n",
            "Epoch: 76, Train Accuracy: 0.82813, Train Loss: 0.39633, Validation Accuracy: 0.80421, Validation Loss: 0.43739, prediction: [0.786, 0.214], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8168421052631579\n",
            "tensor([[5241,  461],\n",
            "        [2044, 3658]])\n",
            "tensor([[867,  83],\n",
            "        [352, 598]])\n",
            "Epoch: 77, Train Accuracy: 0.82497, Train Loss: 0.38750, Validation Accuracy: 0.81053, Validation Loss: 0.41269, prediction: [0.106, 0.894], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8168421052631579\n",
            "tensor([[5234,  468],\n",
            "        [2011, 3691]])\n",
            "tensor([[865,  85],\n",
            "        [348, 602]])\n",
            "Epoch: 78, Train Accuracy: 0.82497, Train Loss: 0.39792, Validation Accuracy: 0.81684, Validation Loss: 0.40600, prediction: [0.313, 0.687], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8168421052631579\n",
            "tensor([[5239,  463],\n",
            "        [2034, 3668]])\n",
            "tensor([[864,  86],\n",
            "        [349, 601]])\n",
            "Epoch: 79, Train Accuracy: 0.82743, Train Loss: 0.39528, Validation Accuracy: 0.81368, Validation Loss: 0.41053, prediction: [0.661, 0.339], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8168421052631579\n",
            "tensor([[5256,  446],\n",
            "        [2061, 3641]])\n",
            "tensor([[867,  83],\n",
            "        [351, 599]])\n",
            "Epoch: 80, Train Accuracy: 0.82743, Train Loss: 0.39053, Validation Accuracy: 0.80737, Validation Loss: 0.41908, prediction: [0.459, 0.541], true label: [1.0, 0.0]\n",
            "0.8073684210526316 0.8168421052631579\n",
            "tensor([[5242,  460],\n",
            "        [2036, 3666]])\n",
            "tensor([[865,  85],\n",
            "        [348, 602]])\n",
            "Epoch: 81, Train Accuracy: 0.82743, Train Loss: 0.39522, Validation Accuracy: 0.80842, Validation Loss: 0.41384, prediction: [0.9, 0.1], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8168421052631579\n",
            "tensor([[5243,  459],\n",
            "        [2034, 3668]])\n",
            "tensor([[865,  85],\n",
            "        [348, 602]])\n",
            "Epoch: 82, Train Accuracy: 0.82778, Train Loss: 0.38270, Validation Accuracy: 0.81263, Validation Loss: 0.44663, prediction: [0.056, 0.944], true label: [0.0, 1.0]\n",
            "0.8126315789473684 0.8168421052631579\n",
            "tensor([[5260,  442],\n",
            "        [2053, 3649]])\n",
            "tensor([[867,  83],\n",
            "        [354, 596]])\n",
            "Epoch: 83, Train Accuracy: 0.82866, Train Loss: 0.39221, Validation Accuracy: 0.80737, Validation Loss: 0.43444, prediction: [0.598, 0.402], true label: [1.0, 0.0]\n",
            "0.8073684210526316 0.8168421052631579\n",
            "tensor([[5244,  458],\n",
            "        [2027, 3675]])\n",
            "tensor([[865,  85],\n",
            "        [350, 600]])\n",
            "Epoch: 84, Train Accuracy: 0.82866, Train Loss: 0.38898, Validation Accuracy: 0.81579, Validation Loss: 0.41220, prediction: [0.027, 0.973], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8168421052631579\n",
            "tensor([[5247,  455],\n",
            "        [2035, 3667]])\n",
            "tensor([[865,  85],\n",
            "        [351, 599]])\n",
            "Epoch: 85, Train Accuracy: 0.82936, Train Loss: 0.38804, Validation Accuracy: 0.81579, Validation Loss: 0.41743, prediction: [0.046, 0.954], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8168421052631579\n",
            "tensor([[5288,  414],\n",
            "        [2166, 3536]])\n",
            "tensor([[865,  85],\n",
            "        [374, 576]])\n",
            "Epoch: 86, Train Accuracy: 0.82076, Train Loss: 0.40041, Validation Accuracy: 0.79368, Validation Loss: 0.43847, prediction: [0.655, 0.345], true label: [0.0, 1.0]\n",
            "0.7936842105263158 0.8168421052631579\n",
            "tensor([[5248,  454],\n",
            "        [2033, 3669]])\n",
            "tensor([[865,  85],\n",
            "        [352, 598]])\n",
            "Epoch: 87, Train Accuracy: 0.82971, Train Loss: 0.38856, Validation Accuracy: 0.81158, Validation Loss: 0.43772, prediction: [0.856, 0.144], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8168421052631579\n",
            "tensor([[5275,  427],\n",
            "        [2061, 3641]])\n",
            "tensor([[868,  82],\n",
            "        [357, 593]])\n",
            "Epoch: 88, Train Accuracy: 0.83076, Train Loss: 0.40040, Validation Accuracy: 0.80421, Validation Loss: 0.42450, prediction: [0.866, 0.134], true label: [1.0, 0.0]\n",
            "0.8042105263157895 0.8168421052631579\n",
            "tensor([[5245,  457],\n",
            "        [2002, 3700]])\n",
            "tensor([[865,  85],\n",
            "        [344, 606]])\n",
            "Epoch: 89, Train Accuracy: 0.82918, Train Loss: 0.39141, Validation Accuracy: 0.81684, Validation Loss: 0.44710, prediction: [0.943, 0.057], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8168421052631579\n",
            "tensor([[5249,  453],\n",
            "        [2011, 3691]])\n",
            "tensor([[865,  85],\n",
            "        [348, 602]])\n",
            "Epoch: 90, Train Accuracy: 0.82971, Train Loss: 0.39224, Validation Accuracy: 0.81684, Validation Loss: 0.41408, prediction: [0.088, 0.912], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8168421052631579\n",
            "tensor([[5250,  452],\n",
            "        [2008, 3694]])\n",
            "tensor([[865,  85],\n",
            "        [345, 605]])\n",
            "Epoch: 91, Train Accuracy: 0.83076, Train Loss: 0.38429, Validation Accuracy: 0.81368, Validation Loss: 0.44241, prediction: [0.784, 0.216], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8168421052631579\n",
            "tensor([[5270,  432],\n",
            "        [2023, 3679]])\n",
            "tensor([[866,  84],\n",
            "        [353, 597]])\n",
            "Epoch: 92, Train Accuracy: 0.83269, Train Loss: 0.38151, Validation Accuracy: 0.80421, Validation Loss: 0.42095, prediction: [0.034, 0.966], true label: [0.0, 1.0]\n",
            "0.8042105263157895 0.8168421052631579\n",
            "tensor([[5275,  427],\n",
            "        [2034, 3668]])\n",
            "tensor([[866,  84],\n",
            "        [359, 591]])\n",
            "Epoch: 93, Train Accuracy: 0.83094, Train Loss: 0.38182, Validation Accuracy: 0.80211, Validation Loss: 0.43064, prediction: [0.863, 0.137], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8168421052631579\n",
            "tensor([[5257,  445],\n",
            "        [2007, 3695]])\n",
            "tensor([[866,  84],\n",
            "        [349, 601]])\n",
            "Epoch: 94, Train Accuracy: 0.83111, Train Loss: 0.38028, Validation Accuracy: 0.81474, Validation Loss: 0.41859, prediction: [0.043, 0.957], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.8168421052631579\n",
            "tensor([[5250,  452],\n",
            "        [1993, 3709]])\n",
            "tensor([[864,  86],\n",
            "        [345, 605]])\n",
            "Epoch: 95, Train Accuracy: 0.83094, Train Loss: 0.37738, Validation Accuracy: 0.81684, Validation Loss: 0.43236, prediction: [0.903, 0.097], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8168421052631579\n",
            "tensor([[5265,  437],\n",
            "        [2016, 3686]])\n",
            "tensor([[866,  84],\n",
            "        [353, 597]])\n",
            "Epoch: 96, Train Accuracy: 0.83374, Train Loss: 0.38200, Validation Accuracy: 0.80526, Validation Loss: 0.43167, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.8052631578947368 0.8168421052631579\n",
            "tensor([[5252,  450],\n",
            "        [1987, 3715]])\n",
            "tensor([[865,  85],\n",
            "        [343, 607]])\n",
            "Epoch: 97, Train Accuracy: 0.83216, Train Loss: 0.37888, Validation Accuracy: 0.81684, Validation Loss: 0.40924, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8168421052631579\n",
            "tensor([[5259,  443],\n",
            "        [1994, 3708]])\n",
            "tensor([[865,  85],\n",
            "        [345, 605]])\n",
            "Epoch: 98, Train Accuracy: 0.83374, Train Loss: 0.38269, Validation Accuracy: 0.81263, Validation Loss: 0.44102, prediction: [0.941, 0.059], true label: [1.0, 0.0]\n",
            "0.8126315789473684 0.8168421052631579\n",
            "tensor([[5241,  461],\n",
            "        [1947, 3755]])\n",
            "tensor([[862,  88],\n",
            "        [339, 611]])\n",
            "Epoch: 99, Train Accuracy: 0.83181, Train Loss: 0.38132, Validation Accuracy: 0.81895, Validation Loss: 0.43194, prediction: [0.697, 0.303], true label: [1.0, 0.0]\n",
            "0.8189473684210526 0.8168421052631579\n",
            "best_state_dict updated\n",
            "tensor([[5260,  442],\n",
            "        [1987, 3715]])\n",
            "tensor([[865,  85],\n",
            "        [347, 603]])\n",
            "Epoch: 100, Train Accuracy: 0.83374, Train Loss: 0.37866, Validation Accuracy: 0.81474, Validation Loss: 0.41712, prediction: [0.618, 0.382], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8189473684210526\n",
            "tensor([[5284,  418],\n",
            "        [2019, 3683]])\n",
            "tensor([[865,  85],\n",
            "        [355, 595]])\n",
            "Epoch: 101, Train Accuracy: 0.83392, Train Loss: 0.38387, Validation Accuracy: 0.80316, Validation Loss: 0.49652, prediction: [0.713, 0.287], true label: [1.0, 0.0]\n",
            "0.8031578947368421 0.8189473684210526\n",
            "tensor([[5256,  446],\n",
            "        [1968, 3734]])\n",
            "tensor([[864,  86],\n",
            "        [342, 608]])\n",
            "Epoch: 102, Train Accuracy: 0.83392, Train Loss: 0.37817, Validation Accuracy: 0.81895, Validation Loss: 0.43289, prediction: [0.834, 0.166], true label: [0.0, 1.0]\n",
            "0.8189473684210526 0.8189473684210526\n",
            "tensor([[5230,  472],\n",
            "        [1877, 3825]])\n",
            "tensor([[861,  89],\n",
            "        [327, 623]])\n",
            "Epoch: 103, Train Accuracy: 0.83076, Train Loss: 0.37977, Validation Accuracy: 0.82000, Validation Loss: 0.40485, prediction: [0.757, 0.243], true label: [1.0, 0.0]\n",
            "0.82 0.8189473684210526\n",
            "best_state_dict updated\n",
            "tensor([[5268,  434],\n",
            "        [1972, 3730]])\n",
            "tensor([[865,  85],\n",
            "        [346, 604]])\n",
            "Epoch: 104, Train Accuracy: 0.83585, Train Loss: 0.37690, Validation Accuracy: 0.80526, Validation Loss: 0.44126, prediction: [0.793, 0.207], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.82\n",
            "tensor([[5271,  431],\n",
            "        [1964, 3738]])\n",
            "tensor([[864,  86],\n",
            "        [345, 605]])\n",
            "Epoch: 105, Train Accuracy: 0.83585, Train Loss: 0.37742, Validation Accuracy: 0.80421, Validation Loss: 0.43090, prediction: [0.083, 0.917], true label: [0.0, 1.0]\n",
            "0.8042105263157895 0.82\n",
            "tensor([[5255,  447],\n",
            "        [1944, 3758]])\n",
            "tensor([[864,  86],\n",
            "        [341, 609]])\n",
            "Epoch: 106, Train Accuracy: 0.83637, Train Loss: 0.37462, Validation Accuracy: 0.81579, Validation Loss: 0.41717, prediction: [0.933, 0.067], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.82\n",
            "tensor([[5248,  454],\n",
            "        [1929, 3773]])\n",
            "tensor([[862,  88],\n",
            "        [337, 613]])\n",
            "Epoch: 107, Train Accuracy: 0.83567, Train Loss: 0.38088, Validation Accuracy: 0.81895, Validation Loss: 0.41762, prediction: [0.96, 0.04], true label: [1.0, 0.0]\n",
            "0.8189473684210526 0.82\n",
            "tensor([[5291,  411],\n",
            "        [2011, 3691]])\n",
            "tensor([[866,  84],\n",
            "        [352, 598]])\n",
            "Epoch: 108, Train Accuracy: 0.83462, Train Loss: 0.37804, Validation Accuracy: 0.80105, Validation Loss: 0.44972, prediction: [0.026, 0.974], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.82\n",
            "tensor([[5291,  411],\n",
            "        [2014, 3688]])\n",
            "tensor([[866,  84],\n",
            "        [352, 598]])\n",
            "Epoch: 109, Train Accuracy: 0.83479, Train Loss: 0.37934, Validation Accuracy: 0.80105, Validation Loss: 0.44543, prediction: [0.793, 0.207], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.82\n",
            "tensor([[5245,  457],\n",
            "        [1901, 3801]])\n",
            "tensor([[863,  87],\n",
            "        [333, 617]])\n",
            "Epoch: 110, Train Accuracy: 0.83585, Train Loss: 0.37326, Validation Accuracy: 0.81895, Validation Loss: 0.41611, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8189473684210526 0.82\n",
            "tensor([[5257,  445],\n",
            "        [1920, 3782]])\n",
            "tensor([[863,  87],\n",
            "        [338, 612]])\n",
            "Epoch: 111, Train Accuracy: 0.83655, Train Loss: 0.37138, Validation Accuracy: 0.81895, Validation Loss: 0.42626, prediction: [0.909, 0.091], true label: [1.0, 0.0]\n",
            "0.8189473684210526 0.82\n",
            "tensor([[5276,  426],\n",
            "        [1960, 3742]])\n",
            "tensor([[864,  86],\n",
            "        [341, 609]])\n",
            "Epoch: 112, Train Accuracy: 0.83743, Train Loss: 0.37369, Validation Accuracy: 0.80842, Validation Loss: 0.44521, prediction: [0.846, 0.154], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.82\n",
            "tensor([[5264,  438],\n",
            "        [1928, 3774]])\n",
            "tensor([[863,  87],\n",
            "        [340, 610]])\n",
            "Epoch: 113, Train Accuracy: 0.83778, Train Loss: 0.37199, Validation Accuracy: 0.81474, Validation Loss: 0.46930, prediction: [0.902, 0.098], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.82\n",
            "tensor([[5256,  446],\n",
            "        [1902, 3800]])\n",
            "tensor([[861,  89],\n",
            "        [334, 616]])\n",
            "Epoch: 114, Train Accuracy: 0.83760, Train Loss: 0.36651, Validation Accuracy: 0.81579, Validation Loss: 0.42881, prediction: [0.425, 0.575], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.82\n",
            "tensor([[5267,  435],\n",
            "        [1918, 3784]])\n",
            "tensor([[862,  88],\n",
            "        [337, 613]])\n",
            "Epoch: 115, Train Accuracy: 0.83830, Train Loss: 0.36878, Validation Accuracy: 0.81368, Validation Loss: 0.45389, prediction: [0.896, 0.104], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.82\n",
            "tensor([[5251,  451],\n",
            "        [1891, 3811]])\n",
            "tensor([[862,  88],\n",
            "        [331, 619]])\n",
            "Epoch: 116, Train Accuracy: 0.83725, Train Loss: 0.37736, Validation Accuracy: 0.81789, Validation Loss: 0.42148, prediction: [0.629, 0.371], true label: [0.0, 1.0]\n",
            "0.8178947368421052 0.82\n",
            "tensor([[5264,  438],\n",
            "        [1896, 3806]])\n",
            "tensor([[861,  89],\n",
            "        [332, 618]])\n",
            "Epoch: 117, Train Accuracy: 0.83813, Train Loss: 0.37245, Validation Accuracy: 0.81474, Validation Loss: 0.45205, prediction: [0.291, 0.709], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.82\n",
            "tensor([[5253,  449],\n",
            "        [1876, 3826]])\n",
            "tensor([[861,  89],\n",
            "        [329, 621]])\n",
            "Epoch: 118, Train Accuracy: 0.83690, Train Loss: 0.37185, Validation Accuracy: 0.81895, Validation Loss: 0.44526, prediction: [0.888, 0.112], true label: [1.0, 0.0]\n",
            "0.8189473684210526 0.82\n",
            "tensor([[5253,  449],\n",
            "        [1867, 3835]])\n",
            "tensor([[860,  90],\n",
            "        [328, 622]])\n",
            "Epoch: 119, Train Accuracy: 0.83813, Train Loss: 0.36808, Validation Accuracy: 0.81789, Validation Loss: 0.43317, prediction: [0.786, 0.214], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.82\n",
            "tensor([[5280,  422],\n",
            "        [1935, 3767]])\n",
            "tensor([[863,  87],\n",
            "        [338, 612]])\n",
            "Epoch: 120, Train Accuracy: 0.83743, Train Loss: 0.37119, Validation Accuracy: 0.80632, Validation Loss: 0.47652, prediction: [0.084, 0.916], true label: [0.0, 1.0]\n",
            "0.8063157894736842 0.82\n",
            "tensor([[5261,  441],\n",
            "        [1868, 3834]])\n",
            "tensor([[860,  90],\n",
            "        [330, 620]])\n",
            "Epoch: 121, Train Accuracy: 0.83953, Train Loss: 0.36794, Validation Accuracy: 0.81789, Validation Loss: 0.44552, prediction: [0.832, 0.168], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.82\n",
            "tensor([[5256,  446],\n",
            "        [1849, 3853]])\n",
            "tensor([[858,  92],\n",
            "        [327, 623]])\n",
            "Epoch: 122, Train Accuracy: 0.83988, Train Loss: 0.36466, Validation Accuracy: 0.82000, Validation Loss: 0.46781, prediction: [0.077, 0.923], true label: [0.0, 1.0]\n",
            "0.82 0.82\n",
            "tensor([[5258,  444],\n",
            "        [1847, 3855]])\n",
            "tensor([[859,  91],\n",
            "        [324, 626]])\n",
            "Epoch: 123, Train Accuracy: 0.84006, Train Loss: 0.35550, Validation Accuracy: 0.82000, Validation Loss: 0.47431, prediction: [0.869, 0.131], true label: [1.0, 0.0]\n",
            "0.82 0.82\n",
            "tensor([[5238,  464],\n",
            "        [1782, 3920]])\n",
            "tensor([[859,  91],\n",
            "        [316, 634]])\n",
            "Epoch: 124, Train Accuracy: 0.83848, Train Loss: 0.37247, Validation Accuracy: 0.82000, Validation Loss: 0.44838, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.82 0.82\n",
            "tensor([[5257,  445],\n",
            "        [1825, 3877]])\n",
            "tensor([[858,  92],\n",
            "        [321, 629]])\n",
            "Epoch: 125, Train Accuracy: 0.84128, Train Loss: 0.37017, Validation Accuracy: 0.82105, Validation Loss: 0.45991, prediction: [0.861, 0.139], true label: [1.0, 0.0]\n",
            "0.8210526315789474 0.82\n",
            "best_state_dict updated\n",
            "tensor([[5268,  434],\n",
            "        [1868, 3834]])\n",
            "tensor([[858,  92],\n",
            "        [329, 621]])\n",
            "Epoch: 126, Train Accuracy: 0.84146, Train Loss: 0.36421, Validation Accuracy: 0.81789, Validation Loss: 0.47702, prediction: [0.797, 0.203], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.8210526315789474\n",
            "tensor([[5249,  453],\n",
            "        [1790, 3912]])\n",
            "tensor([[860,  90],\n",
            "        [317, 633]])\n",
            "Epoch: 127, Train Accuracy: 0.83988, Train Loss: 0.36419, Validation Accuracy: 0.82000, Validation Loss: 0.42982, prediction: [0.951, 0.049], true label: [1.0, 0.0]\n",
            "0.82 0.8210526315789474\n",
            "tensor([[5270,  432],\n",
            "        [1868, 3834]])\n",
            "tensor([[858,  92],\n",
            "        [329, 621]])\n",
            "Epoch: 128, Train Accuracy: 0.84286, Train Loss: 0.35982, Validation Accuracy: 0.81579, Validation Loss: 0.45431, prediction: [0.846, 0.154], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5269,  433],\n",
            "        [1856, 3846]])\n",
            "tensor([[858,  92],\n",
            "        [329, 621]])\n",
            "Epoch: 129, Train Accuracy: 0.84339, Train Loss: 0.36086, Validation Accuracy: 0.81579, Validation Loss: 0.46423, prediction: [0.52, 0.48], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5253,  449],\n",
            "        [1780, 3922]])\n",
            "tensor([[859,  91],\n",
            "        [314, 636]])\n",
            "Epoch: 130, Train Accuracy: 0.84058, Train Loss: 0.36907, Validation Accuracy: 0.81579, Validation Loss: 0.43594, prediction: [0.453, 0.547], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5273,  429],\n",
            "        [1858, 3844]])\n",
            "tensor([[858,  92],\n",
            "        [330, 620]])\n",
            "Epoch: 131, Train Accuracy: 0.84444, Train Loss: 0.36036, Validation Accuracy: 0.81474, Validation Loss: 0.47200, prediction: [0.392, 0.608], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8210526315789474\n",
            "tensor([[5270,  432],\n",
            "        [1837, 3865]])\n",
            "tensor([[857,  93],\n",
            "        [328, 622]])\n",
            "Epoch: 132, Train Accuracy: 0.84444, Train Loss: 0.36158, Validation Accuracy: 0.81579, Validation Loss: 0.44268, prediction: [0.018, 0.982], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5271,  431],\n",
            "        [1835, 3867]])\n",
            "tensor([[856,  94],\n",
            "        [329, 621]])\n",
            "Epoch: 133, Train Accuracy: 0.84532, Train Loss: 0.36039, Validation Accuracy: 0.81368, Validation Loss: 0.51320, prediction: [0.031, 0.969], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8210526315789474\n",
            "tensor([[5276,  426],\n",
            "        [1844, 3858]])\n",
            "tensor([[855,  95],\n",
            "        [327, 623]])\n",
            "Epoch: 134, Train Accuracy: 0.84549, Train Loss: 0.35340, Validation Accuracy: 0.81368, Validation Loss: 0.44949, prediction: [0.471, 0.529], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8210526315789474\n",
            "tensor([[5264,  438],\n",
            "        [1767, 3935]])\n",
            "tensor([[855,  95],\n",
            "        [317, 633]])\n",
            "Epoch: 135, Train Accuracy: 0.84602, Train Loss: 0.36093, Validation Accuracy: 0.81684, Validation Loss: 0.46083, prediction: [0.734, 0.266], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8210526315789474\n",
            "tensor([[5265,  437],\n",
            "        [1810, 3892]])\n",
            "tensor([[855,  95],\n",
            "        [325, 625]])\n",
            "Epoch: 136, Train Accuracy: 0.84655, Train Loss: 0.35955, Validation Accuracy: 0.81368, Validation Loss: 0.48678, prediction: [0.482, 0.518], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8210526315789474\n",
            "tensor([[5273,  429],\n",
            "        [1836, 3866]])\n",
            "tensor([[854,  96],\n",
            "        [324, 626]])\n",
            "Epoch: 137, Train Accuracy: 0.84655, Train Loss: 0.35613, Validation Accuracy: 0.81368, Validation Loss: 0.50999, prediction: [0.929, 0.071], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8210526315789474\n",
            "tensor([[5269,  433],\n",
            "        [1798, 3904]])\n",
            "tensor([[855,  95],\n",
            "        [321, 629]])\n",
            "Epoch: 138, Train Accuracy: 0.84672, Train Loss: 0.35309, Validation Accuracy: 0.81579, Validation Loss: 0.44885, prediction: [0.025, 0.975], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5276,  426],\n",
            "        [1823, 3879]])\n",
            "tensor([[854,  96],\n",
            "        [324, 626]])\n",
            "Epoch: 139, Train Accuracy: 0.84707, Train Loss: 0.35007, Validation Accuracy: 0.81684, Validation Loss: 0.50528, prediction: [0.026, 0.974], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8210526315789474\n",
            "tensor([[5278,  424],\n",
            "        [1809, 3893]])\n",
            "tensor([[853,  97],\n",
            "        [322, 628]])\n",
            "Epoch: 140, Train Accuracy: 0.84830, Train Loss: 0.35365, Validation Accuracy: 0.81579, Validation Loss: 0.48982, prediction: [0.905, 0.095], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8210526315789474\n",
            "tensor([[5265,  437],\n",
            "        [1725, 3977]])\n",
            "tensor([[855,  95],\n",
            "        [310, 640]])\n",
            "Epoch: 141, Train Accuracy: 0.84690, Train Loss: 0.35212, Validation Accuracy: 0.81789, Validation Loss: 0.44890, prediction: [0.69, 0.31], true label: [0.0, 1.0]\n",
            "0.8178947368421052 0.8210526315789474\n",
            "tensor([[5274,  428],\n",
            "        [1802, 3900]])\n",
            "tensor([[853,  97],\n",
            "        [319, 631]])\n",
            "Epoch: 142, Train Accuracy: 0.85005, Train Loss: 0.36230, Validation Accuracy: 0.81474, Validation Loss: 0.45735, prediction: [0.491, 0.509], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8210526315789474\n",
            "tensor([[5279,  423],\n",
            "        [1805, 3897]])\n",
            "tensor([[853,  97],\n",
            "        [319, 631]])\n",
            "Epoch: 143, Train Accuracy: 0.85163, Train Loss: 0.34850, Validation Accuracy: 0.81368, Validation Loss: 0.46058, prediction: [0.698, 0.302], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8210526315789474\n",
            "tensor([[5278,  424],\n",
            "        [1750, 3952]])\n",
            "tensor([[853,  97],\n",
            "        [317, 633]])\n",
            "Epoch: 144, Train Accuracy: 0.85005, Train Loss: 0.35011, Validation Accuracy: 0.81789, Validation Loss: 0.46833, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8178947368421052 0.8210526315789474\n",
            "tensor([[5273,  429],\n",
            "        [1719, 3983]])\n",
            "tensor([[853,  97],\n",
            "        [311, 639]])\n",
            "Epoch: 145, Train Accuracy: 0.85005, Train Loss: 0.34620, Validation Accuracy: 0.82000, Validation Loss: 0.48247, prediction: [0.912, 0.088], true label: [1.0, 0.0]\n",
            "0.82 0.8210526315789474\n",
            "tensor([[5275,  427],\n",
            "        [1726, 3976]])\n",
            "tensor([[853,  97],\n",
            "        [313, 637]])\n",
            "Epoch: 146, Train Accuracy: 0.85058, Train Loss: 0.34635, Validation Accuracy: 0.82211, Validation Loss: 0.45396, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8221052631578948 0.8210526315789474\n",
            "best_state_dict updated\n",
            "tensor([[5310,  392],\n",
            "        [1873, 3829]])\n",
            "tensor([[858,  92],\n",
            "        [340, 610]])\n",
            "Epoch: 147, Train Accuracy: 0.84760, Train Loss: 0.35164, Validation Accuracy: 0.80526, Validation Loss: 0.49583, prediction: [0.138, 0.862], true label: [0.0, 1.0]\n",
            "0.8052631578947368 0.8221052631578948\n",
            "tensor([[5280,  422],\n",
            "        [1743, 3959]])\n",
            "tensor([[854,  96],\n",
            "        [313, 637]])\n",
            "Epoch: 148, Train Accuracy: 0.85181, Train Loss: 0.34471, Validation Accuracy: 0.81895, Validation Loss: 0.45801, prediction: [0.038, 0.962], true label: [0.0, 1.0]\n",
            "0.8189473684210526 0.8221052631578948\n",
            "tensor([[5284,  418],\n",
            "        [1764, 3938]])\n",
            "tensor([[853,  97],\n",
            "        [317, 633]])\n",
            "Epoch: 149, Train Accuracy: 0.85338, Train Loss: 0.34800, Validation Accuracy: 0.81789, Validation Loss: 0.47464, prediction: [0.613, 0.387], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.8221052631578948\n",
            "tensor([[5280,  422],\n",
            "        [1745, 3957]])\n",
            "tensor([[853,  97],\n",
            "        [315, 635]])\n",
            "Epoch: 150, Train Accuracy: 0.85426, Train Loss: 0.34602, Validation Accuracy: 0.81579, Validation Loss: 0.49125, prediction: [0.815, 0.185], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5303,  399],\n",
            "        [1806, 3896]])\n",
            "tensor([[853,  97],\n",
            "        [334, 616]])\n",
            "Epoch: 151, Train Accuracy: 0.85321, Train Loss: 0.34360, Validation Accuracy: 0.81053, Validation Loss: 0.49061, prediction: [0.849, 0.151], true label: [1.0, 0.0]\n",
            "0.8105263157894737 0.8221052631578948\n",
            "tensor([[5297,  405],\n",
            "        [1780, 3922]])\n",
            "tensor([[852,  98],\n",
            "        [320, 630]])\n",
            "Epoch: 152, Train Accuracy: 0.85619, Train Loss: 0.33908, Validation Accuracy: 0.81158, Validation Loss: 0.51157, prediction: [0.727, 0.273], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8221052631578948\n",
            "tensor([[5295,  407],\n",
            "        [1771, 3931]])\n",
            "tensor([[852,  98],\n",
            "        [320, 630]])\n",
            "Epoch: 153, Train Accuracy: 0.85637, Train Loss: 0.35305, Validation Accuracy: 0.81263, Validation Loss: 0.47803, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.8126315789473684 0.8221052631578948\n",
            "tensor([[5286,  416],\n",
            "        [1739, 3963]])\n",
            "tensor([[851,  99],\n",
            "        [317, 633]])\n",
            "Epoch: 154, Train Accuracy: 0.85672, Train Loss: 0.35018, Validation Accuracy: 0.81474, Validation Loss: 0.47698, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.8221052631578948\n",
            "tensor([[5282,  420],\n",
            "        [1691, 4011]])\n",
            "tensor([[850, 100],\n",
            "        [304, 646]])\n",
            "Epoch: 155, Train Accuracy: 0.85672, Train Loss: 0.33952, Validation Accuracy: 0.81579, Validation Loss: 0.49210, prediction: [0.867, 0.133], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5289,  413],\n",
            "        [1712, 3990]])\n",
            "tensor([[850, 100],\n",
            "        [310, 640]])\n",
            "Epoch: 156, Train Accuracy: 0.85689, Train Loss: 0.33362, Validation Accuracy: 0.81368, Validation Loss: 0.49599, prediction: [0.968, 0.032], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8221052631578948\n",
            "tensor([[5278,  424],\n",
            "        [1650, 4052]])\n",
            "tensor([[849, 101],\n",
            "        [304, 646]])\n",
            "Epoch: 157, Train Accuracy: 0.85110, Train Loss: 0.34596, Validation Accuracy: 0.81789, Validation Loss: 0.47580, prediction: [0.498, 0.502], true label: [1.0, 0.0]\n",
            "0.8178947368421052 0.8221052631578948\n",
            "tensor([[5311,  391],\n",
            "        [1738, 3964]])\n",
            "tensor([[853,  97],\n",
            "        [325, 625]])\n",
            "Epoch: 158, Train Accuracy: 0.85935, Train Loss: 0.34457, Validation Accuracy: 0.81263, Validation Loss: 0.48691, prediction: [0.824, 0.176], true label: [1.0, 0.0]\n",
            "0.8126315789473684 0.8221052631578948\n",
            "tensor([[5310,  392],\n",
            "        [1762, 3940]])\n",
            "tensor([[854,  96],\n",
            "        [331, 619]])\n",
            "Epoch: 159, Train Accuracy: 0.85812, Train Loss: 0.33948, Validation Accuracy: 0.81053, Validation Loss: 0.50713, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.8105263157894737 0.8221052631578948\n",
            "tensor([[5306,  396],\n",
            "        [1711, 3991]])\n",
            "tensor([[853,  97],\n",
            "        [322, 628]])\n",
            "Epoch: 160, Train Accuracy: 0.86005, Train Loss: 0.34417, Validation Accuracy: 0.80947, Validation Loss: 0.48850, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8094736842105263 0.8221052631578948\n",
            "tensor([[5288,  414],\n",
            "        [1659, 4043]])\n",
            "tensor([[848, 102],\n",
            "        [300, 650]])\n",
            "Epoch: 161, Train Accuracy: 0.85952, Train Loss: 0.33892, Validation Accuracy: 0.81579, Validation Loss: 0.49797, prediction: [0.935, 0.065], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5312,  390],\n",
            "        [1704, 3998]])\n",
            "tensor([[851,  99],\n",
            "        [317, 633]])\n",
            "Epoch: 162, Train Accuracy: 0.85970, Train Loss: 0.33737, Validation Accuracy: 0.80737, Validation Loss: 0.49021, prediction: [0.914, 0.086], true label: [1.0, 0.0]\n",
            "0.8073684210526316 0.8221052631578948\n",
            "tensor([[5315,  387],\n",
            "        [1709, 3993]])\n",
            "tensor([[851,  99],\n",
            "        [318, 632]])\n",
            "Epoch: 163, Train Accuracy: 0.85917, Train Loss: 0.33967, Validation Accuracy: 0.80526, Validation Loss: 0.51615, prediction: [0.916, 0.084], true label: [1.0, 0.0]\n",
            "0.8052631578947368 0.8221052631578948\n",
            "tensor([[5308,  394],\n",
            "        [1684, 4018]])\n",
            "tensor([[851,  99],\n",
            "        [313, 637]])\n",
            "Epoch: 164, Train Accuracy: 0.86198, Train Loss: 0.32942, Validation Accuracy: 0.81684, Validation Loss: 0.48473, prediction: [0.887, 0.113], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8221052631578948\n",
            "tensor([[5309,  393],\n",
            "        [1668, 4034]])\n",
            "tensor([[851,  99],\n",
            "        [311, 639]])\n",
            "Epoch: 165, Train Accuracy: 0.86286, Train Loss: 0.33790, Validation Accuracy: 0.81368, Validation Loss: 0.50247, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8221052631578948\n",
            "tensor([[5302,  400],\n",
            "        [1651, 4051]])\n",
            "tensor([[850, 100],\n",
            "        [309, 641]])\n",
            "Epoch: 166, Train Accuracy: 0.86373, Train Loss: 0.32817, Validation Accuracy: 0.81579, Validation Loss: 0.53207, prediction: [0.113, 0.887], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5298,  404],\n",
            "        [1624, 4078]])\n",
            "tensor([[847, 103],\n",
            "        [301, 649]])\n",
            "Epoch: 167, Train Accuracy: 0.86215, Train Loss: 0.33157, Validation Accuracy: 0.81684, Validation Loss: 0.48015, prediction: [0.971, 0.029], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8221052631578948\n",
            "tensor([[5313,  389],\n",
            "        [1647, 4055]])\n",
            "tensor([[851,  99],\n",
            "        [311, 639]])\n",
            "Epoch: 168, Train Accuracy: 0.86391, Train Loss: 0.33275, Validation Accuracy: 0.81368, Validation Loss: 0.49245, prediction: [0.898, 0.102], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8221052631578948\n",
            "tensor([[5300,  402],\n",
            "        [1623, 4079]])\n",
            "tensor([[846, 104],\n",
            "        [302, 648]])\n",
            "Epoch: 169, Train Accuracy: 0.86286, Train Loss: 0.32771, Validation Accuracy: 0.81684, Validation Loss: 0.49930, prediction: [0.942, 0.058], true label: [1.0, 0.0]\n",
            "0.8168421052631579 0.8221052631578948\n",
            "tensor([[5316,  386],\n",
            "        [1642, 4060]])\n",
            "tensor([[851,  99],\n",
            "        [310, 640]])\n",
            "Epoch: 170, Train Accuracy: 0.86321, Train Loss: 0.33481, Validation Accuracy: 0.81158, Validation Loss: 0.49181, prediction: [0.112, 0.888], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8221052631578948\n",
            "tensor([[5303,  399],\n",
            "        [1605, 4097]])\n",
            "tensor([[846, 104],\n",
            "        [300, 650]])\n",
            "Epoch: 171, Train Accuracy: 0.86338, Train Loss: 0.32805, Validation Accuracy: 0.81684, Validation Loss: 0.51356, prediction: [0.34, 0.66], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8221052631578948\n",
            "tensor([[5317,  385],\n",
            "        [1624, 4078]])\n",
            "tensor([[850, 100],\n",
            "        [308, 642]])\n",
            "Epoch: 172, Train Accuracy: 0.86426, Train Loss: 0.33329, Validation Accuracy: 0.81158, Validation Loss: 0.49507, prediction: [0.769, 0.231], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8221052631578948\n",
            "tensor([[5311,  391],\n",
            "        [1609, 4093]])\n",
            "tensor([[845, 105],\n",
            "        [304, 646]])\n",
            "Epoch: 173, Train Accuracy: 0.86496, Train Loss: 0.32671, Validation Accuracy: 0.81263, Validation Loss: 0.51201, prediction: [0.93, 0.07], true label: [1.0, 0.0]\n",
            "0.8126315789473684 0.8221052631578948\n",
            "tensor([[5326,  376],\n",
            "        [1630, 4072]])\n",
            "tensor([[851,  99],\n",
            "        [314, 636]])\n",
            "Epoch: 174, Train Accuracy: 0.86549, Train Loss: 0.32208, Validation Accuracy: 0.80316, Validation Loss: 0.50968, prediction: [0.082, 0.918], true label: [0.0, 1.0]\n",
            "0.8031578947368421 0.8221052631578948\n",
            "tensor([[5337,  365],\n",
            "        [1712, 3990]])\n",
            "tensor([[850, 100],\n",
            "        [322, 628]])\n",
            "Epoch: 175, Train Accuracy: 0.86338, Train Loss: 0.32552, Validation Accuracy: 0.80105, Validation Loss: 0.52191, prediction: [0.105, 0.895], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8221052631578948\n",
            "tensor([[5329,  373],\n",
            "        [1623, 4079]])\n",
            "tensor([[852,  98],\n",
            "        [307, 643]])\n",
            "Epoch: 176, Train Accuracy: 0.86636, Train Loss: 0.31984, Validation Accuracy: 0.81474, Validation Loss: 0.49655, prediction: [0.025, 0.975], true label: [0.0, 1.0]\n",
            "0.8147368421052632 0.8221052631578948\n",
            "tensor([[5341,  361],\n",
            "        [1702, 4000]])\n",
            "tensor([[851,  99],\n",
            "        [323, 627]])\n",
            "Epoch: 177, Train Accuracy: 0.86321, Train Loss: 0.33340, Validation Accuracy: 0.80000, Validation Loss: 0.52704, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.8 0.8221052631578948\n",
            "tensor([[5312,  390],\n",
            "        [1568, 4134]])\n",
            "tensor([[847, 103],\n",
            "        [295, 655]])\n",
            "Epoch: 178, Train Accuracy: 0.86531, Train Loss: 0.31619, Validation Accuracy: 0.81684, Validation Loss: 0.49787, prediction: [0.22, 0.78], true label: [0.0, 1.0]\n",
            "0.8168421052631579 0.8221052631578948\n",
            "tensor([[5316,  386],\n",
            "        [1572, 4130]])\n",
            "tensor([[847, 103],\n",
            "        [298, 652]])\n",
            "Epoch: 179, Train Accuracy: 0.86689, Train Loss: 0.31508, Validation Accuracy: 0.81579, Validation Loss: 0.50985, prediction: [0.831, 0.169], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5335,  367],\n",
            "        [1591, 4111]])\n",
            "tensor([[849, 101],\n",
            "        [307, 643]])\n",
            "Epoch: 180, Train Accuracy: 0.86829, Train Loss: 0.31752, Validation Accuracy: 0.81158, Validation Loss: 0.51591, prediction: [0.047, 0.953], true label: [0.0, 1.0]\n",
            "0.8115789473684211 0.8221052631578948\n",
            "tensor([[5315,  387],\n",
            "        [1561, 4141]])\n",
            "tensor([[844, 106],\n",
            "        [292, 658]])\n",
            "Epoch: 181, Train Accuracy: 0.86741, Train Loss: 0.31574, Validation Accuracy: 0.81579, Validation Loss: 0.49249, prediction: [0.888, 0.112], true label: [1.0, 0.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5358,  344],\n",
            "        [1686, 4016]])\n",
            "tensor([[847, 103],\n",
            "        [321, 629]])\n",
            "Epoch: 182, Train Accuracy: 0.86356, Train Loss: 0.32240, Validation Accuracy: 0.79474, Validation Loss: 0.57615, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.7947368421052632 0.8221052631578948\n",
            "tensor([[5348,  354],\n",
            "        [1604, 4098]])\n",
            "tensor([[851,  99],\n",
            "        [312, 638]])\n",
            "Epoch: 183, Train Accuracy: 0.86987, Train Loss: 0.31493, Validation Accuracy: 0.80842, Validation Loss: 0.55474, prediction: [0.771, 0.229], true label: [1.0, 0.0]\n",
            "0.8084210526315789 0.8221052631578948\n",
            "tensor([[5325,  377],\n",
            "        [1560, 4142]])\n",
            "tensor([[845, 105],\n",
            "        [295, 655]])\n",
            "Epoch: 184, Train Accuracy: 0.86934, Train Loss: 0.31080, Validation Accuracy: 0.81474, Validation Loss: 0.50447, prediction: [0.93, 0.07], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8221052631578948\n",
            "tensor([[5316,  386],\n",
            "        [1514, 4188]])\n",
            "tensor([[844, 106],\n",
            "        [295, 655]])\n",
            "Epoch: 185, Train Accuracy: 0.86969, Train Loss: 0.30973, Validation Accuracy: 0.81368, Validation Loss: 0.50554, prediction: [0.199, 0.801], true label: [0.0, 1.0]\n",
            "0.8136842105263158 0.8221052631578948\n",
            "tensor([[5321,  381],\n",
            "        [1505, 4197]])\n",
            "tensor([[843, 107],\n",
            "        [294, 656]])\n",
            "Epoch: 186, Train Accuracy: 0.87040, Train Loss: 0.31395, Validation Accuracy: 0.81368, Validation Loss: 0.51142, prediction: [0.929, 0.071], true label: [1.0, 0.0]\n",
            "0.8136842105263158 0.8221052631578948\n",
            "tensor([[5354,  348],\n",
            "        [1585, 4117]])\n",
            "tensor([[847, 103],\n",
            "        [311, 639]])\n",
            "Epoch: 187, Train Accuracy: 0.86864, Train Loss: 0.31384, Validation Accuracy: 0.79474, Validation Loss: 0.52911, prediction: [0.764, 0.236], true label: [0.0, 1.0]\n",
            "0.7947368421052632 0.8221052631578948\n",
            "tensor([[5334,  368],\n",
            "        [1517, 4185]])\n",
            "tensor([[846, 104],\n",
            "        [300, 650]])\n",
            "Epoch: 188, Train Accuracy: 0.87127, Train Loss: 0.30939, Validation Accuracy: 0.81579, Validation Loss: 0.50414, prediction: [0.829, 0.171], true label: [0.0, 1.0]\n",
            "0.8157894736842105 0.8221052631578948\n",
            "tensor([[5330,  372],\n",
            "        [1499, 4203]])\n",
            "tensor([[842, 108],\n",
            "        [292, 658]])\n",
            "Epoch: 189, Train Accuracy: 0.87162, Train Loss: 0.31205, Validation Accuracy: 0.81474, Validation Loss: 0.55503, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.8147368421052632 0.8221052631578948\n",
            "tensor([[5353,  349],\n",
            "        [1531, 4171]])\n",
            "tensor([[851,  99],\n",
            "        [308, 642]])\n",
            "Epoch: 190, Train Accuracy: 0.87425, Train Loss: 0.30403, Validation Accuracy: 0.80211, Validation Loss: 0.53947, prediction: [0.966, 0.034], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8221052631578948\n",
            "tensor([[5351,  351],\n",
            "        [1518, 4184]])\n",
            "tensor([[849, 101],\n",
            "        [306, 644]])\n",
            "Epoch: 191, Train Accuracy: 0.87548, Train Loss: 0.30359, Validation Accuracy: 0.80842, Validation Loss: 0.61946, prediction: [0.225, 0.775], true label: [0.0, 1.0]\n",
            "0.8084210526315789 0.8221052631578948\n",
            "tensor([[5326,  376],\n",
            "        [1478, 4224]])\n",
            "tensor([[842, 108],\n",
            "        [292, 658]])\n",
            "Epoch: 192, Train Accuracy: 0.87303, Train Loss: 0.30676, Validation Accuracy: 0.81158, Validation Loss: 0.52667, prediction: [0.925, 0.075], true label: [1.0, 0.0]\n",
            "0.8115789473684211 0.8221052631578948\n",
            "tensor([[5362,  340],\n",
            "        [1556, 4146]])\n",
            "tensor([[849, 101],\n",
            "        [308, 642]])\n",
            "Epoch: 193, Train Accuracy: 0.87215, Train Loss: 0.30848, Validation Accuracy: 0.79263, Validation Loss: 0.55469, prediction: [0.92, 0.08], true label: [1.0, 0.0]\n",
            "0.7926315789473685 0.8221052631578948\n",
            "tensor([[5357,  345],\n",
            "        [1505, 4197]])\n",
            "tensor([[846, 104],\n",
            "        [304, 646]])\n",
            "Epoch: 194, Train Accuracy: 0.87601, Train Loss: 0.29884, Validation Accuracy: 0.80632, Validation Loss: 0.53333, prediction: [0.957, 0.043], true label: [1.0, 0.0]\n",
            "0.8063157894736842 0.8221052631578948\n",
            "tensor([[5369,  333],\n",
            "        [1572, 4130]])\n",
            "tensor([[846, 104],\n",
            "        [305, 645]])\n",
            "Epoch: 195, Train Accuracy: 0.87250, Train Loss: 0.30844, Validation Accuracy: 0.79053, Validation Loss: 0.58232, prediction: [0.018, 0.982], true label: [0.0, 1.0]\n",
            "0.7905263157894736 0.8221052631578948\n",
            "tensor([[5364,  338],\n",
            "        [1501, 4201]])\n",
            "tensor([[848, 102],\n",
            "        [308, 642]])\n",
            "Epoch: 196, Train Accuracy: 0.87566, Train Loss: 0.30097, Validation Accuracy: 0.80105, Validation Loss: 0.53198, prediction: [0.121, 0.879], true label: [0.0, 1.0]\n",
            "0.8010526315789473 0.8221052631578948\n",
            "tensor([[5366,  336],\n",
            "        [1534, 4168]])\n",
            "tensor([[845, 105],\n",
            "        [305, 645]])\n",
            "Epoch: 197, Train Accuracy: 0.87425, Train Loss: 0.29601, Validation Accuracy: 0.79158, Validation Loss: 0.54891, prediction: [0.756, 0.244], true label: [1.0, 0.0]\n",
            "0.791578947368421 0.8221052631578948\n",
            "tensor([[5365,  337],\n",
            "        [1480, 4222]])\n",
            "tensor([[844, 106],\n",
            "        [303, 647]])\n",
            "Epoch: 198, Train Accuracy: 0.87653, Train Loss: 0.29571, Validation Accuracy: 0.80105, Validation Loss: 0.57252, prediction: [0.925, 0.075], true label: [1.0, 0.0]\n",
            "0.8010526315789473 0.8221052631578948\n",
            "tensor([[5361,  341],\n",
            "        [1449, 4253]])\n",
            "tensor([[844, 106],\n",
            "        [300, 650]])\n",
            "Epoch: 199, Train Accuracy: 0.87794, Train Loss: 0.29977, Validation Accuracy: 0.80211, Validation Loss: 0.54051, prediction: [0.946, 0.054], true label: [1.0, 0.0]\n",
            "0.8021052631578948 0.8221052631578948\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network10 = copy.deepcopy(network7)"
      ],
      "metadata": {
        "id": "k3jWoU_Rosuq"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "networK15.load_state_dict(best15)\n",
        "q = get_accuracy(networK15, test_load2, nn.CrossEntropyLoss())\n",
        "print(q[0], q[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcNr3WjofA2",
        "outputId": "debddf7d-9a49-48dc-8504-628d8f60eb86"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r                                                     \rtensor([[916, 171],\n",
            "        [233, 854]])\n",
            "0.8206071757129715 1.0633104082559537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network8.load_state_dict(best8)\n",
        "q = get_accuracy(network8, test_load2, nn.CrossEntropyLoss())\n",
        "print(q[0], q[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9tj8yRmXYXD",
        "outputId": "162d6742-4d11-4c5a-c1de-5fce2a88477f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r                                                     \rtensor([[940, 147],\n",
            "        [189, 898]])\n",
            "0.8509659613615456 0.7947094964571685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c,d,e,f,best17,network17=tune_network(net=IGRatioNet,embedding_size=200, batch_size=64, learning_rate=0.00003, epochs=200, device=device, lstm_layers=1, bidirectional=True, learning_rate_decay=0.5, weight_decay=2e-5, dropout=0.5) # 81.6% val set epoch 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4uxQ-WrzXsZc",
        "outputId": "ab61e58b-9737-4d7a-bf8a-043fd876b895"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6520\n",
            "1087\n",
            "1087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r 37/??\t\r 38/??\t\r 39/??\t\r 40/??\t\r 41/??\t\r 42/??\t\r 43/??\t\r 44/??\t\r 45/??\t\r 46/??\t"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6520,    0],\n",
            "        [6520,    0]])\n",
            "tensor([[1087,    0],\n",
            "        [1087,    0]])\n",
            "Epoch: 0, Train Accuracy: 0.53911, Train Loss: 0.68547, Validation Accuracy: 0.55842, Validation Loss: 0.70122, prediction: [0.46, 0.54], true label: [0.0, 1.0]\n",
            "0.5584176632934683 0\n",
            "best_state_dict updated\n",
            "tensor([[6050,  470],\n",
            "        [3554, 2966]])\n",
            "tensor([[1014,   73],\n",
            "        [ 572,  515]])\n",
            "Epoch: 1, Train Accuracy: 0.76610, Train Loss: 0.49188, Validation Accuracy: 0.76633, Validation Loss: 0.45299, prediction: [0.287, 0.713], true label: [1.0, 0.0]\n",
            "0.766329346826127 0.5584176632934683\n",
            "best_state_dict updated\n",
            "tensor([[6022,  498],\n",
            "        [3225, 3295]])\n",
            "tensor([[1015,   72],\n",
            "        [ 515,  572]])\n",
            "Epoch: 2, Train Accuracy: 0.78113, Train Loss: 0.46748, Validation Accuracy: 0.77829, Validation Loss: 0.42486, prediction: [0.657, 0.343], true label: [1.0, 0.0]\n",
            "0.7782888684452622 0.766329346826127\n",
            "best_state_dict updated\n",
            "tensor([[5986,  534],\n",
            "        [2921, 3599]])\n",
            "tensor([[1008,   79],\n",
            "        [ 482,  605]])\n",
            "Epoch: 3, Train Accuracy: 0.79018, Train Loss: 0.44948, Validation Accuracy: 0.78381, Validation Loss: 0.41057, prediction: [0.883, 0.117], true label: [1.0, 0.0]\n",
            "0.7838086476540939 0.7782888684452622\n",
            "best_state_dict updated\n",
            "tensor([[5969,  551],\n",
            "        [2760, 3760]])\n",
            "tensor([[1005,   82],\n",
            "        [ 455,  632]])\n",
            "Epoch: 4, Train Accuracy: 0.79264, Train Loss: 0.43765, Validation Accuracy: 0.78841, Validation Loss: 0.40436, prediction: [0.819, 0.181], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.7838086476540939\n",
            "best_state_dict updated\n",
            "tensor([[6002,  518],\n",
            "        [2688, 3832]])\n",
            "tensor([[999,  88],\n",
            "        [459, 628]])\n",
            "Epoch: 5, Train Accuracy: 0.79417, Train Loss: 0.43063, Validation Accuracy: 0.78749, Validation Loss: 0.41509, prediction: [0.138, 0.862], true label: [1.0, 0.0]\n",
            "0.7874885004599816 0.7884084636614536\n",
            "tensor([[5951,  569],\n",
            "        [2590, 3930]])\n",
            "tensor([[978, 109],\n",
            "        [425, 662]])\n",
            "Epoch: 6, Train Accuracy: 0.79693, Train Loss: 0.42769, Validation Accuracy: 0.78841, Validation Loss: 0.42614, prediction: [0.46, 0.54], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.7884084636614536\n",
            "tensor([[6002,  518],\n",
            "        [2613, 3907]])\n",
            "tensor([[993,  94],\n",
            "        [446, 641]])\n",
            "Epoch: 7, Train Accuracy: 0.80429, Train Loss: 0.42179, Validation Accuracy: 0.79025, Validation Loss: 0.39798, prediction: [0.206, 0.794], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.7884084636614536\n",
            "best_state_dict updated\n",
            "tensor([[5980,  540],\n",
            "        [2546, 3974]])\n",
            "tensor([[987, 100],\n",
            "        [428, 659]])\n",
            "Epoch: 8, Train Accuracy: 0.80475, Train Loss: 0.41823, Validation Accuracy: 0.78933, Validation Loss: 0.41306, prediction: [0.833, 0.167], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.7902483900643974\n",
            "tensor([[6013,  507],\n",
            "        [2572, 3948]])\n",
            "tensor([[993,  94],\n",
            "        [437, 650]])\n",
            "Epoch: 9, Train Accuracy: 0.80660, Train Loss: 0.41566, Validation Accuracy: 0.79209, Validation Loss: 0.40408, prediction: [0.751, 0.249], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7902483900643974\n",
            "best_state_dict updated\n",
            "tensor([[6039,  481],\n",
            "        [2503, 4017]])\n",
            "tensor([[993,  94],\n",
            "        [431, 656]])\n",
            "Epoch: 10, Train Accuracy: 0.80752, Train Loss: 0.40636, Validation Accuracy: 0.79025, Validation Loss: 0.40634, prediction: [0.803, 0.197], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.7920883164673413\n",
            "tensor([[6041,  479],\n",
            "        [2475, 4045]])\n",
            "tensor([[987, 100],\n",
            "        [429, 658]])\n",
            "Epoch: 11, Train Accuracy: 0.81212, Train Loss: 0.40252, Validation Accuracy: 0.79025, Validation Loss: 0.42827, prediction: [0.651, 0.349], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7920883164673413\n",
            "tensor([[5972,  548],\n",
            "        [2439, 4081]])\n",
            "tensor([[969, 118],\n",
            "        [410, 677]])\n",
            "Epoch: 12, Train Accuracy: 0.80813, Train Loss: 0.40755, Validation Accuracy: 0.79025, Validation Loss: 0.40709, prediction: [0.053, 0.947], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7920883164673413\n",
            "tensor([[6027,  493],\n",
            "        [2432, 4088]])\n",
            "tensor([[989,  98],\n",
            "        [421, 666]])\n",
            "Epoch: 13, Train Accuracy: 0.81426, Train Loss: 0.40339, Validation Accuracy: 0.79853, Validation Loss: 0.42026, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.7985280588776449 0.7920883164673413\n",
            "best_state_dict updated\n",
            "tensor([[6016,  504],\n",
            "        [2369, 4151]])\n",
            "tensor([[980, 107],\n",
            "        [415, 672]])\n",
            "Epoch: 14, Train Accuracy: 0.81564, Train Loss: 0.39857, Validation Accuracy: 0.79117, Validation Loss: 0.38888, prediction: [0.903, 0.097], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.7985280588776449\n",
            "tensor([[6034,  486],\n",
            "        [2402, 4118]])\n",
            "tensor([[980, 107],\n",
            "        [423, 664]])\n",
            "Epoch: 15, Train Accuracy: 0.81887, Train Loss: 0.39392, Validation Accuracy: 0.79025, Validation Loss: 0.41589, prediction: [0.121, 0.879], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7985280588776449\n",
            "tensor([[6014,  506],\n",
            "        [2326, 4194]])\n",
            "tensor([[981, 106],\n",
            "        [404, 683]])\n",
            "Epoch: 16, Train Accuracy: 0.81933, Train Loss: 0.39604, Validation Accuracy: 0.79853, Validation Loss: 0.41046, prediction: [0.866, 0.134], true label: [1.0, 0.0]\n",
            "0.7985280588776449 0.7985280588776449\n",
            "tensor([[6044,  476],\n",
            "        [2379, 4141]])\n",
            "tensor([[980, 107],\n",
            "        [411, 676]])\n",
            "Epoch: 17, Train Accuracy: 0.82362, Train Loss: 0.39368, Validation Accuracy: 0.79025, Validation Loss: 0.39053, prediction: [0.209, 0.791], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7985280588776449\n",
            "tensor([[5978,  542],\n",
            "        [2204, 4316]])\n",
            "tensor([[973, 114],\n",
            "        [389, 698]])\n",
            "Epoch: 18, Train Accuracy: 0.82393, Train Loss: 0.38479, Validation Accuracy: 0.79301, Validation Loss: 0.40947, prediction: [0.918, 0.082], true label: [1.0, 0.0]\n",
            "0.7930082796688133 0.7985280588776449\n",
            "tensor([[6036,  484],\n",
            "        [2299, 4221]])\n",
            "tensor([[979, 108],\n",
            "        [399, 688]])\n",
            "Epoch: 19, Train Accuracy: 0.82408, Train Loss: 0.38730, Validation Accuracy: 0.78565, Validation Loss: 0.39695, prediction: [0.172, 0.828], true label: [0.0, 1.0]\n",
            "0.7856485740570377 0.7985280588776449\n",
            "tensor([[6031,  489],\n",
            "        [2247, 4273]])\n",
            "tensor([[977, 110],\n",
            "        [392, 695]])\n",
            "Epoch: 20, Train Accuracy: 0.83006, Train Loss: 0.36650, Validation Accuracy: 0.79301, Validation Loss: 0.39009, prediction: [0.925, 0.075], true label: [1.0, 0.0]\n",
            "0.7930082796688133 0.7985280588776449\n",
            "tensor([[6053,  467],\n",
            "        [2292, 4228]])\n",
            "tensor([[978, 109],\n",
            "        [404, 683]])\n",
            "Epoch: 21, Train Accuracy: 0.82776, Train Loss: 0.37678, Validation Accuracy: 0.78473, Validation Loss: 0.39868, prediction: [0.427, 0.573], true label: [0.0, 1.0]\n",
            "0.7847286108555658 0.7985280588776449\n",
            "tensor([[6045,  475],\n",
            "        [2257, 4263]])\n",
            "tensor([[978, 109],\n",
            "        [398, 689]])\n",
            "Epoch: 22, Train Accuracy: 0.82945, Train Loss: 0.37732, Validation Accuracy: 0.78657, Validation Loss: 0.41780, prediction: [0.824, 0.176], true label: [1.0, 0.0]\n",
            "0.7865685372585096 0.7985280588776449\n",
            "tensor([[5933,  587],\n",
            "        [2105, 4415]])\n",
            "tensor([[962, 125],\n",
            "        [379, 708]])\n",
            "Epoch: 23, Train Accuracy: 0.81902, Train Loss: 0.38185, Validation Accuracy: 0.79301, Validation Loss: 0.39596, prediction: [0.899, 0.101], true label: [1.0, 0.0]\n",
            "0.7930082796688133 0.7985280588776449\n",
            "tensor([[6001,  519],\n",
            "        [2121, 4399]])\n",
            "tensor([[968, 119],\n",
            "        [380, 707]])\n",
            "Epoch: 24, Train Accuracy: 0.83190, Train Loss: 0.37414, Validation Accuracy: 0.79669, Validation Loss: 0.41257, prediction: [0.882, 0.118], true label: [1.0, 0.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6024,  496],\n",
            "        [2149, 4371]])\n",
            "tensor([[968, 119],\n",
            "        [385, 702]])\n",
            "Epoch: 25, Train Accuracy: 0.83604, Train Loss: 0.37128, Validation Accuracy: 0.79577, Validation Loss: 0.38676, prediction: [0.691, 0.309], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6054,  466],\n",
            "        [2190, 4330]])\n",
            "tensor([[975, 112],\n",
            "        [393, 694]])\n",
            "Epoch: 26, Train Accuracy: 0.83267, Train Loss: 0.36684, Validation Accuracy: 0.78749, Validation Loss: 0.41778, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.7985280588776449\n",
            "tensor([[6045,  475],\n",
            "        [2159, 4361]])\n",
            "tensor([[974, 113],\n",
            "        [383, 704]])\n",
            "Epoch: 27, Train Accuracy: 0.83420, Train Loss: 0.36048, Validation Accuracy: 0.79117, Validation Loss: 0.40557, prediction: [0.912, 0.088], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.7985280588776449\n",
            "tensor([[6052,  468],\n",
            "        [2161, 4359]])\n",
            "tensor([[977, 110],\n",
            "        [386, 701]])\n",
            "Epoch: 28, Train Accuracy: 0.83466, Train Loss: 0.36356, Validation Accuracy: 0.79117, Validation Loss: 0.40082, prediction: [0.904, 0.096], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.7985280588776449\n",
            "tensor([[6033,  487],\n",
            "        [2102, 4418]])\n",
            "tensor([[969, 118],\n",
            "        [380, 707]])\n",
            "Epoch: 29, Train Accuracy: 0.83696, Train Loss: 0.36467, Validation Accuracy: 0.79761, Validation Loss: 0.40490, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6025,  495],\n",
            "        [2072, 4448]])\n",
            "tensor([[968, 119],\n",
            "        [376, 711]])\n",
            "Epoch: 30, Train Accuracy: 0.83819, Train Loss: 0.36311, Validation Accuracy: 0.79577, Validation Loss: 0.38941, prediction: [0.904, 0.096], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6037,  483],\n",
            "        [2086, 4434]])\n",
            "tensor([[971, 116],\n",
            "        [376, 711]])\n",
            "Epoch: 31, Train Accuracy: 0.83865, Train Loss: 0.36248, Validation Accuracy: 0.79485, Validation Loss: 0.42640, prediction: [0.879, 0.121], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6045,  475],\n",
            "        [2100, 4420]])\n",
            "tensor([[974, 113],\n",
            "        [381, 706]])\n",
            "Epoch: 32, Train Accuracy: 0.83804, Train Loss: 0.35877, Validation Accuracy: 0.79025, Validation Loss: 0.43182, prediction: [0.021, 0.979], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7985280588776449\n",
            "tensor([[6026,  494],\n",
            "        [2062, 4458]])\n",
            "tensor([[968, 119],\n",
            "        [375, 712]])\n",
            "Epoch: 33, Train Accuracy: 0.83926, Train Loss: 0.35419, Validation Accuracy: 0.79485, Validation Loss: 0.37532, prediction: [0.742, 0.258], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6037,  483],\n",
            "        [2063, 4457]])\n",
            "tensor([[968, 119],\n",
            "        [375, 712]])\n",
            "Epoch: 34, Train Accuracy: 0.84080, Train Loss: 0.36240, Validation Accuracy: 0.79761, Validation Loss: 0.41174, prediction: [0.879, 0.121], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6036,  484],\n",
            "        [2043, 4477]])\n",
            "tensor([[969, 118],\n",
            "        [371, 716]])\n",
            "Epoch: 35, Train Accuracy: 0.84018, Train Loss: 0.35217, Validation Accuracy: 0.79669, Validation Loss: 0.40500, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6037,  483],\n",
            "        [2036, 4484]])\n",
            "tensor([[972, 115],\n",
            "        [377, 710]])\n",
            "Epoch: 36, Train Accuracy: 0.84172, Train Loss: 0.35693, Validation Accuracy: 0.79577, Validation Loss: 0.39096, prediction: [0.761, 0.239], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6047,  473],\n",
            "        [2033, 4487]])\n",
            "tensor([[972, 115],\n",
            "        [375, 712]])\n",
            "Epoch: 37, Train Accuracy: 0.84034, Train Loss: 0.35275, Validation Accuracy: 0.79209, Validation Loss: 0.39928, prediction: [0.239, 0.761], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6057,  463],\n",
            "        [2066, 4454]])\n",
            "tensor([[972, 115],\n",
            "        [377, 710]])\n",
            "Epoch: 38, Train Accuracy: 0.84141, Train Loss: 0.34965, Validation Accuracy: 0.79117, Validation Loss: 0.40145, prediction: [0.909, 0.091], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.7985280588776449\n",
            "tensor([[6036,  484],\n",
            "        [2016, 4504]])\n",
            "tensor([[969, 118],\n",
            "        [369, 718]])\n",
            "Epoch: 39, Train Accuracy: 0.84233, Train Loss: 0.34329, Validation Accuracy: 0.79485, Validation Loss: 0.41823, prediction: [0.933, 0.067], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6030,  490],\n",
            "        [1991, 4529]])\n",
            "tensor([[965, 122],\n",
            "        [367, 720]])\n",
            "Epoch: 40, Train Accuracy: 0.84340, Train Loss: 0.35404, Validation Accuracy: 0.79485, Validation Loss: 0.39432, prediction: [0.193, 0.807], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6044,  476],\n",
            "        [1993, 4527]])\n",
            "tensor([[968, 119],\n",
            "        [371, 716]])\n",
            "Epoch: 41, Train Accuracy: 0.84433, Train Loss: 0.35019, Validation Accuracy: 0.79761, Validation Loss: 0.40230, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6046,  474],\n",
            "        [1999, 4521]])\n",
            "tensor([[969, 118],\n",
            "        [368, 719]])\n",
            "Epoch: 42, Train Accuracy: 0.84540, Train Loss: 0.34517, Validation Accuracy: 0.79393, Validation Loss: 0.39143, prediction: [0.023, 0.977], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6052,  468],\n",
            "        [1996, 4524]])\n",
            "tensor([[971, 116],\n",
            "        [370, 717]])\n",
            "Epoch: 43, Train Accuracy: 0.84724, Train Loss: 0.35663, Validation Accuracy: 0.79393, Validation Loss: 0.39394, prediction: [0.594, 0.406], true label: [1.0, 0.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6069,  451],\n",
            "        [2013, 4507]])\n",
            "tensor([[972, 115],\n",
            "        [375, 712]])\n",
            "Epoch: 44, Train Accuracy: 0.84571, Train Loss: 0.35069, Validation Accuracy: 0.79209, Validation Loss: 0.42716, prediction: [0.53, 0.47], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6017,  503],\n",
            "        [1928, 4592]])\n",
            "tensor([[959, 128],\n",
            "        [357, 730]])\n",
            "Epoch: 45, Train Accuracy: 0.84632, Train Loss: 0.34525, Validation Accuracy: 0.79393, Validation Loss: 0.39255, prediction: [0.484, 0.516], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6051,  469],\n",
            "        [1959, 4561]])\n",
            "tensor([[963, 124],\n",
            "        [368, 719]])\n",
            "Epoch: 46, Train Accuracy: 0.84847, Train Loss: 0.34358, Validation Accuracy: 0.79485, Validation Loss: 0.39581, prediction: [0.959, 0.041], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6050,  470],\n",
            "        [1926, 4594]])\n",
            "tensor([[966, 121],\n",
            "        [365, 722]])\n",
            "Epoch: 47, Train Accuracy: 0.84985, Train Loss: 0.33620, Validation Accuracy: 0.79577, Validation Loss: 0.39191, prediction: [0.075, 0.925], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6078,  442],\n",
            "        [1984, 4536]])\n",
            "tensor([[972, 115],\n",
            "        [376, 711]])\n",
            "Epoch: 48, Train Accuracy: 0.84709, Train Loss: 0.34359, Validation Accuracy: 0.79209, Validation Loss: 0.40328, prediction: [0.29, 0.71], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6064,  456],\n",
            "        [1916, 4604]])\n",
            "tensor([[967, 120],\n",
            "        [367, 720]])\n",
            "Epoch: 49, Train Accuracy: 0.85061, Train Loss: 0.34116, Validation Accuracy: 0.79577, Validation Loss: 0.42109, prediction: [0.102, 0.898], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6025,  495],\n",
            "        [1864, 4656]])\n",
            "tensor([[955, 132],\n",
            "        [357, 730]])\n",
            "Epoch: 50, Train Accuracy: 0.84770, Train Loss: 0.34904, Validation Accuracy: 0.79761, Validation Loss: 0.38910, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6066,  454],\n",
            "        [1917, 4603]])\n",
            "tensor([[970, 117],\n",
            "        [367, 720]])\n",
            "Epoch: 51, Train Accuracy: 0.85322, Train Loss: 0.33602, Validation Accuracy: 0.79393, Validation Loss: 0.37880, prediction: [0.604, 0.396], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6059,  461],\n",
            "        [1886, 4634]])\n",
            "tensor([[965, 122],\n",
            "        [365, 722]])\n",
            "Epoch: 52, Train Accuracy: 0.85414, Train Loss: 0.33111, Validation Accuracy: 0.79669, Validation Loss: 0.38031, prediction: [0.638, 0.362], true label: [1.0, 0.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6062,  458],\n",
            "        [1893, 4627]])\n",
            "tensor([[966, 121],\n",
            "        [366, 721]])\n",
            "Epoch: 53, Train Accuracy: 0.85644, Train Loss: 0.33480, Validation Accuracy: 0.79485, Validation Loss: 0.40026, prediction: [0.398, 0.602], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6076,  444],\n",
            "        [1905, 4615]])\n",
            "tensor([[968, 119],\n",
            "        [366, 721]])\n",
            "Epoch: 54, Train Accuracy: 0.85337, Train Loss: 0.32910, Validation Accuracy: 0.79117, Validation Loss: 0.41289, prediction: [0.014, 0.986], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.7985280588776449\n",
            "tensor([[6048,  472],\n",
            "        [1818, 4702]])\n",
            "tensor([[957, 130],\n",
            "        [356, 731]])\n",
            "Epoch: 55, Train Accuracy: 0.85429, Train Loss: 0.33512, Validation Accuracy: 0.79577, Validation Loss: 0.38901, prediction: [0.952, 0.048], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6074,  446],\n",
            "        [1895, 4625]])\n",
            "tensor([[967, 120],\n",
            "        [364, 723]])\n",
            "Epoch: 56, Train Accuracy: 0.85537, Train Loss: 0.32668, Validation Accuracy: 0.79209, Validation Loss: 0.41856, prediction: [0.007, 0.993], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6094,  426],\n",
            "        [1935, 4585]])\n",
            "tensor([[964, 123],\n",
            "        [377, 710]])\n",
            "Epoch: 57, Train Accuracy: 0.85337, Train Loss: 0.33485, Validation Accuracy: 0.78841, Validation Loss: 0.40874, prediction: [0.56, 0.44], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.7985280588776449\n",
            "tensor([[6077,  443],\n",
            "        [1852, 4668]])\n",
            "tensor([[963, 124],\n",
            "        [366, 721]])\n",
            "Epoch: 58, Train Accuracy: 0.85813, Train Loss: 0.32587, Validation Accuracy: 0.79393, Validation Loss: 0.41599, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6072,  448],\n",
            "        [1859, 4661]])\n",
            "tensor([[966, 121],\n",
            "        [362, 725]])\n",
            "Epoch: 59, Train Accuracy: 0.85920, Train Loss: 0.33794, Validation Accuracy: 0.79301, Validation Loss: 0.40799, prediction: [0.045, 0.955], true label: [0.0, 1.0]\n",
            "0.7930082796688133 0.7985280588776449\n",
            "tensor([[6083,  437],\n",
            "        [1846, 4674]])\n",
            "tensor([[966, 121],\n",
            "        [360, 727]])\n",
            "Epoch: 60, Train Accuracy: 0.85920, Train Loss: 0.32054, Validation Accuracy: 0.79393, Validation Loss: 0.38727, prediction: [0.022, 0.978], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6077,  443],\n",
            "        [1824, 4696]])\n",
            "tensor([[962, 125],\n",
            "        [363, 724]])\n",
            "Epoch: 61, Train Accuracy: 0.86074, Train Loss: 0.33523, Validation Accuracy: 0.79577, Validation Loss: 0.43030, prediction: [0.951, 0.049], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6055,  465],\n",
            "        [1734, 4786]])\n",
            "tensor([[950, 137],\n",
            "        [353, 734]])\n",
            "Epoch: 62, Train Accuracy: 0.85598, Train Loss: 0.32165, Validation Accuracy: 0.79761, Validation Loss: 0.40249, prediction: [0.657, 0.343], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6084,  436],\n",
            "        [1771, 4749]])\n",
            "tensor([[959, 128],\n",
            "        [360, 727]])\n",
            "Epoch: 63, Train Accuracy: 0.86028, Train Loss: 0.32376, Validation Accuracy: 0.79669, Validation Loss: 0.38768, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6093,  427],\n",
            "        [1821, 4699]])\n",
            "tensor([[959, 128],\n",
            "        [364, 723]])\n",
            "Epoch: 64, Train Accuracy: 0.86104, Train Loss: 0.31818, Validation Accuracy: 0.79485, Validation Loss: 0.41375, prediction: [0.717, 0.283], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6088,  432],\n",
            "        [1760, 4760]])\n",
            "tensor([[958, 129],\n",
            "        [362, 725]])\n",
            "Epoch: 65, Train Accuracy: 0.86166, Train Loss: 0.32275, Validation Accuracy: 0.79669, Validation Loss: 0.40737, prediction: [0.023, 0.977], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6062,  458],\n",
            "        [1719, 4801]])\n",
            "tensor([[948, 139],\n",
            "        [356, 731]])\n",
            "Epoch: 66, Train Accuracy: 0.85767, Train Loss: 0.32471, Validation Accuracy: 0.79393, Validation Loss: 0.41485, prediction: [0.044, 0.956], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6108,  412],\n",
            "        [1752, 4768]])\n",
            "tensor([[961, 126],\n",
            "        [360, 727]])\n",
            "Epoch: 67, Train Accuracy: 0.86549, Train Loss: 0.31690, Validation Accuracy: 0.79025, Validation Loss: 0.40982, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7985280588776449\n",
            "tensor([[6103,  417],\n",
            "        [1784, 4736]])\n",
            "tensor([[959, 128],\n",
            "        [365, 722]])\n",
            "Epoch: 68, Train Accuracy: 0.86641, Train Loss: 0.31309, Validation Accuracy: 0.79761, Validation Loss: 0.37687, prediction: [0.858, 0.142], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6101,  419],\n",
            "        [1717, 4803]])\n",
            "tensor([[956, 131],\n",
            "        [355, 732]])\n",
            "Epoch: 69, Train Accuracy: 0.86764, Train Loss: 0.32066, Validation Accuracy: 0.79485, Validation Loss: 0.38274, prediction: [0.562, 0.438], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6099,  421],\n",
            "        [1706, 4814]])\n",
            "tensor([[955, 132],\n",
            "        [352, 735]])\n",
            "Epoch: 70, Train Accuracy: 0.86963, Train Loss: 0.30769, Validation Accuracy: 0.79393, Validation Loss: 0.39394, prediction: [0.134, 0.866], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6104,  416],\n",
            "        [1689, 4831]])\n",
            "tensor([[954, 133],\n",
            "        [355, 732]])\n",
            "Epoch: 71, Train Accuracy: 0.86917, Train Loss: 0.30468, Validation Accuracy: 0.79577, Validation Loss: 0.37218, prediction: [0.911, 0.089], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6120,  400],\n",
            "        [1748, 4772]])\n",
            "tensor([[953, 134],\n",
            "        [369, 718]])\n",
            "Epoch: 72, Train Accuracy: 0.86902, Train Loss: 0.30488, Validation Accuracy: 0.79577, Validation Loss: 0.41181, prediction: [0.924, 0.076], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6122,  398],\n",
            "        [1694, 4826]])\n",
            "tensor([[954, 133],\n",
            "        [359, 728]])\n",
            "Epoch: 73, Train Accuracy: 0.86979, Train Loss: 0.30428, Validation Accuracy: 0.79577, Validation Loss: 0.43258, prediction: [0.796, 0.204], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6118,  402],\n",
            "        [1652, 4868]])\n",
            "tensor([[949, 138],\n",
            "        [355, 732]])\n",
            "Epoch: 74, Train Accuracy: 0.87025, Train Loss: 0.30465, Validation Accuracy: 0.79485, Validation Loss: 0.39124, prediction: [0.901, 0.099], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6124,  396],\n",
            "        [1732, 4788]])\n",
            "tensor([[948, 139],\n",
            "        [374, 713]])\n",
            "Epoch: 75, Train Accuracy: 0.86933, Train Loss: 0.29968, Validation Accuracy: 0.79485, Validation Loss: 0.41199, prediction: [0.511, 0.489], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6115,  405],\n",
            "        [1613, 4907]])\n",
            "tensor([[952, 135],\n",
            "        [344, 743]])\n",
            "Epoch: 76, Train Accuracy: 0.87040, Train Loss: 0.29472, Validation Accuracy: 0.79669, Validation Loss: 0.40901, prediction: [0.413, 0.587], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6120,  400],\n",
            "        [1609, 4911]])\n",
            "tensor([[948, 139],\n",
            "        [354, 733]])\n",
            "Epoch: 77, Train Accuracy: 0.87408, Train Loss: 0.29273, Validation Accuracy: 0.79393, Validation Loss: 0.42103, prediction: [0.045, 0.955], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.7985280588776449\n",
            "tensor([[6105,  415],\n",
            "        [1584, 4936]])\n",
            "tensor([[945, 142],\n",
            "        [343, 744]])\n",
            "Epoch: 78, Train Accuracy: 0.86902, Train Loss: 0.30834, Validation Accuracy: 0.79485, Validation Loss: 0.40581, prediction: [0.043, 0.957], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6136,  384],\n",
            "        [1630, 4890]])\n",
            "tensor([[947, 140],\n",
            "        [361, 726]])\n",
            "Epoch: 79, Train Accuracy: 0.87623, Train Loss: 0.29400, Validation Accuracy: 0.79853, Validation Loss: 0.40963, prediction: [0.808, 0.192], true label: [1.0, 0.0]\n",
            "0.7985280588776449 0.7985280588776449\n",
            "tensor([[6129,  391],\n",
            "        [1609, 4911]])\n",
            "tensor([[948, 139],\n",
            "        [360, 727]])\n",
            "Epoch: 80, Train Accuracy: 0.87561, Train Loss: 0.29343, Validation Accuracy: 0.79669, Validation Loss: 0.40111, prediction: [0.114, 0.886], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.7985280588776449\n",
            "tensor([[6131,  389],\n",
            "        [1576, 4944]])\n",
            "tensor([[946, 141],\n",
            "        [353, 734]])\n",
            "Epoch: 81, Train Accuracy: 0.87745, Train Loss: 0.28362, Validation Accuracy: 0.79577, Validation Loss: 0.41337, prediction: [0.963, 0.037], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6127,  393],\n",
            "        [1536, 4984]])\n",
            "tensor([[948, 139],\n",
            "        [342, 745]])\n",
            "Epoch: 82, Train Accuracy: 0.87899, Train Loss: 0.29020, Validation Accuracy: 0.79577, Validation Loss: 0.40387, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6145,  375],\n",
            "        [1571, 4949]])\n",
            "tensor([[945, 142],\n",
            "        [359, 728]])\n",
            "Epoch: 83, Train Accuracy: 0.87960, Train Loss: 0.28998, Validation Accuracy: 0.79761, Validation Loss: 0.41332, prediction: [0.907, 0.093], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6151,  369],\n",
            "        [1583, 4937]])\n",
            "tensor([[943, 144],\n",
            "        [363, 724]])\n",
            "Epoch: 84, Train Accuracy: 0.88021, Train Loss: 0.28246, Validation Accuracy: 0.79761, Validation Loss: 0.42582, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6135,  385],\n",
            "        [1528, 4992]])\n",
            "tensor([[946, 141],\n",
            "        [350, 737]])\n",
            "Epoch: 85, Train Accuracy: 0.88267, Train Loss: 0.28251, Validation Accuracy: 0.79209, Validation Loss: 0.38387, prediction: [0.68, 0.32], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6154,  366],\n",
            "        [1503, 5017]])\n",
            "tensor([[943, 144],\n",
            "        [351, 736]])\n",
            "Epoch: 86, Train Accuracy: 0.88390, Train Loss: 0.28209, Validation Accuracy: 0.79485, Validation Loss: 0.37988, prediction: [0.499, 0.501], true label: [1.0, 0.0]\n",
            "0.7948482060717571 0.7985280588776449\n",
            "tensor([[6157,  363],\n",
            "        [1495, 5025]])\n",
            "tensor([[940, 147],\n",
            "        [352, 735]])\n",
            "Epoch: 87, Train Accuracy: 0.88482, Train Loss: 0.29095, Validation Accuracy: 0.79577, Validation Loss: 0.40118, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.7985280588776449\n",
            "tensor([[6164,  356],\n",
            "        [1493, 5027]])\n",
            "tensor([[940, 147],\n",
            "        [356, 731]])\n",
            "Epoch: 88, Train Accuracy: 0.88543, Train Loss: 0.27367, Validation Accuracy: 0.79761, Validation Loss: 0.41438, prediction: [0.628, 0.372], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6161,  359],\n",
            "        [1491, 5029]])\n",
            "tensor([[938, 149],\n",
            "        [354, 733]])\n",
            "Epoch: 89, Train Accuracy: 0.88512, Train Loss: 0.27836, Validation Accuracy: 0.79761, Validation Loss: 0.40085, prediction: [0.658, 0.342], true label: [1.0, 0.0]\n",
            "0.797608095676173 0.7985280588776449\n",
            "tensor([[6145,  375],\n",
            "        [1459, 5061]])\n",
            "tensor([[943, 144],\n",
            "        [346, 741]])\n",
            "Epoch: 90, Train Accuracy: 0.88589, Train Loss: 0.27893, Validation Accuracy: 0.79025, Validation Loss: 0.40607, prediction: [0.543, 0.457], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.7985280588776449\n",
            "tensor([[6168,  352],\n",
            "        [1458, 5062]])\n",
            "tensor([[940, 147],\n",
            "        [346, 741]])\n",
            "Epoch: 91, Train Accuracy: 0.88850, Train Loss: 0.27492, Validation Accuracy: 0.79209, Validation Loss: 0.40135, prediction: [0.003, 0.997], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.7985280588776449\n",
            "tensor([[6173,  347],\n",
            "        [1465, 5055]])\n",
            "tensor([[940, 147],\n",
            "        [354, 733]])\n",
            "Epoch: 92, Train Accuracy: 0.88696, Train Loss: 0.26568, Validation Accuracy: 0.80037, Validation Loss: 0.42830, prediction: [0.026, 0.974], true label: [0.0, 1.0]\n",
            "0.8003679852805887 0.7985280588776449\n",
            "best_state_dict updated\n",
            "tensor([[6183,  337],\n",
            "        [1478, 5042]])\n",
            "tensor([[937, 150],\n",
            "        [360, 727]])\n",
            "Epoch: 93, Train Accuracy: 0.88758, Train Loss: 0.26444, Validation Accuracy: 0.80221, Validation Loss: 0.39699, prediction: [0.902, 0.098], true label: [0.0, 1.0]\n",
            "0.8022079116835327 0.8003679852805887\n",
            "best_state_dict updated\n",
            "tensor([[6163,  357],\n",
            "        [1403, 5117]])\n",
            "tensor([[945, 142],\n",
            "        [341, 746]])\n",
            "Epoch: 94, Train Accuracy: 0.88742, Train Loss: 0.26088, Validation Accuracy: 0.78749, Validation Loss: 0.39705, prediction: [0.929, 0.071], true label: [1.0, 0.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6186,  334],\n",
            "        [1442, 5078]])\n",
            "tensor([[936, 151],\n",
            "        [355, 732]])\n",
            "Epoch: 95, Train Accuracy: 0.88926, Train Loss: 0.25797, Validation Accuracy: 0.80037, Validation Loss: 0.41057, prediction: [0.861, 0.139], true label: [1.0, 0.0]\n",
            "0.8003679852805887 0.8022079116835327\n",
            "tensor([[6198,  322],\n",
            "        [1423, 5097]])\n",
            "tensor([[937, 150],\n",
            "        [352, 735]])\n",
            "Epoch: 96, Train Accuracy: 0.89187, Train Loss: 0.26036, Validation Accuracy: 0.79669, Validation Loss: 0.43544, prediction: [0.805, 0.195], true label: [1.0, 0.0]\n",
            "0.796688132474701 0.8022079116835327\n",
            "tensor([[6196,  324],\n",
            "        [1397, 5123]])\n",
            "tensor([[935, 152],\n",
            "        [353, 734]])\n",
            "Epoch: 97, Train Accuracy: 0.89540, Train Loss: 0.25881, Validation Accuracy: 0.79301, Validation Loss: 0.40283, prediction: [0.065, 0.935], true label: [0.0, 1.0]\n",
            "0.7930082796688133 0.8022079116835327\n",
            "tensor([[6203,  317],\n",
            "        [1381, 5139]])\n",
            "tensor([[933, 154],\n",
            "        [347, 740]])\n",
            "Epoch: 98, Train Accuracy: 0.89540, Train Loss: 0.25258, Validation Accuracy: 0.79577, Validation Loss: 0.42740, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.8022079116835327\n",
            "tensor([[6199,  321],\n",
            "        [1363, 5157]])\n",
            "tensor([[938, 149],\n",
            "        [349, 738]])\n",
            "Epoch: 99, Train Accuracy: 0.89647, Train Loss: 0.25634, Validation Accuracy: 0.79209, Validation Loss: 0.41990, prediction: [0.038, 0.962], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6205,  315],\n",
            "        [1363, 5157]])\n",
            "tensor([[933, 154],\n",
            "        [349, 738]])\n",
            "Epoch: 100, Train Accuracy: 0.89494, Train Loss: 0.24729, Validation Accuracy: 0.80221, Validation Loss: 0.43683, prediction: [0.844, 0.156], true label: [1.0, 0.0]\n",
            "0.8022079116835327 0.8022079116835327\n",
            "tensor([[6194,  326],\n",
            "        [1316, 5204]])\n",
            "tensor([[943, 144],\n",
            "        [341, 746]])\n",
            "Epoch: 101, Train Accuracy: 0.89724, Train Loss: 0.25769, Validation Accuracy: 0.78933, Validation Loss: 0.41894, prediction: [0.903, 0.097], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6211,  309],\n",
            "        [1317, 5203]])\n",
            "tensor([[940, 147],\n",
            "        [351, 736]])\n",
            "Epoch: 102, Train Accuracy: 0.90015, Train Loss: 0.24708, Validation Accuracy: 0.79117, Validation Loss: 0.42797, prediction: [0.953, 0.047], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6217,  303],\n",
            "        [1319, 5201]])\n",
            "tensor([[935, 152],\n",
            "        [351, 736]])\n",
            "Epoch: 103, Train Accuracy: 0.89693, Train Loss: 0.23980, Validation Accuracy: 0.80037, Validation Loss: 0.44427, prediction: [0.012, 0.988], true label: [0.0, 1.0]\n",
            "0.8003679852805887 0.8022079116835327\n",
            "tensor([[6214,  306],\n",
            "        [1308, 5212]])\n",
            "tensor([[934, 153],\n",
            "        [347, 740]])\n",
            "Epoch: 104, Train Accuracy: 0.89831, Train Loss: 0.24336, Validation Accuracy: 0.80129, Validation Loss: 0.42916, prediction: [0.008, 0.992], true label: [0.0, 1.0]\n",
            "0.8012879484820608 0.8022079116835327\n",
            "tensor([[6204,  316],\n",
            "        [1267, 5253]])\n",
            "tensor([[942, 145],\n",
            "        [345, 742]])\n",
            "Epoch: 105, Train Accuracy: 0.90368, Train Loss: 0.24517, Validation Accuracy: 0.78749, Validation Loss: 0.43265, prediction: [0.885, 0.115], true label: [1.0, 0.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6229,  291],\n",
            "        [1266, 5254]])\n",
            "tensor([[936, 151],\n",
            "        [345, 742]])\n",
            "Epoch: 106, Train Accuracy: 0.90475, Train Loss: 0.23381, Validation Accuracy: 0.79117, Validation Loss: 0.45174, prediction: [0.007, 0.993], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6226,  294],\n",
            "        [1240, 5280]])\n",
            "tensor([[934, 153],\n",
            "        [344, 743]])\n",
            "Epoch: 107, Train Accuracy: 0.90521, Train Loss: 0.23776, Validation Accuracy: 0.79945, Validation Loss: 0.44132, prediction: [0.198, 0.802], true label: [0.0, 1.0]\n",
            "0.7994480220791168 0.8022079116835327\n",
            "tensor([[6204,  316],\n",
            "        [1227, 5293]])\n",
            "tensor([[939, 148],\n",
            "        [342, 745]])\n",
            "Epoch: 108, Train Accuracy: 0.90567, Train Loss: 0.25508, Validation Accuracy: 0.78841, Validation Loss: 0.46389, prediction: [0.406, 0.594], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6222,  298],\n",
            "        [1244, 5276]])\n",
            "tensor([[941, 146],\n",
            "        [348, 739]])\n",
            "Epoch: 109, Train Accuracy: 0.90736, Train Loss: 0.23959, Validation Accuracy: 0.79025, Validation Loss: 0.45221, prediction: [0.927, 0.073], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6173,  347],\n",
            "        [1229, 5291]])\n",
            "tensor([[936, 151],\n",
            "        [341, 746]])\n",
            "Epoch: 110, Train Accuracy: 0.90061, Train Loss: 0.24424, Validation Accuracy: 0.78289, Validation Loss: 0.43660, prediction: [0.93, 0.07], true label: [1.0, 0.0]\n",
            "0.7828886844526219 0.8022079116835327\n",
            "tensor([[6245,  275],\n",
            "        [1224, 5296]])\n",
            "tensor([[934, 153],\n",
            "        [340, 747]])\n",
            "Epoch: 111, Train Accuracy: 0.90767, Train Loss: 0.22977, Validation Accuracy: 0.79669, Validation Loss: 0.41368, prediction: [0.686, 0.314], true label: [1.0, 0.0]\n",
            "0.796688132474701 0.8022079116835327\n",
            "tensor([[6227,  293],\n",
            "        [1197, 5323]])\n",
            "tensor([[940, 147],\n",
            "        [346, 741]])\n",
            "Epoch: 112, Train Accuracy: 0.91074, Train Loss: 0.23717, Validation Accuracy: 0.78841, Validation Loss: 0.46418, prediction: [0.365, 0.635], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6249,  271],\n",
            "        [1192, 5328]])\n",
            "tensor([[930, 157],\n",
            "        [339, 748]])\n",
            "Epoch: 113, Train Accuracy: 0.90982, Train Loss: 0.23502, Validation Accuracy: 0.79853, Validation Loss: 0.41114, prediction: [0.935, 0.065], true label: [1.0, 0.0]\n",
            "0.7985280588776449 0.8022079116835327\n",
            "tensor([[6255,  265],\n",
            "        [1182, 5338]])\n",
            "tensor([[934, 153],\n",
            "        [335, 752]])\n",
            "Epoch: 114, Train Accuracy: 0.90936, Train Loss: 0.22198, Validation Accuracy: 0.79577, Validation Loss: 0.44428, prediction: [0.068, 0.932], true label: [0.0, 1.0]\n",
            "0.795768169273229 0.8022079116835327\n",
            "tensor([[6250,  270],\n",
            "        [1240, 5280]])\n",
            "tensor([[926, 161],\n",
            "        [342, 745]])\n",
            "Epoch: 115, Train Accuracy: 0.90660, Train Loss: 0.22351, Validation Accuracy: 0.78933, Validation Loss: 0.46834, prediction: [0.873, 0.127], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6253,  267],\n",
            "        [1138, 5382]])\n",
            "tensor([[935, 152],\n",
            "        [337, 750]])\n",
            "Epoch: 116, Train Accuracy: 0.91411, Train Loss: 0.21867, Validation Accuracy: 0.79669, Validation Loss: 0.42316, prediction: [0.033, 0.967], true label: [0.0, 1.0]\n",
            "0.796688132474701 0.8022079116835327\n",
            "tensor([[6257,  263],\n",
            "        [1170, 5350]])\n",
            "tensor([[926, 161],\n",
            "        [336, 751]])\n",
            "Epoch: 117, Train Accuracy: 0.91104, Train Loss: 0.21003, Validation Accuracy: 0.79209, Validation Loss: 0.45769, prediction: [0.015, 0.985], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6235,  285],\n",
            "        [1103, 5417]])\n",
            "tensor([[939, 148],\n",
            "        [344, 743]])\n",
            "Epoch: 118, Train Accuracy: 0.91549, Train Loss: 0.22884, Validation Accuracy: 0.78933, Validation Loss: 0.42562, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6251,  269],\n",
            "        [1098, 5422]])\n",
            "tensor([[937, 150],\n",
            "        [341, 746]])\n",
            "Epoch: 119, Train Accuracy: 0.91718, Train Loss: 0.20968, Validation Accuracy: 0.79485, Validation Loss: 0.45811, prediction: [0.007, 0.993], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.8022079116835327\n",
            "tensor([[6257,  263],\n",
            "        [1161, 5359]])\n",
            "tensor([[926, 161],\n",
            "        [332, 755]])\n",
            "Epoch: 120, Train Accuracy: 0.91212, Train Loss: 0.21379, Validation Accuracy: 0.79025, Validation Loss: 0.42718, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6272,  248],\n",
            "        [1140, 5380]])\n",
            "tensor([[926, 161],\n",
            "        [328, 759]])\n",
            "Epoch: 121, Train Accuracy: 0.91472, Train Loss: 0.20848, Validation Accuracy: 0.79117, Validation Loss: 0.44265, prediction: [0.773, 0.227], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6274,  246],\n",
            "        [1126, 5394]])\n",
            "tensor([[926, 161],\n",
            "        [326, 761]])\n",
            "Epoch: 122, Train Accuracy: 0.91350, Train Loss: 0.20656, Validation Accuracy: 0.79117, Validation Loss: 0.46602, prediction: [0.006, 0.994], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6280,  240],\n",
            "        [1110, 5410]])\n",
            "tensor([[927, 160],\n",
            "        [329, 758]])\n",
            "Epoch: 123, Train Accuracy: 0.91549, Train Loss: 0.20352, Validation Accuracy: 0.78749, Validation Loss: 0.44756, prediction: [0.46, 0.54], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6235,  285],\n",
            "        [1028, 5492]])\n",
            "tensor([[933, 154],\n",
            "        [331, 756]])\n",
            "Epoch: 124, Train Accuracy: 0.91963, Train Loss: 0.20313, Validation Accuracy: 0.79301, Validation Loss: 0.44470, prediction: [0.994, 0.006], true label: [0.0, 1.0]\n",
            "0.7930082796688133 0.8022079116835327\n",
            "tensor([[6289,  231],\n",
            "        [1069, 5451]])\n",
            "tensor([[926, 161],\n",
            "        [326, 761]])\n",
            "Epoch: 125, Train Accuracy: 0.91963, Train Loss: 0.19886, Validation Accuracy: 0.78749, Validation Loss: 0.46570, prediction: [0.157, 0.843], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6286,  234],\n",
            "        [1010, 5510]])\n",
            "tensor([[931, 156],\n",
            "        [336, 751]])\n",
            "Epoch: 126, Train Accuracy: 0.92255, Train Loss: 0.19300, Validation Accuracy: 0.79577, Validation Loss: 0.43425, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.795768169273229 0.8022079116835327\n",
            "tensor([[6299,  221],\n",
            "        [1016, 5504]])\n",
            "tensor([[931, 156],\n",
            "        [337, 750]])\n",
            "Epoch: 127, Train Accuracy: 0.92331, Train Loss: 0.19164, Validation Accuracy: 0.79301, Validation Loss: 0.45803, prediction: [0.985, 0.015], true label: [1.0, 0.0]\n",
            "0.7930082796688133 0.8022079116835327\n",
            "tensor([[6235,  285],\n",
            "        [1008, 5512]])\n",
            "tensor([[931, 156],\n",
            "        [331, 756]])\n",
            "Epoch: 128, Train Accuracy: 0.92101, Train Loss: 0.20321, Validation Accuracy: 0.79393, Validation Loss: 0.45689, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.8022079116835327\n",
            "tensor([[6299,  221],\n",
            "        [ 964, 5556]])\n",
            "tensor([[928, 159],\n",
            "        [325, 762]])\n",
            "Epoch: 129, Train Accuracy: 0.92515, Train Loss: 0.19004, Validation Accuracy: 0.79209, Validation Loss: 0.43458, prediction: [0.958, 0.042], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6279,  241],\n",
            "        [ 953, 5567]])\n",
            "tensor([[932, 155],\n",
            "        [333, 754]])\n",
            "Epoch: 130, Train Accuracy: 0.92561, Train Loss: 0.19245, Validation Accuracy: 0.79393, Validation Loss: 0.47948, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7939282428702852 0.8022079116835327\n",
            "tensor([[6290,  230],\n",
            "        [ 923, 5597]])\n",
            "tensor([[932, 155],\n",
            "        [330, 757]])\n",
            "Epoch: 131, Train Accuracy: 0.92653, Train Loss: 0.19442, Validation Accuracy: 0.78933, Validation Loss: 0.47482, prediction: [0.931, 0.069], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6304,  216],\n",
            "        [ 932, 5588]])\n",
            "tensor([[933, 154],\n",
            "        [330, 757]])\n",
            "Epoch: 132, Train Accuracy: 0.92868, Train Loss: 0.18622, Validation Accuracy: 0.79209, Validation Loss: 0.48609, prediction: [0.967, 0.033], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6307,  213],\n",
            "        [1012, 5508]])\n",
            "tensor([[919, 168],\n",
            "        [329, 758]])\n",
            "Epoch: 133, Train Accuracy: 0.92669, Train Loss: 0.18665, Validation Accuracy: 0.78749, Validation Loss: 0.49043, prediction: [0.009, 0.991], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6317,  203],\n",
            "        [ 897, 5623]])\n",
            "tensor([[930, 157],\n",
            "        [320, 767]])\n",
            "Epoch: 134, Train Accuracy: 0.93144, Train Loss: 0.17595, Validation Accuracy: 0.79209, Validation Loss: 0.46482, prediction: [0.864, 0.136], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6331,  189],\n",
            "        [ 937, 5583]])\n",
            "tensor([[928, 159],\n",
            "        [316, 771]])\n",
            "Epoch: 135, Train Accuracy: 0.93267, Train Loss: 0.17937, Validation Accuracy: 0.78841, Validation Loss: 0.46512, prediction: [0.951, 0.049], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6327,  193],\n",
            "        [ 911, 5609]])\n",
            "tensor([[926, 161],\n",
            "        [317, 770]])\n",
            "Epoch: 136, Train Accuracy: 0.93313, Train Loss: 0.17643, Validation Accuracy: 0.79117, Validation Loss: 0.47232, prediction: [0.034, 0.966], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6328,  192],\n",
            "        [ 904, 5616]])\n",
            "tensor([[926, 161],\n",
            "        [322, 765]])\n",
            "Epoch: 137, Train Accuracy: 0.93359, Train Loss: 0.18174, Validation Accuracy: 0.78473, Validation Loss: 0.46291, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7847286108555658 0.8022079116835327\n",
            "tensor([[6325,  195],\n",
            "        [ 867, 5653]])\n",
            "tensor([[928, 159],\n",
            "        [317, 770]])\n",
            "Epoch: 138, Train Accuracy: 0.93405, Train Loss: 0.16760, Validation Accuracy: 0.78841, Validation Loss: 0.47848, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6328,  192],\n",
            "        [ 840, 5680]])\n",
            "tensor([[930, 157],\n",
            "        [317, 770]])\n",
            "Epoch: 139, Train Accuracy: 0.93482, Train Loss: 0.17475, Validation Accuracy: 0.79209, Validation Loss: 0.48705, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6341,  179],\n",
            "        [ 866, 5654]])\n",
            "tensor([[925, 162],\n",
            "        [318, 769]])\n",
            "Epoch: 140, Train Accuracy: 0.93589, Train Loss: 0.17745, Validation Accuracy: 0.78841, Validation Loss: 0.47104, prediction: [0.903, 0.097], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6339,  181],\n",
            "        [ 839, 5681]])\n",
            "tensor([[924, 163],\n",
            "        [316, 771]])\n",
            "Epoch: 141, Train Accuracy: 0.93788, Train Loss: 0.16591, Validation Accuracy: 0.78841, Validation Loss: 0.49473, prediction: [0.9, 0.1], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6341,  179],\n",
            "        [ 823, 5697]])\n",
            "tensor([[924, 163],\n",
            "        [314, 773]])\n",
            "Epoch: 142, Train Accuracy: 0.93850, Train Loss: 0.16887, Validation Accuracy: 0.79025, Validation Loss: 0.46859, prediction: [0.048, 0.952], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6315,  205],\n",
            "        [ 964, 5556]])\n",
            "tensor([[910, 177],\n",
            "        [317, 770]])\n",
            "Epoch: 143, Train Accuracy: 0.92914, Train Loss: 0.18013, Validation Accuracy: 0.78013, Validation Loss: 0.57369, prediction: [0.989, 0.011], true label: [1.0, 0.0]\n",
            "0.7801287948482061 0.8022079116835327\n",
            "tensor([[6341,  179],\n",
            "        [ 796, 5724]])\n",
            "tensor([[927, 160],\n",
            "        [315, 772]])\n",
            "Epoch: 144, Train Accuracy: 0.93911, Train Loss: 0.16234, Validation Accuracy: 0.79117, Validation Loss: 0.46604, prediction: [0.968, 0.032], true label: [1.0, 0.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6343,  177],\n",
            "        [ 785, 5735]])\n",
            "tensor([[925, 162],\n",
            "        [317, 770]])\n",
            "Epoch: 145, Train Accuracy: 0.94064, Train Loss: 0.15952, Validation Accuracy: 0.79301, Validation Loss: 0.47501, prediction: [0.969, 0.031], true label: [1.0, 0.0]\n",
            "0.7930082796688133 0.8022079116835327\n",
            "tensor([[6353,  167],\n",
            "        [ 798, 5722]])\n",
            "tensor([[920, 167],\n",
            "        [320, 767]])\n",
            "Epoch: 146, Train Accuracy: 0.94294, Train Loss: 0.16044, Validation Accuracy: 0.79025, Validation Loss: 0.53505, prediction: [0.964, 0.036], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6350,  170],\n",
            "        [ 791, 5729]])\n",
            "tensor([[924, 163],\n",
            "        [315, 772]])\n",
            "Epoch: 147, Train Accuracy: 0.94126, Train Loss: 0.15435, Validation Accuracy: 0.78933, Validation Loss: 0.46999, prediction: [0.909, 0.091], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6354,  166],\n",
            "        [ 830, 5690]])\n",
            "tensor([[916, 171],\n",
            "        [314, 773]])\n",
            "Epoch: 148, Train Accuracy: 0.94126, Train Loss: 0.15625, Validation Accuracy: 0.78473, Validation Loss: 0.53977, prediction: [0.005, 0.995], true label: [0.0, 1.0]\n",
            "0.7847286108555658 0.8022079116835327\n",
            "tensor([[6334,  186],\n",
            "        [ 751, 5769]])\n",
            "tensor([[924, 163],\n",
            "        [311, 776]])\n",
            "Epoch: 149, Train Accuracy: 0.94156, Train Loss: 0.15926, Validation Accuracy: 0.79761, Validation Loss: 0.49074, prediction: [0.01, 0.99], true label: [0.0, 1.0]\n",
            "0.797608095676173 0.8022079116835327\n",
            "tensor([[6357,  163],\n",
            "        [ 750, 5770]])\n",
            "tensor([[928, 159],\n",
            "        [319, 768]])\n",
            "Epoch: 150, Train Accuracy: 0.94479, Train Loss: 0.15679, Validation Accuracy: 0.79117, Validation Loss: 0.50720, prediction: [0.011, 0.989], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6363,  157],\n",
            "        [ 802, 5718]])\n",
            "tensor([[917, 170],\n",
            "        [311, 776]])\n",
            "Epoch: 151, Train Accuracy: 0.94141, Train Loss: 0.15191, Validation Accuracy: 0.78749, Validation Loss: 0.58362, prediction: [0.12, 0.88], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6365,  155],\n",
            "        [ 744, 5776]])\n",
            "tensor([[925, 162],\n",
            "        [309, 778]])\n",
            "Epoch: 152, Train Accuracy: 0.94448, Train Loss: 0.14970, Validation Accuracy: 0.78841, Validation Loss: 0.52403, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6370,  150],\n",
            "        [ 719, 5801]])\n",
            "tensor([[923, 164],\n",
            "        [310, 777]])\n",
            "Epoch: 153, Train Accuracy: 0.94647, Train Loss: 0.14631, Validation Accuracy: 0.78841, Validation Loss: 0.52206, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6357,  163],\n",
            "        [ 743, 5777]])\n",
            "tensor([[924, 163],\n",
            "        [310, 777]])\n",
            "Epoch: 154, Train Accuracy: 0.94479, Train Loss: 0.15442, Validation Accuracy: 0.79485, Validation Loss: 0.54493, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.8022079116835327\n",
            "tensor([[6375,  145],\n",
            "        [ 739, 5781]])\n",
            "tensor([[920, 167],\n",
            "        [316, 771]])\n",
            "Epoch: 155, Train Accuracy: 0.94739, Train Loss: 0.14662, Validation Accuracy: 0.78381, Validation Loss: 0.52920, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7838086476540939 0.8022079116835327\n",
            "tensor([[6325,  195],\n",
            "        [ 738, 5782]])\n",
            "tensor([[922, 165],\n",
            "        [306, 781]])\n",
            "Epoch: 156, Train Accuracy: 0.93988, Train Loss: 0.15038, Validation Accuracy: 0.80129, Validation Loss: 0.53498, prediction: [0.988, 0.012], true label: [1.0, 0.0]\n",
            "0.8012879484820608 0.8022079116835327\n",
            "tensor([[6361,  159],\n",
            "        [ 711, 5809]])\n",
            "tensor([[928, 159],\n",
            "        [307, 780]])\n",
            "Epoch: 157, Train Accuracy: 0.94617, Train Loss: 0.14500, Validation Accuracy: 0.79485, Validation Loss: 0.48044, prediction: [0.004, 0.996], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.8022079116835327\n",
            "tensor([[6374,  146],\n",
            "        [ 696, 5824]])\n",
            "tensor([[922, 165],\n",
            "        [316, 771]])\n",
            "Epoch: 158, Train Accuracy: 0.95000, Train Loss: 0.13931, Validation Accuracy: 0.78657, Validation Loss: 0.50777, prediction: [0.629, 0.371], true label: [1.0, 0.0]\n",
            "0.7865685372585096 0.8022079116835327\n",
            "tensor([[6366,  154],\n",
            "        [ 799, 5721]])\n",
            "tensor([[909, 178],\n",
            "        [316, 771]])\n",
            "Epoch: 159, Train Accuracy: 0.94264, Train Loss: 0.14651, Validation Accuracy: 0.78105, Validation Loss: 0.63064, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.781048758049678 0.8022079116835327\n",
            "tensor([[6384,  136],\n",
            "        [ 721, 5799]])\n",
            "tensor([[912, 175],\n",
            "        [310, 777]])\n",
            "Epoch: 160, Train Accuracy: 0.94969, Train Loss: 0.13707, Validation Accuracy: 0.78197, Validation Loss: 0.57194, prediction: [0.992, 0.008], true label: [1.0, 0.0]\n",
            "0.7819687212511499 0.8022079116835327\n",
            "tensor([[6345,  175],\n",
            "        [ 848, 5672]])\n",
            "tensor([[900, 187],\n",
            "        [321, 766]])\n",
            "Epoch: 161, Train Accuracy: 0.94279, Train Loss: 0.14991, Validation Accuracy: 0.77461, Validation Loss: 0.57491, prediction: [0.986, 0.014], true label: [1.0, 0.0]\n",
            "0.7746090156393745 0.8022079116835327\n",
            "tensor([[6375,  145],\n",
            "        [ 666, 5854]])\n",
            "tensor([[913, 174],\n",
            "        [305, 782]])\n",
            "Epoch: 162, Train Accuracy: 0.94831, Train Loss: 0.13548, Validation Accuracy: 0.78657, Validation Loss: 0.54285, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7865685372585096 0.8022079116835327\n",
            "tensor([[6388,  132],\n",
            "        [ 652, 5868]])\n",
            "tensor([[916, 171],\n",
            "        [308, 779]])\n",
            "Epoch: 163, Train Accuracy: 0.95291, Train Loss: 0.13202, Validation Accuracy: 0.78473, Validation Loss: 0.56643, prediction: [0.982, 0.018], true label: [1.0, 0.0]\n",
            "0.7847286108555658 0.8022079116835327\n",
            "tensor([[6388,  132],\n",
            "        [ 709, 5811]])\n",
            "tensor([[910, 177],\n",
            "        [313, 774]])\n",
            "Epoch: 164, Train Accuracy: 0.95046, Train Loss: 0.13645, Validation Accuracy: 0.78197, Validation Loss: 0.61150, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7819687212511499 0.8022079116835327\n",
            "tensor([[6346,  174],\n",
            "        [ 701, 5819]])\n",
            "tensor([[926, 161],\n",
            "        [300, 787]])\n",
            "Epoch: 165, Train Accuracy: 0.94448, Train Loss: 0.14434, Validation Accuracy: 0.79853, Validation Loss: 0.53184, prediction: [0.988, 0.012], true label: [1.0, 0.0]\n",
            "0.7985280588776449 0.8022079116835327\n",
            "tensor([[6320,  200],\n",
            "        [ 744, 5776]])\n",
            "tensor([[923, 164],\n",
            "        [296, 791]])\n",
            "Epoch: 166, Train Accuracy: 0.93773, Train Loss: 0.16248, Validation Accuracy: 0.79485, Validation Loss: 0.53997, prediction: [0.366, 0.634], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.8022079116835327\n",
            "tensor([[6368,  152],\n",
            "        [ 765, 5755]])\n",
            "tensor([[905, 182],\n",
            "        [315, 772]])\n",
            "Epoch: 167, Train Accuracy: 0.94525, Train Loss: 0.14536, Validation Accuracy: 0.78105, Validation Loss: 0.63736, prediction: [0.851, 0.149], true label: [1.0, 0.0]\n",
            "0.781048758049678 0.8022079116835327\n",
            "tensor([[6383,  137],\n",
            "        [ 628, 5892]])\n",
            "tensor([[914, 173],\n",
            "        [308, 779]])\n",
            "Epoch: 168, Train Accuracy: 0.95230, Train Loss: 0.13003, Validation Accuracy: 0.78749, Validation Loss: 0.53070, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6369,  151],\n",
            "        [ 715, 5805]])\n",
            "tensor([[904, 183],\n",
            "        [312, 775]])\n",
            "Epoch: 169, Train Accuracy: 0.95061, Train Loss: 0.13746, Validation Accuracy: 0.78013, Validation Loss: 0.66472, prediction: [0.964, 0.036], true label: [1.0, 0.0]\n",
            "0.7801287948482061 0.8022079116835327\n",
            "tensor([[6393,  127],\n",
            "        [ 602, 5918]])\n",
            "tensor([[913, 174],\n",
            "        [305, 782]])\n",
            "Epoch: 170, Train Accuracy: 0.95460, Train Loss: 0.12924, Validation Accuracy: 0.78657, Validation Loss: 0.58756, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.7865685372585096 0.8022079116835327\n",
            "tensor([[6389,  131],\n",
            "        [ 630, 5890]])\n",
            "tensor([[907, 180],\n",
            "        [303, 784]])\n",
            "Epoch: 171, Train Accuracy: 0.95675, Train Loss: 0.12900, Validation Accuracy: 0.78657, Validation Loss: 0.62970, prediction: [0.002, 0.998], true label: [0.0, 1.0]\n",
            "0.7865685372585096 0.8022079116835327\n",
            "tensor([[6394,  126],\n",
            "        [ 601, 5919]])\n",
            "tensor([[911, 176],\n",
            "        [303, 784]])\n",
            "Epoch: 172, Train Accuracy: 0.95598, Train Loss: 0.12178, Validation Accuracy: 0.78933, Validation Loss: 0.57607, prediction: [0.984, 0.016], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6402,  118],\n",
            "        [ 587, 5933]])\n",
            "tensor([[908, 179],\n",
            "        [306, 781]])\n",
            "Epoch: 173, Train Accuracy: 0.95736, Train Loss: 0.11971, Validation Accuracy: 0.78841, Validation Loss: 0.61116, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6402,  118],\n",
            "        [ 622, 5898]])\n",
            "tensor([[905, 182],\n",
            "        [304, 783]])\n",
            "Epoch: 174, Train Accuracy: 0.95752, Train Loss: 0.12245, Validation Accuracy: 0.78289, Validation Loss: 0.63666, prediction: [0.977, 0.023], true label: [1.0, 0.0]\n",
            "0.7828886844526219 0.8022079116835327\n",
            "tensor([[6372,  148],\n",
            "        [ 636, 5884]])\n",
            "tensor([[921, 166],\n",
            "        [293, 794]])\n",
            "Epoch: 175, Train Accuracy: 0.94770, Train Loss: 0.13214, Validation Accuracy: 0.79485, Validation Loss: 0.52441, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7948482060717571 0.8022079116835327\n",
            "tensor([[6405,  115],\n",
            "        [ 569, 5951]])\n",
            "tensor([[908, 179],\n",
            "        [307, 780]])\n",
            "Epoch: 176, Train Accuracy: 0.96028, Train Loss: 0.11622, Validation Accuracy: 0.78749, Validation Loss: 0.60794, prediction: [0.037, 0.963], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6406,  114],\n",
            "        [ 556, 5964]])\n",
            "tensor([[909, 178],\n",
            "        [309, 778]])\n",
            "Epoch: 177, Train Accuracy: 0.96028, Train Loss: 0.11782, Validation Accuracy: 0.78933, Validation Loss: 0.62446, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6404,  116],\n",
            "        [ 550, 5970]])\n",
            "tensor([[906, 181],\n",
            "        [303, 784]])\n",
            "Epoch: 178, Train Accuracy: 0.96150, Train Loss: 0.11040, Validation Accuracy: 0.79209, Validation Loss: 0.66872, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6409,  111],\n",
            "        [ 541, 5979]])\n",
            "tensor([[908, 179],\n",
            "        [301, 786]])\n",
            "Epoch: 179, Train Accuracy: 0.96212, Train Loss: 0.12045, Validation Accuracy: 0.79117, Validation Loss: 0.65662, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6398,  122],\n",
            "        [ 529, 5991]])\n",
            "tensor([[904, 183],\n",
            "        [299, 788]])\n",
            "Epoch: 180, Train Accuracy: 0.96258, Train Loss: 0.11799, Validation Accuracy: 0.79117, Validation Loss: 0.64700, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7911683532658693 0.8022079116835327\n",
            "tensor([[6405,  115],\n",
            "        [ 521, 5999]])\n",
            "tensor([[903, 184],\n",
            "        [301, 786]])\n",
            "Epoch: 181, Train Accuracy: 0.96350, Train Loss: 0.11287, Validation Accuracy: 0.79025, Validation Loss: 0.65604, prediction: [0.997, 0.003], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6393,  127],\n",
            "        [ 621, 5899]])\n",
            "tensor([[904, 183],\n",
            "        [298, 789]])\n",
            "Epoch: 182, Train Accuracy: 0.95890, Train Loss: 0.11646, Validation Accuracy: 0.78565, Validation Loss: 0.66690, prediction: [0.994, 0.006], true label: [0.0, 1.0]\n",
            "0.7856485740570377 0.8022079116835327\n",
            "tensor([[6408,  112],\n",
            "        [ 516, 6004]])\n",
            "tensor([[912, 175],\n",
            "        [297, 790]])\n",
            "Epoch: 183, Train Accuracy: 0.96319, Train Loss: 0.11309, Validation Accuracy: 0.79393, Validation Loss: 0.65113, prediction: [0.966, 0.034], true label: [1.0, 0.0]\n",
            "0.7939282428702852 0.8022079116835327\n",
            "tensor([[6406,  114],\n",
            "        [ 517, 6003]])\n",
            "tensor([[906, 181],\n",
            "        [299, 788]])\n",
            "Epoch: 184, Train Accuracy: 0.96426, Train Loss: 0.11157, Validation Accuracy: 0.79301, Validation Loss: 0.66288, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7930082796688133 0.8022079116835327\n",
            "tensor([[6328,  192],\n",
            "        [ 827, 5693]])\n",
            "tensor([[886, 201],\n",
            "        [318, 769]])\n",
            "Epoch: 185, Train Accuracy: 0.93359, Train Loss: 0.15272, Validation Accuracy: 0.77093, Validation Loss: 0.78931, prediction: [0.018, 0.982], true label: [0.0, 1.0]\n",
            "0.7709291628334867 0.8022079116835327\n",
            "tensor([[6412,  108],\n",
            "        [ 530, 5990]])\n",
            "tensor([[900, 187],\n",
            "        [295, 792]])\n",
            "Epoch: 186, Train Accuracy: 0.96442, Train Loss: 0.10550, Validation Accuracy: 0.78749, Validation Loss: 0.65117, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7874885004599816 0.8022079116835327\n",
            "tensor([[6413,  107],\n",
            "        [ 507, 6013]])\n",
            "tensor([[911, 176],\n",
            "        [298, 789]])\n",
            "Epoch: 187, Train Accuracy: 0.96580, Train Loss: 0.10568, Validation Accuracy: 0.78841, Validation Loss: 0.68456, prediction: [0.988, 0.012], true label: [1.0, 0.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6408,  112],\n",
            "        [ 568, 5952]])\n",
            "tensor([[897, 190],\n",
            "        [295, 792]])\n",
            "Epoch: 188, Train Accuracy: 0.96043, Train Loss: 0.11192, Validation Accuracy: 0.78565, Validation Loss: 0.71485, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.7856485740570377 0.8022079116835327\n",
            "tensor([[6408,  112],\n",
            "        [ 487, 6033]])\n",
            "tensor([[908, 179],\n",
            "        [298, 789]])\n",
            "Epoch: 189, Train Accuracy: 0.96442, Train Loss: 0.10716, Validation Accuracy: 0.78841, Validation Loss: 0.67172, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7884084636614536 0.8022079116835327\n",
            "tensor([[6414,  106],\n",
            "        [ 494, 6026]])\n",
            "tensor([[901, 186],\n",
            "        [294, 793]])\n",
            "Epoch: 190, Train Accuracy: 0.96518, Train Loss: 0.09959, Validation Accuracy: 0.79209, Validation Loss: 0.69604, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6413,  107],\n",
            "        [ 515, 6005]])\n",
            "tensor([[914, 173],\n",
            "        [301, 786]])\n",
            "Epoch: 191, Train Accuracy: 0.96411, Train Loss: 0.10629, Validation Accuracy: 0.79025, Validation Loss: 0.59959, prediction: [0.981, 0.019], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6412,  108],\n",
            "        [ 474, 6046]])\n",
            "tensor([[912, 175],\n",
            "        [295, 792]])\n",
            "Epoch: 192, Train Accuracy: 0.96641, Train Loss: 0.09751, Validation Accuracy: 0.78933, Validation Loss: 0.64196, prediction: [0.961, 0.039], true label: [1.0, 0.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6418,  102],\n",
            "        [ 457, 6063]])\n",
            "tensor([[904, 183],\n",
            "        [297, 790]])\n",
            "Epoch: 193, Train Accuracy: 0.96702, Train Loss: 0.09897, Validation Accuracy: 0.78933, Validation Loss: 0.71969, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7893284268629255 0.8022079116835327\n",
            "tensor([[6421,   99],\n",
            "        [ 475, 6045]])\n",
            "tensor([[913, 174],\n",
            "        [298, 789]])\n",
            "Epoch: 194, Train Accuracy: 0.96626, Train Loss: 0.10453, Validation Accuracy: 0.79209, Validation Loss: 0.65234, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7920883164673413 0.8022079116835327\n",
            "tensor([[6414,  106],\n",
            "        [ 430, 6090]])\n",
            "tensor([[905, 182],\n",
            "        [289, 798]])\n",
            "Epoch: 195, Train Accuracy: 0.96748, Train Loss: 0.09947, Validation Accuracy: 0.78473, Validation Loss: 0.72569, prediction: [0.993, 0.007], true label: [1.0, 0.0]\n",
            "0.7847286108555658 0.8022079116835327\n",
            "tensor([[6423,   97],\n",
            "        [ 451, 6069]])\n",
            "tensor([[902, 185],\n",
            "        [292, 795]])\n",
            "Epoch: 196, Train Accuracy: 0.96733, Train Loss: 0.09247, Validation Accuracy: 0.79025, Validation Loss: 0.72614, prediction: [0.995, 0.005], true label: [1.0, 0.0]\n",
            "0.7902483900643974 0.8022079116835327\n",
            "tensor([[6423,   97],\n",
            "        [ 439, 6081]])\n",
            "tensor([[908, 179],\n",
            "        [290, 797]])\n",
            "Epoch: 197, Train Accuracy: 0.96887, Train Loss: 0.09624, Validation Accuracy: 0.78657, Validation Loss: 0.65828, prediction: [0.001, 0.999], true label: [0.0, 1.0]\n",
            "0.7865685372585096 0.8022079116835327\n",
            "tensor([[6391,  129],\n",
            "        [ 538, 5982]])\n",
            "tensor([[916, 171],\n",
            "        [290, 797]])\n",
            "Epoch: 198, Train Accuracy: 0.95813, Train Loss: 0.11166, Validation Accuracy: 0.79945, Validation Loss: 0.66673, prediction: [0.996, 0.004], true label: [1.0, 0.0]\n",
            "0.7994480220791168 0.8022079116835327\n",
            "tensor([[6421,   99],\n",
            "        [ 434, 6086]])\n",
            "tensor([[911, 176],\n",
            "        [290, 797]])\n",
            "Epoch: 199, Train Accuracy: 0.96810, Train Loss: 0.09442, Validation Accuracy: 0.79025, Validation Loss: 0.68664, prediction: [0.0, 1.0], true label: [0.0, 1.0]\n",
            "0.7902483900643974 0.8022079116835327\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network17.load_state_dict(best17)\n",
        "q = get_accuracy(network17, test_load2, nn.CrossEntropyLoss())\n",
        "print(q[0], q[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fExfS5PaXwoH",
        "outputId": "c4d9a5d7-6eb4-4c04-a69c-69ca9e7d9e52"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 0/??\t\r 1/??\t\r 2/??\t\r 3/??\t\r 4/??\t\r 5/??\t\r 6/??\t\r 7/??\t\r 8/??\t\r 9/??\t\r 10/??\t\r 11/??\t\r 12/??\t\r 13/??\t\r 14/??\t\r 15/??\t\r 16/??\t\r 17/??\t\r 18/??\t\r 19/??\t\r 20/??\t\r 21/??\t\r 22/??\t\r 23/??\t\r 24/??\t\r 25/??\t\r 26/??\t\r 27/??\t\r 28/??\t\r 29/??\t\r 30/??\t\r 31/??\t\r 32/??\t\r 33/??\t\r 34/??\t\r 35/??\t\r 36/??\t\r                                                     \rtensor([[990,  97],\n",
            "        [397, 690]])\n",
            "0.7985280588776449 0.4674076000228524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q[2]"
      ],
      "metadata": {
        "id": "SAB8nDVzVkhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWNhnhzleVKd"
      },
      "source": [
        "# IGNORE ALL CODE BELOW THIS POINT\n",
        "To Tune the network run the tune_network function. The function takes in all of the hyperparameters available for tuning which have been implemented. Vary the values and note any models with high validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9AW6gaz-xqc",
        "outputId": "34e75a02-2b34-4a0c-ce3c-62718deebd8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 913/??\t|||||||||\n",
            " 304/??\t|||\n",
            "Epoch: 0, Train Accuracy: 0.57202, Train Loss: 0.68293, Validation Accuracy: 0.56570, Validation Loss: 0.68778, prediction: [0.595, 0.405], true label: [1.0, 0.0]\n",
            " 913/??\t|||||||||\n",
            " 304/??\t|||\n",
            "Epoch: 1, Train Accuracy: 0.57202, Train Loss: 0.68189, Validation Accuracy: 0.56570, Validation Loss: 0.68601, prediction: [0.554, 0.446], true label: [1.0, 0.0]\n",
            " 913/??\t|||||||||\n",
            " 304/??\t|||\n",
            "Epoch: 2, Train Accuracy: 0.57202, Train Loss: 0.67303, Validation Accuracy: 0.56570, Validation Loss: 0.68359, prediction: [0.547, 0.453], true label: [1.0, 0.0]\n",
            " 913/??\t|||||||||\n",
            " 304/??\t|||\n",
            "Epoch: 3, Train Accuracy: 0.67250, Train Loss: 0.61398, Validation Accuracy: 0.62681, Validation Loss: 0.65184, prediction: [0.583, 0.417], true label: [0.0, 1.0]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "([0.5720227670753065,\n",
              "  0.5720227670753065,\n",
              "  0.5720227670753065,\n",
              "  0.6725043782837128],\n",
              " [0.6829329426160647,\n",
              "  0.6818892047021371,\n",
              "  0.6730256313692701,\n",
              "  0.6139797669022394],\n",
              " [0.5657030223390276,\n",
              "  0.5657030223390276,\n",
              "  0.5657030223390276,\n",
              "  0.6268068331143233],\n",
              " [0.6877802771173025,\n",
              "  0.686014464419139,\n",
              "  0.6835889861379799,\n",
              "  0.6518410842277502],\n",
              " [0, 1, 2, 3])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.random.manual_seed(0)\n",
        "#ratio_net = RatioNet2(input_size=len(tokenised_data.vocab), batch_size=5, device=device)\n",
        "ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=5, device=device, embedding_size=200, hidden_size=200, lstm_input_size=300)\n",
        "#ratio_net =  SpamRNN(input_size=len(tokenised_data.vocab), hidden_size=200, device=device)\n",
        "#ratio_net =  SpamRNN(input_size=len(tokenised_data.vocab), hidden_size=200, device=device)\n",
        "#ratio_net = no_conv_RatioNet(input_size=len(tokenised_data.vocab), batch_size=5, device=device)\n",
        "train_net(ratio_net.to(device), [train_loader,val_loader,test_loader], epochs=4, device=device)\n",
        "#train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=500 , learning_rate=0.001, adam=True)\n",
        "#train_network(ratio_net.to(device), train_loader, val_loader, num_epochs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UGV_kmNyM8i",
        "outputId": "a904b378-d8e7-4ba2-d5ed-04a70a714145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 0.5657030223390276\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5657030223390276, 0.6818610225853167)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_accuracy(ratio_net, val_loader, nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn59WDzVVquX"
      },
      "outputs": [],
      "source": [
        "class TweetRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(TweetRNN, self).__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        print(x.shape)\n",
        "        x = self.emb(x)\n",
        "        print(x.shape)\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt1uzfs2Xifp"
      },
      "outputs": [],
      "source": [
        "def get_tweet_vectors(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        tweet = line[-1]\n",
        "        if i % 59 == 0:\n",
        "            # obtain an embedding for the entire tweet\n",
        "            tweet_emb = sum(glove_vector[w] for w in split_tweet(tweet))\n",
        "            # generate a label: 1 = happy, 0 = sad\n",
        "            label = torch.tensor(int(line[0] == \"4\")).long()\n",
        "            # place the data set in either the training, validation, or test set\n",
        "            if i % 5 < 3:\n",
        "                train.append((tweet_emb, label)) # 60% training\n",
        "            elif i % 5 == 4:\n",
        "                valid.append((tweet_emb, label)) # 20% validation\n",
        "            else:\n",
        "                test.append((tweet_emb, label)) # 20% test\n",
        "    return train, valid, test\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
        "\n",
        "train, valid, test = get_tweet_vectors(glove)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "_VoXCSyVYfzO",
        "outputId": "ef6f1ab0-822d-4fe4-8ec6-b47fb57eda21"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-800ec952ff16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m dataset = torchtext.data.TabularDataset(\"SMSSpamCollection\", # name of the file\n\u001b[1;32m     14\u001b[0m                                         \u001b[0;34m\"tsv\"\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# fields are separated by a tab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                         fields)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#split dateset into 60-20-20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, format, fields, skip_header, csv_reader_params, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             'tsv': Example.fromCSV, 'csv': Example.fromCSV}[format]\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municode_csv_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcsv_reader_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SMSSpamCollection'"
          ]
        }
      ],
      "source": [
        "text_field = torchtext.data.Field(sequential=True,      # text sequence\n",
        "                                  tokenize=lambda x: x,        # because are building a character-RNN\n",
        "                                  include_lengths=True,        # to track the length of sequences, for batching\n",
        "                                  batch_first=True,\n",
        "                                  use_vocab=True)              # to turn each character into an integer index\n",
        "label_field = torchtext.data.Field(sequential=False,    # not a sequence\n",
        "                                   use_vocab=False,            # don't need to track vocabulary\n",
        "                                   is_target=True,      \n",
        "                                   batch_first=True,\n",
        "                                   preprocessing=lambda x: int(x == 'spam')) # convert text to 0 and 1\n",
        "\n",
        "fields = [('label', label_field), ('sms', text_field)]\n",
        "dataset = torchtext.data.TabularDataset(\"SMSSpamCollection\", # name of the file\n",
        "                                        \"tsv\",                      # fields are separated by a tab\n",
        "                                        fields)\n",
        "\n",
        "train, valid, test = dataset.split(split_ratio=[0.6, 0.2, 0.2], random_state=random.seed(0)) #split dateset into 60-20-20\n",
        "                                                                                             # chunks\n",
        "old_train_examples = train.examples\n",
        "# get all the spam messages in `train`\n",
        "train_spam = []\n",
        "for item in train.examples:\n",
        "    if item.label == 1:\n",
        "        train_spam.append(item)\n",
        "# duplicate each spam message 6 more times\n",
        "train.examples = old_train_examples + train_spam * 6\n",
        "\n",
        "# an unbalanced dataset may lead to the model learning to always predict the\n",
        "# most common of the 2 classes, in this case non-spam comments, and still\n",
        "# getting a good accuracy/low loss. But this doesnt actually teach the model\n",
        "# what the difference between a spam or a non-spam comment is. In other words,\n",
        "# an unbalanced set with much less spam data will lead to large false negative\n",
        "# rate likely close to 100%.\n",
        "text_field.build_vocab(train)\n",
        "\n",
        "train_iter = torchtext.data.BucketIterator(train,\n",
        "                                           batch_size=5,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "valid_iter = torchtext.data.BucketIterator(valid,\n",
        "                                           batch_size=5,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "test_iter  = torchtext.data.BucketIterator(test,\n",
        "                                           batch_size=5,\n",
        "                                           sort_key=lambda x: len(x.sms), # to minimize padding\n",
        "                                           sort_within_batch=True,        # sort within each batch\n",
        "                                           repeat=False)                  # repeat the iterator for many epochs\n",
        "# save the original training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxFnYaQxYgld"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2rZUTunqk6w"
      },
      "outputs": [],
      "source": [
        "#ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10)\n",
        "ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10, device=device, embedding_size=200,num_layers=4, hidden_size=200, lstm_input_size=500)\n",
        "\n",
        "train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=500 , learning_rate=0.001, adam=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ki32v8-q5wJ"
      },
      "outputs": [],
      "source": [
        "#ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10)\n",
        "ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10, device=device, embedding_size=50,num_layers=1, hidden_size=50, lstm_input_size=500)\n",
        "\n",
        "train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=200 , learning_rate=10, adam=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YewFiEBumqq"
      },
      "outputs": [],
      "source": [
        "#ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10)\n",
        "ratio_net = no_conv_RatioNet(input_size=len(tokenised_data.vocab), batch_size=10, device=device, embedding_size=50,num_layers=1, hidden_size=50, lstm_input_size=50)\n",
        "\n",
        "train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=200 , learning_rate=0.01, adam=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GvTVCbMweza"
      },
      "outputs": [],
      "source": [
        "#ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10)\n",
        "ratio_net = no_lstm_RatioNet(input_size=len(tokenised_data.vocab), batch_size=10, device=device, embedding_size=50,num_layers=1, hidden_size=50, lstm_input_size=50)\n",
        "\n",
        "train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=200 , learning_rate=0.01, adam=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoJHVohb_KyT"
      },
      "outputs": [],
      "source": [
        "#ratio_net = RatioNet(input_size=len(tokenised_data.vocab), batch_size=10)\n",
        "ratio_net = RatioNet2(input_size=len(tokenised_data.vocab), batch_size=10, device=device, embedding_size=50,num_layers=1, hidden_size=50, lstm_input_size=50)\n",
        "\n",
        "train_net(ratio_net, sanity_loader, device=device, sanity_check=True, epochs=200 , learning_rate=0.000000001, adam=True, weight_decay=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sD5_iGFxK2t",
        "outputId": "5b121095-b67a-4446-a97c-ebe3b03925fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1EFGmsoEPtJ"
      },
      "outputs": [],
      "source": [
        "_onehot_tweets = torch.eye(len(tokenised_data.vocab))\n",
        "onehot_labels = torch.eye(2)\n",
        "\n",
        "def train_network(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-5):\n",
        "    #criterion = nn.CrossEntropyLoss()\n",
        "    #criterion = nn.HuberLoss()\n",
        "    #criterion = nn.L1Loss()\n",
        "    #criterion = nn.BCEWithLogitsLoss()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    losses, train_acc, valid_acc = [], [], []\n",
        "    epochs = []\n",
        "    train_acc = []\n",
        "    valid_acc = []\n",
        "    for epoch in range(num_epochs):\n",
        "        loss_sum = 0\n",
        "        total = 0\n",
        "        for tweets, labels in train_loader:\n",
        "            #print(tweets.shape)\n",
        "            #print(labels.shape)\n",
        "            tweets, labels = tweets.type(torch.LongTensor).to(device), onehot_labels[labels.type(torch.LongTensor)].to(device)   # onehot_tweets[tweets.type(torch.LongTensor)].to(device)\n",
        "            #print(tweets.shape)\n",
        "            #print(labels.shape)            #print(tweets.shape)\n",
        "            #tweets = tweets.to(device)\n",
        "            #labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            #if epoch == 4:\n",
        "            #  print(tweets.shape)\n",
        "            pred = model(tweets)\n",
        "            loss = criterion(pred, labels) #torch.sqrt(criterion(pred, labels))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += float(loss)\n",
        "            total += 1\n",
        "        train_acc.append(get_accuracy(model, train_loader, criterion)[0])\n",
        "        valid_acc.append(get_accuracy(model, valid_loader, criterion)[0])\n",
        "        epochs.append(epoch)\n",
        "        losses.append(loss_sum/total)     \n",
        "        print(f\"Epoch: {epoch}, Train Loss: {loss_sum/total}, Train Acc: {train_acc[epoch]} Validation Loss: [not yet available], prediction: {F.softmax(pred[-1])}, true ratio: {labels[-1]}\")\n",
        "    print(len(train_acc))\n",
        "              #if epoch % 5 == 4:\n",
        "        #    epochs.append(epoch)\n",
        "\n",
        "        #    print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "         #       epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "        #print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "        #       epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "        #print(f\"Epoch: {epoch}, Train Loss: {loss}, Validation Loss: [not yet available], prediction: {pred[-1]}, true ratio: {labels[-1]}\")\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "# def get_accuracy(model, data_loader):\n",
        "#     correct, total = 0, 0\n",
        "#     for tweets, labels in data_loader:\n",
        "#         output = model(tweets)\n",
        "#         pred = output.max(1, keepdim=True)[1]\n",
        "#         correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "#         total += labels.shape[0]\n",
        "\n",
        "#     return correct / total"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kJniJ07JgPKz",
        "aWNhnhzleVKd"
      ],
      "name": "Demonstration of model",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}